{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN\n",
    "\n",
    "1. Load libraries\n",
    "2. MNIST dataset download \n",
    "3. Random sample $z$ from normal distribution\n",
    "4. Generative model $G$\n",
    "5. Disciminative model $D$\n",
    "6. Train model $G$ and $D$\n",
    "   1. Initialize model \\\\(G\\\\) and \\\\(D\\\\)\n",
    "   2. Loss functions & Optimizers\n",
    "   3. Train models\n",
    "   4. Save model weights\n",
    "7. Visualization (Interpolation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.utils as utils\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy: 1.16.0\n",
      "pandas: 0.25.3\n",
      "matlotlib: 3.0.3\n",
      "torch: 1.5.1\n",
      "torchvision: 0.6.1\n"
     ]
    }
   ],
   "source": [
    "print('numpy: ' + np.__version__)\n",
    "print('pandas: ' + pd.__version__)\n",
    "print('matlotlib: ' + matplotlib.__version__)\n",
    "print('torch: ' + torch.__version__)\n",
    "print('torchvision: ' + torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if is_cuda else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MNIST dataset download \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizer\n",
    "standardizer = transforms.Compose([\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=0,\n",
    "                                                        std=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "train_data = dsets.MNIST(root='../data/', train=True, transform=standardizer, download=True)\n",
    "test_data = dsets.MNIST(root='../data/', train=False, transform=standardizer, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size, shuffle=True)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x360 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize\n",
    "mini_batch_img, mini_batch_lbl = next(iter(train_data_loader))\n",
    "\n",
    "plt.figure(figsize=(4,5))\n",
    "for i in range(16):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plt.imshow(mini_batch_img[i].squeeze(), cmap='gray')\n",
    "    plt.title(mini_batch_lbl[i].numpy())\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.savefig('../result/GAN/1-GAN/1-dataloader-example.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📌 **NOTE**  \n",
    ">  \n",
    "> MNIST 이미지를 문제없이 다운로드했다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random sample $z$ from normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_noise = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random sampling from normal distribution\n",
    "def random_sample_z_space(batch_size=1, dim_noise=100):\n",
    "    return torch.randn(batch_size, dim_noise, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z\t:torch.Size([64, 100])\n",
      "tensor([[-0.3182, -1.7208,  0.5103,  ..., -0.8757, -0.3125,  0.3312],\n",
      "        [ 0.4950, -1.2124, -0.9291,  ..., -0.4321, -0.5056,  1.8559],\n",
      "        [-1.7881, -0.2417,  1.8614,  ..., -0.1981,  0.4994, -0.4451],\n",
      "        ...,\n",
      "        [ 1.2351,  0.0241, -0.8569,  ...,  0.5661, -0.6482,  0.6429],\n",
      "        [-0.2499, -0.9189, -1.5429,  ...,  0.3856, -1.7420, -0.6433],\n",
      "        [ 1.6969,  0.4347, -1.6991,  ..., -0.5768,  1.0312, -1.1297]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Random sampling\n",
    "z = random_sample_z_space(batch_size)\n",
    "\n",
    "print(\"z\\t:{}\".format(z.shape))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📌 **NOTE**  \n",
    ">  \n",
    "> Random noise를 성공적으로 샘플링했다 !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generative model $G$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_hidden = 256\n",
    "\n",
    "sz_output = 28\n",
    "dim_output = sz_output**2\n",
    "\n",
    "num_channels = 1\n",
    "img_shape = (num_channels, sz_output, sz_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Generator(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Generator, self).__init__()\n",
    "\n",
    "#         def block(in_feat, out_feat, normalize=True):\n",
    "#             layers = [nn.Linear(in_feat, out_feat)]\n",
    "#             if normalize:\n",
    "#                 layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "#             layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "#             return layers\n",
    "\n",
    "#         self.model = nn.Sequential(\n",
    "#             *block(100, 128, normalize=False),\n",
    "#             *block(128, 256),\n",
    "#             *block(256, 512),\n",
    "#             *block(512, 1024),\n",
    "#             nn.Linear(1024, int(np.prod(img_shape))),\n",
    "#             nn.Tanh()\n",
    "#         )\n",
    "#     def forward(self, z):\n",
    "#         img = self.model(z)\n",
    "#         img = img.view(img.size(0), *img_shape)\n",
    "#         return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "                    nn.Linear(dim_noise, dim_hidden),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.1),\n",
    "                    nn.Linear(dim_hidden, dim_hidden),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.1),\n",
    "                    nn.Linear(dim_hidden, dim_output),\n",
    "                    nn.Tanh()\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), *img_shape)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z\t:torch.Size([64, 100])\n",
      "G(z)\t:torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "G = Generator().to(device)\n",
    "\n",
    "print(\"z\\t:{}\".format(z.shape))\n",
    "print(\"G(z)\\t:{}\".format(G(z).size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(G(z)[0].squeeze().cpu().detach(), cmap='gray');\n",
    "plt.axis('off')\n",
    "plt.savefig('../result/GAN/1-GAN/2-G(z).png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📌 **NOTE**  \n",
    ">  \n",
    "> $G$가 학습이 되지 않은 상태라 의미없는 노이즈 데이터만 만들어낸다 !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Disciminative model $D$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Discriminator(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Discriminator, self).__init__()\n",
    "\n",
    "#         self.model = nn.Sequential(\n",
    "#             nn.Linear(int(np.prod(img_shape)), 512),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Linear(512, 256),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Linear(256, 1),\n",
    "#             nn.Sigmoid(),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, img):\n",
    "#         img_flat = img.view(img.size(0), -1)\n",
    "#         validity = self.model(img_flat)\n",
    "#         return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(dim_output, dim_hidden),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(dim_hidden, dim_hidden),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(dim_hidden, 1),\n",
    "            nn.Sigmoid()    \n",
    "        )\n",
    "    \n",
    "    def forward(self, img):\n",
    "        flat_img = img.view(img.size(0), -1)\n",
    "        check_validity = self.model(flat_img)\n",
    "        \n",
    "        return check_validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z\t:torch.Size([64, 100])\n",
      "G(z)\t:torch.Size([64, 1, 28, 28])\n",
      "D(G(z))\t:torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "D = Discriminator().to(device)\n",
    "\n",
    "print(\"z\\t:{}\".format(z.shape))\n",
    "print(\"G(z)\\t:{}\".format(G(z).size()))\n",
    "print(\"D(G(z))\\t:{}\".format(D(G(z)).size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📌 **NOTE**  \n",
    ">  \n",
    "> Generator $G$를 역순으로 뒤집은 형태인 Discriminator $D$를 정의한다.  \n",
    "> $D$의 출력은 Fake와 Real을 구별하는 sigmoid function이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train model $G$ and $D$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-1. Initialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-2. Loss function & optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-3. Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "interval_save_img = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = torch.cuda.FloatTensor if is_cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 0/938] loss_G: 0.683718, loss_D: 0.696356\n",
      "[Epoch 0/200] [Batch 10/938] loss_G: 0.674789, loss_D: 0.604316\n",
      "[Epoch 0/200] [Batch 20/938] loss_G: 0.620165, loss_D: 0.517185\n",
      "[Epoch 0/200] [Batch 30/938] loss_G: 0.512904, loss_D: 0.544590\n",
      "[Epoch 0/200] [Batch 40/938] loss_G: 0.814957, loss_D: 0.440064\n",
      "[Epoch 0/200] [Batch 50/938] loss_G: 1.004035, loss_D: 0.536133\n",
      "[Epoch 0/200] [Batch 60/938] loss_G: 0.994721, loss_D: 0.649995\n",
      "[Epoch 0/200] [Batch 70/938] loss_G: 1.462310, loss_D: 0.395173\n",
      "[Epoch 0/200] [Batch 80/938] loss_G: 2.140393, loss_D: 0.151049\n",
      "[Epoch 0/200] [Batch 90/938] loss_G: 2.327324, loss_D: 0.108779\n",
      "[Epoch 0/200] [Batch 100/938] loss_G: 2.321014, loss_D: 0.132675\n",
      "[Epoch 0/200] [Batch 110/938] loss_G: 2.287968, loss_D: 0.161966\n",
      "[Epoch 0/200] [Batch 120/938] loss_G: 2.441562, loss_D: 0.116379\n",
      "[Epoch 0/200] [Batch 130/938] loss_G: 2.364642, loss_D: 0.117669\n",
      "[Epoch 0/200] [Batch 140/938] loss_G: 2.711775, loss_D: 0.129386\n",
      "[Epoch 0/200] [Batch 150/938] loss_G: 3.099469, loss_D: 0.086199\n",
      "[Epoch 0/200] [Batch 160/938] loss_G: 3.043759, loss_D: 0.094738\n",
      "[Epoch 0/200] [Batch 170/938] loss_G: 3.266734, loss_D: 0.147882\n",
      "[Epoch 0/200] [Batch 180/938] loss_G: 3.672598, loss_D: 0.090032\n",
      "[Epoch 0/200] [Batch 190/938] loss_G: 3.900552, loss_D: 0.050446\n",
      "[Epoch 0/200] [Batch 200/938] loss_G: 3.818623, loss_D: 0.049807\n",
      "[Epoch 0/200] [Batch 210/938] loss_G: 2.853349, loss_D: 0.079804\n",
      "[Epoch 0/200] [Batch 220/938] loss_G: 2.520598, loss_D: 0.254488\n",
      "[Epoch 0/200] [Batch 230/938] loss_G: 4.219109, loss_D: 0.052487\n",
      "[Epoch 0/200] [Batch 240/938] loss_G: 3.594002, loss_D: 0.042128\n",
      "[Epoch 0/200] [Batch 250/938] loss_G: 3.511476, loss_D: 0.097909\n",
      "[Epoch 0/200] [Batch 260/938] loss_G: 2.970575, loss_D: 0.141950\n",
      "[Epoch 0/200] [Batch 270/938] loss_G: 2.861085, loss_D: 0.174246\n",
      "[Epoch 0/200] [Batch 280/938] loss_G: 2.368767, loss_D: 0.404393\n",
      "[Epoch 0/200] [Batch 290/938] loss_G: 3.247942, loss_D: 0.149862\n",
      "[Epoch 0/200] [Batch 300/938] loss_G: 3.781710, loss_D: 0.067960\n",
      "[Epoch 0/200] [Batch 310/938] loss_G: 3.768832, loss_D: 0.111156\n",
      "[Epoch 0/200] [Batch 320/938] loss_G: 3.597728, loss_D: 0.073639\n",
      "[Epoch 0/200] [Batch 330/938] loss_G: 3.852829, loss_D: 0.128349\n",
      "[Epoch 0/200] [Batch 340/938] loss_G: 5.250925, loss_D: 0.057235\n",
      "[Epoch 0/200] [Batch 350/938] loss_G: 6.078910, loss_D: 0.014717\n",
      "[Epoch 0/200] [Batch 360/938] loss_G: 6.413630, loss_D: 0.020045\n",
      "[Epoch 0/200] [Batch 370/938] loss_G: 4.551191, loss_D: 0.098230\n",
      "[Epoch 0/200] [Batch 380/938] loss_G: 5.587730, loss_D: 0.082492\n",
      "[Epoch 0/200] [Batch 390/938] loss_G: 5.856094, loss_D: 0.031812\n",
      "[Epoch 0/200] [Batch 400/938] loss_G: 4.647610, loss_D: 0.048451\n",
      "[Epoch 0/200] [Batch 410/938] loss_G: 3.959698, loss_D: 0.092635\n",
      "[Epoch 0/200] [Batch 420/938] loss_G: 2.555871, loss_D: 0.158352\n",
      "[Epoch 0/200] [Batch 430/938] loss_G: 3.876055, loss_D: 0.098447\n",
      "[Epoch 0/200] [Batch 440/938] loss_G: 4.202053, loss_D: 0.077665\n",
      "[Epoch 0/200] [Batch 450/938] loss_G: 3.727611, loss_D: 0.062099\n",
      "[Epoch 0/200] [Batch 460/938] loss_G: 3.283450, loss_D: 0.192264\n",
      "[Epoch 0/200] [Batch 470/938] loss_G: 2.363001, loss_D: 0.353447\n",
      "[Epoch 0/200] [Batch 480/938] loss_G: 2.425013, loss_D: 0.248875\n",
      "[Epoch 0/200] [Batch 490/938] loss_G: 3.722651, loss_D: 0.078112\n",
      "[Epoch 0/200] [Batch 500/938] loss_G: 4.969911, loss_D: 0.057352\n",
      "[Epoch 0/200] [Batch 510/938] loss_G: 4.113788, loss_D: 0.109309\n",
      "[Epoch 0/200] [Batch 520/938] loss_G: 2.250584, loss_D: 0.278443\n",
      "[Epoch 0/200] [Batch 530/938] loss_G: 2.146259, loss_D: 0.183212\n",
      "[Epoch 0/200] [Batch 540/938] loss_G: 3.240758, loss_D: 0.101404\n",
      "[Epoch 0/200] [Batch 550/938] loss_G: 4.507947, loss_D: 0.043253\n",
      "[Epoch 0/200] [Batch 560/938] loss_G: 3.790917, loss_D: 0.059025\n",
      "[Epoch 0/200] [Batch 570/938] loss_G: 1.947964, loss_D: 0.243574\n",
      "[Epoch 0/200] [Batch 580/938] loss_G: 1.427340, loss_D: 0.505403\n",
      "[Epoch 0/200] [Batch 590/938] loss_G: 1.642997, loss_D: 0.266106\n",
      "[Epoch 0/200] [Batch 600/938] loss_G: 2.949218, loss_D: 0.104182\n",
      "[Epoch 0/200] [Batch 610/938] loss_G: 2.709145, loss_D: 0.125848\n",
      "[Epoch 0/200] [Batch 620/938] loss_G: 1.581715, loss_D: 0.313286\n",
      "[Epoch 0/200] [Batch 630/938] loss_G: 0.632762, loss_D: 0.766241\n",
      "[Epoch 0/200] [Batch 640/938] loss_G: 0.388516, loss_D: 0.842850\n",
      "[Epoch 0/200] [Batch 650/938] loss_G: 0.734288, loss_D: 0.527958\n",
      "[Epoch 0/200] [Batch 660/938] loss_G: 1.596663, loss_D: 0.216142\n",
      "[Epoch 0/200] [Batch 670/938] loss_G: 2.149584, loss_D: 0.128002\n",
      "[Epoch 0/200] [Batch 680/938] loss_G: 1.802932, loss_D: 0.196249\n",
      "[Epoch 0/200] [Batch 690/938] loss_G: 1.359636, loss_D: 0.380265\n",
      "[Epoch 0/200] [Batch 700/938] loss_G: 0.828199, loss_D: 0.772759\n",
      "[Epoch 0/200] [Batch 710/938] loss_G: 1.353918, loss_D: 0.410501\n",
      "[Epoch 0/200] [Batch 720/938] loss_G: 2.684150, loss_D: 0.135009\n",
      "[Epoch 0/200] [Batch 730/938] loss_G: 2.393256, loss_D: 0.141396\n",
      "[Epoch 0/200] [Batch 740/938] loss_G: 1.488210, loss_D: 0.248622\n",
      "[Epoch 0/200] [Batch 750/938] loss_G: 1.225890, loss_D: 0.366660\n",
      "[Epoch 0/200] [Batch 760/938] loss_G: 1.518842, loss_D: 0.282057\n",
      "[Epoch 0/200] [Batch 770/938] loss_G: 1.973413, loss_D: 0.160740\n",
      "[Epoch 0/200] [Batch 780/938] loss_G: 1.470897, loss_D: 0.250032\n",
      "[Epoch 0/200] [Batch 790/938] loss_G: 0.842329, loss_D: 0.575237\n",
      "[Epoch 0/200] [Batch 800/938] loss_G: 0.794611, loss_D: 0.579308\n",
      "[Epoch 0/200] [Batch 810/938] loss_G: 0.947004, loss_D: 0.449680\n",
      "[Epoch 0/200] [Batch 820/938] loss_G: 1.482231, loss_D: 0.311086\n",
      "[Epoch 0/200] [Batch 830/938] loss_G: 2.384664, loss_D: 0.123408\n",
      "[Epoch 0/200] [Batch 840/938] loss_G: 1.759496, loss_D: 0.165694\n",
      "[Epoch 0/200] [Batch 850/938] loss_G: 1.028896, loss_D: 0.578944\n",
      "[Epoch 0/200] [Batch 860/938] loss_G: 1.559556, loss_D: 0.321240\n",
      "[Epoch 0/200] [Batch 870/938] loss_G: 2.624669, loss_D: 0.132460\n",
      "[Epoch 0/200] [Batch 880/938] loss_G: 2.363612, loss_D: 0.124279\n",
      "[Epoch 0/200] [Batch 890/938] loss_G: 1.871630, loss_D: 0.238652\n",
      "[Epoch 0/200] [Batch 900/938] loss_G: 1.380456, loss_D: 0.370505\n",
      "[Epoch 0/200] [Batch 910/938] loss_G: 1.579604, loss_D: 0.296206\n",
      "[Epoch 0/200] [Batch 920/938] loss_G: 1.651715, loss_D: 0.283953\n",
      "[Epoch 0/200] [Batch 930/938] loss_G: 1.729808, loss_D: 0.244288\n",
      "[Epoch 1/200] [Batch 0/938] loss_G: 2.095063, loss_D: 0.165487\n",
      "[Epoch 1/200] [Batch 10/938] loss_G: 2.203856, loss_D: 0.139208\n",
      "[Epoch 1/200] [Batch 20/938] loss_G: 1.729817, loss_D: 0.237435\n",
      "[Epoch 1/200] [Batch 30/938] loss_G: 1.315259, loss_D: 0.436512\n",
      "[Epoch 1/200] [Batch 40/938] loss_G: 1.256585, loss_D: 0.331460\n",
      "[Epoch 1/200] [Batch 50/938] loss_G: 2.772456, loss_D: 0.106283\n",
      "[Epoch 1/200] [Batch 60/938] loss_G: 2.303797, loss_D: 0.100500\n",
      "[Epoch 1/200] [Batch 70/938] loss_G: 1.649300, loss_D: 0.205309\n",
      "[Epoch 1/200] [Batch 80/938] loss_G: 1.950868, loss_D: 0.178766\n",
      "[Epoch 1/200] [Batch 90/938] loss_G: 1.827679, loss_D: 0.255047\n",
      "[Epoch 1/200] [Batch 100/938] loss_G: 2.316141, loss_D: 0.191060\n",
      "[Epoch 1/200] [Batch 110/938] loss_G: 2.390341, loss_D: 0.094913\n",
      "[Epoch 1/200] [Batch 120/938] loss_G: 1.659114, loss_D: 0.205748\n",
      "[Epoch 1/200] [Batch 130/938] loss_G: 1.566292, loss_D: 0.268817\n",
      "[Epoch 1/200] [Batch 140/938] loss_G: 1.696342, loss_D: 0.226401\n",
      "[Epoch 1/200] [Batch 150/938] loss_G: 2.682482, loss_D: 0.115523\n",
      "[Epoch 1/200] [Batch 160/938] loss_G: 3.239975, loss_D: 0.070263\n",
      "[Epoch 1/200] [Batch 170/938] loss_G: 2.438257, loss_D: 0.099904\n",
      "[Epoch 1/200] [Batch 180/938] loss_G: 1.547207, loss_D: 0.330717\n",
      "[Epoch 1/200] [Batch 190/938] loss_G: 1.311514, loss_D: 0.392740\n",
      "[Epoch 1/200] [Batch 200/938] loss_G: 1.941481, loss_D: 0.193393\n",
      "[Epoch 1/200] [Batch 210/938] loss_G: 2.395935, loss_D: 0.104876\n",
      "[Epoch 1/200] [Batch 220/938] loss_G: 2.821429, loss_D: 0.106514\n",
      "[Epoch 1/200] [Batch 230/938] loss_G: 2.371777, loss_D: 0.093593\n",
      "[Epoch 1/200] [Batch 240/938] loss_G: 2.022969, loss_D: 0.145567\n",
      "[Epoch 1/200] [Batch 250/938] loss_G: 1.615165, loss_D: 0.302478\n",
      "[Epoch 1/200] [Batch 260/938] loss_G: 1.807856, loss_D: 0.249292\n",
      "[Epoch 1/200] [Batch 270/938] loss_G: 2.280087, loss_D: 0.172291\n",
      "[Epoch 1/200] [Batch 280/938] loss_G: 2.069715, loss_D: 0.136391\n",
      "[Epoch 1/200] [Batch 290/938] loss_G: 2.200036, loss_D: 0.196203\n",
      "[Epoch 1/200] [Batch 300/938] loss_G: 3.235591, loss_D: 0.083712\n",
      "[Epoch 1/200] [Batch 310/938] loss_G: 2.916765, loss_D: 0.113165\n",
      "[Epoch 1/200] [Batch 320/938] loss_G: 2.487143, loss_D: 0.174006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 330/938] loss_G: 2.020194, loss_D: 0.278048\n",
      "[Epoch 1/200] [Batch 340/938] loss_G: 1.925663, loss_D: 0.274203\n",
      "[Epoch 1/200] [Batch 350/938] loss_G: 2.375228, loss_D: 0.139260\n",
      "[Epoch 1/200] [Batch 360/938] loss_G: 2.306455, loss_D: 0.231728\n",
      "[Epoch 1/200] [Batch 370/938] loss_G: 2.140430, loss_D: 0.257023\n",
      "[Epoch 1/200] [Batch 380/938] loss_G: 2.419726, loss_D: 0.275377\n",
      "[Epoch 1/200] [Batch 390/938] loss_G: 2.452874, loss_D: 0.140049\n",
      "[Epoch 1/200] [Batch 400/938] loss_G: 2.630054, loss_D: 0.160317\n",
      "[Epoch 1/200] [Batch 410/938] loss_G: 1.760442, loss_D: 0.363431\n",
      "[Epoch 1/200] [Batch 420/938] loss_G: 1.660855, loss_D: 0.455470\n",
      "[Epoch 1/200] [Batch 430/938] loss_G: 2.320894, loss_D: 0.243888\n",
      "[Epoch 1/200] [Batch 440/938] loss_G: 2.483372, loss_D: 0.350809\n",
      "[Epoch 1/200] [Batch 450/938] loss_G: 1.828489, loss_D: 0.330492\n",
      "[Epoch 1/200] [Batch 460/938] loss_G: 1.686571, loss_D: 0.390465\n",
      "[Epoch 1/200] [Batch 470/938] loss_G: 3.005343, loss_D: 0.142877\n",
      "[Epoch 1/200] [Batch 480/938] loss_G: 2.522070, loss_D: 0.191126\n",
      "[Epoch 1/200] [Batch 490/938] loss_G: 1.399197, loss_D: 0.673183\n",
      "[Epoch 1/200] [Batch 500/938] loss_G: 0.704860, loss_D: 0.869855\n",
      "[Epoch 1/200] [Batch 510/938] loss_G: 1.399979, loss_D: 0.335268\n",
      "[Epoch 1/200] [Batch 520/938] loss_G: 2.289682, loss_D: 0.150713\n",
      "[Epoch 1/200] [Batch 530/938] loss_G: 2.363680, loss_D: 0.132669\n",
      "[Epoch 1/200] [Batch 540/938] loss_G: 1.757437, loss_D: 0.304510\n",
      "[Epoch 1/200] [Batch 550/938] loss_G: 2.238939, loss_D: 0.350876\n",
      "[Epoch 1/200] [Batch 560/938] loss_G: 1.197290, loss_D: 0.723288\n",
      "[Epoch 1/200] [Batch 570/938] loss_G: 1.730948, loss_D: 0.297288\n",
      "[Epoch 1/200] [Batch 580/938] loss_G: 4.056017, loss_D: 0.128394\n",
      "[Epoch 1/200] [Batch 590/938] loss_G: 2.630378, loss_D: 0.140083\n",
      "[Epoch 1/200] [Batch 600/938] loss_G: 1.709722, loss_D: 0.246556\n",
      "[Epoch 1/200] [Batch 610/938] loss_G: 1.777467, loss_D: 0.336110\n",
      "[Epoch 1/200] [Batch 620/938] loss_G: 2.983847, loss_D: 0.131230\n",
      "[Epoch 1/200] [Batch 630/938] loss_G: 2.897422, loss_D: 0.093793\n",
      "[Epoch 1/200] [Batch 640/938] loss_G: 1.783890, loss_D: 0.310523\n",
      "[Epoch 1/200] [Batch 650/938] loss_G: 1.457957, loss_D: 0.371979\n",
      "[Epoch 1/200] [Batch 660/938] loss_G: 3.657686, loss_D: 0.069034\n",
      "[Epoch 1/200] [Batch 670/938] loss_G: 3.419053, loss_D: 0.115807\n",
      "[Epoch 1/200] [Batch 680/938] loss_G: 2.155798, loss_D: 0.244925\n",
      "[Epoch 1/200] [Batch 690/938] loss_G: 1.963748, loss_D: 0.234810\n",
      "[Epoch 1/200] [Batch 700/938] loss_G: 1.238054, loss_D: 0.450373\n",
      "[Epoch 1/200] [Batch 710/938] loss_G: 1.422263, loss_D: 0.281563\n",
      "[Epoch 1/200] [Batch 720/938] loss_G: 2.169201, loss_D: 0.157890\n",
      "[Epoch 1/200] [Batch 730/938] loss_G: 2.408235, loss_D: 0.133903\n",
      "[Epoch 1/200] [Batch 740/938] loss_G: 2.358736, loss_D: 0.150189\n",
      "[Epoch 1/200] [Batch 750/938] loss_G: 1.692707, loss_D: 0.329853\n",
      "[Epoch 1/200] [Batch 760/938] loss_G: 1.663527, loss_D: 0.311762\n",
      "[Epoch 1/200] [Batch 770/938] loss_G: 2.366452, loss_D: 0.094233\n",
      "[Epoch 1/200] [Batch 780/938] loss_G: 2.914563, loss_D: 0.113416\n",
      "[Epoch 1/200] [Batch 790/938] loss_G: 2.264162, loss_D: 0.193361\n",
      "[Epoch 1/200] [Batch 800/938] loss_G: 2.419012, loss_D: 0.244731\n",
      "[Epoch 1/200] [Batch 810/938] loss_G: 2.553185, loss_D: 0.145765\n",
      "[Epoch 1/200] [Batch 820/938] loss_G: 2.944053, loss_D: 0.108908\n",
      "[Epoch 1/200] [Batch 830/938] loss_G: 2.282784, loss_D: 0.133849\n",
      "[Epoch 1/200] [Batch 840/938] loss_G: 1.457667, loss_D: 0.549130\n",
      "[Epoch 1/200] [Batch 850/938] loss_G: 2.301654, loss_D: 0.174780\n",
      "[Epoch 1/200] [Batch 860/938] loss_G: 3.265817, loss_D: 0.055014\n",
      "[Epoch 1/200] [Batch 870/938] loss_G: 2.152595, loss_D: 0.209837\n",
      "[Epoch 1/200] [Batch 880/938] loss_G: 1.892269, loss_D: 0.214690\n",
      "[Epoch 1/200] [Batch 890/938] loss_G: 2.665389, loss_D: 0.155611\n",
      "[Epoch 1/200] [Batch 900/938] loss_G: 3.414266, loss_D: 0.056319\n",
      "[Epoch 1/200] [Batch 910/938] loss_G: 2.631967, loss_D: 0.148566\n",
      "[Epoch 1/200] [Batch 920/938] loss_G: 2.220925, loss_D: 0.185434\n",
      "[Epoch 1/200] [Batch 930/938] loss_G: 2.266107, loss_D: 0.317732\n",
      "[Epoch 2/200] [Batch 0/938] loss_G: 2.224588, loss_D: 0.179094\n",
      "[Epoch 2/200] [Batch 10/938] loss_G: 1.782108, loss_D: 0.170732\n",
      "[Epoch 2/200] [Batch 20/938] loss_G: 2.938125, loss_D: 0.089696\n",
      "[Epoch 2/200] [Batch 30/938] loss_G: 2.741393, loss_D: 0.121615\n",
      "[Epoch 2/200] [Batch 40/938] loss_G: 2.753849, loss_D: 0.098111\n",
      "[Epoch 2/200] [Batch 50/938] loss_G: 2.500470, loss_D: 0.169681\n",
      "[Epoch 2/200] [Batch 60/938] loss_G: 2.747608, loss_D: 0.182125\n",
      "[Epoch 2/200] [Batch 70/938] loss_G: 2.905008, loss_D: 0.119479\n",
      "[Epoch 2/200] [Batch 80/938] loss_G: 2.345225, loss_D: 0.118007\n",
      "[Epoch 2/200] [Batch 90/938] loss_G: 2.398636, loss_D: 0.178144\n",
      "[Epoch 2/200] [Batch 100/938] loss_G: 2.135448, loss_D: 0.212614\n",
      "[Epoch 2/200] [Batch 110/938] loss_G: 2.443798, loss_D: 0.147643\n",
      "[Epoch 2/200] [Batch 120/938] loss_G: 3.169352, loss_D: 0.087942\n",
      "[Epoch 2/200] [Batch 130/938] loss_G: 3.192603, loss_D: 0.083063\n",
      "[Epoch 2/200] [Batch 140/938] loss_G: 2.841321, loss_D: 0.084192\n",
      "[Epoch 2/200] [Batch 150/938] loss_G: 2.355843, loss_D: 0.168310\n",
      "[Epoch 2/200] [Batch 160/938] loss_G: 1.831111, loss_D: 0.190847\n",
      "[Epoch 2/200] [Batch 170/938] loss_G: 2.091932, loss_D: 0.138758\n",
      "[Epoch 2/200] [Batch 180/938] loss_G: 3.027754, loss_D: 0.059325\n",
      "[Epoch 2/200] [Batch 190/938] loss_G: 2.709680, loss_D: 0.142123\n",
      "[Epoch 2/200] [Batch 200/938] loss_G: 2.685645, loss_D: 0.146645\n",
      "[Epoch 2/200] [Batch 210/938] loss_G: 2.785766, loss_D: 0.128149\n",
      "[Epoch 2/200] [Batch 220/938] loss_G: 2.637159, loss_D: 0.125355\n",
      "[Epoch 2/200] [Batch 230/938] loss_G: 2.761417, loss_D: 0.162676\n",
      "[Epoch 2/200] [Batch 240/938] loss_G: 2.621989, loss_D: 0.110888\n",
      "[Epoch 2/200] [Batch 250/938] loss_G: 2.732302, loss_D: 0.148520\n",
      "[Epoch 2/200] [Batch 260/938] loss_G: 2.800805, loss_D: 0.100214\n",
      "[Epoch 2/200] [Batch 270/938] loss_G: 2.733442, loss_D: 0.200471\n",
      "[Epoch 2/200] [Batch 280/938] loss_G: 2.204033, loss_D: 0.220861\n",
      "[Epoch 2/200] [Batch 290/938] loss_G: 2.195034, loss_D: 0.210381\n",
      "[Epoch 2/200] [Batch 300/938] loss_G: 2.653380, loss_D: 0.100521\n",
      "[Epoch 2/200] [Batch 310/938] loss_G: 3.001105, loss_D: 0.071712\n",
      "[Epoch 2/200] [Batch 320/938] loss_G: 3.190425, loss_D: 0.113369\n",
      "[Epoch 2/200] [Batch 330/938] loss_G: 2.951308, loss_D: 0.086500\n",
      "[Epoch 2/200] [Batch 340/938] loss_G: 2.379857, loss_D: 0.161854\n",
      "[Epoch 2/200] [Batch 350/938] loss_G: 2.768879, loss_D: 0.174154\n",
      "[Epoch 2/200] [Batch 360/938] loss_G: 3.522519, loss_D: 0.063448\n",
      "[Epoch 2/200] [Batch 370/938] loss_G: 3.744646, loss_D: 0.103830\n",
      "[Epoch 2/200] [Batch 380/938] loss_G: 3.669923, loss_D: 0.102645\n",
      "[Epoch 2/200] [Batch 390/938] loss_G: 2.437854, loss_D: 0.205478\n",
      "[Epoch 2/200] [Batch 400/938] loss_G: 2.533631, loss_D: 0.268244\n",
      "[Epoch 2/200] [Batch 410/938] loss_G: 4.069021, loss_D: 0.038652\n",
      "[Epoch 2/200] [Batch 420/938] loss_G: 3.057671, loss_D: 0.055422\n",
      "[Epoch 2/200] [Batch 430/938] loss_G: 3.977239, loss_D: 0.057386\n",
      "[Epoch 2/200] [Batch 440/938] loss_G: 3.048291, loss_D: 0.078404\n",
      "[Epoch 2/200] [Batch 450/938] loss_G: 3.097642, loss_D: 0.100517\n",
      "[Epoch 2/200] [Batch 460/938] loss_G: 3.358327, loss_D: 0.098967\n",
      "[Epoch 2/200] [Batch 470/938] loss_G: 2.695167, loss_D: 0.098746\n",
      "[Epoch 2/200] [Batch 480/938] loss_G: 3.118401, loss_D: 0.136519\n",
      "[Epoch 2/200] [Batch 490/938] loss_G: 3.397931, loss_D: 0.075279\n",
      "[Epoch 2/200] [Batch 500/938] loss_G: 3.611389, loss_D: 0.080195\n",
      "[Epoch 2/200] [Batch 510/938] loss_G: 2.882997, loss_D: 0.081238\n",
      "[Epoch 2/200] [Batch 520/938] loss_G: 3.117544, loss_D: 0.107928\n",
      "[Epoch 2/200] [Batch 530/938] loss_G: 3.431450, loss_D: 0.099786\n",
      "[Epoch 2/200] [Batch 540/938] loss_G: 2.781856, loss_D: 0.113792\n",
      "[Epoch 2/200] [Batch 550/938] loss_G: 3.056587, loss_D: 0.104313\n",
      "[Epoch 2/200] [Batch 560/938] loss_G: 3.090636, loss_D: 0.102458\n",
      "[Epoch 2/200] [Batch 570/938] loss_G: 2.876913, loss_D: 0.061049\n",
      "[Epoch 2/200] [Batch 580/938] loss_G: 3.410672, loss_D: 0.083691\n",
      "[Epoch 2/200] [Batch 590/938] loss_G: 3.732326, loss_D: 0.093990\n",
      "[Epoch 2/200] [Batch 600/938] loss_G: 2.798363, loss_D: 0.107636\n",
      "[Epoch 2/200] [Batch 610/938] loss_G: 3.317343, loss_D: 0.068470\n",
      "[Epoch 2/200] [Batch 620/938] loss_G: 2.951730, loss_D: 0.092582\n",
      "[Epoch 2/200] [Batch 630/938] loss_G: 3.359761, loss_D: 0.117696\n",
      "[Epoch 2/200] [Batch 640/938] loss_G: 3.676510, loss_D: 0.064556\n",
      "[Epoch 2/200] [Batch 650/938] loss_G: 3.302730, loss_D: 0.092727\n",
      "[Epoch 2/200] [Batch 660/938] loss_G: 3.058962, loss_D: 0.164786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 670/938] loss_G: 2.644143, loss_D: 0.103282\n",
      "[Epoch 2/200] [Batch 680/938] loss_G: 2.750593, loss_D: 0.185791\n",
      "[Epoch 2/200] [Batch 690/938] loss_G: 3.261181, loss_D: 0.043747\n",
      "[Epoch 2/200] [Batch 700/938] loss_G: 3.686024, loss_D: 0.094593\n",
      "[Epoch 2/200] [Batch 710/938] loss_G: 3.019256, loss_D: 0.151297\n",
      "[Epoch 2/200] [Batch 720/938] loss_G: 3.193425, loss_D: 0.186273\n",
      "[Epoch 2/200] [Batch 730/938] loss_G: 3.564164, loss_D: 0.141160\n",
      "[Epoch 2/200] [Batch 740/938] loss_G: 3.710384, loss_D: 0.053486\n",
      "[Epoch 2/200] [Batch 750/938] loss_G: 4.192745, loss_D: 0.053502\n",
      "[Epoch 2/200] [Batch 760/938] loss_G: 3.663553, loss_D: 0.052170\n",
      "[Epoch 2/200] [Batch 770/938] loss_G: 3.357250, loss_D: 0.078695\n",
      "[Epoch 2/200] [Batch 780/938] loss_G: 2.843921, loss_D: 0.088902\n",
      "[Epoch 2/200] [Batch 790/938] loss_G: 2.975783, loss_D: 0.078420\n",
      "[Epoch 2/200] [Batch 800/938] loss_G: 3.744084, loss_D: 0.084747\n",
      "[Epoch 2/200] [Batch 810/938] loss_G: 2.588960, loss_D: 0.195570\n",
      "[Epoch 2/200] [Batch 820/938] loss_G: 2.763784, loss_D: 0.075872\n",
      "[Epoch 2/200] [Batch 830/938] loss_G: 3.174083, loss_D: 0.089997\n",
      "[Epoch 2/200] [Batch 840/938] loss_G: 3.500768, loss_D: 0.094079\n",
      "[Epoch 2/200] [Batch 850/938] loss_G: 3.334066, loss_D: 0.128550\n",
      "[Epoch 2/200] [Batch 860/938] loss_G: 3.964842, loss_D: 0.120175\n",
      "[Epoch 2/200] [Batch 870/938] loss_G: 3.625692, loss_D: 0.082712\n",
      "[Epoch 2/200] [Batch 880/938] loss_G: 2.811656, loss_D: 0.085805\n",
      "[Epoch 2/200] [Batch 890/938] loss_G: 3.104264, loss_D: 0.160199\n",
      "[Epoch 2/200] [Batch 900/938] loss_G: 3.331346, loss_D: 0.097601\n",
      "[Epoch 2/200] [Batch 910/938] loss_G: 3.145091, loss_D: 0.110319\n",
      "[Epoch 2/200] [Batch 920/938] loss_G: 3.801012, loss_D: 0.110112\n",
      "[Epoch 2/200] [Batch 930/938] loss_G: 3.682328, loss_D: 0.050638\n",
      "[Epoch 3/200] [Batch 0/938] loss_G: 3.768955, loss_D: 0.060692\n",
      "[Epoch 3/200] [Batch 10/938] loss_G: 4.361277, loss_D: 0.070555\n",
      "[Epoch 3/200] [Batch 20/938] loss_G: 4.156297, loss_D: 0.062404\n",
      "[Epoch 3/200] [Batch 30/938] loss_G: 3.749867, loss_D: 0.095590\n",
      "[Epoch 3/200] [Batch 40/938] loss_G: 3.049403, loss_D: 0.153313\n",
      "[Epoch 3/200] [Batch 50/938] loss_G: 3.823375, loss_D: 0.045732\n",
      "[Epoch 3/200] [Batch 60/938] loss_G: 3.680015, loss_D: 0.070420\n",
      "[Epoch 3/200] [Batch 70/938] loss_G: 3.257407, loss_D: 0.149925\n",
      "[Epoch 3/200] [Batch 80/938] loss_G: 4.248249, loss_D: 0.165061\n",
      "[Epoch 3/200] [Batch 90/938] loss_G: 4.291771, loss_D: 0.035520\n",
      "[Epoch 3/200] [Batch 100/938] loss_G: 3.532108, loss_D: 0.102067\n",
      "[Epoch 3/200] [Batch 110/938] loss_G: 3.780956, loss_D: 0.056337\n",
      "[Epoch 3/200] [Batch 120/938] loss_G: 3.655720, loss_D: 0.053708\n",
      "[Epoch 3/200] [Batch 130/938] loss_G: 3.954213, loss_D: 0.085349\n",
      "[Epoch 3/200] [Batch 140/938] loss_G: 4.033982, loss_D: 0.060742\n",
      "[Epoch 3/200] [Batch 150/938] loss_G: 3.730351, loss_D: 0.069513\n",
      "[Epoch 3/200] [Batch 160/938] loss_G: 3.530920, loss_D: 0.082042\n",
      "[Epoch 3/200] [Batch 170/938] loss_G: 3.817607, loss_D: 0.090270\n",
      "[Epoch 3/200] [Batch 180/938] loss_G: 3.802248, loss_D: 0.115507\n",
      "[Epoch 3/200] [Batch 190/938] loss_G: 4.260979, loss_D: 0.026200\n",
      "[Epoch 3/200] [Batch 200/938] loss_G: 3.552915, loss_D: 0.125580\n",
      "[Epoch 3/200] [Batch 210/938] loss_G: 3.167687, loss_D: 0.143580\n",
      "[Epoch 3/200] [Batch 220/938] loss_G: 4.174495, loss_D: 0.117946\n",
      "[Epoch 3/200] [Batch 230/938] loss_G: 3.577492, loss_D: 0.094365\n",
      "[Epoch 3/200] [Batch 240/938] loss_G: 3.171231, loss_D: 0.083268\n",
      "[Epoch 3/200] [Batch 250/938] loss_G: 3.086801, loss_D: 0.046180\n",
      "[Epoch 3/200] [Batch 260/938] loss_G: 4.276318, loss_D: 0.082059\n",
      "[Epoch 3/200] [Batch 270/938] loss_G: 3.584690, loss_D: 0.104574\n",
      "[Epoch 3/200] [Batch 280/938] loss_G: 2.775587, loss_D: 0.122644\n",
      "[Epoch 3/200] [Batch 290/938] loss_G: 3.976283, loss_D: 0.044739\n",
      "[Epoch 3/200] [Batch 300/938] loss_G: 3.384390, loss_D: 0.234084\n",
      "[Epoch 3/200] [Batch 310/938] loss_G: 4.089907, loss_D: 0.121804\n",
      "[Epoch 3/200] [Batch 320/938] loss_G: 3.563641, loss_D: 0.104596\n",
      "[Epoch 3/200] [Batch 330/938] loss_G: 3.962620, loss_D: 0.065118\n",
      "[Epoch 3/200] [Batch 340/938] loss_G: 3.742394, loss_D: 0.049698\n",
      "[Epoch 3/200] [Batch 350/938] loss_G: 3.918777, loss_D: 0.108228\n",
      "[Epoch 3/200] [Batch 360/938] loss_G: 3.900243, loss_D: 0.107443\n",
      "[Epoch 3/200] [Batch 370/938] loss_G: 4.235110, loss_D: 0.055859\n",
      "[Epoch 3/200] [Batch 380/938] loss_G: 3.529451, loss_D: 0.080926\n",
      "[Epoch 3/200] [Batch 390/938] loss_G: 4.034710, loss_D: 0.087786\n",
      "[Epoch 3/200] [Batch 400/938] loss_G: 3.863419, loss_D: 0.031689\n",
      "[Epoch 3/200] [Batch 410/938] loss_G: 4.011487, loss_D: 0.055463\n",
      "[Epoch 3/200] [Batch 420/938] loss_G: 3.327701, loss_D: 0.052700\n",
      "[Epoch 3/200] [Batch 430/938] loss_G: 4.093624, loss_D: 0.112918\n",
      "[Epoch 3/200] [Batch 440/938] loss_G: 4.084041, loss_D: 0.110279\n",
      "[Epoch 3/200] [Batch 450/938] loss_G: 3.942420, loss_D: 0.054813\n",
      "[Epoch 3/200] [Batch 460/938] loss_G: 3.792134, loss_D: 0.060907\n",
      "[Epoch 3/200] [Batch 470/938] loss_G: 3.891658, loss_D: 0.037245\n",
      "[Epoch 3/200] [Batch 480/938] loss_G: 3.793870, loss_D: 0.036927\n",
      "[Epoch 3/200] [Batch 490/938] loss_G: 3.671971, loss_D: 0.167047\n",
      "[Epoch 3/200] [Batch 500/938] loss_G: 3.853680, loss_D: 0.168029\n",
      "[Epoch 3/200] [Batch 510/938] loss_G: 3.530842, loss_D: 0.126344\n",
      "[Epoch 3/200] [Batch 520/938] loss_G: 3.760486, loss_D: 0.040815\n",
      "[Epoch 3/200] [Batch 530/938] loss_G: 3.716819, loss_D: 0.041777\n",
      "[Epoch 3/200] [Batch 540/938] loss_G: 3.426158, loss_D: 0.064762\n",
      "[Epoch 3/200] [Batch 550/938] loss_G: 3.589469, loss_D: 0.112540\n",
      "[Epoch 3/200] [Batch 560/938] loss_G: 3.456866, loss_D: 0.053115\n",
      "[Epoch 3/200] [Batch 570/938] loss_G: 3.340464, loss_D: 0.054751\n",
      "[Epoch 3/200] [Batch 580/938] loss_G: 4.353251, loss_D: 0.222141\n",
      "[Epoch 3/200] [Batch 590/938] loss_G: 4.419847, loss_D: 0.070764\n",
      "[Epoch 3/200] [Batch 600/938] loss_G: 3.789388, loss_D: 0.075203\n",
      "[Epoch 3/200] [Batch 610/938] loss_G: 4.264593, loss_D: 0.090884\n",
      "[Epoch 3/200] [Batch 620/938] loss_G: 3.693777, loss_D: 0.085319\n",
      "[Epoch 3/200] [Batch 630/938] loss_G: 3.789090, loss_D: 0.137059\n",
      "[Epoch 3/200] [Batch 640/938] loss_G: 3.882784, loss_D: 0.161401\n",
      "[Epoch 3/200] [Batch 650/938] loss_G: 3.701806, loss_D: 0.062937\n",
      "[Epoch 3/200] [Batch 660/938] loss_G: 4.610418, loss_D: 0.073700\n",
      "[Epoch 3/200] [Batch 670/938] loss_G: 3.890704, loss_D: 0.042650\n",
      "[Epoch 3/200] [Batch 680/938] loss_G: 3.666793, loss_D: 0.066750\n",
      "[Epoch 3/200] [Batch 690/938] loss_G: 3.405090, loss_D: 0.117536\n",
      "[Epoch 3/200] [Batch 700/938] loss_G: 4.056811, loss_D: 0.113661\n",
      "[Epoch 3/200] [Batch 710/938] loss_G: 3.772802, loss_D: 0.154982\n",
      "[Epoch 3/200] [Batch 720/938] loss_G: 3.235274, loss_D: 0.152939\n",
      "[Epoch 3/200] [Batch 730/938] loss_G: 3.354218, loss_D: 0.073627\n",
      "[Epoch 3/200] [Batch 740/938] loss_G: 4.569288, loss_D: 0.103617\n",
      "[Epoch 3/200] [Batch 750/938] loss_G: 4.567875, loss_D: 0.115392\n",
      "[Epoch 3/200] [Batch 760/938] loss_G: 4.856350, loss_D: 0.165624\n",
      "[Epoch 3/200] [Batch 770/938] loss_G: 4.255708, loss_D: 0.067659\n",
      "[Epoch 3/200] [Batch 780/938] loss_G: 3.661834, loss_D: 0.067408\n",
      "[Epoch 3/200] [Batch 790/938] loss_G: 3.133832, loss_D: 0.113750\n",
      "[Epoch 3/200] [Batch 800/938] loss_G: 3.306811, loss_D: 0.127256\n",
      "[Epoch 3/200] [Batch 810/938] loss_G: 4.187326, loss_D: 0.121104\n",
      "[Epoch 3/200] [Batch 820/938] loss_G: 4.348211, loss_D: 0.095168\n",
      "[Epoch 3/200] [Batch 830/938] loss_G: 4.342819, loss_D: 0.108376\n",
      "[Epoch 3/200] [Batch 840/938] loss_G: 4.239610, loss_D: 0.125522\n",
      "[Epoch 3/200] [Batch 850/938] loss_G: 3.466631, loss_D: 0.156689\n",
      "[Epoch 3/200] [Batch 860/938] loss_G: 3.433573, loss_D: 0.236235\n",
      "[Epoch 3/200] [Batch 870/938] loss_G: 4.071330, loss_D: 0.105207\n",
      "[Epoch 3/200] [Batch 880/938] loss_G: 4.094443, loss_D: 0.056094\n",
      "[Epoch 3/200] [Batch 890/938] loss_G: 4.130657, loss_D: 0.061100\n",
      "[Epoch 3/200] [Batch 900/938] loss_G: 3.893766, loss_D: 0.126738\n",
      "[Epoch 3/200] [Batch 910/938] loss_G: 4.261174, loss_D: 0.077460\n",
      "[Epoch 3/200] [Batch 920/938] loss_G: 3.841792, loss_D: 0.087854\n",
      "[Epoch 3/200] [Batch 930/938] loss_G: 2.987420, loss_D: 0.092232\n",
      "[Epoch 4/200] [Batch 0/938] loss_G: 3.334195, loss_D: 0.114623\n",
      "[Epoch 4/200] [Batch 10/938] loss_G: 3.521556, loss_D: 0.112699\n",
      "[Epoch 4/200] [Batch 20/938] loss_G: 3.328534, loss_D: 0.135431\n",
      "[Epoch 4/200] [Batch 30/938] loss_G: 3.837775, loss_D: 0.079784\n",
      "[Epoch 4/200] [Batch 40/938] loss_G: 3.929301, loss_D: 0.051140\n",
      "[Epoch 4/200] [Batch 50/938] loss_G: 3.321278, loss_D: 0.065321\n",
      "[Epoch 4/200] [Batch 60/938] loss_G: 3.720615, loss_D: 0.100123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/200] [Batch 70/938] loss_G: 3.601062, loss_D: 0.079000\n",
      "[Epoch 4/200] [Batch 80/938] loss_G: 3.048441, loss_D: 0.170620\n",
      "[Epoch 4/200] [Batch 90/938] loss_G: 5.192246, loss_D: 0.035897\n",
      "[Epoch 4/200] [Batch 100/938] loss_G: 4.673231, loss_D: 0.041926\n",
      "[Epoch 4/200] [Batch 110/938] loss_G: 3.731694, loss_D: 0.039838\n",
      "[Epoch 4/200] [Batch 120/938] loss_G: 3.208025, loss_D: 0.138208\n",
      "[Epoch 4/200] [Batch 130/938] loss_G: 3.412352, loss_D: 0.118834\n",
      "[Epoch 4/200] [Batch 140/938] loss_G: 3.905241, loss_D: 0.085386\n",
      "[Epoch 4/200] [Batch 150/938] loss_G: 4.219119, loss_D: 0.074034\n",
      "[Epoch 4/200] [Batch 160/938] loss_G: 3.771666, loss_D: 0.099274\n",
      "[Epoch 4/200] [Batch 170/938] loss_G: 3.783530, loss_D: 0.186587\n",
      "[Epoch 4/200] [Batch 180/938] loss_G: 3.547362, loss_D: 0.181992\n",
      "[Epoch 4/200] [Batch 190/938] loss_G: 3.770017, loss_D: 0.108100\n",
      "[Epoch 4/200] [Batch 200/938] loss_G: 3.910418, loss_D: 0.110374\n",
      "[Epoch 4/200] [Batch 210/938] loss_G: 3.850103, loss_D: 0.159203\n",
      "[Epoch 4/200] [Batch 220/938] loss_G: 3.656871, loss_D: 0.130302\n",
      "[Epoch 4/200] [Batch 230/938] loss_G: 3.811735, loss_D: 0.084627\n",
      "[Epoch 4/200] [Batch 240/938] loss_G: 3.484364, loss_D: 0.252673\n",
      "[Epoch 4/200] [Batch 250/938] loss_G: 3.369310, loss_D: 0.098057\n",
      "[Epoch 4/200] [Batch 260/938] loss_G: 4.036371, loss_D: 0.090726\n",
      "[Epoch 4/200] [Batch 270/938] loss_G: 3.218406, loss_D: 0.125306\n",
      "[Epoch 4/200] [Batch 280/938] loss_G: 3.354960, loss_D: 0.072670\n",
      "[Epoch 4/200] [Batch 290/938] loss_G: 3.375926, loss_D: 0.058256\n",
      "[Epoch 4/200] [Batch 300/938] loss_G: 4.025703, loss_D: 0.062836\n",
      "[Epoch 4/200] [Batch 310/938] loss_G: 3.304730, loss_D: 0.114274\n",
      "[Epoch 4/200] [Batch 320/938] loss_G: 3.615086, loss_D: 0.040188\n",
      "[Epoch 4/200] [Batch 330/938] loss_G: 3.901657, loss_D: 0.091235\n",
      "[Epoch 4/200] [Batch 340/938] loss_G: 3.771091, loss_D: 0.136298\n",
      "[Epoch 4/200] [Batch 350/938] loss_G: 3.374063, loss_D: 0.131557\n",
      "[Epoch 4/200] [Batch 360/938] loss_G: 3.766288, loss_D: 0.082734\n",
      "[Epoch 4/200] [Batch 370/938] loss_G: 3.483268, loss_D: 0.070223\n",
      "[Epoch 4/200] [Batch 380/938] loss_G: 3.662354, loss_D: 0.137967\n",
      "[Epoch 4/200] [Batch 390/938] loss_G: 3.927537, loss_D: 0.100242\n",
      "[Epoch 4/200] [Batch 400/938] loss_G: 4.414838, loss_D: 0.101991\n",
      "[Epoch 4/200] [Batch 410/938] loss_G: 4.817646, loss_D: 0.038061\n",
      "[Epoch 4/200] [Batch 420/938] loss_G: 4.297245, loss_D: 0.064642\n",
      "[Epoch 4/200] [Batch 430/938] loss_G: 3.367312, loss_D: 0.081419\n",
      "[Epoch 4/200] [Batch 440/938] loss_G: 3.806829, loss_D: 0.073497\n",
      "[Epoch 4/200] [Batch 450/938] loss_G: 3.264933, loss_D: 0.318823\n",
      "[Epoch 4/200] [Batch 460/938] loss_G: 3.152049, loss_D: 0.137963\n",
      "[Epoch 4/200] [Batch 470/938] loss_G: 5.366471, loss_D: 0.029258\n",
      "[Epoch 4/200] [Batch 480/938] loss_G: 4.608057, loss_D: 0.021214\n",
      "[Epoch 4/200] [Batch 490/938] loss_G: 3.309350, loss_D: 0.076335\n",
      "[Epoch 4/200] [Batch 500/938] loss_G: 3.661988, loss_D: 0.076912\n",
      "[Epoch 4/200] [Batch 510/938] loss_G: 4.771280, loss_D: 0.035037\n",
      "[Epoch 4/200] [Batch 520/938] loss_G: 4.088320, loss_D: 0.041694\n",
      "[Epoch 4/200] [Batch 530/938] loss_G: 3.602206, loss_D: 0.051103\n",
      "[Epoch 4/200] [Batch 540/938] loss_G: 4.411174, loss_D: 0.049931\n",
      "[Epoch 4/200] [Batch 550/938] loss_G: 4.296501, loss_D: 0.098758\n",
      "[Epoch 4/200] [Batch 560/938] loss_G: 4.350461, loss_D: 0.044796\n",
      "[Epoch 4/200] [Batch 570/938] loss_G: 4.541221, loss_D: 0.156643\n",
      "[Epoch 4/200] [Batch 580/938] loss_G: 3.910271, loss_D: 0.050228\n",
      "[Epoch 4/200] [Batch 590/938] loss_G: 3.551866, loss_D: 0.077353\n",
      "[Epoch 4/200] [Batch 600/938] loss_G: 3.641619, loss_D: 0.120142\n",
      "[Epoch 4/200] [Batch 610/938] loss_G: 3.449759, loss_D: 0.081516\n",
      "[Epoch 4/200] [Batch 620/938] loss_G: 3.234746, loss_D: 0.087737\n",
      "[Epoch 4/200] [Batch 630/938] loss_G: 4.276047, loss_D: 0.074589\n",
      "[Epoch 4/200] [Batch 640/938] loss_G: 3.704286, loss_D: 0.078781\n",
      "[Epoch 4/200] [Batch 650/938] loss_G: 4.355771, loss_D: 0.053554\n",
      "[Epoch 4/200] [Batch 660/938] loss_G: 3.429475, loss_D: 0.067081\n",
      "[Epoch 4/200] [Batch 670/938] loss_G: 4.005090, loss_D: 0.151206\n",
      "[Epoch 4/200] [Batch 680/938] loss_G: 3.983231, loss_D: 0.070180\n",
      "[Epoch 4/200] [Batch 690/938] loss_G: 3.677160, loss_D: 0.065250\n",
      "[Epoch 4/200] [Batch 700/938] loss_G: 3.444448, loss_D: 0.106843\n",
      "[Epoch 4/200] [Batch 710/938] loss_G: 3.465364, loss_D: 0.074934\n",
      "[Epoch 4/200] [Batch 720/938] loss_G: 3.207610, loss_D: 0.173911\n",
      "[Epoch 4/200] [Batch 730/938] loss_G: 3.508911, loss_D: 0.091886\n",
      "[Epoch 4/200] [Batch 740/938] loss_G: 4.401857, loss_D: 0.050911\n",
      "[Epoch 4/200] [Batch 750/938] loss_G: 4.555077, loss_D: 0.060178\n",
      "[Epoch 4/200] [Batch 760/938] loss_G: 4.216586, loss_D: 0.081050\n",
      "[Epoch 4/200] [Batch 770/938] loss_G: 3.434444, loss_D: 0.052283\n",
      "[Epoch 4/200] [Batch 780/938] loss_G: 3.231370, loss_D: 0.093449\n",
      "[Epoch 4/200] [Batch 790/938] loss_G: 4.126500, loss_D: 0.075680\n",
      "[Epoch 4/200] [Batch 800/938] loss_G: 3.882575, loss_D: 0.087043\n",
      "[Epoch 4/200] [Batch 810/938] loss_G: 4.695658, loss_D: 0.059417\n",
      "[Epoch 4/200] [Batch 820/938] loss_G: 4.859439, loss_D: 0.065801\n",
      "[Epoch 4/200] [Batch 830/938] loss_G: 4.922710, loss_D: 0.053229\n",
      "[Epoch 4/200] [Batch 840/938] loss_G: 4.186388, loss_D: 0.148276\n",
      "[Epoch 4/200] [Batch 850/938] loss_G: 4.050681, loss_D: 0.119587\n",
      "[Epoch 4/200] [Batch 860/938] loss_G: 3.910812, loss_D: 0.176428\n",
      "[Epoch 4/200] [Batch 870/938] loss_G: 4.781526, loss_D: 0.062816\n",
      "[Epoch 4/200] [Batch 880/938] loss_G: 5.059217, loss_D: 0.098455\n",
      "[Epoch 4/200] [Batch 890/938] loss_G: 4.564018, loss_D: 0.033779\n",
      "[Epoch 4/200] [Batch 900/938] loss_G: 4.425003, loss_D: 0.137793\n",
      "[Epoch 4/200] [Batch 910/938] loss_G: 4.245911, loss_D: 0.109502\n",
      "[Epoch 4/200] [Batch 920/938] loss_G: 4.700039, loss_D: 0.066823\n",
      "[Epoch 4/200] [Batch 930/938] loss_G: 4.481077, loss_D: 0.070801\n",
      "[Epoch 5/200] [Batch 0/938] loss_G: 2.681078, loss_D: 0.161050\n",
      "[Epoch 5/200] [Batch 10/938] loss_G: 4.208683, loss_D: 0.113679\n",
      "[Epoch 5/200] [Batch 20/938] loss_G: 4.450391, loss_D: 0.137757\n",
      "[Epoch 5/200] [Batch 30/938] loss_G: 3.768392, loss_D: 0.115390\n",
      "[Epoch 5/200] [Batch 40/938] loss_G: 4.015481, loss_D: 0.050813\n",
      "[Epoch 5/200] [Batch 50/938] loss_G: 4.950756, loss_D: 0.126178\n",
      "[Epoch 5/200] [Batch 60/938] loss_G: 5.075036, loss_D: 0.119632\n",
      "[Epoch 5/200] [Batch 70/938] loss_G: 5.021294, loss_D: 0.069775\n",
      "[Epoch 5/200] [Batch 80/938] loss_G: 3.390939, loss_D: 0.116706\n",
      "[Epoch 5/200] [Batch 90/938] loss_G: 2.908149, loss_D: 0.151905\n",
      "[Epoch 5/200] [Batch 100/938] loss_G: 3.194986, loss_D: 0.058651\n",
      "[Epoch 5/200] [Batch 110/938] loss_G: 4.066372, loss_D: 0.128661\n",
      "[Epoch 5/200] [Batch 120/938] loss_G: 4.761403, loss_D: 0.041377\n",
      "[Epoch 5/200] [Batch 130/938] loss_G: 4.934801, loss_D: 0.046477\n",
      "[Epoch 5/200] [Batch 140/938] loss_G: 4.926750, loss_D: 0.090051\n",
      "[Epoch 5/200] [Batch 150/938] loss_G: 4.504691, loss_D: 0.061308\n",
      "[Epoch 5/200] [Batch 160/938] loss_G: 4.663635, loss_D: 0.038145\n",
      "[Epoch 5/200] [Batch 170/938] loss_G: 4.878201, loss_D: 0.077745\n",
      "[Epoch 5/200] [Batch 180/938] loss_G: 4.439524, loss_D: 0.094076\n",
      "[Epoch 5/200] [Batch 190/938] loss_G: 5.203431, loss_D: 0.157601\n",
      "[Epoch 5/200] [Batch 200/938] loss_G: 4.844438, loss_D: 0.115092\n",
      "[Epoch 5/200] [Batch 210/938] loss_G: 5.052601, loss_D: 0.062881\n",
      "[Epoch 5/200] [Batch 220/938] loss_G: 4.113566, loss_D: 0.108685\n",
      "[Epoch 5/200] [Batch 230/938] loss_G: 4.296807, loss_D: 0.137804\n",
      "[Epoch 5/200] [Batch 240/938] loss_G: 5.589599, loss_D: 0.040984\n",
      "[Epoch 5/200] [Batch 250/938] loss_G: 4.456373, loss_D: 0.057863\n",
      "[Epoch 5/200] [Batch 260/938] loss_G: 3.907098, loss_D: 0.124927\n",
      "[Epoch 5/200] [Batch 270/938] loss_G: 4.289527, loss_D: 0.076248\n",
      "[Epoch 5/200] [Batch 280/938] loss_G: 3.518569, loss_D: 0.140548\n",
      "[Epoch 5/200] [Batch 290/938] loss_G: 4.228768, loss_D: 0.041664\n",
      "[Epoch 5/200] [Batch 300/938] loss_G: 3.879900, loss_D: 0.131894\n",
      "[Epoch 5/200] [Batch 310/938] loss_G: 3.592891, loss_D: 0.071302\n",
      "[Epoch 5/200] [Batch 320/938] loss_G: 3.390597, loss_D: 0.083862\n",
      "[Epoch 5/200] [Batch 330/938] loss_G: 3.709713, loss_D: 0.132030\n",
      "[Epoch 5/200] [Batch 340/938] loss_G: 4.393656, loss_D: 0.047111\n",
      "[Epoch 5/200] [Batch 350/938] loss_G: 3.743039, loss_D: 0.041513\n",
      "[Epoch 5/200] [Batch 360/938] loss_G: 3.933189, loss_D: 0.083271\n",
      "[Epoch 5/200] [Batch 370/938] loss_G: 3.468310, loss_D: 0.064235\n",
      "[Epoch 5/200] [Batch 380/938] loss_G: 4.464681, loss_D: 0.109014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/200] [Batch 390/938] loss_G: 3.842458, loss_D: 0.077458\n",
      "[Epoch 5/200] [Batch 400/938] loss_G: 4.516842, loss_D: 0.041502\n",
      "[Epoch 5/200] [Batch 410/938] loss_G: 4.587695, loss_D: 0.046560\n",
      "[Epoch 5/200] [Batch 420/938] loss_G: 4.467386, loss_D: 0.081908\n",
      "[Epoch 5/200] [Batch 430/938] loss_G: 3.119454, loss_D: 0.101503\n",
      "[Epoch 5/200] [Batch 440/938] loss_G: 3.861745, loss_D: 0.083118\n",
      "[Epoch 5/200] [Batch 450/938] loss_G: 4.326084, loss_D: 0.104104\n",
      "[Epoch 5/200] [Batch 460/938] loss_G: 4.026845, loss_D: 0.117096\n",
      "[Epoch 5/200] [Batch 470/938] loss_G: 5.153755, loss_D: 0.053029\n",
      "[Epoch 5/200] [Batch 480/938] loss_G: 4.414168, loss_D: 0.073768\n",
      "[Epoch 5/200] [Batch 490/938] loss_G: 3.873950, loss_D: 0.058457\n",
      "[Epoch 5/200] [Batch 500/938] loss_G: 4.212194, loss_D: 0.125696\n",
      "[Epoch 5/200] [Batch 510/938] loss_G: 3.949207, loss_D: 0.067529\n",
      "[Epoch 5/200] [Batch 520/938] loss_G: 4.529775, loss_D: 0.041879\n",
      "[Epoch 5/200] [Batch 530/938] loss_G: 4.491733, loss_D: 0.053422\n",
      "[Epoch 5/200] [Batch 540/938] loss_G: 4.521369, loss_D: 0.105796\n",
      "[Epoch 5/200] [Batch 550/938] loss_G: 3.924180, loss_D: 0.123808\n",
      "[Epoch 5/200] [Batch 560/938] loss_G: 3.803757, loss_D: 0.135554\n",
      "[Epoch 5/200] [Batch 570/938] loss_G: 4.024129, loss_D: 0.129636\n",
      "[Epoch 5/200] [Batch 580/938] loss_G: 4.747471, loss_D: 0.073383\n",
      "[Epoch 5/200] [Batch 590/938] loss_G: 4.183432, loss_D: 0.040126\n",
      "[Epoch 5/200] [Batch 600/938] loss_G: 4.413228, loss_D: 0.091705\n",
      "[Epoch 5/200] [Batch 610/938] loss_G: 4.268053, loss_D: 0.131022\n",
      "[Epoch 5/200] [Batch 620/938] loss_G: 3.746242, loss_D: 0.145090\n",
      "[Epoch 5/200] [Batch 630/938] loss_G: 4.518789, loss_D: 0.046116\n",
      "[Epoch 5/200] [Batch 640/938] loss_G: 4.380711, loss_D: 0.050970\n",
      "[Epoch 5/200] [Batch 650/938] loss_G: 3.653466, loss_D: 0.102731\n",
      "[Epoch 5/200] [Batch 660/938] loss_G: 4.602812, loss_D: 0.192892\n",
      "[Epoch 5/200] [Batch 670/938] loss_G: 4.855737, loss_D: 0.068937\n",
      "[Epoch 5/200] [Batch 680/938] loss_G: 4.456096, loss_D: 0.048683\n",
      "[Epoch 5/200] [Batch 690/938] loss_G: 4.230772, loss_D: 0.093162\n",
      "[Epoch 5/200] [Batch 700/938] loss_G: 5.540589, loss_D: 0.062147\n",
      "[Epoch 5/200] [Batch 710/938] loss_G: 4.037449, loss_D: 0.059118\n",
      "[Epoch 5/200] [Batch 720/938] loss_G: 3.845893, loss_D: 0.072598\n",
      "[Epoch 5/200] [Batch 730/938] loss_G: 4.252748, loss_D: 0.097659\n",
      "[Epoch 5/200] [Batch 740/938] loss_G: 4.835933, loss_D: 0.071773\n",
      "[Epoch 5/200] [Batch 750/938] loss_G: 3.877350, loss_D: 0.038915\n",
      "[Epoch 5/200] [Batch 760/938] loss_G: 3.503587, loss_D: 0.135595\n",
      "[Epoch 5/200] [Batch 770/938] loss_G: 4.642158, loss_D: 0.035002\n",
      "[Epoch 5/200] [Batch 780/938] loss_G: 4.309334, loss_D: 0.068207\n",
      "[Epoch 5/200] [Batch 790/938] loss_G: 4.300492, loss_D: 0.164571\n",
      "[Epoch 5/200] [Batch 800/938] loss_G: 4.222839, loss_D: 0.103440\n",
      "[Epoch 5/200] [Batch 810/938] loss_G: 4.496762, loss_D: 0.042691\n",
      "[Epoch 5/200] [Batch 820/938] loss_G: 4.290392, loss_D: 0.124171\n",
      "[Epoch 5/200] [Batch 830/938] loss_G: 4.024763, loss_D: 0.056117\n",
      "[Epoch 5/200] [Batch 840/938] loss_G: 4.470448, loss_D: 0.041883\n",
      "[Epoch 5/200] [Batch 850/938] loss_G: 4.720389, loss_D: 0.060264\n",
      "[Epoch 5/200] [Batch 860/938] loss_G: 3.924310, loss_D: 0.142304\n",
      "[Epoch 5/200] [Batch 870/938] loss_G: 4.424761, loss_D: 0.062526\n",
      "[Epoch 5/200] [Batch 880/938] loss_G: 3.542855, loss_D: 0.156474\n",
      "[Epoch 5/200] [Batch 890/938] loss_G: 3.420510, loss_D: 0.070137\n",
      "[Epoch 5/200] [Batch 900/938] loss_G: 4.440665, loss_D: 0.101098\n",
      "[Epoch 5/200] [Batch 910/938] loss_G: 4.597330, loss_D: 0.059843\n",
      "[Epoch 5/200] [Batch 920/938] loss_G: 4.327070, loss_D: 0.128767\n",
      "[Epoch 5/200] [Batch 930/938] loss_G: 4.167556, loss_D: 0.076325\n",
      "[Epoch 6/200] [Batch 0/938] loss_G: 3.307907, loss_D: 0.063604\n",
      "[Epoch 6/200] [Batch 10/938] loss_G: 5.235564, loss_D: 0.018774\n",
      "[Epoch 6/200] [Batch 20/938] loss_G: 5.013704, loss_D: 0.073849\n",
      "[Epoch 6/200] [Batch 30/938] loss_G: 4.258539, loss_D: 0.046429\n",
      "[Epoch 6/200] [Batch 40/938] loss_G: 5.139843, loss_D: 0.090735\n",
      "[Epoch 6/200] [Batch 50/938] loss_G: 4.556745, loss_D: 0.094399\n",
      "[Epoch 6/200] [Batch 60/938] loss_G: 3.768642, loss_D: 0.101728\n",
      "[Epoch 6/200] [Batch 70/938] loss_G: 4.243155, loss_D: 0.076862\n",
      "[Epoch 6/200] [Batch 80/938] loss_G: 4.883265, loss_D: 0.082452\n",
      "[Epoch 6/200] [Batch 90/938] loss_G: 5.349568, loss_D: 0.077286\n",
      "[Epoch 6/200] [Batch 100/938] loss_G: 5.149359, loss_D: 0.040071\n",
      "[Epoch 6/200] [Batch 110/938] loss_G: 4.313294, loss_D: 0.100981\n",
      "[Epoch 6/200] [Batch 120/938] loss_G: 3.901602, loss_D: 0.111441\n",
      "[Epoch 6/200] [Batch 130/938] loss_G: 3.968020, loss_D: 0.072546\n",
      "[Epoch 6/200] [Batch 140/938] loss_G: 4.161188, loss_D: 0.076642\n",
      "[Epoch 6/200] [Batch 150/938] loss_G: 4.445318, loss_D: 0.083445\n",
      "[Epoch 6/200] [Batch 160/938] loss_G: 5.325933, loss_D: 0.047401\n",
      "[Epoch 6/200] [Batch 170/938] loss_G: 4.297482, loss_D: 0.140093\n",
      "[Epoch 6/200] [Batch 180/938] loss_G: 3.736580, loss_D: 0.041021\n",
      "[Epoch 6/200] [Batch 190/938] loss_G: 5.451679, loss_D: 0.091165\n",
      "[Epoch 6/200] [Batch 200/938] loss_G: 4.622061, loss_D: 0.068306\n",
      "[Epoch 6/200] [Batch 210/938] loss_G: 4.432896, loss_D: 0.058529\n",
      "[Epoch 6/200] [Batch 220/938] loss_G: 3.750158, loss_D: 0.137367\n",
      "[Epoch 6/200] [Batch 230/938] loss_G: 4.082303, loss_D: 0.111166\n",
      "[Epoch 6/200] [Batch 240/938] loss_G: 3.875144, loss_D: 0.041720\n",
      "[Epoch 6/200] [Batch 250/938] loss_G: 4.014011, loss_D: 0.089478\n",
      "[Epoch 6/200] [Batch 260/938] loss_G: 4.043238, loss_D: 0.068990\n",
      "[Epoch 6/200] [Batch 270/938] loss_G: 5.160692, loss_D: 0.057280\n",
      "[Epoch 6/200] [Batch 280/938] loss_G: 3.765928, loss_D: 0.035821\n",
      "[Epoch 6/200] [Batch 290/938] loss_G: 4.849931, loss_D: 0.032082\n",
      "[Epoch 6/200] [Batch 300/938] loss_G: 4.194385, loss_D: 0.141279\n",
      "[Epoch 6/200] [Batch 310/938] loss_G: 4.216584, loss_D: 0.066564\n",
      "[Epoch 6/200] [Batch 320/938] loss_G: 4.223501, loss_D: 0.045947\n",
      "[Epoch 6/200] [Batch 330/938] loss_G: 3.951150, loss_D: 0.106930\n",
      "[Epoch 6/200] [Batch 340/938] loss_G: 4.202108, loss_D: 0.060991\n",
      "[Epoch 6/200] [Batch 350/938] loss_G: 4.292021, loss_D: 0.089905\n",
      "[Epoch 6/200] [Batch 360/938] loss_G: 4.526546, loss_D: 0.047181\n",
      "[Epoch 6/200] [Batch 370/938] loss_G: 4.236086, loss_D: 0.085052\n",
      "[Epoch 6/200] [Batch 380/938] loss_G: 4.657020, loss_D: 0.065399\n",
      "[Epoch 6/200] [Batch 390/938] loss_G: 3.678208, loss_D: 0.080059\n",
      "[Epoch 6/200] [Batch 400/938] loss_G: 4.797859, loss_D: 0.111830\n",
      "[Epoch 6/200] [Batch 410/938] loss_G: 3.722705, loss_D: 0.108760\n",
      "[Epoch 6/200] [Batch 420/938] loss_G: 4.170717, loss_D: 0.048040\n",
      "[Epoch 6/200] [Batch 430/938] loss_G: 3.904472, loss_D: 0.096299\n",
      "[Epoch 6/200] [Batch 440/938] loss_G: 4.354051, loss_D: 0.090882\n",
      "[Epoch 6/200] [Batch 450/938] loss_G: 4.064275, loss_D: 0.115188\n",
      "[Epoch 6/200] [Batch 460/938] loss_G: 4.617043, loss_D: 0.063146\n",
      "[Epoch 6/200] [Batch 470/938] loss_G: 4.297007, loss_D: 0.029882\n",
      "[Epoch 6/200] [Batch 480/938] loss_G: 4.202888, loss_D: 0.150780\n",
      "[Epoch 6/200] [Batch 490/938] loss_G: 4.480107, loss_D: 0.057629\n",
      "[Epoch 6/200] [Batch 500/938] loss_G: 4.158931, loss_D: 0.117949\n",
      "[Epoch 6/200] [Batch 510/938] loss_G: 3.898984, loss_D: 0.121153\n",
      "[Epoch 6/200] [Batch 520/938] loss_G: 4.365263, loss_D: 0.047369\n",
      "[Epoch 6/200] [Batch 530/938] loss_G: 3.957099, loss_D: 0.071929\n",
      "[Epoch 6/200] [Batch 540/938] loss_G: 4.302380, loss_D: 0.087700\n",
      "[Epoch 6/200] [Batch 550/938] loss_G: 4.035864, loss_D: 0.107363\n",
      "[Epoch 6/200] [Batch 560/938] loss_G: 3.790499, loss_D: 0.061079\n",
      "[Epoch 6/200] [Batch 570/938] loss_G: 3.688172, loss_D: 0.080130\n",
      "[Epoch 6/200] [Batch 580/938] loss_G: 4.125348, loss_D: 0.097516\n",
      "[Epoch 6/200] [Batch 590/938] loss_G: 4.307400, loss_D: 0.115149\n",
      "[Epoch 6/200] [Batch 600/938] loss_G: 5.412594, loss_D: 0.085750\n",
      "[Epoch 6/200] [Batch 610/938] loss_G: 4.915873, loss_D: 0.073740\n",
      "[Epoch 6/200] [Batch 620/938] loss_G: 4.016729, loss_D: 0.029956\n",
      "[Epoch 6/200] [Batch 630/938] loss_G: 4.342277, loss_D: 0.136698\n",
      "[Epoch 6/200] [Batch 640/938] loss_G: 3.358278, loss_D: 0.128815\n",
      "[Epoch 6/200] [Batch 650/938] loss_G: 3.583618, loss_D: 0.218470\n",
      "[Epoch 6/200] [Batch 660/938] loss_G: 4.580632, loss_D: 0.061172\n",
      "[Epoch 6/200] [Batch 670/938] loss_G: 4.498593, loss_D: 0.099602\n",
      "[Epoch 6/200] [Batch 680/938] loss_G: 4.600528, loss_D: 0.053631\n",
      "[Epoch 6/200] [Batch 690/938] loss_G: 4.762596, loss_D: 0.064033\n",
      "[Epoch 6/200] [Batch 700/938] loss_G: 3.695983, loss_D: 0.095132\n",
      "[Epoch 6/200] [Batch 710/938] loss_G: 3.950603, loss_D: 0.184398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/200] [Batch 720/938] loss_G: 3.894314, loss_D: 0.206778\n",
      "[Epoch 6/200] [Batch 730/938] loss_G: 4.384395, loss_D: 0.066216\n",
      "[Epoch 6/200] [Batch 740/938] loss_G: 4.189514, loss_D: 0.046031\n",
      "[Epoch 6/200] [Batch 750/938] loss_G: 3.703839, loss_D: 0.080448\n",
      "[Epoch 6/200] [Batch 760/938] loss_G: 3.966189, loss_D: 0.086788\n",
      "[Epoch 6/200] [Batch 770/938] loss_G: 4.288933, loss_D: 0.071195\n",
      "[Epoch 6/200] [Batch 780/938] loss_G: 3.618999, loss_D: 0.118945\n",
      "[Epoch 6/200] [Batch 790/938] loss_G: 4.115332, loss_D: 0.047320\n",
      "[Epoch 6/200] [Batch 800/938] loss_G: 4.000480, loss_D: 0.034159\n",
      "[Epoch 6/200] [Batch 810/938] loss_G: 3.874892, loss_D: 0.079932\n",
      "[Epoch 6/200] [Batch 820/938] loss_G: 3.410522, loss_D: 0.110686\n",
      "[Epoch 6/200] [Batch 830/938] loss_G: 4.243672, loss_D: 0.069624\n",
      "[Epoch 6/200] [Batch 840/938] loss_G: 4.730143, loss_D: 0.047431\n",
      "[Epoch 6/200] [Batch 850/938] loss_G: 4.612368, loss_D: 0.129201\n",
      "[Epoch 6/200] [Batch 860/938] loss_G: 4.097874, loss_D: 0.064098\n",
      "[Epoch 6/200] [Batch 870/938] loss_G: 3.800627, loss_D: 0.069433\n",
      "[Epoch 6/200] [Batch 880/938] loss_G: 4.508758, loss_D: 0.077994\n",
      "[Epoch 6/200] [Batch 890/938] loss_G: 4.377788, loss_D: 0.109371\n",
      "[Epoch 6/200] [Batch 900/938] loss_G: 3.693752, loss_D: 0.060565\n",
      "[Epoch 6/200] [Batch 910/938] loss_G: 3.964532, loss_D: 0.101401\n",
      "[Epoch 6/200] [Batch 920/938] loss_G: 4.248792, loss_D: 0.052308\n",
      "[Epoch 6/200] [Batch 930/938] loss_G: 4.155293, loss_D: 0.050004\n",
      "[Epoch 7/200] [Batch 0/938] loss_G: 4.407666, loss_D: 0.058457\n",
      "[Epoch 7/200] [Batch 10/938] loss_G: 3.947057, loss_D: 0.126208\n",
      "[Epoch 7/200] [Batch 20/938] loss_G: 4.390687, loss_D: 0.061359\n",
      "[Epoch 7/200] [Batch 30/938] loss_G: 4.610285, loss_D: 0.077867\n",
      "[Epoch 7/200] [Batch 40/938] loss_G: 4.377953, loss_D: 0.052437\n",
      "[Epoch 7/200] [Batch 50/938] loss_G: 3.825255, loss_D: 0.065779\n",
      "[Epoch 7/200] [Batch 60/938] loss_G: 4.039907, loss_D: 0.131539\n",
      "[Epoch 7/200] [Batch 70/938] loss_G: 3.856137, loss_D: 0.101415\n",
      "[Epoch 7/200] [Batch 80/938] loss_G: 3.741510, loss_D: 0.169068\n",
      "[Epoch 7/200] [Batch 90/938] loss_G: 4.440258, loss_D: 0.025945\n",
      "[Epoch 7/200] [Batch 100/938] loss_G: 4.470492, loss_D: 0.114609\n",
      "[Epoch 7/200] [Batch 110/938] loss_G: 4.956077, loss_D: 0.112132\n",
      "[Epoch 7/200] [Batch 120/938] loss_G: 4.587926, loss_D: 0.084945\n",
      "[Epoch 7/200] [Batch 130/938] loss_G: 4.782258, loss_D: 0.088445\n",
      "[Epoch 7/200] [Batch 140/938] loss_G: 4.113042, loss_D: 0.091185\n",
      "[Epoch 7/200] [Batch 150/938] loss_G: 3.629067, loss_D: 0.129035\n",
      "[Epoch 7/200] [Batch 160/938] loss_G: 4.822578, loss_D: 0.052744\n",
      "[Epoch 7/200] [Batch 170/938] loss_G: 4.833496, loss_D: 0.089923\n",
      "[Epoch 7/200] [Batch 180/938] loss_G: 3.532971, loss_D: 0.195922\n",
      "[Epoch 7/200] [Batch 190/938] loss_G: 3.633830, loss_D: 0.101596\n",
      "[Epoch 7/200] [Batch 200/938] loss_G: 4.843715, loss_D: 0.031724\n",
      "[Epoch 7/200] [Batch 210/938] loss_G: 4.059825, loss_D: 0.117665\n",
      "[Epoch 7/200] [Batch 220/938] loss_G: 4.449473, loss_D: 0.059118\n",
      "[Epoch 7/200] [Batch 230/938] loss_G: 5.005019, loss_D: 0.094686\n",
      "[Epoch 7/200] [Batch 240/938] loss_G: 4.177135, loss_D: 0.067658\n",
      "[Epoch 7/200] [Batch 250/938] loss_G: 3.623715, loss_D: 0.081457\n",
      "[Epoch 7/200] [Batch 260/938] loss_G: 3.525876, loss_D: 0.072341\n",
      "[Epoch 7/200] [Batch 270/938] loss_G: 5.110274, loss_D: 0.116438\n",
      "[Epoch 7/200] [Batch 280/938] loss_G: 3.520439, loss_D: 0.070999\n",
      "[Epoch 7/200] [Batch 290/938] loss_G: 3.778337, loss_D: 0.111683\n",
      "[Epoch 7/200] [Batch 300/938] loss_G: 4.798760, loss_D: 0.093168\n",
      "[Epoch 7/200] [Batch 310/938] loss_G: 4.619885, loss_D: 0.082261\n",
      "[Epoch 7/200] [Batch 320/938] loss_G: 3.943162, loss_D: 0.182684\n",
      "[Epoch 7/200] [Batch 330/938] loss_G: 4.664446, loss_D: 0.077478\n",
      "[Epoch 7/200] [Batch 340/938] loss_G: 4.298893, loss_D: 0.124222\n",
      "[Epoch 7/200] [Batch 350/938] loss_G: 3.536356, loss_D: 0.173224\n",
      "[Epoch 7/200] [Batch 360/938] loss_G: 4.552985, loss_D: 0.061282\n",
      "[Epoch 7/200] [Batch 370/938] loss_G: 3.769025, loss_D: 0.046376\n",
      "[Epoch 7/200] [Batch 380/938] loss_G: 3.887169, loss_D: 0.081020\n",
      "[Epoch 7/200] [Batch 390/938] loss_G: 5.060870, loss_D: 0.013722\n",
      "[Epoch 7/200] [Batch 400/938] loss_G: 3.650953, loss_D: 0.088452\n",
      "[Epoch 7/200] [Batch 410/938] loss_G: 4.159516, loss_D: 0.147500\n",
      "[Epoch 7/200] [Batch 420/938] loss_G: 4.463299, loss_D: 0.079181\n",
      "[Epoch 7/200] [Batch 430/938] loss_G: 3.927005, loss_D: 0.082630\n",
      "[Epoch 7/200] [Batch 440/938] loss_G: 3.459655, loss_D: 0.115195\n",
      "[Epoch 7/200] [Batch 450/938] loss_G: 5.065210, loss_D: 0.048553\n",
      "[Epoch 7/200] [Batch 460/938] loss_G: 4.593767, loss_D: 0.065161\n",
      "[Epoch 7/200] [Batch 470/938] loss_G: 3.204350, loss_D: 0.145248\n",
      "[Epoch 7/200] [Batch 480/938] loss_G: 4.053550, loss_D: 0.129582\n",
      "[Epoch 7/200] [Batch 490/938] loss_G: 4.407372, loss_D: 0.083665\n",
      "[Epoch 7/200] [Batch 500/938] loss_G: 4.576217, loss_D: 0.081821\n",
      "[Epoch 7/200] [Batch 510/938] loss_G: 4.837955, loss_D: 0.107718\n",
      "[Epoch 7/200] [Batch 520/938] loss_G: 3.573926, loss_D: 0.076593\n",
      "[Epoch 7/200] [Batch 530/938] loss_G: 3.719753, loss_D: 0.056832\n",
      "[Epoch 7/200] [Batch 540/938] loss_G: 4.110225, loss_D: 0.091056\n",
      "[Epoch 7/200] [Batch 550/938] loss_G: 4.159526, loss_D: 0.031274\n",
      "[Epoch 7/200] [Batch 560/938] loss_G: 3.633553, loss_D: 0.066698\n",
      "[Epoch 7/200] [Batch 570/938] loss_G: 5.024115, loss_D: 0.061699\n",
      "[Epoch 7/200] [Batch 580/938] loss_G: 4.019495, loss_D: 0.055875\n",
      "[Epoch 7/200] [Batch 590/938] loss_G: 4.119302, loss_D: 0.073456\n",
      "[Epoch 7/200] [Batch 600/938] loss_G: 3.832865, loss_D: 0.100437\n",
      "[Epoch 7/200] [Batch 610/938] loss_G: 4.414172, loss_D: 0.146574\n",
      "[Epoch 7/200] [Batch 620/938] loss_G: 4.069252, loss_D: 0.054865\n",
      "[Epoch 7/200] [Batch 630/938] loss_G: 4.179236, loss_D: 0.066676\n",
      "[Epoch 7/200] [Batch 640/938] loss_G: 4.468194, loss_D: 0.137518\n",
      "[Epoch 7/200] [Batch 650/938] loss_G: 4.006572, loss_D: 0.048178\n",
      "[Epoch 7/200] [Batch 660/938] loss_G: 4.197353, loss_D: 0.097208\n",
      "[Epoch 7/200] [Batch 670/938] loss_G: 4.331044, loss_D: 0.072694\n",
      "[Epoch 7/200] [Batch 680/938] loss_G: 3.578748, loss_D: 0.122802\n",
      "[Epoch 7/200] [Batch 690/938] loss_G: 3.740431, loss_D: 0.114323\n",
      "[Epoch 7/200] [Batch 700/938] loss_G: 3.573034, loss_D: 0.119507\n",
      "[Epoch 7/200] [Batch 710/938] loss_G: 4.559649, loss_D: 0.087617\n",
      "[Epoch 7/200] [Batch 720/938] loss_G: 4.320865, loss_D: 0.168124\n",
      "[Epoch 7/200] [Batch 730/938] loss_G: 4.748902, loss_D: 0.041530\n",
      "[Epoch 7/200] [Batch 740/938] loss_G: 4.310623, loss_D: 0.054506\n",
      "[Epoch 7/200] [Batch 750/938] loss_G: 4.727006, loss_D: 0.121385\n",
      "[Epoch 7/200] [Batch 760/938] loss_G: 3.756563, loss_D: 0.093278\n",
      "[Epoch 7/200] [Batch 770/938] loss_G: 4.451876, loss_D: 0.036611\n",
      "[Epoch 7/200] [Batch 780/938] loss_G: 4.139880, loss_D: 0.133896\n",
      "[Epoch 7/200] [Batch 790/938] loss_G: 4.828399, loss_D: 0.140478\n",
      "[Epoch 7/200] [Batch 800/938] loss_G: 5.481586, loss_D: 0.110461\n",
      "[Epoch 7/200] [Batch 810/938] loss_G: 3.891082, loss_D: 0.061549\n",
      "[Epoch 7/200] [Batch 820/938] loss_G: 3.978650, loss_D: 0.133776\n",
      "[Epoch 7/200] [Batch 830/938] loss_G: 4.375653, loss_D: 0.025836\n",
      "[Epoch 7/200] [Batch 840/938] loss_G: 4.254865, loss_D: 0.042506\n",
      "[Epoch 7/200] [Batch 850/938] loss_G: 4.083724, loss_D: 0.140063\n",
      "[Epoch 7/200] [Batch 860/938] loss_G: 4.919560, loss_D: 0.111484\n",
      "[Epoch 7/200] [Batch 870/938] loss_G: 5.142216, loss_D: 0.055888\n",
      "[Epoch 7/200] [Batch 880/938] loss_G: 4.666116, loss_D: 0.069706\n",
      "[Epoch 7/200] [Batch 890/938] loss_G: 4.602202, loss_D: 0.071400\n",
      "[Epoch 7/200] [Batch 900/938] loss_G: 4.954305, loss_D: 0.076947\n",
      "[Epoch 7/200] [Batch 910/938] loss_G: 4.264359, loss_D: 0.036740\n",
      "[Epoch 7/200] [Batch 920/938] loss_G: 4.703612, loss_D: 0.103024\n",
      "[Epoch 7/200] [Batch 930/938] loss_G: 4.744563, loss_D: 0.112881\n",
      "[Epoch 8/200] [Batch 0/938] loss_G: 3.621905, loss_D: 0.068431\n",
      "[Epoch 8/200] [Batch 10/938] loss_G: 4.857654, loss_D: 0.106101\n",
      "[Epoch 8/200] [Batch 20/938] loss_G: 4.229210, loss_D: 0.074767\n",
      "[Epoch 8/200] [Batch 30/938] loss_G: 3.723053, loss_D: 0.160225\n",
      "[Epoch 8/200] [Batch 40/938] loss_G: 4.243874, loss_D: 0.069531\n",
      "[Epoch 8/200] [Batch 50/938] loss_G: 4.550214, loss_D: 0.051132\n",
      "[Epoch 8/200] [Batch 60/938] loss_G: 3.863054, loss_D: 0.151516\n",
      "[Epoch 8/200] [Batch 70/938] loss_G: 4.076397, loss_D: 0.038489\n",
      "[Epoch 8/200] [Batch 80/938] loss_G: 4.390533, loss_D: 0.084349\n",
      "[Epoch 8/200] [Batch 90/938] loss_G: 4.297631, loss_D: 0.119862\n",
      "[Epoch 8/200] [Batch 100/938] loss_G: 4.390646, loss_D: 0.044293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/200] [Batch 110/938] loss_G: 4.007702, loss_D: 0.171940\n",
      "[Epoch 8/200] [Batch 120/938] loss_G: 4.621639, loss_D: 0.059447\n",
      "[Epoch 8/200] [Batch 130/938] loss_G: 4.944177, loss_D: 0.081962\n",
      "[Epoch 8/200] [Batch 140/938] loss_G: 4.012628, loss_D: 0.119776\n",
      "[Epoch 8/200] [Batch 150/938] loss_G: 4.299732, loss_D: 0.051799\n",
      "[Epoch 8/200] [Batch 160/938] loss_G: 3.930598, loss_D: 0.057457\n",
      "[Epoch 8/200] [Batch 170/938] loss_G: 3.974014, loss_D: 0.118930\n",
      "[Epoch 8/200] [Batch 180/938] loss_G: 4.444620, loss_D: 0.105868\n",
      "[Epoch 8/200] [Batch 190/938] loss_G: 4.427369, loss_D: 0.092737\n",
      "[Epoch 8/200] [Batch 200/938] loss_G: 4.659076, loss_D: 0.067965\n",
      "[Epoch 8/200] [Batch 210/938] loss_G: 3.864879, loss_D: 0.135054\n",
      "[Epoch 8/200] [Batch 220/938] loss_G: 4.567395, loss_D: 0.100793\n",
      "[Epoch 8/200] [Batch 230/938] loss_G: 4.725262, loss_D: 0.050209\n",
      "[Epoch 8/200] [Batch 240/938] loss_G: 5.327128, loss_D: 0.084870\n",
      "[Epoch 8/200] [Batch 250/938] loss_G: 4.259110, loss_D: 0.120728\n",
      "[Epoch 8/200] [Batch 260/938] loss_G: 5.515543, loss_D: 0.129794\n",
      "[Epoch 8/200] [Batch 270/938] loss_G: 4.169873, loss_D: 0.101963\n",
      "[Epoch 8/200] [Batch 280/938] loss_G: 5.197342, loss_D: 0.087130\n",
      "[Epoch 8/200] [Batch 290/938] loss_G: 4.912313, loss_D: 0.035144\n",
      "[Epoch 8/200] [Batch 300/938] loss_G: 4.154827, loss_D: 0.089568\n",
      "[Epoch 8/200] [Batch 310/938] loss_G: 4.220890, loss_D: 0.045025\n",
      "[Epoch 8/200] [Batch 320/938] loss_G: 4.075155, loss_D: 0.101256\n",
      "[Epoch 8/200] [Batch 330/938] loss_G: 4.144382, loss_D: 0.107421\n",
      "[Epoch 8/200] [Batch 340/938] loss_G: 4.558195, loss_D: 0.108941\n",
      "[Epoch 8/200] [Batch 350/938] loss_G: 4.435473, loss_D: 0.148563\n",
      "[Epoch 8/200] [Batch 360/938] loss_G: 5.121902, loss_D: 0.047821\n",
      "[Epoch 8/200] [Batch 370/938] loss_G: 4.403275, loss_D: 0.088123\n",
      "[Epoch 8/200] [Batch 380/938] loss_G: 5.247447, loss_D: 0.052394\n",
      "[Epoch 8/200] [Batch 390/938] loss_G: 4.548071, loss_D: 0.032863\n",
      "[Epoch 8/200] [Batch 400/938] loss_G: 4.777822, loss_D: 0.071238\n",
      "[Epoch 8/200] [Batch 410/938] loss_G: 4.937095, loss_D: 0.036971\n",
      "[Epoch 8/200] [Batch 420/938] loss_G: 4.463298, loss_D: 0.113884\n",
      "[Epoch 8/200] [Batch 430/938] loss_G: 4.541255, loss_D: 0.090534\n",
      "[Epoch 8/200] [Batch 440/938] loss_G: 4.923340, loss_D: 0.075284\n",
      "[Epoch 8/200] [Batch 450/938] loss_G: 4.111446, loss_D: 0.095517\n",
      "[Epoch 8/200] [Batch 460/938] loss_G: 4.275574, loss_D: 0.126479\n",
      "[Epoch 8/200] [Batch 470/938] loss_G: 4.504549, loss_D: 0.095021\n",
      "[Epoch 8/200] [Batch 480/938] loss_G: 4.348900, loss_D: 0.090042\n",
      "[Epoch 8/200] [Batch 490/938] loss_G: 5.416546, loss_D: 0.050476\n",
      "[Epoch 8/200] [Batch 500/938] loss_G: 4.457787, loss_D: 0.092219\n",
      "[Epoch 8/200] [Batch 510/938] loss_G: 3.541770, loss_D: 0.177563\n",
      "[Epoch 8/200] [Batch 520/938] loss_G: 5.139033, loss_D: 0.115182\n",
      "[Epoch 8/200] [Batch 530/938] loss_G: 3.679174, loss_D: 0.094744\n",
      "[Epoch 8/200] [Batch 540/938] loss_G: 3.842694, loss_D: 0.143898\n",
      "[Epoch 8/200] [Batch 550/938] loss_G: 4.618996, loss_D: 0.081116\n",
      "[Epoch 8/200] [Batch 560/938] loss_G: 4.199267, loss_D: 0.059451\n",
      "[Epoch 8/200] [Batch 570/938] loss_G: 4.411445, loss_D: 0.086899\n",
      "[Epoch 8/200] [Batch 580/938] loss_G: 3.706741, loss_D: 0.101323\n",
      "[Epoch 8/200] [Batch 590/938] loss_G: 3.743301, loss_D: 0.084880\n",
      "[Epoch 8/200] [Batch 600/938] loss_G: 4.455452, loss_D: 0.048175\n",
      "[Epoch 8/200] [Batch 610/938] loss_G: 4.396784, loss_D: 0.081629\n",
      "[Epoch 8/200] [Batch 620/938] loss_G: 3.484600, loss_D: 0.131172\n",
      "[Epoch 8/200] [Batch 630/938] loss_G: 4.696370, loss_D: 0.121732\n",
      "[Epoch 8/200] [Batch 640/938] loss_G: 4.188627, loss_D: 0.068532\n",
      "[Epoch 8/200] [Batch 650/938] loss_G: 3.962700, loss_D: 0.099075\n",
      "[Epoch 8/200] [Batch 660/938] loss_G: 4.450369, loss_D: 0.094801\n",
      "[Epoch 8/200] [Batch 670/938] loss_G: 3.921190, loss_D: 0.034239\n",
      "[Epoch 8/200] [Batch 680/938] loss_G: 5.010489, loss_D: 0.021365\n",
      "[Epoch 8/200] [Batch 690/938] loss_G: 4.128582, loss_D: 0.055888\n",
      "[Epoch 8/200] [Batch 700/938] loss_G: 4.592081, loss_D: 0.145691\n",
      "[Epoch 8/200] [Batch 710/938] loss_G: 4.077589, loss_D: 0.121302\n",
      "[Epoch 8/200] [Batch 720/938] loss_G: 4.042816, loss_D: 0.108757\n",
      "[Epoch 8/200] [Batch 730/938] loss_G: 4.482232, loss_D: 0.220003\n",
      "[Epoch 8/200] [Batch 740/938] loss_G: 4.196335, loss_D: 0.095834\n",
      "[Epoch 8/200] [Batch 750/938] loss_G: 4.569896, loss_D: 0.068827\n",
      "[Epoch 8/200] [Batch 760/938] loss_G: 4.680213, loss_D: 0.034346\n",
      "[Epoch 8/200] [Batch 770/938] loss_G: 4.201876, loss_D: 0.060918\n",
      "[Epoch 8/200] [Batch 780/938] loss_G: 4.809328, loss_D: 0.051230\n",
      "[Epoch 8/200] [Batch 790/938] loss_G: 4.049627, loss_D: 0.122390\n",
      "[Epoch 8/200] [Batch 800/938] loss_G: 3.926278, loss_D: 0.137371\n",
      "[Epoch 8/200] [Batch 810/938] loss_G: 3.692942, loss_D: 0.168186\n",
      "[Epoch 8/200] [Batch 820/938] loss_G: 5.088716, loss_D: 0.050204\n",
      "[Epoch 8/200] [Batch 830/938] loss_G: 4.121677, loss_D: 0.087788\n",
      "[Epoch 8/200] [Batch 840/938] loss_G: 4.114281, loss_D: 0.136847\n",
      "[Epoch 8/200] [Batch 850/938] loss_G: 4.799371, loss_D: 0.125283\n",
      "[Epoch 8/200] [Batch 860/938] loss_G: 4.140858, loss_D: 0.090036\n",
      "[Epoch 8/200] [Batch 870/938] loss_G: 3.987785, loss_D: 0.226876\n",
      "[Epoch 8/200] [Batch 880/938] loss_G: 4.832718, loss_D: 0.029428\n",
      "[Epoch 8/200] [Batch 890/938] loss_G: 4.216792, loss_D: 0.081150\n",
      "[Epoch 8/200] [Batch 900/938] loss_G: 4.024248, loss_D: 0.070347\n",
      "[Epoch 8/200] [Batch 910/938] loss_G: 4.154387, loss_D: 0.098506\n",
      "[Epoch 8/200] [Batch 920/938] loss_G: 4.641307, loss_D: 0.067780\n",
      "[Epoch 8/200] [Batch 930/938] loss_G: 4.359568, loss_D: 0.137716\n",
      "[Epoch 9/200] [Batch 0/938] loss_G: 4.447758, loss_D: 0.125982\n",
      "[Epoch 9/200] [Batch 10/938] loss_G: 3.718458, loss_D: 0.077561\n",
      "[Epoch 9/200] [Batch 20/938] loss_G: 4.731194, loss_D: 0.146327\n",
      "[Epoch 9/200] [Batch 30/938] loss_G: 4.871957, loss_D: 0.120176\n",
      "[Epoch 9/200] [Batch 40/938] loss_G: 4.061333, loss_D: 0.040502\n",
      "[Epoch 9/200] [Batch 50/938] loss_G: 4.215998, loss_D: 0.041417\n",
      "[Epoch 9/200] [Batch 60/938] loss_G: 4.339613, loss_D: 0.068806\n",
      "[Epoch 9/200] [Batch 70/938] loss_G: 3.535644, loss_D: 0.095545\n",
      "[Epoch 9/200] [Batch 80/938] loss_G: 4.490265, loss_D: 0.107002\n",
      "[Epoch 9/200] [Batch 90/938] loss_G: 4.708724, loss_D: 0.024988\n",
      "[Epoch 9/200] [Batch 100/938] loss_G: 3.978937, loss_D: 0.081950\n",
      "[Epoch 9/200] [Batch 110/938] loss_G: 4.125097, loss_D: 0.099290\n",
      "[Epoch 9/200] [Batch 120/938] loss_G: 4.050761, loss_D: 0.096488\n",
      "[Epoch 9/200] [Batch 130/938] loss_G: 4.424901, loss_D: 0.111621\n",
      "[Epoch 9/200] [Batch 140/938] loss_G: 3.971614, loss_D: 0.120248\n",
      "[Epoch 9/200] [Batch 150/938] loss_G: 4.746196, loss_D: 0.132096\n",
      "[Epoch 9/200] [Batch 160/938] loss_G: 5.093622, loss_D: 0.106714\n",
      "[Epoch 9/200] [Batch 170/938] loss_G: 4.367974, loss_D: 0.090178\n",
      "[Epoch 9/200] [Batch 180/938] loss_G: 4.473678, loss_D: 0.103260\n",
      "[Epoch 9/200] [Batch 190/938] loss_G: 4.719443, loss_D: 0.062159\n",
      "[Epoch 9/200] [Batch 200/938] loss_G: 4.142720, loss_D: 0.162808\n",
      "[Epoch 9/200] [Batch 210/938] loss_G: 4.965914, loss_D: 0.120220\n",
      "[Epoch 9/200] [Batch 220/938] loss_G: 5.250353, loss_D: 0.097579\n",
      "[Epoch 9/200] [Batch 230/938] loss_G: 4.632995, loss_D: 0.084612\n",
      "[Epoch 9/200] [Batch 240/938] loss_G: 4.752522, loss_D: 0.041661\n",
      "[Epoch 9/200] [Batch 250/938] loss_G: 5.156168, loss_D: 0.038023\n",
      "[Epoch 9/200] [Batch 260/938] loss_G: 3.866799, loss_D: 0.094864\n",
      "[Epoch 9/200] [Batch 270/938] loss_G: 4.830794, loss_D: 0.085887\n",
      "[Epoch 9/200] [Batch 280/938] loss_G: 5.362517, loss_D: 0.040950\n",
      "[Epoch 9/200] [Batch 290/938] loss_G: 4.405821, loss_D: 0.201065\n",
      "[Epoch 9/200] [Batch 300/938] loss_G: 4.617211, loss_D: 0.112429\n",
      "[Epoch 9/200] [Batch 310/938] loss_G: 4.942989, loss_D: 0.044021\n",
      "[Epoch 9/200] [Batch 320/938] loss_G: 4.305397, loss_D: 0.068690\n",
      "[Epoch 9/200] [Batch 330/938] loss_G: 4.570253, loss_D: 0.072094\n",
      "[Epoch 9/200] [Batch 340/938] loss_G: 4.713044, loss_D: 0.127723\n",
      "[Epoch 9/200] [Batch 350/938] loss_G: 3.557679, loss_D: 0.083551\n",
      "[Epoch 9/200] [Batch 360/938] loss_G: 4.479322, loss_D: 0.062929\n",
      "[Epoch 9/200] [Batch 370/938] loss_G: 4.198072, loss_D: 0.093114\n",
      "[Epoch 9/200] [Batch 380/938] loss_G: 4.030314, loss_D: 0.066046\n",
      "[Epoch 9/200] [Batch 390/938] loss_G: 4.008589, loss_D: 0.064122\n",
      "[Epoch 9/200] [Batch 400/938] loss_G: 3.781210, loss_D: 0.161896\n",
      "[Epoch 9/200] [Batch 410/938] loss_G: 4.266384, loss_D: 0.099203\n",
      "[Epoch 9/200] [Batch 420/938] loss_G: 3.517647, loss_D: 0.115545\n",
      "[Epoch 9/200] [Batch 430/938] loss_G: 4.271703, loss_D: 0.117927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/200] [Batch 440/938] loss_G: 4.210487, loss_D: 0.101845\n",
      "[Epoch 9/200] [Batch 450/938] loss_G: 4.328856, loss_D: 0.055218\n",
      "[Epoch 9/200] [Batch 460/938] loss_G: 4.629799, loss_D: 0.084363\n",
      "[Epoch 9/200] [Batch 470/938] loss_G: 4.673168, loss_D: 0.082267\n",
      "[Epoch 9/200] [Batch 480/938] loss_G: 4.295148, loss_D: 0.128669\n",
      "[Epoch 9/200] [Batch 490/938] loss_G: 4.713391, loss_D: 0.052152\n",
      "[Epoch 9/200] [Batch 500/938] loss_G: 4.921872, loss_D: 0.164737\n",
      "[Epoch 9/200] [Batch 510/938] loss_G: 3.839081, loss_D: 0.070249\n",
      "[Epoch 9/200] [Batch 520/938] loss_G: 4.341181, loss_D: 0.118450\n",
      "[Epoch 9/200] [Batch 530/938] loss_G: 4.535260, loss_D: 0.053120\n",
      "[Epoch 9/200] [Batch 540/938] loss_G: 3.996611, loss_D: 0.104877\n",
      "[Epoch 9/200] [Batch 550/938] loss_G: 3.379588, loss_D: 0.132416\n",
      "[Epoch 9/200] [Batch 560/938] loss_G: 3.833204, loss_D: 0.163151\n",
      "[Epoch 9/200] [Batch 570/938] loss_G: 3.414525, loss_D: 0.095533\n",
      "[Epoch 9/200] [Batch 580/938] loss_G: 4.459683, loss_D: 0.080764\n",
      "[Epoch 9/200] [Batch 590/938] loss_G: 4.293237, loss_D: 0.069301\n",
      "[Epoch 9/200] [Batch 600/938] loss_G: 3.863794, loss_D: 0.118267\n",
      "[Epoch 9/200] [Batch 610/938] loss_G: 4.068465, loss_D: 0.135578\n",
      "[Epoch 9/200] [Batch 620/938] loss_G: 3.579359, loss_D: 0.076445\n",
      "[Epoch 9/200] [Batch 630/938] loss_G: 4.379239, loss_D: 0.130147\n",
      "[Epoch 9/200] [Batch 640/938] loss_G: 3.742488, loss_D: 0.058376\n",
      "[Epoch 9/200] [Batch 650/938] loss_G: 4.840825, loss_D: 0.061055\n",
      "[Epoch 9/200] [Batch 660/938] loss_G: 3.875016, loss_D: 0.058421\n",
      "[Epoch 9/200] [Batch 670/938] loss_G: 4.221366, loss_D: 0.038180\n",
      "[Epoch 9/200] [Batch 680/938] loss_G: 3.751063, loss_D: 0.090811\n",
      "[Epoch 9/200] [Batch 690/938] loss_G: 4.045806, loss_D: 0.075633\n",
      "[Epoch 9/200] [Batch 700/938] loss_G: 4.227397, loss_D: 0.120111\n",
      "[Epoch 9/200] [Batch 710/938] loss_G: 3.802720, loss_D: 0.090944\n",
      "[Epoch 9/200] [Batch 720/938] loss_G: 4.299707, loss_D: 0.093682\n",
      "[Epoch 9/200] [Batch 730/938] loss_G: 5.134398, loss_D: 0.043465\n",
      "[Epoch 9/200] [Batch 740/938] loss_G: 5.045454, loss_D: 0.042831\n",
      "[Epoch 9/200] [Batch 750/938] loss_G: 3.552292, loss_D: 0.081937\n",
      "[Epoch 9/200] [Batch 760/938] loss_G: 5.366703, loss_D: 0.138132\n",
      "[Epoch 9/200] [Batch 770/938] loss_G: 4.975934, loss_D: 0.051105\n",
      "[Epoch 9/200] [Batch 780/938] loss_G: 4.897718, loss_D: 0.061708\n",
      "[Epoch 9/200] [Batch 790/938] loss_G: 3.743922, loss_D: 0.134381\n",
      "[Epoch 9/200] [Batch 800/938] loss_G: 4.794791, loss_D: 0.107261\n",
      "[Epoch 9/200] [Batch 810/938] loss_G: 4.807252, loss_D: 0.110569\n",
      "[Epoch 9/200] [Batch 820/938] loss_G: 4.466264, loss_D: 0.100670\n",
      "[Epoch 9/200] [Batch 830/938] loss_G: 4.236879, loss_D: 0.097759\n",
      "[Epoch 9/200] [Batch 840/938] loss_G: 3.946591, loss_D: 0.066188\n",
      "[Epoch 9/200] [Batch 850/938] loss_G: 4.189945, loss_D: 0.079212\n",
      "[Epoch 9/200] [Batch 860/938] loss_G: 4.272042, loss_D: 0.034000\n",
      "[Epoch 9/200] [Batch 870/938] loss_G: 3.545108, loss_D: 0.127942\n",
      "[Epoch 9/200] [Batch 880/938] loss_G: 3.980705, loss_D: 0.117642\n",
      "[Epoch 9/200] [Batch 890/938] loss_G: 4.926570, loss_D: 0.116359\n",
      "[Epoch 9/200] [Batch 900/938] loss_G: 4.046622, loss_D: 0.086818\n",
      "[Epoch 9/200] [Batch 910/938] loss_G: 3.907562, loss_D: 0.152670\n",
      "[Epoch 9/200] [Batch 920/938] loss_G: 4.142613, loss_D: 0.054895\n",
      "[Epoch 9/200] [Batch 930/938] loss_G: 3.568362, loss_D: 0.081599\n",
      "[Epoch 10/200] [Batch 0/938] loss_G: 3.746558, loss_D: 0.105283\n",
      "[Epoch 10/200] [Batch 10/938] loss_G: 3.487670, loss_D: 0.108942\n",
      "[Epoch 10/200] [Batch 20/938] loss_G: 4.356819, loss_D: 0.074933\n",
      "[Epoch 10/200] [Batch 30/938] loss_G: 3.970500, loss_D: 0.121786\n",
      "[Epoch 10/200] [Batch 40/938] loss_G: 4.641761, loss_D: 0.050395\n",
      "[Epoch 10/200] [Batch 50/938] loss_G: 4.089911, loss_D: 0.070914\n",
      "[Epoch 10/200] [Batch 60/938] loss_G: 4.419169, loss_D: 0.119774\n",
      "[Epoch 10/200] [Batch 70/938] loss_G: 4.441370, loss_D: 0.122960\n",
      "[Epoch 10/200] [Batch 80/938] loss_G: 3.652716, loss_D: 0.213859\n",
      "[Epoch 10/200] [Batch 90/938] loss_G: 4.801398, loss_D: 0.070684\n",
      "[Epoch 10/200] [Batch 100/938] loss_G: 4.009708, loss_D: 0.062063\n",
      "[Epoch 10/200] [Batch 110/938] loss_G: 4.224644, loss_D: 0.069292\n",
      "[Epoch 10/200] [Batch 120/938] loss_G: 4.750844, loss_D: 0.082696\n",
      "[Epoch 10/200] [Batch 130/938] loss_G: 4.513680, loss_D: 0.053054\n",
      "[Epoch 10/200] [Batch 140/938] loss_G: 4.274585, loss_D: 0.186196\n",
      "[Epoch 10/200] [Batch 150/938] loss_G: 3.703980, loss_D: 0.102278\n",
      "[Epoch 10/200] [Batch 160/938] loss_G: 4.527781, loss_D: 0.042400\n",
      "[Epoch 10/200] [Batch 170/938] loss_G: 4.013458, loss_D: 0.136475\n",
      "[Epoch 10/200] [Batch 180/938] loss_G: 3.763690, loss_D: 0.133711\n",
      "[Epoch 10/200] [Batch 190/938] loss_G: 5.029770, loss_D: 0.093250\n",
      "[Epoch 10/200] [Batch 200/938] loss_G: 4.533816, loss_D: 0.103518\n",
      "[Epoch 10/200] [Batch 210/938] loss_G: 4.124520, loss_D: 0.142404\n",
      "[Epoch 10/200] [Batch 220/938] loss_G: 3.971617, loss_D: 0.119521\n",
      "[Epoch 10/200] [Batch 230/938] loss_G: 4.280504, loss_D: 0.118880\n",
      "[Epoch 10/200] [Batch 240/938] loss_G: 4.142317, loss_D: 0.087787\n",
      "[Epoch 10/200] [Batch 250/938] loss_G: 4.039576, loss_D: 0.089672\n",
      "[Epoch 10/200] [Batch 260/938] loss_G: 3.656464, loss_D: 0.090972\n",
      "[Epoch 10/200] [Batch 270/938] loss_G: 4.810043, loss_D: 0.092802\n",
      "[Epoch 10/200] [Batch 280/938] loss_G: 4.390193, loss_D: 0.148602\n",
      "[Epoch 10/200] [Batch 290/938] loss_G: 4.428177, loss_D: 0.091548\n",
      "[Epoch 10/200] [Batch 300/938] loss_G: 5.566228, loss_D: 0.068986\n",
      "[Epoch 10/200] [Batch 310/938] loss_G: 5.199337, loss_D: 0.067571\n",
      "[Epoch 10/200] [Batch 320/938] loss_G: 4.051105, loss_D: 0.059640\n",
      "[Epoch 10/200] [Batch 330/938] loss_G: 4.281489, loss_D: 0.071146\n",
      "[Epoch 10/200] [Batch 340/938] loss_G: 4.034005, loss_D: 0.147032\n",
      "[Epoch 10/200] [Batch 350/938] loss_G: 3.747510, loss_D: 0.145390\n",
      "[Epoch 10/200] [Batch 360/938] loss_G: 3.841107, loss_D: 0.093733\n",
      "[Epoch 10/200] [Batch 370/938] loss_G: 4.792616, loss_D: 0.076276\n",
      "[Epoch 10/200] [Batch 380/938] loss_G: 4.004153, loss_D: 0.129172\n",
      "[Epoch 10/200] [Batch 390/938] loss_G: 4.658198, loss_D: 0.114716\n",
      "[Epoch 10/200] [Batch 400/938] loss_G: 4.793792, loss_D: 0.083821\n",
      "[Epoch 10/200] [Batch 410/938] loss_G: 4.468112, loss_D: 0.104268\n",
      "[Epoch 10/200] [Batch 420/938] loss_G: 4.642443, loss_D: 0.060917\n",
      "[Epoch 10/200] [Batch 430/938] loss_G: 4.159065, loss_D: 0.095445\n",
      "[Epoch 10/200] [Batch 440/938] loss_G: 4.901671, loss_D: 0.108183\n",
      "[Epoch 10/200] [Batch 450/938] loss_G: 3.858627, loss_D: 0.043997\n",
      "[Epoch 10/200] [Batch 460/938] loss_G: 5.052302, loss_D: 0.064368\n",
      "[Epoch 10/200] [Batch 470/938] loss_G: 3.825275, loss_D: 0.230710\n",
      "[Epoch 10/200] [Batch 480/938] loss_G: 4.571633, loss_D: 0.037168\n",
      "[Epoch 10/200] [Batch 490/938] loss_G: 4.592518, loss_D: 0.089525\n",
      "[Epoch 10/200] [Batch 500/938] loss_G: 4.769689, loss_D: 0.058896\n",
      "[Epoch 10/200] [Batch 510/938] loss_G: 3.945920, loss_D: 0.095854\n",
      "[Epoch 10/200] [Batch 520/938] loss_G: 4.322907, loss_D: 0.099446\n",
      "[Epoch 10/200] [Batch 530/938] loss_G: 4.711740, loss_D: 0.049007\n",
      "[Epoch 10/200] [Batch 540/938] loss_G: 4.848134, loss_D: 0.089793\n",
      "[Epoch 10/200] [Batch 550/938] loss_G: 4.484840, loss_D: 0.101834\n",
      "[Epoch 10/200] [Batch 560/938] loss_G: 4.145897, loss_D: 0.177736\n",
      "[Epoch 10/200] [Batch 570/938] loss_G: 3.409718, loss_D: 0.097777\n",
      "[Epoch 10/200] [Batch 580/938] loss_G: 4.383999, loss_D: 0.059116\n",
      "[Epoch 10/200] [Batch 590/938] loss_G: 4.643597, loss_D: 0.033192\n",
      "[Epoch 10/200] [Batch 600/938] loss_G: 4.092529, loss_D: 0.120732\n",
      "[Epoch 10/200] [Batch 610/938] loss_G: 4.123463, loss_D: 0.122947\n",
      "[Epoch 10/200] [Batch 620/938] loss_G: 4.396587, loss_D: 0.051200\n",
      "[Epoch 10/200] [Batch 630/938] loss_G: 3.694978, loss_D: 0.200710\n",
      "[Epoch 10/200] [Batch 640/938] loss_G: 4.492917, loss_D: 0.115395\n",
      "[Epoch 10/200] [Batch 650/938] loss_G: 3.942139, loss_D: 0.164017\n",
      "[Epoch 10/200] [Batch 660/938] loss_G: 4.027297, loss_D: 0.114872\n",
      "[Epoch 10/200] [Batch 670/938] loss_G: 3.902105, loss_D: 0.192265\n",
      "[Epoch 10/200] [Batch 680/938] loss_G: 4.423072, loss_D: 0.096436\n",
      "[Epoch 10/200] [Batch 690/938] loss_G: 5.016454, loss_D: 0.033464\n",
      "[Epoch 10/200] [Batch 700/938] loss_G: 3.767967, loss_D: 0.095276\n",
      "[Epoch 10/200] [Batch 710/938] loss_G: 4.749972, loss_D: 0.061727\n",
      "[Epoch 10/200] [Batch 720/938] loss_G: 4.493718, loss_D: 0.084628\n",
      "[Epoch 10/200] [Batch 730/938] loss_G: 3.643021, loss_D: 0.098806\n",
      "[Epoch 10/200] [Batch 740/938] loss_G: 4.806553, loss_D: 0.051449\n",
      "[Epoch 10/200] [Batch 750/938] loss_G: 4.610162, loss_D: 0.102797\n",
      "[Epoch 10/200] [Batch 760/938] loss_G: 4.338687, loss_D: 0.136657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/200] [Batch 770/938] loss_G: 4.084138, loss_D: 0.061060\n",
      "[Epoch 10/200] [Batch 780/938] loss_G: 4.240312, loss_D: 0.079446\n",
      "[Epoch 10/200] [Batch 790/938] loss_G: 4.723854, loss_D: 0.096882\n",
      "[Epoch 10/200] [Batch 800/938] loss_G: 4.086908, loss_D: 0.053959\n",
      "[Epoch 10/200] [Batch 810/938] loss_G: 4.507470, loss_D: 0.070113\n",
      "[Epoch 10/200] [Batch 820/938] loss_G: 3.697772, loss_D: 0.137741\n",
      "[Epoch 10/200] [Batch 830/938] loss_G: 4.045848, loss_D: 0.100752\n",
      "[Epoch 10/200] [Batch 840/938] loss_G: 4.922998, loss_D: 0.311082\n",
      "[Epoch 10/200] [Batch 850/938] loss_G: 4.374313, loss_D: 0.095496\n",
      "[Epoch 10/200] [Batch 860/938] loss_G: 3.691082, loss_D: 0.097261\n",
      "[Epoch 10/200] [Batch 870/938] loss_G: 4.405246, loss_D: 0.138316\n",
      "[Epoch 10/200] [Batch 880/938] loss_G: 4.137438, loss_D: 0.131007\n",
      "[Epoch 10/200] [Batch 890/938] loss_G: 3.596334, loss_D: 0.114990\n",
      "[Epoch 10/200] [Batch 900/938] loss_G: 4.567985, loss_D: 0.112605\n",
      "[Epoch 10/200] [Batch 910/938] loss_G: 4.310379, loss_D: 0.062681\n",
      "[Epoch 10/200] [Batch 920/938] loss_G: 4.651379, loss_D: 0.092324\n",
      "[Epoch 10/200] [Batch 930/938] loss_G: 4.939107, loss_D: 0.052129\n",
      "[Epoch 11/200] [Batch 0/938] loss_G: 3.768828, loss_D: 0.115236\n",
      "[Epoch 11/200] [Batch 10/938] loss_G: 4.729060, loss_D: 0.062451\n",
      "[Epoch 11/200] [Batch 20/938] loss_G: 4.511121, loss_D: 0.120789\n",
      "[Epoch 11/200] [Batch 30/938] loss_G: 3.918665, loss_D: 0.150329\n",
      "[Epoch 11/200] [Batch 40/938] loss_G: 4.170695, loss_D: 0.089792\n",
      "[Epoch 11/200] [Batch 50/938] loss_G: 4.334053, loss_D: 0.120211\n",
      "[Epoch 11/200] [Batch 60/938] loss_G: 3.920870, loss_D: 0.137917\n",
      "[Epoch 11/200] [Batch 70/938] loss_G: 3.747020, loss_D: 0.170405\n",
      "[Epoch 11/200] [Batch 80/938] loss_G: 4.359327, loss_D: 0.181838\n",
      "[Epoch 11/200] [Batch 90/938] loss_G: 4.222157, loss_D: 0.180137\n",
      "[Epoch 11/200] [Batch 100/938] loss_G: 4.588716, loss_D: 0.097344\n",
      "[Epoch 11/200] [Batch 110/938] loss_G: 4.692631, loss_D: 0.074300\n",
      "[Epoch 11/200] [Batch 120/938] loss_G: 4.755789, loss_D: 0.032573\n",
      "[Epoch 11/200] [Batch 130/938] loss_G: 4.463955, loss_D: 0.137273\n",
      "[Epoch 11/200] [Batch 140/938] loss_G: 4.899888, loss_D: 0.127618\n",
      "[Epoch 11/200] [Batch 150/938] loss_G: 4.406316, loss_D: 0.093355\n",
      "[Epoch 11/200] [Batch 160/938] loss_G: 4.743033, loss_D: 0.057342\n",
      "[Epoch 11/200] [Batch 170/938] loss_G: 4.226629, loss_D: 0.106690\n",
      "[Epoch 11/200] [Batch 180/938] loss_G: 4.079239, loss_D: 0.119842\n",
      "[Epoch 11/200] [Batch 190/938] loss_G: 4.556087, loss_D: 0.099859\n",
      "[Epoch 11/200] [Batch 200/938] loss_G: 4.116553, loss_D: 0.092529\n",
      "[Epoch 11/200] [Batch 210/938] loss_G: 4.102420, loss_D: 0.104306\n",
      "[Epoch 11/200] [Batch 220/938] loss_G: 3.665085, loss_D: 0.179912\n",
      "[Epoch 11/200] [Batch 230/938] loss_G: 4.026994, loss_D: 0.152658\n",
      "[Epoch 11/200] [Batch 240/938] loss_G: 4.323919, loss_D: 0.080063\n",
      "[Epoch 11/200] [Batch 250/938] loss_G: 4.063546, loss_D: 0.106935\n",
      "[Epoch 11/200] [Batch 260/938] loss_G: 4.310626, loss_D: 0.066605\n",
      "[Epoch 11/200] [Batch 270/938] loss_G: 3.576250, loss_D: 0.098347\n",
      "[Epoch 11/200] [Batch 280/938] loss_G: 4.280772, loss_D: 0.112506\n",
      "[Epoch 11/200] [Batch 290/938] loss_G: 3.919563, loss_D: 0.176908\n",
      "[Epoch 11/200] [Batch 300/938] loss_G: 4.060171, loss_D: 0.141232\n",
      "[Epoch 11/200] [Batch 310/938] loss_G: 3.481065, loss_D: 0.109019\n",
      "[Epoch 11/200] [Batch 320/938] loss_G: 4.166101, loss_D: 0.138085\n",
      "[Epoch 11/200] [Batch 330/938] loss_G: 4.679510, loss_D: 0.068153\n",
      "[Epoch 11/200] [Batch 340/938] loss_G: 4.494083, loss_D: 0.080063\n",
      "[Epoch 11/200] [Batch 350/938] loss_G: 4.225045, loss_D: 0.078786\n",
      "[Epoch 11/200] [Batch 360/938] loss_G: 5.068692, loss_D: 0.078153\n",
      "[Epoch 11/200] [Batch 370/938] loss_G: 3.881079, loss_D: 0.148640\n",
      "[Epoch 11/200] [Batch 380/938] loss_G: 3.784600, loss_D: 0.099772\n",
      "[Epoch 11/200] [Batch 390/938] loss_G: 4.607099, loss_D: 0.092191\n",
      "[Epoch 11/200] [Batch 400/938] loss_G: 3.927620, loss_D: 0.087708\n",
      "[Epoch 11/200] [Batch 410/938] loss_G: 3.697943, loss_D: 0.146492\n",
      "[Epoch 11/200] [Batch 420/938] loss_G: 4.144444, loss_D: 0.161354\n",
      "[Epoch 11/200] [Batch 430/938] loss_G: 4.581351, loss_D: 0.043927\n",
      "[Epoch 11/200] [Batch 440/938] loss_G: 3.949577, loss_D: 0.051407\n",
      "[Epoch 11/200] [Batch 450/938] loss_G: 4.317379, loss_D: 0.194017\n",
      "[Epoch 11/200] [Batch 460/938] loss_G: 4.071137, loss_D: 0.108066\n",
      "[Epoch 11/200] [Batch 470/938] loss_G: 3.945259, loss_D: 0.088384\n",
      "[Epoch 11/200] [Batch 480/938] loss_G: 3.264687, loss_D: 0.109082\n",
      "[Epoch 11/200] [Batch 490/938] loss_G: 4.520897, loss_D: 0.083418\n",
      "[Epoch 11/200] [Batch 500/938] loss_G: 4.379520, loss_D: 0.055196\n",
      "[Epoch 11/200] [Batch 510/938] loss_G: 4.377491, loss_D: 0.105950\n",
      "[Epoch 11/200] [Batch 520/938] loss_G: 4.461504, loss_D: 0.074142\n",
      "[Epoch 11/200] [Batch 530/938] loss_G: 3.898329, loss_D: 0.125307\n",
      "[Epoch 11/200] [Batch 540/938] loss_G: 4.474617, loss_D: 0.149395\n",
      "[Epoch 11/200] [Batch 550/938] loss_G: 3.940435, loss_D: 0.094914\n",
      "[Epoch 11/200] [Batch 560/938] loss_G: 3.838597, loss_D: 0.056657\n",
      "[Epoch 11/200] [Batch 570/938] loss_G: 3.932675, loss_D: 0.105333\n",
      "[Epoch 11/200] [Batch 580/938] loss_G: 3.916945, loss_D: 0.196969\n",
      "[Epoch 11/200] [Batch 590/938] loss_G: 4.126103, loss_D: 0.137871\n",
      "[Epoch 11/200] [Batch 600/938] loss_G: 4.823627, loss_D: 0.191550\n",
      "[Epoch 11/200] [Batch 610/938] loss_G: 4.532231, loss_D: 0.096481\n",
      "[Epoch 11/200] [Batch 620/938] loss_G: 3.650478, loss_D: 0.079611\n",
      "[Epoch 11/200] [Batch 630/938] loss_G: 4.223852, loss_D: 0.092459\n",
      "[Epoch 11/200] [Batch 640/938] loss_G: 3.882207, loss_D: 0.097317\n",
      "[Epoch 11/200] [Batch 650/938] loss_G: 4.674069, loss_D: 0.110208\n",
      "[Epoch 11/200] [Batch 660/938] loss_G: 4.126937, loss_D: 0.093210\n",
      "[Epoch 11/200] [Batch 670/938] loss_G: 3.789375, loss_D: 0.098669\n",
      "[Epoch 11/200] [Batch 680/938] loss_G: 3.879673, loss_D: 0.177389\n",
      "[Epoch 11/200] [Batch 690/938] loss_G: 3.627053, loss_D: 0.132390\n",
      "[Epoch 11/200] [Batch 700/938] loss_G: 4.058986, loss_D: 0.091369\n",
      "[Epoch 11/200] [Batch 710/938] loss_G: 3.919106, loss_D: 0.158604\n",
      "[Epoch 11/200] [Batch 720/938] loss_G: 4.269330, loss_D: 0.171811\n",
      "[Epoch 11/200] [Batch 730/938] loss_G: 4.155302, loss_D: 0.095021\n",
      "[Epoch 11/200] [Batch 740/938] loss_G: 3.516975, loss_D: 0.079251\n",
      "[Epoch 11/200] [Batch 750/938] loss_G: 4.009568, loss_D: 0.123920\n",
      "[Epoch 11/200] [Batch 760/938] loss_G: 3.935838, loss_D: 0.126890\n",
      "[Epoch 11/200] [Batch 770/938] loss_G: 4.698225, loss_D: 0.079665\n",
      "[Epoch 11/200] [Batch 780/938] loss_G: 4.079385, loss_D: 0.074535\n",
      "[Epoch 11/200] [Batch 790/938] loss_G: 4.157330, loss_D: 0.120673\n",
      "[Epoch 11/200] [Batch 800/938] loss_G: 3.577656, loss_D: 0.204690\n",
      "[Epoch 11/200] [Batch 810/938] loss_G: 3.769667, loss_D: 0.133180\n",
      "[Epoch 11/200] [Batch 820/938] loss_G: 3.864072, loss_D: 0.211245\n",
      "[Epoch 11/200] [Batch 830/938] loss_G: 3.762262, loss_D: 0.065305\n",
      "[Epoch 11/200] [Batch 840/938] loss_G: 4.027066, loss_D: 0.100203\n",
      "[Epoch 11/200] [Batch 850/938] loss_G: 4.168781, loss_D: 0.110875\n",
      "[Epoch 11/200] [Batch 860/938] loss_G: 4.148687, loss_D: 0.036667\n",
      "[Epoch 11/200] [Batch 870/938] loss_G: 3.650360, loss_D: 0.153522\n",
      "[Epoch 11/200] [Batch 880/938] loss_G: 3.504812, loss_D: 0.158725\n",
      "[Epoch 11/200] [Batch 890/938] loss_G: 4.136151, loss_D: 0.124241\n",
      "[Epoch 11/200] [Batch 900/938] loss_G: 4.555970, loss_D: 0.124938\n",
      "[Epoch 11/200] [Batch 910/938] loss_G: 4.352435, loss_D: 0.188469\n",
      "[Epoch 11/200] [Batch 920/938] loss_G: 4.610047, loss_D: 0.086330\n",
      "[Epoch 11/200] [Batch 930/938] loss_G: 3.646696, loss_D: 0.101083\n",
      "[Epoch 12/200] [Batch 0/938] loss_G: 4.094718, loss_D: 0.140841\n",
      "[Epoch 12/200] [Batch 10/938] loss_G: 3.828815, loss_D: 0.119171\n",
      "[Epoch 12/200] [Batch 20/938] loss_G: 3.744009, loss_D: 0.132938\n",
      "[Epoch 12/200] [Batch 30/938] loss_G: 3.299181, loss_D: 0.178470\n",
      "[Epoch 12/200] [Batch 40/938] loss_G: 3.812433, loss_D: 0.105682\n",
      "[Epoch 12/200] [Batch 50/938] loss_G: 4.338381, loss_D: 0.085552\n",
      "[Epoch 12/200] [Batch 60/938] loss_G: 4.629535, loss_D: 0.136472\n",
      "[Epoch 12/200] [Batch 70/938] loss_G: 3.866955, loss_D: 0.136796\n",
      "[Epoch 12/200] [Batch 80/938] loss_G: 4.823396, loss_D: 0.196665\n",
      "[Epoch 12/200] [Batch 90/938] loss_G: 4.632062, loss_D: 0.149114\n",
      "[Epoch 12/200] [Batch 100/938] loss_G: 4.323211, loss_D: 0.127070\n",
      "[Epoch 12/200] [Batch 110/938] loss_G: 3.923959, loss_D: 0.091552\n",
      "[Epoch 12/200] [Batch 120/938] loss_G: 4.201359, loss_D: 0.194073\n",
      "[Epoch 12/200] [Batch 130/938] loss_G: 4.507957, loss_D: 0.086939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/200] [Batch 140/938] loss_G: 3.350327, loss_D: 0.203775\n",
      "[Epoch 12/200] [Batch 150/938] loss_G: 3.591321, loss_D: 0.100042\n",
      "[Epoch 12/200] [Batch 160/938] loss_G: 3.903654, loss_D: 0.207761\n",
      "[Epoch 12/200] [Batch 170/938] loss_G: 4.674144, loss_D: 0.148674\n",
      "[Epoch 12/200] [Batch 180/938] loss_G: 4.124494, loss_D: 0.104741\n",
      "[Epoch 12/200] [Batch 190/938] loss_G: 3.335319, loss_D: 0.111910\n",
      "[Epoch 12/200] [Batch 200/938] loss_G: 4.524511, loss_D: 0.195368\n",
      "[Epoch 12/200] [Batch 210/938] loss_G: 3.628899, loss_D: 0.129493\n",
      "[Epoch 12/200] [Batch 220/938] loss_G: 3.872733, loss_D: 0.217500\n",
      "[Epoch 12/200] [Batch 230/938] loss_G: 3.779887, loss_D: 0.091322\n",
      "[Epoch 12/200] [Batch 240/938] loss_G: 4.198842, loss_D: 0.095245\n",
      "[Epoch 12/200] [Batch 250/938] loss_G: 5.111543, loss_D: 0.100208\n",
      "[Epoch 12/200] [Batch 260/938] loss_G: 3.958228, loss_D: 0.078815\n",
      "[Epoch 12/200] [Batch 270/938] loss_G: 4.113915, loss_D: 0.092697\n",
      "[Epoch 12/200] [Batch 280/938] loss_G: 4.817684, loss_D: 0.081138\n",
      "[Epoch 12/200] [Batch 290/938] loss_G: 3.701784, loss_D: 0.188084\n",
      "[Epoch 12/200] [Batch 300/938] loss_G: 3.925392, loss_D: 0.087260\n",
      "[Epoch 12/200] [Batch 310/938] loss_G: 3.990396, loss_D: 0.176901\n",
      "[Epoch 12/200] [Batch 320/938] loss_G: 4.050168, loss_D: 0.116185\n",
      "[Epoch 12/200] [Batch 330/938] loss_G: 3.555028, loss_D: 0.126602\n",
      "[Epoch 12/200] [Batch 340/938] loss_G: 4.639499, loss_D: 0.089565\n",
      "[Epoch 12/200] [Batch 350/938] loss_G: 4.281233, loss_D: 0.116203\n",
      "[Epoch 12/200] [Batch 360/938] loss_G: 4.317255, loss_D: 0.119932\n",
      "[Epoch 12/200] [Batch 370/938] loss_G: 4.690936, loss_D: 0.039777\n",
      "[Epoch 12/200] [Batch 380/938] loss_G: 4.462096, loss_D: 0.104345\n",
      "[Epoch 12/200] [Batch 390/938] loss_G: 4.451050, loss_D: 0.042443\n",
      "[Epoch 12/200] [Batch 400/938] loss_G: 4.073244, loss_D: 0.120130\n",
      "[Epoch 12/200] [Batch 410/938] loss_G: 4.415462, loss_D: 0.112682\n",
      "[Epoch 12/200] [Batch 420/938] loss_G: 4.036583, loss_D: 0.071347\n",
      "[Epoch 12/200] [Batch 430/938] loss_G: 4.401834, loss_D: 0.096647\n",
      "[Epoch 12/200] [Batch 440/938] loss_G: 4.904560, loss_D: 0.100515\n",
      "[Epoch 12/200] [Batch 450/938] loss_G: 3.618822, loss_D: 0.117121\n",
      "[Epoch 12/200] [Batch 460/938] loss_G: 4.347541, loss_D: 0.138918\n",
      "[Epoch 12/200] [Batch 470/938] loss_G: 3.899112, loss_D: 0.109971\n",
      "[Epoch 12/200] [Batch 480/938] loss_G: 3.790638, loss_D: 0.169425\n",
      "[Epoch 12/200] [Batch 490/938] loss_G: 4.253335, loss_D: 0.094732\n",
      "[Epoch 12/200] [Batch 500/938] loss_G: 3.753348, loss_D: 0.091877\n",
      "[Epoch 12/200] [Batch 510/938] loss_G: 4.221818, loss_D: 0.234302\n",
      "[Epoch 12/200] [Batch 520/938] loss_G: 4.121561, loss_D: 0.142073\n",
      "[Epoch 12/200] [Batch 530/938] loss_G: 3.447659, loss_D: 0.095329\n",
      "[Epoch 12/200] [Batch 540/938] loss_G: 3.328688, loss_D: 0.152567\n",
      "[Epoch 12/200] [Batch 550/938] loss_G: 4.377254, loss_D: 0.180242\n",
      "[Epoch 12/200] [Batch 560/938] loss_G: 4.169816, loss_D: 0.157675\n",
      "[Epoch 12/200] [Batch 570/938] loss_G: 4.254104, loss_D: 0.065949\n",
      "[Epoch 12/200] [Batch 580/938] loss_G: 3.473439, loss_D: 0.124380\n",
      "[Epoch 12/200] [Batch 590/938] loss_G: 3.809713, loss_D: 0.102841\n",
      "[Epoch 12/200] [Batch 600/938] loss_G: 3.452133, loss_D: 0.169511\n",
      "[Epoch 12/200] [Batch 610/938] loss_G: 3.387269, loss_D: 0.081064\n",
      "[Epoch 12/200] [Batch 620/938] loss_G: 4.192767, loss_D: 0.145632\n",
      "[Epoch 12/200] [Batch 630/938] loss_G: 3.820577, loss_D: 0.101085\n",
      "[Epoch 12/200] [Batch 640/938] loss_G: 3.267214, loss_D: 0.178731\n",
      "[Epoch 12/200] [Batch 650/938] loss_G: 3.863156, loss_D: 0.131300\n",
      "[Epoch 12/200] [Batch 660/938] loss_G: 4.140873, loss_D: 0.052129\n",
      "[Epoch 12/200] [Batch 670/938] loss_G: 3.783383, loss_D: 0.072565\n",
      "[Epoch 12/200] [Batch 680/938] loss_G: 3.533361, loss_D: 0.105797\n",
      "[Epoch 12/200] [Batch 690/938] loss_G: 3.526298, loss_D: 0.161777\n",
      "[Epoch 12/200] [Batch 700/938] loss_G: 3.914732, loss_D: 0.092830\n",
      "[Epoch 12/200] [Batch 710/938] loss_G: 3.370973, loss_D: 0.128727\n",
      "[Epoch 12/200] [Batch 720/938] loss_G: 3.678749, loss_D: 0.225848\n",
      "[Epoch 12/200] [Batch 730/938] loss_G: 3.891855, loss_D: 0.068757\n",
      "[Epoch 12/200] [Batch 740/938] loss_G: 4.711296, loss_D: 0.161635\n",
      "[Epoch 12/200] [Batch 750/938] loss_G: 3.982721, loss_D: 0.101786\n",
      "[Epoch 12/200] [Batch 760/938] loss_G: 3.340501, loss_D: 0.111822\n",
      "[Epoch 12/200] [Batch 770/938] loss_G: 4.002966, loss_D: 0.101424\n",
      "[Epoch 12/200] [Batch 780/938] loss_G: 4.109487, loss_D: 0.052415\n",
      "[Epoch 12/200] [Batch 790/938] loss_G: 3.835441, loss_D: 0.236388\n",
      "[Epoch 12/200] [Batch 800/938] loss_G: 4.188316, loss_D: 0.094542\n",
      "[Epoch 12/200] [Batch 810/938] loss_G: 4.461537, loss_D: 0.120066\n",
      "[Epoch 12/200] [Batch 820/938] loss_G: 3.876790, loss_D: 0.068673\n",
      "[Epoch 12/200] [Batch 830/938] loss_G: 4.030386, loss_D: 0.130376\n",
      "[Epoch 12/200] [Batch 840/938] loss_G: 4.154860, loss_D: 0.094953\n",
      "[Epoch 12/200] [Batch 850/938] loss_G: 4.128383, loss_D: 0.080226\n",
      "[Epoch 12/200] [Batch 860/938] loss_G: 4.024703, loss_D: 0.146850\n",
      "[Epoch 12/200] [Batch 870/938] loss_G: 4.503414, loss_D: 0.108058\n",
      "[Epoch 12/200] [Batch 880/938] loss_G: 4.228558, loss_D: 0.054374\n",
      "[Epoch 12/200] [Batch 890/938] loss_G: 4.479685, loss_D: 0.077363\n",
      "[Epoch 12/200] [Batch 900/938] loss_G: 3.771477, loss_D: 0.102535\n",
      "[Epoch 12/200] [Batch 910/938] loss_G: 4.321751, loss_D: 0.103411\n",
      "[Epoch 12/200] [Batch 920/938] loss_G: 3.989305, loss_D: 0.076964\n",
      "[Epoch 12/200] [Batch 930/938] loss_G: 4.325532, loss_D: 0.051282\n",
      "[Epoch 13/200] [Batch 0/938] loss_G: 4.001805, loss_D: 0.120722\n",
      "[Epoch 13/200] [Batch 10/938] loss_G: 4.686013, loss_D: 0.089238\n",
      "[Epoch 13/200] [Batch 20/938] loss_G: 3.563235, loss_D: 0.092264\n",
      "[Epoch 13/200] [Batch 30/938] loss_G: 3.768945, loss_D: 0.106910\n",
      "[Epoch 13/200] [Batch 40/938] loss_G: 4.640591, loss_D: 0.071131\n",
      "[Epoch 13/200] [Batch 50/938] loss_G: 3.897616, loss_D: 0.118271\n",
      "[Epoch 13/200] [Batch 60/938] loss_G: 4.340952, loss_D: 0.089505\n",
      "[Epoch 13/200] [Batch 70/938] loss_G: 4.568542, loss_D: 0.039288\n",
      "[Epoch 13/200] [Batch 80/938] loss_G: 3.969754, loss_D: 0.137209\n",
      "[Epoch 13/200] [Batch 90/938] loss_G: 3.960361, loss_D: 0.164639\n",
      "[Epoch 13/200] [Batch 100/938] loss_G: 4.035177, loss_D: 0.188183\n",
      "[Epoch 13/200] [Batch 110/938] loss_G: 3.702470, loss_D: 0.189041\n",
      "[Epoch 13/200] [Batch 120/938] loss_G: 4.129675, loss_D: 0.099667\n",
      "[Epoch 13/200] [Batch 130/938] loss_G: 3.911599, loss_D: 0.118096\n",
      "[Epoch 13/200] [Batch 140/938] loss_G: 3.972187, loss_D: 0.145268\n",
      "[Epoch 13/200] [Batch 150/938] loss_G: 4.267037, loss_D: 0.068370\n",
      "[Epoch 13/200] [Batch 160/938] loss_G: 3.683223, loss_D: 0.060928\n",
      "[Epoch 13/200] [Batch 170/938] loss_G: 3.794295, loss_D: 0.125081\n",
      "[Epoch 13/200] [Batch 180/938] loss_G: 3.724452, loss_D: 0.171097\n",
      "[Epoch 13/200] [Batch 190/938] loss_G: 3.367917, loss_D: 0.166717\n",
      "[Epoch 13/200] [Batch 200/938] loss_G: 4.442294, loss_D: 0.058957\n",
      "[Epoch 13/200] [Batch 210/938] loss_G: 3.820563, loss_D: 0.091043\n",
      "[Epoch 13/200] [Batch 220/938] loss_G: 4.569098, loss_D: 0.065353\n",
      "[Epoch 13/200] [Batch 230/938] loss_G: 3.859322, loss_D: 0.157848\n",
      "[Epoch 13/200] [Batch 240/938] loss_G: 3.910984, loss_D: 0.097433\n",
      "[Epoch 13/200] [Batch 250/938] loss_G: 3.380551, loss_D: 0.206032\n",
      "[Epoch 13/200] [Batch 260/938] loss_G: 4.278738, loss_D: 0.129287\n",
      "[Epoch 13/200] [Batch 270/938] loss_G: 4.759891, loss_D: 0.090070\n",
      "[Epoch 13/200] [Batch 280/938] loss_G: 3.290081, loss_D: 0.097487\n",
      "[Epoch 13/200] [Batch 290/938] loss_G: 3.831401, loss_D: 0.107717\n",
      "[Epoch 13/200] [Batch 300/938] loss_G: 3.646563, loss_D: 0.087845\n",
      "[Epoch 13/200] [Batch 310/938] loss_G: 3.807503, loss_D: 0.147319\n",
      "[Epoch 13/200] [Batch 320/938] loss_G: 3.524685, loss_D: 0.143618\n",
      "[Epoch 13/200] [Batch 330/938] loss_G: 3.632825, loss_D: 0.197524\n",
      "[Epoch 13/200] [Batch 340/938] loss_G: 3.062073, loss_D: 0.203852\n",
      "[Epoch 13/200] [Batch 350/938] loss_G: 4.478445, loss_D: 0.114369\n",
      "[Epoch 13/200] [Batch 360/938] loss_G: 4.547285, loss_D: 0.193054\n",
      "[Epoch 13/200] [Batch 370/938] loss_G: 4.110059, loss_D: 0.161873\n",
      "[Epoch 13/200] [Batch 380/938] loss_G: 3.922181, loss_D: 0.093856\n",
      "[Epoch 13/200] [Batch 390/938] loss_G: 4.502701, loss_D: 0.161050\n",
      "[Epoch 13/200] [Batch 400/938] loss_G: 4.243932, loss_D: 0.157825\n",
      "[Epoch 13/200] [Batch 410/938] loss_G: 3.991937, loss_D: 0.116044\n",
      "[Epoch 13/200] [Batch 420/938] loss_G: 3.617925, loss_D: 0.097532\n",
      "[Epoch 13/200] [Batch 430/938] loss_G: 4.386887, loss_D: 0.057472\n",
      "[Epoch 13/200] [Batch 440/938] loss_G: 3.919580, loss_D: 0.069248\n",
      "[Epoch 13/200] [Batch 450/938] loss_G: 3.295919, loss_D: 0.063985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13/200] [Batch 460/938] loss_G: 4.530436, loss_D: 0.087320\n",
      "[Epoch 13/200] [Batch 470/938] loss_G: 4.353297, loss_D: 0.125546\n",
      "[Epoch 13/200] [Batch 480/938] loss_G: 4.703059, loss_D: 0.097416\n",
      "[Epoch 13/200] [Batch 490/938] loss_G: 4.540564, loss_D: 0.086318\n",
      "[Epoch 13/200] [Batch 500/938] loss_G: 3.681551, loss_D: 0.114540\n",
      "[Epoch 13/200] [Batch 510/938] loss_G: 3.740301, loss_D: 0.170533\n",
      "[Epoch 13/200] [Batch 520/938] loss_G: 3.761839, loss_D: 0.086181\n",
      "[Epoch 13/200] [Batch 530/938] loss_G: 3.728296, loss_D: 0.056628\n",
      "[Epoch 13/200] [Batch 540/938] loss_G: 3.313395, loss_D: 0.096352\n",
      "[Epoch 13/200] [Batch 550/938] loss_G: 3.695944, loss_D: 0.137050\n",
      "[Epoch 13/200] [Batch 560/938] loss_G: 3.841375, loss_D: 0.126331\n",
      "[Epoch 13/200] [Batch 570/938] loss_G: 3.768120, loss_D: 0.210768\n",
      "[Epoch 13/200] [Batch 580/938] loss_G: 3.647026, loss_D: 0.057925\n",
      "[Epoch 13/200] [Batch 590/938] loss_G: 3.773802, loss_D: 0.112512\n",
      "[Epoch 13/200] [Batch 600/938] loss_G: 4.123393, loss_D: 0.194892\n",
      "[Epoch 13/200] [Batch 610/938] loss_G: 3.654720, loss_D: 0.115314\n",
      "[Epoch 13/200] [Batch 620/938] loss_G: 4.321813, loss_D: 0.121355\n",
      "[Epoch 13/200] [Batch 630/938] loss_G: 3.851863, loss_D: 0.160247\n",
      "[Epoch 13/200] [Batch 640/938] loss_G: 3.650857, loss_D: 0.094100\n",
      "[Epoch 13/200] [Batch 650/938] loss_G: 3.992126, loss_D: 0.075278\n",
      "[Epoch 13/200] [Batch 660/938] loss_G: 4.694325, loss_D: 0.141814\n",
      "[Epoch 13/200] [Batch 670/938] loss_G: 3.498940, loss_D: 0.141121\n",
      "[Epoch 13/200] [Batch 680/938] loss_G: 4.144652, loss_D: 0.206245\n",
      "[Epoch 13/200] [Batch 690/938] loss_G: 4.268023, loss_D: 0.133873\n",
      "[Epoch 13/200] [Batch 700/938] loss_G: 4.407824, loss_D: 0.078698\n",
      "[Epoch 13/200] [Batch 710/938] loss_G: 3.605339, loss_D: 0.197765\n",
      "[Epoch 13/200] [Batch 720/938] loss_G: 4.325434, loss_D: 0.186512\n",
      "[Epoch 13/200] [Batch 730/938] loss_G: 3.462043, loss_D: 0.166969\n",
      "[Epoch 13/200] [Batch 740/938] loss_G: 3.822270, loss_D: 0.120695\n",
      "[Epoch 13/200] [Batch 750/938] loss_G: 3.944234, loss_D: 0.093065\n",
      "[Epoch 13/200] [Batch 760/938] loss_G: 3.509306, loss_D: 0.151605\n",
      "[Epoch 13/200] [Batch 770/938] loss_G: 3.932257, loss_D: 0.099974\n",
      "[Epoch 13/200] [Batch 780/938] loss_G: 4.425381, loss_D: 0.067875\n",
      "[Epoch 13/200] [Batch 790/938] loss_G: 4.131925, loss_D: 0.095660\n",
      "[Epoch 13/200] [Batch 800/938] loss_G: 4.027271, loss_D: 0.176359\n",
      "[Epoch 13/200] [Batch 810/938] loss_G: 3.860749, loss_D: 0.061593\n",
      "[Epoch 13/200] [Batch 820/938] loss_G: 4.362854, loss_D: 0.087736\n",
      "[Epoch 13/200] [Batch 830/938] loss_G: 4.390061, loss_D: 0.151252\n",
      "[Epoch 13/200] [Batch 840/938] loss_G: 3.642045, loss_D: 0.179378\n",
      "[Epoch 13/200] [Batch 850/938] loss_G: 4.065724, loss_D: 0.182203\n",
      "[Epoch 13/200] [Batch 860/938] loss_G: 3.530392, loss_D: 0.117622\n",
      "[Epoch 13/200] [Batch 870/938] loss_G: 3.545149, loss_D: 0.146429\n",
      "[Epoch 13/200] [Batch 880/938] loss_G: 3.569805, loss_D: 0.188926\n",
      "[Epoch 13/200] [Batch 890/938] loss_G: 4.618398, loss_D: 0.113360\n",
      "[Epoch 13/200] [Batch 900/938] loss_G: 4.488877, loss_D: 0.127900\n",
      "[Epoch 13/200] [Batch 910/938] loss_G: 3.635365, loss_D: 0.121902\n",
      "[Epoch 13/200] [Batch 920/938] loss_G: 3.781847, loss_D: 0.118087\n",
      "[Epoch 13/200] [Batch 930/938] loss_G: 4.133624, loss_D: 0.121082\n",
      "[Epoch 14/200] [Batch 0/938] loss_G: 3.799631, loss_D: 0.058264\n",
      "[Epoch 14/200] [Batch 10/938] loss_G: 4.193885, loss_D: 0.096398\n",
      "[Epoch 14/200] [Batch 20/938] loss_G: 4.329487, loss_D: 0.067812\n",
      "[Epoch 14/200] [Batch 30/938] loss_G: 3.601915, loss_D: 0.080847\n",
      "[Epoch 14/200] [Batch 40/938] loss_G: 3.634444, loss_D: 0.127240\n",
      "[Epoch 14/200] [Batch 50/938] loss_G: 3.096066, loss_D: 0.207467\n",
      "[Epoch 14/200] [Batch 60/938] loss_G: 3.837079, loss_D: 0.125833\n",
      "[Epoch 14/200] [Batch 70/938] loss_G: 3.709784, loss_D: 0.143879\n",
      "[Epoch 14/200] [Batch 80/938] loss_G: 4.004855, loss_D: 0.073489\n",
      "[Epoch 14/200] [Batch 90/938] loss_G: 4.122355, loss_D: 0.068218\n",
      "[Epoch 14/200] [Batch 100/938] loss_G: 4.043941, loss_D: 0.136908\n",
      "[Epoch 14/200] [Batch 110/938] loss_G: 3.401679, loss_D: 0.153558\n",
      "[Epoch 14/200] [Batch 120/938] loss_G: 4.076787, loss_D: 0.113101\n",
      "[Epoch 14/200] [Batch 130/938] loss_G: 4.100342, loss_D: 0.072221\n",
      "[Epoch 14/200] [Batch 140/938] loss_G: 3.681822, loss_D: 0.149373\n",
      "[Epoch 14/200] [Batch 150/938] loss_G: 3.909266, loss_D: 0.028160\n",
      "[Epoch 14/200] [Batch 160/938] loss_G: 4.493723, loss_D: 0.130823\n",
      "[Epoch 14/200] [Batch 170/938] loss_G: 3.670604, loss_D: 0.204788\n",
      "[Epoch 14/200] [Batch 180/938] loss_G: 3.366143, loss_D: 0.149485\n",
      "[Epoch 14/200] [Batch 190/938] loss_G: 4.430095, loss_D: 0.095263\n",
      "[Epoch 14/200] [Batch 200/938] loss_G: 3.823209, loss_D: 0.076084\n",
      "[Epoch 14/200] [Batch 210/938] loss_G: 3.904574, loss_D: 0.128680\n",
      "[Epoch 14/200] [Batch 220/938] loss_G: 3.655604, loss_D: 0.133537\n",
      "[Epoch 14/200] [Batch 230/938] loss_G: 2.817590, loss_D: 0.170545\n",
      "[Epoch 14/200] [Batch 240/938] loss_G: 3.248997, loss_D: 0.119489\n",
      "[Epoch 14/200] [Batch 250/938] loss_G: 3.847961, loss_D: 0.075860\n",
      "[Epoch 14/200] [Batch 260/938] loss_G: 4.004276, loss_D: 0.084224\n",
      "[Epoch 14/200] [Batch 270/938] loss_G: 4.182911, loss_D: 0.215658\n",
      "[Epoch 14/200] [Batch 280/938] loss_G: 3.963876, loss_D: 0.079727\n",
      "[Epoch 14/200] [Batch 290/938] loss_G: 3.644922, loss_D: 0.132701\n",
      "[Epoch 14/200] [Batch 300/938] loss_G: 3.781940, loss_D: 0.110350\n",
      "[Epoch 14/200] [Batch 310/938] loss_G: 3.797460, loss_D: 0.101507\n",
      "[Epoch 14/200] [Batch 320/938] loss_G: 4.000552, loss_D: 0.145492\n",
      "[Epoch 14/200] [Batch 330/938] loss_G: 3.280066, loss_D: 0.259226\n",
      "[Epoch 14/200] [Batch 340/938] loss_G: 3.183096, loss_D: 0.208246\n",
      "[Epoch 14/200] [Batch 350/938] loss_G: 3.721005, loss_D: 0.118002\n",
      "[Epoch 14/200] [Batch 360/938] loss_G: 4.022263, loss_D: 0.139732\n",
      "[Epoch 14/200] [Batch 370/938] loss_G: 4.067846, loss_D: 0.119930\n",
      "[Epoch 14/200] [Batch 380/938] loss_G: 4.193883, loss_D: 0.051577\n",
      "[Epoch 14/200] [Batch 390/938] loss_G: 3.790335, loss_D: 0.222576\n",
      "[Epoch 14/200] [Batch 400/938] loss_G: 3.874353, loss_D: 0.152330\n",
      "[Epoch 14/200] [Batch 410/938] loss_G: 4.367180, loss_D: 0.058102\n",
      "[Epoch 14/200] [Batch 420/938] loss_G: 4.150420, loss_D: 0.081503\n",
      "[Epoch 14/200] [Batch 430/938] loss_G: 3.534692, loss_D: 0.181594\n",
      "[Epoch 14/200] [Batch 440/938] loss_G: 3.388645, loss_D: 0.118424\n",
      "[Epoch 14/200] [Batch 450/938] loss_G: 4.544155, loss_D: 0.108469\n",
      "[Epoch 14/200] [Batch 460/938] loss_G: 3.651324, loss_D: 0.138854\n",
      "[Epoch 14/200] [Batch 470/938] loss_G: 3.832229, loss_D: 0.144026\n",
      "[Epoch 14/200] [Batch 480/938] loss_G: 4.205301, loss_D: 0.104570\n",
      "[Epoch 14/200] [Batch 490/938] loss_G: 4.247143, loss_D: 0.081548\n",
      "[Epoch 14/200] [Batch 500/938] loss_G: 3.616962, loss_D: 0.152621\n",
      "[Epoch 14/200] [Batch 510/938] loss_G: 3.561180, loss_D: 0.143113\n",
      "[Epoch 14/200] [Batch 520/938] loss_G: 3.624668, loss_D: 0.089090\n",
      "[Epoch 14/200] [Batch 530/938] loss_G: 3.644990, loss_D: 0.140084\n",
      "[Epoch 14/200] [Batch 540/938] loss_G: 4.477125, loss_D: 0.146216\n",
      "[Epoch 14/200] [Batch 550/938] loss_G: 4.575732, loss_D: 0.074908\n",
      "[Epoch 14/200] [Batch 560/938] loss_G: 4.073631, loss_D: 0.120353\n",
      "[Epoch 14/200] [Batch 570/938] loss_G: 4.028523, loss_D: 0.223859\n",
      "[Epoch 14/200] [Batch 580/938] loss_G: 3.732970, loss_D: 0.195436\n",
      "[Epoch 14/200] [Batch 590/938] loss_G: 4.288462, loss_D: 0.088720\n",
      "[Epoch 14/200] [Batch 600/938] loss_G: 4.377558, loss_D: 0.108162\n",
      "[Epoch 14/200] [Batch 610/938] loss_G: 4.059165, loss_D: 0.082694\n",
      "[Epoch 14/200] [Batch 620/938] loss_G: 4.136653, loss_D: 0.104457\n",
      "[Epoch 14/200] [Batch 630/938] loss_G: 3.635242, loss_D: 0.247341\n",
      "[Epoch 14/200] [Batch 640/938] loss_G: 3.791074, loss_D: 0.216117\n",
      "[Epoch 14/200] [Batch 650/938] loss_G: 3.583400, loss_D: 0.095303\n",
      "[Epoch 14/200] [Batch 660/938] loss_G: 3.907330, loss_D: 0.194272\n",
      "[Epoch 14/200] [Batch 670/938] loss_G: 3.997895, loss_D: 0.111377\n",
      "[Epoch 14/200] [Batch 680/938] loss_G: 4.291945, loss_D: 0.136990\n",
      "[Epoch 14/200] [Batch 690/938] loss_G: 4.683551, loss_D: 0.128555\n",
      "[Epoch 14/200] [Batch 700/938] loss_G: 3.215561, loss_D: 0.107070\n",
      "[Epoch 14/200] [Batch 710/938] loss_G: 3.873086, loss_D: 0.067874\n",
      "[Epoch 14/200] [Batch 720/938] loss_G: 3.880338, loss_D: 0.133548\n",
      "[Epoch 14/200] [Batch 730/938] loss_G: 3.698166, loss_D: 0.147216\n",
      "[Epoch 14/200] [Batch 740/938] loss_G: 4.041897, loss_D: 0.182948\n",
      "[Epoch 14/200] [Batch 750/938] loss_G: 3.418962, loss_D: 0.193539\n",
      "[Epoch 14/200] [Batch 760/938] loss_G: 4.258742, loss_D: 0.072401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14/200] [Batch 770/938] loss_G: 4.184202, loss_D: 0.100073\n",
      "[Epoch 14/200] [Batch 780/938] loss_G: 4.203980, loss_D: 0.162918\n",
      "[Epoch 14/200] [Batch 790/938] loss_G: 4.121017, loss_D: 0.140621\n",
      "[Epoch 14/200] [Batch 800/938] loss_G: 3.134674, loss_D: 0.201324\n",
      "[Epoch 14/200] [Batch 810/938] loss_G: 3.832624, loss_D: 0.257117\n",
      "[Epoch 14/200] [Batch 820/938] loss_G: 4.490222, loss_D: 0.154228\n",
      "[Epoch 14/200] [Batch 830/938] loss_G: 3.776445, loss_D: 0.092815\n",
      "[Epoch 14/200] [Batch 840/938] loss_G: 3.971447, loss_D: 0.204607\n",
      "[Epoch 14/200] [Batch 850/938] loss_G: 4.744212, loss_D: 0.100483\n",
      "[Epoch 14/200] [Batch 860/938] loss_G: 3.739189, loss_D: 0.177658\n",
      "[Epoch 14/200] [Batch 870/938] loss_G: 3.456127, loss_D: 0.185018\n",
      "[Epoch 14/200] [Batch 880/938] loss_G: 3.654760, loss_D: 0.185430\n",
      "[Epoch 14/200] [Batch 890/938] loss_G: 3.557564, loss_D: 0.122360\n",
      "[Epoch 14/200] [Batch 900/938] loss_G: 4.098633, loss_D: 0.136725\n",
      "[Epoch 14/200] [Batch 910/938] loss_G: 4.235595, loss_D: 0.086430\n",
      "[Epoch 14/200] [Batch 920/938] loss_G: 3.643062, loss_D: 0.091373\n",
      "[Epoch 14/200] [Batch 930/938] loss_G: 4.468796, loss_D: 0.221631\n",
      "[Epoch 15/200] [Batch 0/938] loss_G: 3.940293, loss_D: 0.151285\n",
      "[Epoch 15/200] [Batch 10/938] loss_G: 2.802257, loss_D: 0.200560\n",
      "[Epoch 15/200] [Batch 20/938] loss_G: 3.556353, loss_D: 0.087105\n",
      "[Epoch 15/200] [Batch 30/938] loss_G: 4.188186, loss_D: 0.140325\n",
      "[Epoch 15/200] [Batch 40/938] loss_G: 3.878289, loss_D: 0.256217\n",
      "[Epoch 15/200] [Batch 50/938] loss_G: 3.364850, loss_D: 0.132207\n",
      "[Epoch 15/200] [Batch 60/938] loss_G: 4.009919, loss_D: 0.147173\n",
      "[Epoch 15/200] [Batch 70/938] loss_G: 3.926245, loss_D: 0.186155\n",
      "[Epoch 15/200] [Batch 80/938] loss_G: 4.141236, loss_D: 0.138190\n",
      "[Epoch 15/200] [Batch 90/938] loss_G: 4.032408, loss_D: 0.105801\n",
      "[Epoch 15/200] [Batch 100/938] loss_G: 3.697194, loss_D: 0.166129\n",
      "[Epoch 15/200] [Batch 110/938] loss_G: 4.219076, loss_D: 0.098937\n",
      "[Epoch 15/200] [Batch 120/938] loss_G: 3.872989, loss_D: 0.074949\n",
      "[Epoch 15/200] [Batch 130/938] loss_G: 3.867023, loss_D: 0.143527\n",
      "[Epoch 15/200] [Batch 140/938] loss_G: 4.411433, loss_D: 0.103035\n",
      "[Epoch 15/200] [Batch 150/938] loss_G: 4.394934, loss_D: 0.060749\n",
      "[Epoch 15/200] [Batch 160/938] loss_G: 3.924968, loss_D: 0.073484\n",
      "[Epoch 15/200] [Batch 170/938] loss_G: 5.057607, loss_D: 0.158114\n",
      "[Epoch 15/200] [Batch 180/938] loss_G: 3.227243, loss_D: 0.224787\n",
      "[Epoch 15/200] [Batch 190/938] loss_G: 4.452544, loss_D: 0.050157\n",
      "[Epoch 15/200] [Batch 200/938] loss_G: 3.992836, loss_D: 0.101747\n",
      "[Epoch 15/200] [Batch 210/938] loss_G: 4.216794, loss_D: 0.155495\n",
      "[Epoch 15/200] [Batch 220/938] loss_G: 3.736762, loss_D: 0.173043\n",
      "[Epoch 15/200] [Batch 230/938] loss_G: 4.136100, loss_D: 0.122042\n",
      "[Epoch 15/200] [Batch 240/938] loss_G: 5.006184, loss_D: 0.122887\n",
      "[Epoch 15/200] [Batch 250/938] loss_G: 3.667758, loss_D: 0.253595\n",
      "[Epoch 15/200] [Batch 260/938] loss_G: 3.553440, loss_D: 0.203229\n",
      "[Epoch 15/200] [Batch 270/938] loss_G: 4.143650, loss_D: 0.117262\n",
      "[Epoch 15/200] [Batch 280/938] loss_G: 3.699883, loss_D: 0.104749\n",
      "[Epoch 15/200] [Batch 290/938] loss_G: 3.732302, loss_D: 0.174581\n",
      "[Epoch 15/200] [Batch 300/938] loss_G: 3.295378, loss_D: 0.268788\n",
      "[Epoch 15/200] [Batch 310/938] loss_G: 3.949502, loss_D: 0.085498\n",
      "[Epoch 15/200] [Batch 320/938] loss_G: 3.839200, loss_D: 0.151063\n",
      "[Epoch 15/200] [Batch 330/938] loss_G: 3.786048, loss_D: 0.048278\n",
      "[Epoch 15/200] [Batch 340/938] loss_G: 3.767358, loss_D: 0.133186\n",
      "[Epoch 15/200] [Batch 350/938] loss_G: 4.746139, loss_D: 0.118089\n",
      "[Epoch 15/200] [Batch 360/938] loss_G: 3.323704, loss_D: 0.140893\n",
      "[Epoch 15/200] [Batch 370/938] loss_G: 3.713300, loss_D: 0.209695\n",
      "[Epoch 15/200] [Batch 380/938] loss_G: 4.487982, loss_D: 0.062350\n",
      "[Epoch 15/200] [Batch 390/938] loss_G: 3.737588, loss_D: 0.132299\n",
      "[Epoch 15/200] [Batch 400/938] loss_G: 3.645186, loss_D: 0.110652\n",
      "[Epoch 15/200] [Batch 410/938] loss_G: 4.323398, loss_D: 0.160924\n",
      "[Epoch 15/200] [Batch 420/938] loss_G: 4.574009, loss_D: 0.151938\n",
      "[Epoch 15/200] [Batch 430/938] loss_G: 4.267180, loss_D: 0.108141\n",
      "[Epoch 15/200] [Batch 440/938] loss_G: 3.667534, loss_D: 0.167305\n",
      "[Epoch 15/200] [Batch 450/938] loss_G: 4.852535, loss_D: 0.137959\n",
      "[Epoch 15/200] [Batch 460/938] loss_G: 4.321530, loss_D: 0.089936\n",
      "[Epoch 15/200] [Batch 470/938] loss_G: 4.875154, loss_D: 0.088541\n",
      "[Epoch 15/200] [Batch 480/938] loss_G: 3.819993, loss_D: 0.189037\n",
      "[Epoch 15/200] [Batch 490/938] loss_G: 3.893094, loss_D: 0.133218\n",
      "[Epoch 15/200] [Batch 500/938] loss_G: 4.294473, loss_D: 0.076119\n",
      "[Epoch 15/200] [Batch 510/938] loss_G: 4.161278, loss_D: 0.092752\n",
      "[Epoch 15/200] [Batch 520/938] loss_G: 4.015699, loss_D: 0.170102\n",
      "[Epoch 15/200] [Batch 530/938] loss_G: 4.032044, loss_D: 0.101786\n",
      "[Epoch 15/200] [Batch 540/938] loss_G: 3.847645, loss_D: 0.166994\n",
      "[Epoch 15/200] [Batch 550/938] loss_G: 3.594412, loss_D: 0.207753\n",
      "[Epoch 15/200] [Batch 560/938] loss_G: 4.381203, loss_D: 0.158641\n",
      "[Epoch 15/200] [Batch 570/938] loss_G: 3.916505, loss_D: 0.085934\n",
      "[Epoch 15/200] [Batch 580/938] loss_G: 3.766278, loss_D: 0.069514\n",
      "[Epoch 15/200] [Batch 590/938] loss_G: 3.540318, loss_D: 0.278699\n",
      "[Epoch 15/200] [Batch 600/938] loss_G: 4.270086, loss_D: 0.073519\n",
      "[Epoch 15/200] [Batch 610/938] loss_G: 3.921936, loss_D: 0.181552\n",
      "[Epoch 15/200] [Batch 620/938] loss_G: 4.201687, loss_D: 0.114218\n",
      "[Epoch 15/200] [Batch 630/938] loss_G: 3.658340, loss_D: 0.253290\n",
      "[Epoch 15/200] [Batch 640/938] loss_G: 3.978546, loss_D: 0.225176\n",
      "[Epoch 15/200] [Batch 650/938] loss_G: 4.722675, loss_D: 0.083959\n",
      "[Epoch 15/200] [Batch 660/938] loss_G: 4.117553, loss_D: 0.086351\n",
      "[Epoch 15/200] [Batch 670/938] loss_G: 4.216980, loss_D: 0.157684\n",
      "[Epoch 15/200] [Batch 680/938] loss_G: 4.625504, loss_D: 0.135244\n",
      "[Epoch 15/200] [Batch 690/938] loss_G: 4.097636, loss_D: 0.067056\n",
      "[Epoch 15/200] [Batch 700/938] loss_G: 4.866558, loss_D: 0.160867\n",
      "[Epoch 15/200] [Batch 710/938] loss_G: 3.769775, loss_D: 0.181048\n",
      "[Epoch 15/200] [Batch 720/938] loss_G: 4.383766, loss_D: 0.146194\n",
      "[Epoch 15/200] [Batch 730/938] loss_G: 3.687816, loss_D: 0.151681\n",
      "[Epoch 15/200] [Batch 740/938] loss_G: 3.771023, loss_D: 0.093978\n",
      "[Epoch 15/200] [Batch 750/938] loss_G: 4.188511, loss_D: 0.065277\n",
      "[Epoch 15/200] [Batch 760/938] loss_G: 3.886441, loss_D: 0.087771\n",
      "[Epoch 15/200] [Batch 770/938] loss_G: 3.599600, loss_D: 0.112750\n",
      "[Epoch 15/200] [Batch 780/938] loss_G: 3.453676, loss_D: 0.112901\n",
      "[Epoch 15/200] [Batch 790/938] loss_G: 4.225612, loss_D: 0.093770\n",
      "[Epoch 15/200] [Batch 800/938] loss_G: 3.988045, loss_D: 0.197049\n",
      "[Epoch 15/200] [Batch 810/938] loss_G: 3.664600, loss_D: 0.118578\n",
      "[Epoch 15/200] [Batch 820/938] loss_G: 4.256243, loss_D: 0.171454\n",
      "[Epoch 15/200] [Batch 830/938] loss_G: 4.038349, loss_D: 0.093866\n",
      "[Epoch 15/200] [Batch 840/938] loss_G: 4.003876, loss_D: 0.149166\n",
      "[Epoch 15/200] [Batch 850/938] loss_G: 4.441660, loss_D: 0.120683\n",
      "[Epoch 15/200] [Batch 860/938] loss_G: 3.702950, loss_D: 0.125612\n",
      "[Epoch 15/200] [Batch 870/938] loss_G: 3.574875, loss_D: 0.176986\n",
      "[Epoch 15/200] [Batch 880/938] loss_G: 4.040916, loss_D: 0.153352\n",
      "[Epoch 15/200] [Batch 890/938] loss_G: 3.800490, loss_D: 0.091443\n",
      "[Epoch 15/200] [Batch 900/938] loss_G: 4.235754, loss_D: 0.225373\n",
      "[Epoch 15/200] [Batch 910/938] loss_G: 4.009118, loss_D: 0.168862\n",
      "[Epoch 15/200] [Batch 920/938] loss_G: 4.153229, loss_D: 0.103599\n",
      "[Epoch 15/200] [Batch 930/938] loss_G: 3.721642, loss_D: 0.125094\n",
      "[Epoch 16/200] [Batch 0/938] loss_G: 3.649393, loss_D: 0.108080\n",
      "[Epoch 16/200] [Batch 10/938] loss_G: 3.872915, loss_D: 0.109555\n",
      "[Epoch 16/200] [Batch 20/938] loss_G: 3.911446, loss_D: 0.192364\n",
      "[Epoch 16/200] [Batch 30/938] loss_G: 3.893613, loss_D: 0.109241\n",
      "[Epoch 16/200] [Batch 40/938] loss_G: 3.580606, loss_D: 0.136615\n",
      "[Epoch 16/200] [Batch 50/938] loss_G: 3.792927, loss_D: 0.173554\n",
      "[Epoch 16/200] [Batch 60/938] loss_G: 3.954890, loss_D: 0.146601\n",
      "[Epoch 16/200] [Batch 70/938] loss_G: 3.548305, loss_D: 0.135123\n",
      "[Epoch 16/200] [Batch 80/938] loss_G: 3.216852, loss_D: 0.239274\n",
      "[Epoch 16/200] [Batch 90/938] loss_G: 3.375178, loss_D: 0.143325\n",
      "[Epoch 16/200] [Batch 100/938] loss_G: 3.074372, loss_D: 0.144762\n",
      "[Epoch 16/200] [Batch 110/938] loss_G: 3.597938, loss_D: 0.210608\n",
      "[Epoch 16/200] [Batch 120/938] loss_G: 3.854990, loss_D: 0.138580\n",
      "[Epoch 16/200] [Batch 130/938] loss_G: 4.045263, loss_D: 0.145127\n",
      "[Epoch 16/200] [Batch 140/938] loss_G: 3.799984, loss_D: 0.058696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16/200] [Batch 150/938] loss_G: 4.153309, loss_D: 0.143443\n",
      "[Epoch 16/200] [Batch 160/938] loss_G: 3.299722, loss_D: 0.115452\n",
      "[Epoch 16/200] [Batch 170/938] loss_G: 4.720846, loss_D: 0.141226\n",
      "[Epoch 16/200] [Batch 180/938] loss_G: 4.777937, loss_D: 0.113077\n",
      "[Epoch 16/200] [Batch 190/938] loss_G: 4.057212, loss_D: 0.118051\n",
      "[Epoch 16/200] [Batch 200/938] loss_G: 4.596266, loss_D: 0.075279\n",
      "[Epoch 16/200] [Batch 210/938] loss_G: 4.092980, loss_D: 0.096933\n",
      "[Epoch 16/200] [Batch 220/938] loss_G: 4.089166, loss_D: 0.142836\n",
      "[Epoch 16/200] [Batch 230/938] loss_G: 4.019273, loss_D: 0.173510\n",
      "[Epoch 16/200] [Batch 240/938] loss_G: 4.725247, loss_D: 0.053020\n",
      "[Epoch 16/200] [Batch 250/938] loss_G: 3.866400, loss_D: 0.107246\n",
      "[Epoch 16/200] [Batch 260/938] loss_G: 4.064603, loss_D: 0.132707\n",
      "[Epoch 16/200] [Batch 270/938] loss_G: 4.323129, loss_D: 0.091468\n",
      "[Epoch 16/200] [Batch 280/938] loss_G: 3.545696, loss_D: 0.151904\n",
      "[Epoch 16/200] [Batch 290/938] loss_G: 3.544988, loss_D: 0.161885\n",
      "[Epoch 16/200] [Batch 300/938] loss_G: 4.278888, loss_D: 0.123059\n",
      "[Epoch 16/200] [Batch 310/938] loss_G: 3.481869, loss_D: 0.185573\n",
      "[Epoch 16/200] [Batch 320/938] loss_G: 3.920685, loss_D: 0.227333\n",
      "[Epoch 16/200] [Batch 330/938] loss_G: 3.593266, loss_D: 0.082188\n",
      "[Epoch 16/200] [Batch 340/938] loss_G: 3.768861, loss_D: 0.100031\n",
      "[Epoch 16/200] [Batch 350/938] loss_G: 3.494934, loss_D: 0.197090\n",
      "[Epoch 16/200] [Batch 360/938] loss_G: 3.586902, loss_D: 0.116705\n",
      "[Epoch 16/200] [Batch 370/938] loss_G: 3.905719, loss_D: 0.145573\n",
      "[Epoch 16/200] [Batch 380/938] loss_G: 3.531159, loss_D: 0.109072\n",
      "[Epoch 16/200] [Batch 390/938] loss_G: 4.739571, loss_D: 0.215113\n",
      "[Epoch 16/200] [Batch 400/938] loss_G: 3.966311, loss_D: 0.142673\n",
      "[Epoch 16/200] [Batch 410/938] loss_G: 3.407576, loss_D: 0.204296\n",
      "[Epoch 16/200] [Batch 420/938] loss_G: 3.718294, loss_D: 0.138586\n",
      "[Epoch 16/200] [Batch 430/938] loss_G: 3.817744, loss_D: 0.131496\n",
      "[Epoch 16/200] [Batch 440/938] loss_G: 3.616570, loss_D: 0.205142\n",
      "[Epoch 16/200] [Batch 450/938] loss_G: 3.407888, loss_D: 0.122107\n",
      "[Epoch 16/200] [Batch 460/938] loss_G: 3.490228, loss_D: 0.125561\n",
      "[Epoch 16/200] [Batch 470/938] loss_G: 3.815877, loss_D: 0.117045\n",
      "[Epoch 16/200] [Batch 480/938] loss_G: 3.584219, loss_D: 0.185283\n",
      "[Epoch 16/200] [Batch 490/938] loss_G: 3.945018, loss_D: 0.102387\n",
      "[Epoch 16/200] [Batch 500/938] loss_G: 4.056478, loss_D: 0.209340\n",
      "[Epoch 16/200] [Batch 510/938] loss_G: 3.419936, loss_D: 0.168029\n",
      "[Epoch 16/200] [Batch 520/938] loss_G: 3.494667, loss_D: 0.156219\n",
      "[Epoch 16/200] [Batch 530/938] loss_G: 3.032792, loss_D: 0.127416\n",
      "[Epoch 16/200] [Batch 540/938] loss_G: 3.639515, loss_D: 0.184287\n",
      "[Epoch 16/200] [Batch 550/938] loss_G: 3.202384, loss_D: 0.152158\n",
      "[Epoch 16/200] [Batch 560/938] loss_G: 3.697279, loss_D: 0.122740\n",
      "[Epoch 16/200] [Batch 570/938] loss_G: 3.843186, loss_D: 0.160461\n",
      "[Epoch 16/200] [Batch 580/938] loss_G: 3.165420, loss_D: 0.205346\n",
      "[Epoch 16/200] [Batch 590/938] loss_G: 3.658927, loss_D: 0.136811\n",
      "[Epoch 16/200] [Batch 600/938] loss_G: 4.410318, loss_D: 0.100790\n",
      "[Epoch 16/200] [Batch 610/938] loss_G: 3.609067, loss_D: 0.102142\n",
      "[Epoch 16/200] [Batch 620/938] loss_G: 3.314209, loss_D: 0.159931\n",
      "[Epoch 16/200] [Batch 630/938] loss_G: 3.270411, loss_D: 0.189900\n",
      "[Epoch 16/200] [Batch 640/938] loss_G: 4.033233, loss_D: 0.097641\n",
      "[Epoch 16/200] [Batch 650/938] loss_G: 3.863005, loss_D: 0.096378\n",
      "[Epoch 16/200] [Batch 660/938] loss_G: 3.668798, loss_D: 0.239732\n",
      "[Epoch 16/200] [Batch 670/938] loss_G: 3.331104, loss_D: 0.215887\n",
      "[Epoch 16/200] [Batch 680/938] loss_G: 3.720129, loss_D: 0.186600\n",
      "[Epoch 16/200] [Batch 690/938] loss_G: 3.767698, loss_D: 0.113451\n",
      "[Epoch 16/200] [Batch 700/938] loss_G: 3.508375, loss_D: 0.168201\n",
      "[Epoch 16/200] [Batch 710/938] loss_G: 4.028752, loss_D: 0.128342\n",
      "[Epoch 16/200] [Batch 720/938] loss_G: 3.202450, loss_D: 0.244200\n",
      "[Epoch 16/200] [Batch 730/938] loss_G: 4.274770, loss_D: 0.171546\n",
      "[Epoch 16/200] [Batch 740/938] loss_G: 3.409213, loss_D: 0.141079\n",
      "[Epoch 16/200] [Batch 750/938] loss_G: 3.808238, loss_D: 0.250832\n",
      "[Epoch 16/200] [Batch 760/938] loss_G: 3.864757, loss_D: 0.165610\n",
      "[Epoch 16/200] [Batch 770/938] loss_G: 3.611151, loss_D: 0.237173\n",
      "[Epoch 16/200] [Batch 780/938] loss_G: 3.308540, loss_D: 0.158847\n",
      "[Epoch 16/200] [Batch 790/938] loss_G: 3.914729, loss_D: 0.112581\n",
      "[Epoch 16/200] [Batch 800/938] loss_G: 3.489826, loss_D: 0.177546\n",
      "[Epoch 16/200] [Batch 810/938] loss_G: 3.837619, loss_D: 0.180455\n",
      "[Epoch 16/200] [Batch 820/938] loss_G: 3.447464, loss_D: 0.146042\n",
      "[Epoch 16/200] [Batch 830/938] loss_G: 3.626757, loss_D: 0.177957\n",
      "[Epoch 16/200] [Batch 840/938] loss_G: 3.359539, loss_D: 0.164044\n",
      "[Epoch 16/200] [Batch 850/938] loss_G: 4.099074, loss_D: 0.112721\n",
      "[Epoch 16/200] [Batch 860/938] loss_G: 4.405628, loss_D: 0.162591\n",
      "[Epoch 16/200] [Batch 870/938] loss_G: 3.321339, loss_D: 0.217126\n",
      "[Epoch 16/200] [Batch 880/938] loss_G: 2.833226, loss_D: 0.217705\n",
      "[Epoch 16/200] [Batch 890/938] loss_G: 3.956659, loss_D: 0.109014\n",
      "[Epoch 16/200] [Batch 900/938] loss_G: 3.838097, loss_D: 0.159031\n",
      "[Epoch 16/200] [Batch 910/938] loss_G: 3.578904, loss_D: 0.156151\n",
      "[Epoch 16/200] [Batch 920/938] loss_G: 3.532812, loss_D: 0.157964\n",
      "[Epoch 16/200] [Batch 930/938] loss_G: 3.577066, loss_D: 0.139959\n",
      "[Epoch 17/200] [Batch 0/938] loss_G: 3.520362, loss_D: 0.149704\n",
      "[Epoch 17/200] [Batch 10/938] loss_G: 2.898497, loss_D: 0.151300\n",
      "[Epoch 17/200] [Batch 20/938] loss_G: 3.702467, loss_D: 0.204207\n",
      "[Epoch 17/200] [Batch 30/938] loss_G: 4.630062, loss_D: 0.150607\n",
      "[Epoch 17/200] [Batch 40/938] loss_G: 3.714781, loss_D: 0.122956\n",
      "[Epoch 17/200] [Batch 50/938] loss_G: 3.589136, loss_D: 0.215816\n",
      "[Epoch 17/200] [Batch 60/938] loss_G: 4.525057, loss_D: 0.134095\n",
      "[Epoch 17/200] [Batch 70/938] loss_G: 4.096648, loss_D: 0.134538\n",
      "[Epoch 17/200] [Batch 80/938] loss_G: 3.883780, loss_D: 0.145058\n",
      "[Epoch 17/200] [Batch 90/938] loss_G: 3.570250, loss_D: 0.166151\n",
      "[Epoch 17/200] [Batch 100/938] loss_G: 3.677403, loss_D: 0.100752\n",
      "[Epoch 17/200] [Batch 110/938] loss_G: 4.278146, loss_D: 0.202214\n",
      "[Epoch 17/200] [Batch 120/938] loss_G: 4.393674, loss_D: 0.179770\n",
      "[Epoch 17/200] [Batch 130/938] loss_G: 4.188515, loss_D: 0.223182\n",
      "[Epoch 17/200] [Batch 140/938] loss_G: 4.289880, loss_D: 0.118462\n",
      "[Epoch 17/200] [Batch 150/938] loss_G: 3.797223, loss_D: 0.179651\n",
      "[Epoch 17/200] [Batch 160/938] loss_G: 3.244267, loss_D: 0.203217\n",
      "[Epoch 17/200] [Batch 170/938] loss_G: 3.769781, loss_D: 0.091703\n",
      "[Epoch 17/200] [Batch 180/938] loss_G: 4.269328, loss_D: 0.175577\n",
      "[Epoch 17/200] [Batch 190/938] loss_G: 3.532736, loss_D: 0.149278\n",
      "[Epoch 17/200] [Batch 200/938] loss_G: 3.314440, loss_D: 0.268087\n",
      "[Epoch 17/200] [Batch 210/938] loss_G: 3.339351, loss_D: 0.177078\n",
      "[Epoch 17/200] [Batch 220/938] loss_G: 4.107753, loss_D: 0.121731\n",
      "[Epoch 17/200] [Batch 230/938] loss_G: 4.215193, loss_D: 0.109487\n",
      "[Epoch 17/200] [Batch 240/938] loss_G: 3.657745, loss_D: 0.109202\n",
      "[Epoch 17/200] [Batch 250/938] loss_G: 3.203587, loss_D: 0.151492\n",
      "[Epoch 17/200] [Batch 260/938] loss_G: 3.902991, loss_D: 0.094217\n",
      "[Epoch 17/200] [Batch 270/938] loss_G: 4.000241, loss_D: 0.138375\n",
      "[Epoch 17/200] [Batch 280/938] loss_G: 3.960683, loss_D: 0.072739\n",
      "[Epoch 17/200] [Batch 290/938] loss_G: 3.784622, loss_D: 0.234031\n",
      "[Epoch 17/200] [Batch 300/938] loss_G: 5.076426, loss_D: 0.176202\n",
      "[Epoch 17/200] [Batch 310/938] loss_G: 3.442142, loss_D: 0.120815\n",
      "[Epoch 17/200] [Batch 320/938] loss_G: 2.678744, loss_D: 0.215014\n",
      "[Epoch 17/200] [Batch 330/938] loss_G: 3.678592, loss_D: 0.183733\n",
      "[Epoch 17/200] [Batch 340/938] loss_G: 4.071343, loss_D: 0.206473\n",
      "[Epoch 17/200] [Batch 350/938] loss_G: 3.560853, loss_D: 0.119764\n",
      "[Epoch 17/200] [Batch 360/938] loss_G: 3.361895, loss_D: 0.179592\n",
      "[Epoch 17/200] [Batch 370/938] loss_G: 4.100962, loss_D: 0.116492\n",
      "[Epoch 17/200] [Batch 380/938] loss_G: 3.682137, loss_D: 0.209786\n",
      "[Epoch 17/200] [Batch 390/938] loss_G: 4.041440, loss_D: 0.123688\n",
      "[Epoch 17/200] [Batch 400/938] loss_G: 3.761973, loss_D: 0.207516\n",
      "[Epoch 17/200] [Batch 410/938] loss_G: 4.129012, loss_D: 0.185878\n",
      "[Epoch 17/200] [Batch 420/938] loss_G: 3.364500, loss_D: 0.149583\n",
      "[Epoch 17/200] [Batch 430/938] loss_G: 3.582946, loss_D: 0.212999\n",
      "[Epoch 17/200] [Batch 440/938] loss_G: 3.790696, loss_D: 0.133521\n",
      "[Epoch 17/200] [Batch 450/938] loss_G: 3.664224, loss_D: 0.149431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/200] [Batch 460/938] loss_G: 3.802079, loss_D: 0.190880\n",
      "[Epoch 17/200] [Batch 470/938] loss_G: 4.152883, loss_D: 0.142173\n",
      "[Epoch 17/200] [Batch 480/938] loss_G: 4.414654, loss_D: 0.077514\n",
      "[Epoch 17/200] [Batch 490/938] loss_G: 3.674009, loss_D: 0.161045\n",
      "[Epoch 17/200] [Batch 500/938] loss_G: 3.563250, loss_D: 0.113834\n",
      "[Epoch 17/200] [Batch 510/938] loss_G: 3.709027, loss_D: 0.124685\n",
      "[Epoch 17/200] [Batch 520/938] loss_G: 3.761069, loss_D: 0.074936\n",
      "[Epoch 17/200] [Batch 530/938] loss_G: 3.795323, loss_D: 0.116324\n",
      "[Epoch 17/200] [Batch 540/938] loss_G: 3.916155, loss_D: 0.141618\n",
      "[Epoch 17/200] [Batch 550/938] loss_G: 3.467243, loss_D: 0.220507\n",
      "[Epoch 17/200] [Batch 560/938] loss_G: 3.507877, loss_D: 0.138860\n",
      "[Epoch 17/200] [Batch 570/938] loss_G: 3.832745, loss_D: 0.179206\n",
      "[Epoch 17/200] [Batch 580/938] loss_G: 3.351775, loss_D: 0.210142\n",
      "[Epoch 17/200] [Batch 590/938] loss_G: 3.091580, loss_D: 0.199592\n",
      "[Epoch 17/200] [Batch 600/938] loss_G: 3.608711, loss_D: 0.125276\n",
      "[Epoch 17/200] [Batch 610/938] loss_G: 3.910429, loss_D: 0.234129\n",
      "[Epoch 17/200] [Batch 620/938] loss_G: 2.875872, loss_D: 0.196541\n",
      "[Epoch 17/200] [Batch 630/938] loss_G: 3.541518, loss_D: 0.173513\n",
      "[Epoch 17/200] [Batch 640/938] loss_G: 3.319539, loss_D: 0.132932\n",
      "[Epoch 17/200] [Batch 650/938] loss_G: 4.040648, loss_D: 0.099224\n",
      "[Epoch 17/200] [Batch 660/938] loss_G: 3.304046, loss_D: 0.125422\n",
      "[Epoch 17/200] [Batch 670/938] loss_G: 3.618199, loss_D: 0.138393\n",
      "[Epoch 17/200] [Batch 680/938] loss_G: 3.944096, loss_D: 0.255086\n",
      "[Epoch 17/200] [Batch 690/938] loss_G: 3.277713, loss_D: 0.182502\n",
      "[Epoch 17/200] [Batch 700/938] loss_G: 3.505585, loss_D: 0.190922\n",
      "[Epoch 17/200] [Batch 710/938] loss_G: 3.267101, loss_D: 0.211322\n",
      "[Epoch 17/200] [Batch 720/938] loss_G: 3.260312, loss_D: 0.116248\n",
      "[Epoch 17/200] [Batch 730/938] loss_G: 4.123096, loss_D: 0.200440\n",
      "[Epoch 17/200] [Batch 740/938] loss_G: 4.296822, loss_D: 0.099084\n",
      "[Epoch 17/200] [Batch 750/938] loss_G: 3.530489, loss_D: 0.123443\n",
      "[Epoch 17/200] [Batch 760/938] loss_G: 3.982509, loss_D: 0.201529\n",
      "[Epoch 17/200] [Batch 770/938] loss_G: 3.384084, loss_D: 0.207078\n",
      "[Epoch 17/200] [Batch 780/938] loss_G: 3.373826, loss_D: 0.149859\n",
      "[Epoch 17/200] [Batch 790/938] loss_G: 3.781648, loss_D: 0.157637\n",
      "[Epoch 17/200] [Batch 800/938] loss_G: 3.606914, loss_D: 0.155271\n",
      "[Epoch 17/200] [Batch 810/938] loss_G: 4.254539, loss_D: 0.167489\n",
      "[Epoch 17/200] [Batch 820/938] loss_G: 3.958568, loss_D: 0.267339\n",
      "[Epoch 17/200] [Batch 830/938] loss_G: 4.015847, loss_D: 0.241453\n",
      "[Epoch 17/200] [Batch 840/938] loss_G: 3.946463, loss_D: 0.119200\n",
      "[Epoch 17/200] [Batch 850/938] loss_G: 4.373979, loss_D: 0.087144\n",
      "[Epoch 17/200] [Batch 860/938] loss_G: 3.837239, loss_D: 0.208204\n",
      "[Epoch 17/200] [Batch 870/938] loss_G: 3.966121, loss_D: 0.116289\n",
      "[Epoch 17/200] [Batch 880/938] loss_G: 4.085227, loss_D: 0.199930\n",
      "[Epoch 17/200] [Batch 890/938] loss_G: 3.533535, loss_D: 0.158424\n",
      "[Epoch 17/200] [Batch 900/938] loss_G: 3.741786, loss_D: 0.103581\n",
      "[Epoch 17/200] [Batch 910/938] loss_G: 4.265654, loss_D: 0.054226\n",
      "[Epoch 17/200] [Batch 920/938] loss_G: 3.668648, loss_D: 0.083878\n",
      "[Epoch 17/200] [Batch 930/938] loss_G: 3.756727, loss_D: 0.268962\n",
      "[Epoch 18/200] [Batch 0/938] loss_G: 3.254952, loss_D: 0.207098\n",
      "[Epoch 18/200] [Batch 10/938] loss_G: 3.816301, loss_D: 0.164675\n",
      "[Epoch 18/200] [Batch 20/938] loss_G: 4.129417, loss_D: 0.146677\n",
      "[Epoch 18/200] [Batch 30/938] loss_G: 3.620980, loss_D: 0.156917\n",
      "[Epoch 18/200] [Batch 40/938] loss_G: 3.977141, loss_D: 0.117589\n",
      "[Epoch 18/200] [Batch 50/938] loss_G: 3.618300, loss_D: 0.196564\n",
      "[Epoch 18/200] [Batch 60/938] loss_G: 3.623713, loss_D: 0.183149\n",
      "[Epoch 18/200] [Batch 70/938] loss_G: 3.555228, loss_D: 0.242748\n",
      "[Epoch 18/200] [Batch 80/938] loss_G: 3.542857, loss_D: 0.213828\n",
      "[Epoch 18/200] [Batch 90/938] loss_G: 4.158492, loss_D: 0.169713\n",
      "[Epoch 18/200] [Batch 100/938] loss_G: 3.005568, loss_D: 0.124976\n",
      "[Epoch 18/200] [Batch 110/938] loss_G: 4.105101, loss_D: 0.118286\n",
      "[Epoch 18/200] [Batch 120/938] loss_G: 3.858093, loss_D: 0.211243\n",
      "[Epoch 18/200] [Batch 130/938] loss_G: 3.823410, loss_D: 0.151708\n",
      "[Epoch 18/200] [Batch 140/938] loss_G: 3.571978, loss_D: 0.179149\n",
      "[Epoch 18/200] [Batch 150/938] loss_G: 3.350400, loss_D: 0.175479\n",
      "[Epoch 18/200] [Batch 160/938] loss_G: 3.804939, loss_D: 0.091330\n",
      "[Epoch 18/200] [Batch 170/938] loss_G: 3.416800, loss_D: 0.144817\n",
      "[Epoch 18/200] [Batch 180/938] loss_G: 3.789585, loss_D: 0.081113\n",
      "[Epoch 18/200] [Batch 190/938] loss_G: 3.549070, loss_D: 0.082031\n",
      "[Epoch 18/200] [Batch 200/938] loss_G: 3.805059, loss_D: 0.097408\n",
      "[Epoch 18/200] [Batch 210/938] loss_G: 3.654126, loss_D: 0.181964\n",
      "[Epoch 18/200] [Batch 220/938] loss_G: 4.790824, loss_D: 0.119356\n",
      "[Epoch 18/200] [Batch 230/938] loss_G: 3.423538, loss_D: 0.118394\n",
      "[Epoch 18/200] [Batch 240/938] loss_G: 3.496604, loss_D: 0.190062\n",
      "[Epoch 18/200] [Batch 250/938] loss_G: 3.683090, loss_D: 0.156513\n",
      "[Epoch 18/200] [Batch 260/938] loss_G: 4.148189, loss_D: 0.185606\n",
      "[Epoch 18/200] [Batch 270/938] loss_G: 3.797569, loss_D: 0.121494\n",
      "[Epoch 18/200] [Batch 280/938] loss_G: 2.948992, loss_D: 0.231992\n",
      "[Epoch 18/200] [Batch 290/938] loss_G: 4.551928, loss_D: 0.108794\n",
      "[Epoch 18/200] [Batch 300/938] loss_G: 4.190766, loss_D: 0.083565\n",
      "[Epoch 18/200] [Batch 310/938] loss_G: 3.921609, loss_D: 0.131324\n",
      "[Epoch 18/200] [Batch 320/938] loss_G: 4.985822, loss_D: 0.059591\n",
      "[Epoch 18/200] [Batch 330/938] loss_G: 4.847879, loss_D: 0.102185\n",
      "[Epoch 18/200] [Batch 340/938] loss_G: 3.388666, loss_D: 0.269459\n",
      "[Epoch 18/200] [Batch 350/938] loss_G: 2.810184, loss_D: 0.215809\n",
      "[Epoch 18/200] [Batch 360/938] loss_G: 4.047969, loss_D: 0.272227\n",
      "[Epoch 18/200] [Batch 370/938] loss_G: 3.080540, loss_D: 0.174563\n",
      "[Epoch 18/200] [Batch 380/938] loss_G: 3.458586, loss_D: 0.139413\n",
      "[Epoch 18/200] [Batch 390/938] loss_G: 3.251949, loss_D: 0.175753\n",
      "[Epoch 18/200] [Batch 400/938] loss_G: 3.206577, loss_D: 0.196293\n",
      "[Epoch 18/200] [Batch 410/938] loss_G: 3.650630, loss_D: 0.197096\n",
      "[Epoch 18/200] [Batch 420/938] loss_G: 3.973804, loss_D: 0.151222\n",
      "[Epoch 18/200] [Batch 430/938] loss_G: 3.326468, loss_D: 0.148957\n",
      "[Epoch 18/200] [Batch 440/938] loss_G: 4.089706, loss_D: 0.116637\n",
      "[Epoch 18/200] [Batch 450/938] loss_G: 3.608726, loss_D: 0.196382\n",
      "[Epoch 18/200] [Batch 460/938] loss_G: 3.667082, loss_D: 0.075109\n",
      "[Epoch 18/200] [Batch 470/938] loss_G: 3.309799, loss_D: 0.103537\n",
      "[Epoch 18/200] [Batch 480/938] loss_G: 3.993865, loss_D: 0.122527\n",
      "[Epoch 18/200] [Batch 490/938] loss_G: 3.797697, loss_D: 0.102563\n",
      "[Epoch 18/200] [Batch 500/938] loss_G: 3.896729, loss_D: 0.132161\n",
      "[Epoch 18/200] [Batch 510/938] loss_G: 3.673113, loss_D: 0.140370\n",
      "[Epoch 18/200] [Batch 520/938] loss_G: 3.577014, loss_D: 0.128957\n",
      "[Epoch 18/200] [Batch 530/938] loss_G: 3.650643, loss_D: 0.186417\n",
      "[Epoch 18/200] [Batch 540/938] loss_G: 3.942398, loss_D: 0.172320\n",
      "[Epoch 18/200] [Batch 550/938] loss_G: 3.931191, loss_D: 0.103009\n",
      "[Epoch 18/200] [Batch 560/938] loss_G: 4.292383, loss_D: 0.095948\n",
      "[Epoch 18/200] [Batch 570/938] loss_G: 3.141576, loss_D: 0.131294\n",
      "[Epoch 18/200] [Batch 580/938] loss_G: 3.956730, loss_D: 0.082674\n",
      "[Epoch 18/200] [Batch 590/938] loss_G: 3.626887, loss_D: 0.135302\n",
      "[Epoch 18/200] [Batch 600/938] loss_G: 3.615584, loss_D: 0.208728\n",
      "[Epoch 18/200] [Batch 610/938] loss_G: 3.586046, loss_D: 0.173223\n",
      "[Epoch 18/200] [Batch 620/938] loss_G: 3.398605, loss_D: 0.144092\n",
      "[Epoch 18/200] [Batch 630/938] loss_G: 3.909349, loss_D: 0.095619\n",
      "[Epoch 18/200] [Batch 640/938] loss_G: 3.625985, loss_D: 0.206819\n",
      "[Epoch 18/200] [Batch 650/938] loss_G: 3.662567, loss_D: 0.161919\n",
      "[Epoch 18/200] [Batch 660/938] loss_G: 3.262289, loss_D: 0.185456\n",
      "[Epoch 18/200] [Batch 670/938] loss_G: 3.012735, loss_D: 0.176361\n",
      "[Epoch 18/200] [Batch 680/938] loss_G: 2.910628, loss_D: 0.250114\n",
      "[Epoch 18/200] [Batch 690/938] loss_G: 3.239170, loss_D: 0.210348\n",
      "[Epoch 18/200] [Batch 700/938] loss_G: 3.823156, loss_D: 0.173626\n",
      "[Epoch 18/200] [Batch 710/938] loss_G: 3.948411, loss_D: 0.060346\n",
      "[Epoch 18/200] [Batch 720/938] loss_G: 4.073055, loss_D: 0.105618\n",
      "[Epoch 18/200] [Batch 730/938] loss_G: 3.763704, loss_D: 0.080639\n",
      "[Epoch 18/200] [Batch 740/938] loss_G: 2.990075, loss_D: 0.175598\n",
      "[Epoch 18/200] [Batch 750/938] loss_G: 4.054761, loss_D: 0.096162\n",
      "[Epoch 18/200] [Batch 760/938] loss_G: 4.253796, loss_D: 0.092504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18/200] [Batch 770/938] loss_G: 3.931636, loss_D: 0.200922\n",
      "[Epoch 18/200] [Batch 780/938] loss_G: 3.129616, loss_D: 0.171609\n",
      "[Epoch 18/200] [Batch 790/938] loss_G: 3.281999, loss_D: 0.221530\n",
      "[Epoch 18/200] [Batch 800/938] loss_G: 4.266397, loss_D: 0.087399\n",
      "[Epoch 18/200] [Batch 810/938] loss_G: 3.757385, loss_D: 0.168040\n",
      "[Epoch 18/200] [Batch 820/938] loss_G: 3.789811, loss_D: 0.203614\n",
      "[Epoch 18/200] [Batch 830/938] loss_G: 3.628823, loss_D: 0.237290\n",
      "[Epoch 18/200] [Batch 840/938] loss_G: 3.750302, loss_D: 0.174521\n",
      "[Epoch 18/200] [Batch 850/938] loss_G: 3.797146, loss_D: 0.159898\n",
      "[Epoch 18/200] [Batch 860/938] loss_G: 3.930872, loss_D: 0.096761\n",
      "[Epoch 18/200] [Batch 870/938] loss_G: 4.252918, loss_D: 0.058207\n",
      "[Epoch 18/200] [Batch 880/938] loss_G: 4.125318, loss_D: 0.194926\n",
      "[Epoch 18/200] [Batch 890/938] loss_G: 3.640683, loss_D: 0.260767\n",
      "[Epoch 18/200] [Batch 900/938] loss_G: 3.236953, loss_D: 0.194154\n",
      "[Epoch 18/200] [Batch 910/938] loss_G: 3.433996, loss_D: 0.143038\n",
      "[Epoch 18/200] [Batch 920/938] loss_G: 3.932621, loss_D: 0.140096\n",
      "[Epoch 18/200] [Batch 930/938] loss_G: 4.541286, loss_D: 0.127147\n",
      "[Epoch 19/200] [Batch 0/938] loss_G: 3.876813, loss_D: 0.200523\n",
      "[Epoch 19/200] [Batch 10/938] loss_G: 3.822076, loss_D: 0.115959\n",
      "[Epoch 19/200] [Batch 20/938] loss_G: 3.807455, loss_D: 0.147487\n",
      "[Epoch 19/200] [Batch 30/938] loss_G: 3.343505, loss_D: 0.098679\n",
      "[Epoch 19/200] [Batch 40/938] loss_G: 3.564103, loss_D: 0.111995\n",
      "[Epoch 19/200] [Batch 50/938] loss_G: 4.401938, loss_D: 0.093849\n",
      "[Epoch 19/200] [Batch 60/938] loss_G: 3.389462, loss_D: 0.177979\n",
      "[Epoch 19/200] [Batch 70/938] loss_G: 3.610252, loss_D: 0.114919\n",
      "[Epoch 19/200] [Batch 80/938] loss_G: 3.354332, loss_D: 0.155149\n",
      "[Epoch 19/200] [Batch 90/938] loss_G: 3.592558, loss_D: 0.148150\n",
      "[Epoch 19/200] [Batch 100/938] loss_G: 3.766641, loss_D: 0.126182\n",
      "[Epoch 19/200] [Batch 110/938] loss_G: 3.605433, loss_D: 0.107760\n",
      "[Epoch 19/200] [Batch 120/938] loss_G: 3.477921, loss_D: 0.162738\n",
      "[Epoch 19/200] [Batch 130/938] loss_G: 3.069774, loss_D: 0.243947\n",
      "[Epoch 19/200] [Batch 140/938] loss_G: 3.775879, loss_D: 0.161990\n",
      "[Epoch 19/200] [Batch 150/938] loss_G: 3.814333, loss_D: 0.075256\n",
      "[Epoch 19/200] [Batch 160/938] loss_G: 3.332096, loss_D: 0.143146\n",
      "[Epoch 19/200] [Batch 170/938] loss_G: 3.415073, loss_D: 0.204288\n",
      "[Epoch 19/200] [Batch 180/938] loss_G: 3.405787, loss_D: 0.215175\n",
      "[Epoch 19/200] [Batch 190/938] loss_G: 3.540449, loss_D: 0.247622\n",
      "[Epoch 19/200] [Batch 200/938] loss_G: 3.260354, loss_D: 0.243440\n",
      "[Epoch 19/200] [Batch 210/938] loss_G: 3.492807, loss_D: 0.203921\n",
      "[Epoch 19/200] [Batch 220/938] loss_G: 3.727558, loss_D: 0.161499\n",
      "[Epoch 19/200] [Batch 230/938] loss_G: 3.063955, loss_D: 0.191395\n",
      "[Epoch 19/200] [Batch 240/938] loss_G: 3.579186, loss_D: 0.211237\n",
      "[Epoch 19/200] [Batch 250/938] loss_G: 3.991058, loss_D: 0.172344\n",
      "[Epoch 19/200] [Batch 260/938] loss_G: 3.641292, loss_D: 0.174278\n",
      "[Epoch 19/200] [Batch 270/938] loss_G: 4.016454, loss_D: 0.155374\n",
      "[Epoch 19/200] [Batch 280/938] loss_G: 3.905475, loss_D: 0.140887\n",
      "[Epoch 19/200] [Batch 290/938] loss_G: 3.327438, loss_D: 0.167211\n",
      "[Epoch 19/200] [Batch 300/938] loss_G: 3.085730, loss_D: 0.213492\n",
      "[Epoch 19/200] [Batch 310/938] loss_G: 3.773758, loss_D: 0.131838\n",
      "[Epoch 19/200] [Batch 320/938] loss_G: 3.614917, loss_D: 0.147992\n",
      "[Epoch 19/200] [Batch 330/938] loss_G: 4.315656, loss_D: 0.099628\n",
      "[Epoch 19/200] [Batch 340/938] loss_G: 3.587022, loss_D: 0.097395\n",
      "[Epoch 19/200] [Batch 350/938] loss_G: 3.565094, loss_D: 0.102379\n",
      "[Epoch 19/200] [Batch 360/938] loss_G: 4.070079, loss_D: 0.203132\n",
      "[Epoch 19/200] [Batch 370/938] loss_G: 3.829611, loss_D: 0.225605\n",
      "[Epoch 19/200] [Batch 380/938] loss_G: 3.793268, loss_D: 0.157828\n",
      "[Epoch 19/200] [Batch 390/938] loss_G: 3.336400, loss_D: 0.274601\n",
      "[Epoch 19/200] [Batch 400/938] loss_G: 3.388000, loss_D: 0.172008\n",
      "[Epoch 19/200] [Batch 410/938] loss_G: 3.193205, loss_D: 0.259474\n",
      "[Epoch 19/200] [Batch 420/938] loss_G: 3.299930, loss_D: 0.174615\n",
      "[Epoch 19/200] [Batch 430/938] loss_G: 4.204577, loss_D: 0.176696\n",
      "[Epoch 19/200] [Batch 440/938] loss_G: 3.430638, loss_D: 0.188243\n",
      "[Epoch 19/200] [Batch 450/938] loss_G: 3.526320, loss_D: 0.115492\n",
      "[Epoch 19/200] [Batch 460/938] loss_G: 3.272012, loss_D: 0.225323\n",
      "[Epoch 19/200] [Batch 470/938] loss_G: 3.732723, loss_D: 0.104184\n",
      "[Epoch 19/200] [Batch 480/938] loss_G: 3.455750, loss_D: 0.236438\n",
      "[Epoch 19/200] [Batch 490/938] loss_G: 3.511046, loss_D: 0.149007\n",
      "[Epoch 19/200] [Batch 500/938] loss_G: 3.390290, loss_D: 0.190080\n",
      "[Epoch 19/200] [Batch 510/938] loss_G: 3.767998, loss_D: 0.155894\n",
      "[Epoch 19/200] [Batch 520/938] loss_G: 3.938507, loss_D: 0.226232\n",
      "[Epoch 19/200] [Batch 530/938] loss_G: 3.104756, loss_D: 0.243564\n",
      "[Epoch 19/200] [Batch 540/938] loss_G: 3.263805, loss_D: 0.170557\n",
      "[Epoch 19/200] [Batch 550/938] loss_G: 2.958076, loss_D: 0.257753\n",
      "[Epoch 19/200] [Batch 560/938] loss_G: 3.323691, loss_D: 0.207391\n",
      "[Epoch 19/200] [Batch 570/938] loss_G: 4.116425, loss_D: 0.211936\n",
      "[Epoch 19/200] [Batch 580/938] loss_G: 3.328486, loss_D: 0.283049\n",
      "[Epoch 19/200] [Batch 590/938] loss_G: 3.618168, loss_D: 0.125995\n",
      "[Epoch 19/200] [Batch 600/938] loss_G: 3.314874, loss_D: 0.202796\n",
      "[Epoch 19/200] [Batch 610/938] loss_G: 3.389007, loss_D: 0.146949\n",
      "[Epoch 19/200] [Batch 620/938] loss_G: 3.366931, loss_D: 0.187114\n",
      "[Epoch 19/200] [Batch 630/938] loss_G: 3.940229, loss_D: 0.139369\n",
      "[Epoch 19/200] [Batch 640/938] loss_G: 3.305945, loss_D: 0.211767\n",
      "[Epoch 19/200] [Batch 650/938] loss_G: 4.121066, loss_D: 0.114815\n",
      "[Epoch 19/200] [Batch 660/938] loss_G: 3.056300, loss_D: 0.205227\n",
      "[Epoch 19/200] [Batch 670/938] loss_G: 3.823265, loss_D: 0.138335\n",
      "[Epoch 19/200] [Batch 680/938] loss_G: 3.806458, loss_D: 0.151013\n",
      "[Epoch 19/200] [Batch 690/938] loss_G: 3.273890, loss_D: 0.207621\n",
      "[Epoch 19/200] [Batch 700/938] loss_G: 3.317314, loss_D: 0.190995\n",
      "[Epoch 19/200] [Batch 710/938] loss_G: 3.313541, loss_D: 0.152925\n",
      "[Epoch 19/200] [Batch 720/938] loss_G: 3.217359, loss_D: 0.142555\n",
      "[Epoch 19/200] [Batch 730/938] loss_G: 3.699611, loss_D: 0.204837\n",
      "[Epoch 19/200] [Batch 740/938] loss_G: 3.447592, loss_D: 0.166981\n",
      "[Epoch 19/200] [Batch 750/938] loss_G: 2.836536, loss_D: 0.325995\n",
      "[Epoch 19/200] [Batch 760/938] loss_G: 4.361433, loss_D: 0.194637\n",
      "[Epoch 19/200] [Batch 770/938] loss_G: 3.655354, loss_D: 0.130402\n",
      "[Epoch 19/200] [Batch 780/938] loss_G: 3.470362, loss_D: 0.190179\n",
      "[Epoch 19/200] [Batch 790/938] loss_G: 3.286577, loss_D: 0.158920\n",
      "[Epoch 19/200] [Batch 800/938] loss_G: 3.039317, loss_D: 0.253605\n",
      "[Epoch 19/200] [Batch 810/938] loss_G: 3.686519, loss_D: 0.197859\n",
      "[Epoch 19/200] [Batch 820/938] loss_G: 3.950626, loss_D: 0.266469\n",
      "[Epoch 19/200] [Batch 830/938] loss_G: 3.518941, loss_D: 0.143497\n",
      "[Epoch 19/200] [Batch 840/938] loss_G: 3.520991, loss_D: 0.266572\n",
      "[Epoch 19/200] [Batch 850/938] loss_G: 3.262997, loss_D: 0.116445\n",
      "[Epoch 19/200] [Batch 860/938] loss_G: 3.279062, loss_D: 0.104519\n",
      "[Epoch 19/200] [Batch 870/938] loss_G: 3.341357, loss_D: 0.150906\n",
      "[Epoch 19/200] [Batch 880/938] loss_G: 3.590675, loss_D: 0.164480\n",
      "[Epoch 19/200] [Batch 890/938] loss_G: 3.616253, loss_D: 0.152906\n",
      "[Epoch 19/200] [Batch 900/938] loss_G: 3.821663, loss_D: 0.081614\n",
      "[Epoch 19/200] [Batch 910/938] loss_G: 3.316406, loss_D: 0.094933\n",
      "[Epoch 19/200] [Batch 920/938] loss_G: 3.189867, loss_D: 0.244541\n",
      "[Epoch 19/200] [Batch 930/938] loss_G: 3.866382, loss_D: 0.133181\n",
      "[Epoch 20/200] [Batch 0/938] loss_G: 3.826520, loss_D: 0.077212\n",
      "[Epoch 20/200] [Batch 10/938] loss_G: 3.311926, loss_D: 0.182830\n",
      "[Epoch 20/200] [Batch 20/938] loss_G: 3.414594, loss_D: 0.153462\n",
      "[Epoch 20/200] [Batch 30/938] loss_G: 3.546539, loss_D: 0.098294\n",
      "[Epoch 20/200] [Batch 40/938] loss_G: 3.871354, loss_D: 0.101075\n",
      "[Epoch 20/200] [Batch 50/938] loss_G: 3.873785, loss_D: 0.120969\n",
      "[Epoch 20/200] [Batch 60/938] loss_G: 3.815987, loss_D: 0.234939\n",
      "[Epoch 20/200] [Batch 70/938] loss_G: 3.569852, loss_D: 0.213525\n",
      "[Epoch 20/200] [Batch 80/938] loss_G: 3.377381, loss_D: 0.165329\n",
      "[Epoch 20/200] [Batch 90/938] loss_G: 3.149508, loss_D: 0.158740\n",
      "[Epoch 20/200] [Batch 100/938] loss_G: 3.647961, loss_D: 0.222599\n",
      "[Epoch 20/200] [Batch 110/938] loss_G: 3.299170, loss_D: 0.222767\n",
      "[Epoch 20/200] [Batch 120/938] loss_G: 3.662464, loss_D: 0.186575\n",
      "[Epoch 20/200] [Batch 130/938] loss_G: 4.193083, loss_D: 0.205745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20/200] [Batch 140/938] loss_G: 3.477538, loss_D: 0.169168\n",
      "[Epoch 20/200] [Batch 150/938] loss_G: 3.135267, loss_D: 0.285987\n",
      "[Epoch 20/200] [Batch 160/938] loss_G: 3.411040, loss_D: 0.169068\n",
      "[Epoch 20/200] [Batch 170/938] loss_G: 3.897499, loss_D: 0.122015\n",
      "[Epoch 20/200] [Batch 180/938] loss_G: 4.053060, loss_D: 0.181186\n",
      "[Epoch 20/200] [Batch 190/938] loss_G: 3.943816, loss_D: 0.151251\n",
      "[Epoch 20/200] [Batch 200/938] loss_G: 4.018503, loss_D: 0.180644\n",
      "[Epoch 20/200] [Batch 210/938] loss_G: 4.088905, loss_D: 0.161788\n",
      "[Epoch 20/200] [Batch 220/938] loss_G: 4.096750, loss_D: 0.225948\n",
      "[Epoch 20/200] [Batch 230/938] loss_G: 3.671149, loss_D: 0.147036\n",
      "[Epoch 20/200] [Batch 240/938] loss_G: 3.317431, loss_D: 0.123793\n",
      "[Epoch 20/200] [Batch 250/938] loss_G: 3.870902, loss_D: 0.123574\n",
      "[Epoch 20/200] [Batch 260/938] loss_G: 3.449975, loss_D: 0.193352\n",
      "[Epoch 20/200] [Batch 270/938] loss_G: 2.656715, loss_D: 0.236250\n",
      "[Epoch 20/200] [Batch 280/938] loss_G: 3.288978, loss_D: 0.151724\n",
      "[Epoch 20/200] [Batch 290/938] loss_G: 3.880034, loss_D: 0.183009\n",
      "[Epoch 20/200] [Batch 300/938] loss_G: 3.648466, loss_D: 0.177048\n",
      "[Epoch 20/200] [Batch 310/938] loss_G: 2.645981, loss_D: 0.179337\n",
      "[Epoch 20/200] [Batch 320/938] loss_G: 2.879207, loss_D: 0.226779\n",
      "[Epoch 20/200] [Batch 330/938] loss_G: 3.686211, loss_D: 0.139617\n",
      "[Epoch 20/200] [Batch 340/938] loss_G: 3.538314, loss_D: 0.096338\n",
      "[Epoch 20/200] [Batch 350/938] loss_G: 3.442604, loss_D: 0.175123\n",
      "[Epoch 20/200] [Batch 360/938] loss_G: 3.481536, loss_D: 0.176318\n",
      "[Epoch 20/200] [Batch 370/938] loss_G: 3.956060, loss_D: 0.152609\n",
      "[Epoch 20/200] [Batch 380/938] loss_G: 3.576092, loss_D: 0.090162\n",
      "[Epoch 20/200] [Batch 390/938] loss_G: 3.427976, loss_D: 0.124912\n",
      "[Epoch 20/200] [Batch 400/938] loss_G: 3.831017, loss_D: 0.109482\n",
      "[Epoch 20/200] [Batch 410/938] loss_G: 3.970263, loss_D: 0.178920\n",
      "[Epoch 20/200] [Batch 420/938] loss_G: 4.022794, loss_D: 0.070290\n",
      "[Epoch 20/200] [Batch 430/938] loss_G: 3.599182, loss_D: 0.130722\n",
      "[Epoch 20/200] [Batch 440/938] loss_G: 3.816918, loss_D: 0.259461\n",
      "[Epoch 20/200] [Batch 450/938] loss_G: 3.242970, loss_D: 0.228141\n",
      "[Epoch 20/200] [Batch 460/938] loss_G: 3.581654, loss_D: 0.108068\n",
      "[Epoch 20/200] [Batch 470/938] loss_G: 4.413705, loss_D: 0.128932\n",
      "[Epoch 20/200] [Batch 480/938] loss_G: 2.888869, loss_D: 0.164510\n",
      "[Epoch 20/200] [Batch 490/938] loss_G: 3.211036, loss_D: 0.180397\n",
      "[Epoch 20/200] [Batch 500/938] loss_G: 3.254299, loss_D: 0.113637\n",
      "[Epoch 20/200] [Batch 510/938] loss_G: 3.751768, loss_D: 0.205215\n",
      "[Epoch 20/200] [Batch 520/938] loss_G: 3.617928, loss_D: 0.155976\n",
      "[Epoch 20/200] [Batch 530/938] loss_G: 2.823242, loss_D: 0.281411\n",
      "[Epoch 20/200] [Batch 540/938] loss_G: 3.775105, loss_D: 0.216382\n",
      "[Epoch 20/200] [Batch 550/938] loss_G: 3.537243, loss_D: 0.117725\n",
      "[Epoch 20/200] [Batch 560/938] loss_G: 4.004781, loss_D: 0.116848\n",
      "[Epoch 20/200] [Batch 570/938] loss_G: 3.836504, loss_D: 0.251654\n",
      "[Epoch 20/200] [Batch 580/938] loss_G: 3.455554, loss_D: 0.185798\n",
      "[Epoch 20/200] [Batch 590/938] loss_G: 3.712165, loss_D: 0.165076\n",
      "[Epoch 20/200] [Batch 600/938] loss_G: 4.523202, loss_D: 0.120765\n",
      "[Epoch 20/200] [Batch 610/938] loss_G: 3.441782, loss_D: 0.198545\n",
      "[Epoch 20/200] [Batch 620/938] loss_G: 3.788770, loss_D: 0.164292\n",
      "[Epoch 20/200] [Batch 630/938] loss_G: 3.276622, loss_D: 0.112481\n",
      "[Epoch 20/200] [Batch 640/938] loss_G: 3.315436, loss_D: 0.152351\n",
      "[Epoch 20/200] [Batch 650/938] loss_G: 4.145679, loss_D: 0.133348\n",
      "[Epoch 20/200] [Batch 660/938] loss_G: 3.634395, loss_D: 0.183799\n",
      "[Epoch 20/200] [Batch 670/938] loss_G: 3.641839, loss_D: 0.107988\n",
      "[Epoch 20/200] [Batch 680/938] loss_G: 3.374234, loss_D: 0.108071\n",
      "[Epoch 20/200] [Batch 690/938] loss_G: 3.334609, loss_D: 0.218053\n",
      "[Epoch 20/200] [Batch 700/938] loss_G: 3.690483, loss_D: 0.258896\n",
      "[Epoch 20/200] [Batch 710/938] loss_G: 3.291765, loss_D: 0.217141\n",
      "[Epoch 20/200] [Batch 720/938] loss_G: 3.189960, loss_D: 0.136535\n",
      "[Epoch 20/200] [Batch 730/938] loss_G: 3.398828, loss_D: 0.205668\n",
      "[Epoch 20/200] [Batch 740/938] loss_G: 3.347341, loss_D: 0.168741\n",
      "[Epoch 20/200] [Batch 750/938] loss_G: 3.693727, loss_D: 0.180910\n",
      "[Epoch 20/200] [Batch 760/938] loss_G: 3.506497, loss_D: 0.197018\n",
      "[Epoch 20/200] [Batch 770/938] loss_G: 3.552184, loss_D: 0.173174\n",
      "[Epoch 20/200] [Batch 780/938] loss_G: 3.504001, loss_D: 0.161050\n",
      "[Epoch 20/200] [Batch 790/938] loss_G: 3.384286, loss_D: 0.121589\n",
      "[Epoch 20/200] [Batch 800/938] loss_G: 3.727702, loss_D: 0.165326\n",
      "[Epoch 20/200] [Batch 810/938] loss_G: 4.158445, loss_D: 0.154380\n",
      "[Epoch 20/200] [Batch 820/938] loss_G: 3.321380, loss_D: 0.181428\n",
      "[Epoch 20/200] [Batch 830/938] loss_G: 3.110090, loss_D: 0.222144\n",
      "[Epoch 20/200] [Batch 840/938] loss_G: 3.027249, loss_D: 0.203277\n",
      "[Epoch 20/200] [Batch 850/938] loss_G: 3.400327, loss_D: 0.228213\n",
      "[Epoch 20/200] [Batch 860/938] loss_G: 2.857448, loss_D: 0.214924\n",
      "[Epoch 20/200] [Batch 870/938] loss_G: 3.542647, loss_D: 0.243153\n",
      "[Epoch 20/200] [Batch 880/938] loss_G: 2.880391, loss_D: 0.258169\n",
      "[Epoch 20/200] [Batch 890/938] loss_G: 3.094307, loss_D: 0.252123\n",
      "[Epoch 20/200] [Batch 900/938] loss_G: 3.364410, loss_D: 0.127067\n",
      "[Epoch 20/200] [Batch 910/938] loss_G: 3.052524, loss_D: 0.162676\n",
      "[Epoch 20/200] [Batch 920/938] loss_G: 3.725962, loss_D: 0.288738\n",
      "[Epoch 20/200] [Batch 930/938] loss_G: 3.379575, loss_D: 0.249874\n",
      "[Epoch 21/200] [Batch 0/938] loss_G: 3.380322, loss_D: 0.247105\n",
      "[Epoch 21/200] [Batch 10/938] loss_G: 3.451536, loss_D: 0.248424\n",
      "[Epoch 21/200] [Batch 20/938] loss_G: 3.192959, loss_D: 0.261851\n",
      "[Epoch 21/200] [Batch 30/938] loss_G: 3.241314, loss_D: 0.136981\n",
      "[Epoch 21/200] [Batch 40/938] loss_G: 3.611008, loss_D: 0.251871\n",
      "[Epoch 21/200] [Batch 50/938] loss_G: 3.383554, loss_D: 0.142013\n",
      "[Epoch 21/200] [Batch 60/938] loss_G: 3.752407, loss_D: 0.130629\n",
      "[Epoch 21/200] [Batch 70/938] loss_G: 3.886881, loss_D: 0.109691\n",
      "[Epoch 21/200] [Batch 80/938] loss_G: 3.456113, loss_D: 0.238081\n",
      "[Epoch 21/200] [Batch 90/938] loss_G: 3.132447, loss_D: 0.230087\n",
      "[Epoch 21/200] [Batch 100/938] loss_G: 3.435225, loss_D: 0.197315\n",
      "[Epoch 21/200] [Batch 110/938] loss_G: 3.899541, loss_D: 0.101127\n",
      "[Epoch 21/200] [Batch 120/938] loss_G: 3.702813, loss_D: 0.068862\n",
      "[Epoch 21/200] [Batch 130/938] loss_G: 3.348952, loss_D: 0.146357\n",
      "[Epoch 21/200] [Batch 140/938] loss_G: 3.348787, loss_D: 0.095148\n",
      "[Epoch 21/200] [Batch 150/938] loss_G: 4.207548, loss_D: 0.180022\n",
      "[Epoch 21/200] [Batch 160/938] loss_G: 3.438333, loss_D: 0.189989\n",
      "[Epoch 21/200] [Batch 170/938] loss_G: 3.356165, loss_D: 0.193623\n",
      "[Epoch 21/200] [Batch 180/938] loss_G: 3.540643, loss_D: 0.135709\n",
      "[Epoch 21/200] [Batch 190/938] loss_G: 3.202277, loss_D: 0.201806\n",
      "[Epoch 21/200] [Batch 200/938] loss_G: 3.082892, loss_D: 0.135545\n",
      "[Epoch 21/200] [Batch 210/938] loss_G: 3.543830, loss_D: 0.157322\n",
      "[Epoch 21/200] [Batch 220/938] loss_G: 3.335152, loss_D: 0.157030\n",
      "[Epoch 21/200] [Batch 230/938] loss_G: 2.904288, loss_D: 0.182163\n",
      "[Epoch 21/200] [Batch 240/938] loss_G: 3.258342, loss_D: 0.206581\n",
      "[Epoch 21/200] [Batch 250/938] loss_G: 3.404082, loss_D: 0.353959\n",
      "[Epoch 21/200] [Batch 260/938] loss_G: 3.004972, loss_D: 0.175755\n",
      "[Epoch 21/200] [Batch 270/938] loss_G: 3.903605, loss_D: 0.102611\n",
      "[Epoch 21/200] [Batch 280/938] loss_G: 3.888515, loss_D: 0.103250\n",
      "[Epoch 21/200] [Batch 290/938] loss_G: 3.370200, loss_D: 0.148979\n",
      "[Epoch 21/200] [Batch 300/938] loss_G: 3.418203, loss_D: 0.146876\n",
      "[Epoch 21/200] [Batch 310/938] loss_G: 4.006790, loss_D: 0.159461\n",
      "[Epoch 21/200] [Batch 320/938] loss_G: 3.933132, loss_D: 0.163062\n",
      "[Epoch 21/200] [Batch 330/938] loss_G: 3.066049, loss_D: 0.201551\n",
      "[Epoch 21/200] [Batch 340/938] loss_G: 3.396621, loss_D: 0.214434\n",
      "[Epoch 21/200] [Batch 350/938] loss_G: 4.197011, loss_D: 0.124636\n",
      "[Epoch 21/200] [Batch 360/938] loss_G: 3.179805, loss_D: 0.180141\n",
      "[Epoch 21/200] [Batch 370/938] loss_G: 4.080081, loss_D: 0.213056\n",
      "[Epoch 21/200] [Batch 380/938] loss_G: 3.378911, loss_D: 0.179444\n",
      "[Epoch 21/200] [Batch 390/938] loss_G: 3.439414, loss_D: 0.187981\n",
      "[Epoch 21/200] [Batch 400/938] loss_G: 3.097816, loss_D: 0.203237\n",
      "[Epoch 21/200] [Batch 410/938] loss_G: 3.450442, loss_D: 0.183348\n",
      "[Epoch 21/200] [Batch 420/938] loss_G: 3.094043, loss_D: 0.181843\n",
      "[Epoch 21/200] [Batch 430/938] loss_G: 4.041926, loss_D: 0.299769\n",
      "[Epoch 21/200] [Batch 440/938] loss_G: 3.155252, loss_D: 0.164230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21/200] [Batch 450/938] loss_G: 3.254866, loss_D: 0.260289\n",
      "[Epoch 21/200] [Batch 460/938] loss_G: 3.397056, loss_D: 0.181898\n",
      "[Epoch 21/200] [Batch 470/938] loss_G: 3.543317, loss_D: 0.244823\n",
      "[Epoch 21/200] [Batch 480/938] loss_G: 2.827051, loss_D: 0.261922\n",
      "[Epoch 21/200] [Batch 490/938] loss_G: 3.371068, loss_D: 0.246240\n",
      "[Epoch 21/200] [Batch 500/938] loss_G: 3.426193, loss_D: 0.156270\n",
      "[Epoch 21/200] [Batch 510/938] loss_G: 3.008962, loss_D: 0.173588\n",
      "[Epoch 21/200] [Batch 520/938] loss_G: 3.427014, loss_D: 0.148669\n",
      "[Epoch 21/200] [Batch 530/938] loss_G: 3.410791, loss_D: 0.162920\n",
      "[Epoch 21/200] [Batch 540/938] loss_G: 3.465054, loss_D: 0.150063\n",
      "[Epoch 21/200] [Batch 550/938] loss_G: 3.510225, loss_D: 0.148921\n",
      "[Epoch 21/200] [Batch 560/938] loss_G: 3.393355, loss_D: 0.162558\n",
      "[Epoch 21/200] [Batch 570/938] loss_G: 3.435977, loss_D: 0.207725\n",
      "[Epoch 21/200] [Batch 580/938] loss_G: 2.918485, loss_D: 0.304933\n",
      "[Epoch 21/200] [Batch 590/938] loss_G: 3.071678, loss_D: 0.178595\n",
      "[Epoch 21/200] [Batch 600/938] loss_G: 3.234867, loss_D: 0.228770\n",
      "[Epoch 21/200] [Batch 610/938] loss_G: 2.861294, loss_D: 0.373387\n",
      "[Epoch 21/200] [Batch 620/938] loss_G: 2.975128, loss_D: 0.186343\n",
      "[Epoch 21/200] [Batch 630/938] loss_G: 3.794719, loss_D: 0.201631\n",
      "[Epoch 21/200] [Batch 640/938] loss_G: 3.334632, loss_D: 0.230160\n",
      "[Epoch 21/200] [Batch 650/938] loss_G: 3.112088, loss_D: 0.280379\n",
      "[Epoch 21/200] [Batch 660/938] loss_G: 3.708245, loss_D: 0.140865\n",
      "[Epoch 21/200] [Batch 670/938] loss_G: 3.120232, loss_D: 0.167617\n",
      "[Epoch 21/200] [Batch 680/938] loss_G: 3.629700, loss_D: 0.102294\n",
      "[Epoch 21/200] [Batch 690/938] loss_G: 3.236423, loss_D: 0.115999\n",
      "[Epoch 21/200] [Batch 700/938] loss_G: 3.373309, loss_D: 0.190761\n",
      "[Epoch 21/200] [Batch 710/938] loss_G: 3.852867, loss_D: 0.166742\n",
      "[Epoch 21/200] [Batch 720/938] loss_G: 3.469014, loss_D: 0.145474\n",
      "[Epoch 21/200] [Batch 730/938] loss_G: 3.271035, loss_D: 0.198592\n",
      "[Epoch 21/200] [Batch 740/938] loss_G: 3.333103, loss_D: 0.222981\n",
      "[Epoch 21/200] [Batch 750/938] loss_G: 3.257120, loss_D: 0.092091\n",
      "[Epoch 21/200] [Batch 760/938] loss_G: 3.817186, loss_D: 0.160853\n",
      "[Epoch 21/200] [Batch 770/938] loss_G: 3.078258, loss_D: 0.130917\n",
      "[Epoch 21/200] [Batch 780/938] loss_G: 3.338988, loss_D: 0.106998\n",
      "[Epoch 21/200] [Batch 790/938] loss_G: 3.291080, loss_D: 0.114667\n",
      "[Epoch 21/200] [Batch 800/938] loss_G: 3.539923, loss_D: 0.195757\n",
      "[Epoch 21/200] [Batch 810/938] loss_G: 3.122367, loss_D: 0.179158\n",
      "[Epoch 21/200] [Batch 820/938] loss_G: 2.496209, loss_D: 0.310787\n",
      "[Epoch 21/200] [Batch 830/938] loss_G: 3.341170, loss_D: 0.191392\n",
      "[Epoch 21/200] [Batch 840/938] loss_G: 3.059465, loss_D: 0.273712\n",
      "[Epoch 21/200] [Batch 850/938] loss_G: 3.141628, loss_D: 0.180127\n",
      "[Epoch 21/200] [Batch 860/938] loss_G: 3.064926, loss_D: 0.173969\n",
      "[Epoch 21/200] [Batch 870/938] loss_G: 3.250920, loss_D: 0.181610\n",
      "[Epoch 21/200] [Batch 880/938] loss_G: 3.777121, loss_D: 0.145053\n",
      "[Epoch 21/200] [Batch 890/938] loss_G: 3.182897, loss_D: 0.231032\n",
      "[Epoch 21/200] [Batch 900/938] loss_G: 3.537158, loss_D: 0.148031\n",
      "[Epoch 21/200] [Batch 910/938] loss_G: 3.444656, loss_D: 0.190124\n",
      "[Epoch 21/200] [Batch 920/938] loss_G: 3.384814, loss_D: 0.180412\n",
      "[Epoch 21/200] [Batch 930/938] loss_G: 3.127713, loss_D: 0.168077\n",
      "[Epoch 22/200] [Batch 0/938] loss_G: 4.165118, loss_D: 0.084787\n",
      "[Epoch 22/200] [Batch 10/938] loss_G: 3.110795, loss_D: 0.157965\n",
      "[Epoch 22/200] [Batch 20/938] loss_G: 2.841410, loss_D: 0.226077\n",
      "[Epoch 22/200] [Batch 30/938] loss_G: 3.562560, loss_D: 0.169274\n",
      "[Epoch 22/200] [Batch 40/938] loss_G: 3.904368, loss_D: 0.147984\n",
      "[Epoch 22/200] [Batch 50/938] loss_G: 3.460399, loss_D: 0.214950\n",
      "[Epoch 22/200] [Batch 60/938] loss_G: 3.011324, loss_D: 0.240703\n",
      "[Epoch 22/200] [Batch 70/938] loss_G: 3.219179, loss_D: 0.146483\n",
      "[Epoch 22/200] [Batch 80/938] loss_G: 3.256667, loss_D: 0.185964\n",
      "[Epoch 22/200] [Batch 90/938] loss_G: 3.876243, loss_D: 0.183470\n",
      "[Epoch 22/200] [Batch 100/938] loss_G: 3.384439, loss_D: 0.144961\n",
      "[Epoch 22/200] [Batch 110/938] loss_G: 3.652500, loss_D: 0.187378\n",
      "[Epoch 22/200] [Batch 120/938] loss_G: 3.935278, loss_D: 0.191715\n",
      "[Epoch 22/200] [Batch 130/938] loss_G: 2.953016, loss_D: 0.179274\n",
      "[Epoch 22/200] [Batch 140/938] loss_G: 3.887701, loss_D: 0.115787\n",
      "[Epoch 22/200] [Batch 150/938] loss_G: 3.235976, loss_D: 0.132323\n",
      "[Epoch 22/200] [Batch 160/938] loss_G: 3.281711, loss_D: 0.127528\n",
      "[Epoch 22/200] [Batch 170/938] loss_G: 3.879378, loss_D: 0.081904\n",
      "[Epoch 22/200] [Batch 180/938] loss_G: 3.334243, loss_D: 0.175826\n",
      "[Epoch 22/200] [Batch 190/938] loss_G: 3.264824, loss_D: 0.189554\n",
      "[Epoch 22/200] [Batch 200/938] loss_G: 3.831910, loss_D: 0.113557\n",
      "[Epoch 22/200] [Batch 210/938] loss_G: 3.576875, loss_D: 0.198746\n",
      "[Epoch 22/200] [Batch 220/938] loss_G: 4.058991, loss_D: 0.162445\n",
      "[Epoch 22/200] [Batch 230/938] loss_G: 3.085524, loss_D: 0.216884\n",
      "[Epoch 22/200] [Batch 240/938] loss_G: 3.735829, loss_D: 0.171616\n",
      "[Epoch 22/200] [Batch 250/938] loss_G: 3.710815, loss_D: 0.116169\n",
      "[Epoch 22/200] [Batch 260/938] loss_G: 3.888428, loss_D: 0.124410\n",
      "[Epoch 22/200] [Batch 270/938] loss_G: 3.102194, loss_D: 0.202790\n",
      "[Epoch 22/200] [Batch 280/938] loss_G: 3.212966, loss_D: 0.267787\n",
      "[Epoch 22/200] [Batch 290/938] loss_G: 3.978991, loss_D: 0.131445\n",
      "[Epoch 22/200] [Batch 300/938] loss_G: 3.266899, loss_D: 0.149160\n",
      "[Epoch 22/200] [Batch 310/938] loss_G: 3.717994, loss_D: 0.199258\n",
      "[Epoch 22/200] [Batch 320/938] loss_G: 3.594606, loss_D: 0.175633\n",
      "[Epoch 22/200] [Batch 330/938] loss_G: 3.503655, loss_D: 0.106892\n",
      "[Epoch 22/200] [Batch 340/938] loss_G: 3.832081, loss_D: 0.238083\n",
      "[Epoch 22/200] [Batch 350/938] loss_G: 3.687642, loss_D: 0.181722\n",
      "[Epoch 22/200] [Batch 360/938] loss_G: 3.486340, loss_D: 0.185774\n",
      "[Epoch 22/200] [Batch 370/938] loss_G: 3.450088, loss_D: 0.168478\n",
      "[Epoch 22/200] [Batch 380/938] loss_G: 3.664590, loss_D: 0.139428\n",
      "[Epoch 22/200] [Batch 390/938] loss_G: 3.594741, loss_D: 0.147733\n",
      "[Epoch 22/200] [Batch 400/938] loss_G: 3.111907, loss_D: 0.122450\n",
      "[Epoch 22/200] [Batch 410/938] loss_G: 3.204832, loss_D: 0.168458\n",
      "[Epoch 22/200] [Batch 420/938] loss_G: 3.423461, loss_D: 0.148387\n",
      "[Epoch 22/200] [Batch 430/938] loss_G: 3.378674, loss_D: 0.128232\n",
      "[Epoch 22/200] [Batch 440/938] loss_G: 3.350246, loss_D: 0.203742\n",
      "[Epoch 22/200] [Batch 450/938] loss_G: 3.321764, loss_D: 0.138692\n",
      "[Epoch 22/200] [Batch 460/938] loss_G: 3.140669, loss_D: 0.242199\n",
      "[Epoch 22/200] [Batch 470/938] loss_G: 3.320637, loss_D: 0.197428\n",
      "[Epoch 22/200] [Batch 480/938] loss_G: 3.238711, loss_D: 0.138345\n",
      "[Epoch 22/200] [Batch 490/938] loss_G: 3.270845, loss_D: 0.245344\n",
      "[Epoch 22/200] [Batch 500/938] loss_G: 2.970878, loss_D: 0.192497\n",
      "[Epoch 22/200] [Batch 510/938] loss_G: 3.152598, loss_D: 0.179449\n",
      "[Epoch 22/200] [Batch 520/938] loss_G: 3.089916, loss_D: 0.262028\n",
      "[Epoch 22/200] [Batch 530/938] loss_G: 3.549778, loss_D: 0.145325\n",
      "[Epoch 22/200] [Batch 540/938] loss_G: 3.152756, loss_D: 0.163815\n",
      "[Epoch 22/200] [Batch 550/938] loss_G: 3.301404, loss_D: 0.192669\n",
      "[Epoch 22/200] [Batch 560/938] loss_G: 3.034542, loss_D: 0.208490\n",
      "[Epoch 22/200] [Batch 570/938] loss_G: 3.237894, loss_D: 0.216344\n",
      "[Epoch 22/200] [Batch 580/938] loss_G: 3.385938, loss_D: 0.170357\n",
      "[Epoch 22/200] [Batch 590/938] loss_G: 3.626972, loss_D: 0.216784\n",
      "[Epoch 22/200] [Batch 600/938] loss_G: 3.086642, loss_D: 0.161249\n",
      "[Epoch 22/200] [Batch 610/938] loss_G: 3.319689, loss_D: 0.245722\n",
      "[Epoch 22/200] [Batch 620/938] loss_G: 3.605476, loss_D: 0.258959\n",
      "[Epoch 22/200] [Batch 630/938] loss_G: 3.556504, loss_D: 0.207469\n",
      "[Epoch 22/200] [Batch 640/938] loss_G: 3.436368, loss_D: 0.203948\n",
      "[Epoch 22/200] [Batch 650/938] loss_G: 4.159513, loss_D: 0.153356\n",
      "[Epoch 22/200] [Batch 660/938] loss_G: 3.395578, loss_D: 0.123188\n",
      "[Epoch 22/200] [Batch 670/938] loss_G: 3.369596, loss_D: 0.229043\n",
      "[Epoch 22/200] [Batch 680/938] loss_G: 3.797915, loss_D: 0.204593\n",
      "[Epoch 22/200] [Batch 690/938] loss_G: 2.815403, loss_D: 0.304099\n",
      "[Epoch 22/200] [Batch 700/938] loss_G: 2.993525, loss_D: 0.171661\n",
      "[Epoch 22/200] [Batch 710/938] loss_G: 3.580677, loss_D: 0.274932\n",
      "[Epoch 22/200] [Batch 720/938] loss_G: 4.095801, loss_D: 0.203460\n",
      "[Epoch 22/200] [Batch 730/938] loss_G: 3.647863, loss_D: 0.238359\n",
      "[Epoch 22/200] [Batch 740/938] loss_G: 3.147438, loss_D: 0.243399\n",
      "[Epoch 22/200] [Batch 750/938] loss_G: 3.365526, loss_D: 0.148058\n",
      "[Epoch 22/200] [Batch 760/938] loss_G: 3.849974, loss_D: 0.275820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22/200] [Batch 770/938] loss_G: 3.782088, loss_D: 0.164140\n",
      "[Epoch 22/200] [Batch 780/938] loss_G: 2.537337, loss_D: 0.243664\n",
      "[Epoch 22/200] [Batch 790/938] loss_G: 3.224246, loss_D: 0.167536\n",
      "[Epoch 22/200] [Batch 800/938] loss_G: 3.678126, loss_D: 0.228003\n",
      "[Epoch 22/200] [Batch 810/938] loss_G: 3.131526, loss_D: 0.154335\n",
      "[Epoch 22/200] [Batch 820/938] loss_G: 3.028387, loss_D: 0.172514\n",
      "[Epoch 22/200] [Batch 830/938] loss_G: 3.068406, loss_D: 0.182491\n",
      "[Epoch 22/200] [Batch 840/938] loss_G: 3.031011, loss_D: 0.193540\n",
      "[Epoch 22/200] [Batch 850/938] loss_G: 3.282004, loss_D: 0.214040\n",
      "[Epoch 22/200] [Batch 860/938] loss_G: 2.794191, loss_D: 0.165823\n",
      "[Epoch 22/200] [Batch 870/938] loss_G: 3.309574, loss_D: 0.216038\n",
      "[Epoch 22/200] [Batch 880/938] loss_G: 3.541031, loss_D: 0.194241\n",
      "[Epoch 22/200] [Batch 890/938] loss_G: 2.866721, loss_D: 0.271724\n",
      "[Epoch 22/200] [Batch 900/938] loss_G: 3.195112, loss_D: 0.271193\n",
      "[Epoch 22/200] [Batch 910/938] loss_G: 3.293019, loss_D: 0.201478\n",
      "[Epoch 22/200] [Batch 920/938] loss_G: 3.031815, loss_D: 0.172602\n",
      "[Epoch 22/200] [Batch 930/938] loss_G: 3.187419, loss_D: 0.186300\n",
      "[Epoch 23/200] [Batch 0/938] loss_G: 3.638125, loss_D: 0.139517\n",
      "[Epoch 23/200] [Batch 10/938] loss_G: 2.910052, loss_D: 0.254462\n",
      "[Epoch 23/200] [Batch 20/938] loss_G: 3.620678, loss_D: 0.184942\n",
      "[Epoch 23/200] [Batch 30/938] loss_G: 3.425278, loss_D: 0.103428\n",
      "[Epoch 23/200] [Batch 40/938] loss_G: 3.893875, loss_D: 0.175392\n",
      "[Epoch 23/200] [Batch 50/938] loss_G: 2.896807, loss_D: 0.174002\n",
      "[Epoch 23/200] [Batch 60/938] loss_G: 3.809381, loss_D: 0.182099\n",
      "[Epoch 23/200] [Batch 70/938] loss_G: 3.868536, loss_D: 0.118360\n",
      "[Epoch 23/200] [Batch 80/938] loss_G: 3.263555, loss_D: 0.254315\n",
      "[Epoch 23/200] [Batch 90/938] loss_G: 2.711871, loss_D: 0.202228\n",
      "[Epoch 23/200] [Batch 100/938] loss_G: 3.719094, loss_D: 0.121399\n",
      "[Epoch 23/200] [Batch 110/938] loss_G: 3.325875, loss_D: 0.226428\n",
      "[Epoch 23/200] [Batch 120/938] loss_G: 2.904894, loss_D: 0.223606\n",
      "[Epoch 23/200] [Batch 130/938] loss_G: 3.319493, loss_D: 0.145221\n",
      "[Epoch 23/200] [Batch 140/938] loss_G: 3.327416, loss_D: 0.263444\n",
      "[Epoch 23/200] [Batch 150/938] loss_G: 2.744410, loss_D: 0.283341\n",
      "[Epoch 23/200] [Batch 160/938] loss_G: 3.205615, loss_D: 0.174968\n",
      "[Epoch 23/200] [Batch 170/938] loss_G: 3.091937, loss_D: 0.173177\n",
      "[Epoch 23/200] [Batch 180/938] loss_G: 2.945682, loss_D: 0.187680\n",
      "[Epoch 23/200] [Batch 190/938] loss_G: 3.021571, loss_D: 0.233213\n",
      "[Epoch 23/200] [Batch 200/938] loss_G: 2.870067, loss_D: 0.201927\n",
      "[Epoch 23/200] [Batch 210/938] loss_G: 3.440369, loss_D: 0.128938\n",
      "[Epoch 23/200] [Batch 220/938] loss_G: 3.341805, loss_D: 0.132186\n",
      "[Epoch 23/200] [Batch 230/938] loss_G: 3.746867, loss_D: 0.187468\n",
      "[Epoch 23/200] [Batch 240/938] loss_G: 3.066072, loss_D: 0.193203\n",
      "[Epoch 23/200] [Batch 250/938] loss_G: 3.065517, loss_D: 0.264895\n",
      "[Epoch 23/200] [Batch 260/938] loss_G: 3.424109, loss_D: 0.151728\n",
      "[Epoch 23/200] [Batch 270/938] loss_G: 3.322167, loss_D: 0.163112\n",
      "[Epoch 23/200] [Batch 280/938] loss_G: 3.241580, loss_D: 0.195393\n",
      "[Epoch 23/200] [Batch 290/938] loss_G: 3.336111, loss_D: 0.117036\n",
      "[Epoch 23/200] [Batch 300/938] loss_G: 3.768526, loss_D: 0.147539\n",
      "[Epoch 23/200] [Batch 310/938] loss_G: 2.978991, loss_D: 0.208507\n",
      "[Epoch 23/200] [Batch 320/938] loss_G: 3.738784, loss_D: 0.154016\n",
      "[Epoch 23/200] [Batch 330/938] loss_G: 3.149238, loss_D: 0.156227\n",
      "[Epoch 23/200] [Batch 340/938] loss_G: 3.299538, loss_D: 0.222345\n",
      "[Epoch 23/200] [Batch 350/938] loss_G: 3.111894, loss_D: 0.231391\n",
      "[Epoch 23/200] [Batch 360/938] loss_G: 3.451164, loss_D: 0.183248\n",
      "[Epoch 23/200] [Batch 370/938] loss_G: 2.763097, loss_D: 0.217524\n",
      "[Epoch 23/200] [Batch 380/938] loss_G: 3.438254, loss_D: 0.208337\n",
      "[Epoch 23/200] [Batch 390/938] loss_G: 3.522499, loss_D: 0.221613\n",
      "[Epoch 23/200] [Batch 400/938] loss_G: 3.024932, loss_D: 0.243742\n",
      "[Epoch 23/200] [Batch 410/938] loss_G: 4.082976, loss_D: 0.211107\n",
      "[Epoch 23/200] [Batch 420/938] loss_G: 2.714042, loss_D: 0.120781\n",
      "[Epoch 23/200] [Batch 430/938] loss_G: 3.491766, loss_D: 0.204477\n",
      "[Epoch 23/200] [Batch 440/938] loss_G: 2.616273, loss_D: 0.282115\n",
      "[Epoch 23/200] [Batch 450/938] loss_G: 3.144260, loss_D: 0.192067\n",
      "[Epoch 23/200] [Batch 460/938] loss_G: 3.356335, loss_D: 0.183165\n",
      "[Epoch 23/200] [Batch 470/938] loss_G: 2.779572, loss_D: 0.251447\n",
      "[Epoch 23/200] [Batch 480/938] loss_G: 3.372421, loss_D: 0.120638\n",
      "[Epoch 23/200] [Batch 490/938] loss_G: 3.411254, loss_D: 0.140839\n",
      "[Epoch 23/200] [Batch 500/938] loss_G: 3.216623, loss_D: 0.127323\n",
      "[Epoch 23/200] [Batch 510/938] loss_G: 3.193015, loss_D: 0.195045\n",
      "[Epoch 23/200] [Batch 520/938] loss_G: 2.937293, loss_D: 0.171573\n",
      "[Epoch 23/200] [Batch 530/938] loss_G: 4.422998, loss_D: 0.207522\n",
      "[Epoch 23/200] [Batch 540/938] loss_G: 3.298029, loss_D: 0.184759\n",
      "[Epoch 23/200] [Batch 550/938] loss_G: 2.955579, loss_D: 0.195103\n",
      "[Epoch 23/200] [Batch 560/938] loss_G: 3.905544, loss_D: 0.173469\n",
      "[Epoch 23/200] [Batch 570/938] loss_G: 2.982097, loss_D: 0.203339\n",
      "[Epoch 23/200] [Batch 580/938] loss_G: 3.032920, loss_D: 0.244644\n",
      "[Epoch 23/200] [Batch 590/938] loss_G: 3.249078, loss_D: 0.289528\n",
      "[Epoch 23/200] [Batch 600/938] loss_G: 3.178673, loss_D: 0.259631\n",
      "[Epoch 23/200] [Batch 610/938] loss_G: 3.134630, loss_D: 0.128722\n",
      "[Epoch 23/200] [Batch 620/938] loss_G: 3.190102, loss_D: 0.200810\n",
      "[Epoch 23/200] [Batch 630/938] loss_G: 2.887350, loss_D: 0.333338\n",
      "[Epoch 23/200] [Batch 640/938] loss_G: 3.375263, loss_D: 0.199212\n",
      "[Epoch 23/200] [Batch 650/938] loss_G: 2.923246, loss_D: 0.149093\n",
      "[Epoch 23/200] [Batch 660/938] loss_G: 3.441339, loss_D: 0.240032\n",
      "[Epoch 23/200] [Batch 670/938] loss_G: 2.646750, loss_D: 0.352654\n",
      "[Epoch 23/200] [Batch 680/938] loss_G: 2.900279, loss_D: 0.181694\n",
      "[Epoch 23/200] [Batch 690/938] loss_G: 3.362319, loss_D: 0.194699\n",
      "[Epoch 23/200] [Batch 700/938] loss_G: 3.169687, loss_D: 0.295138\n",
      "[Epoch 23/200] [Batch 710/938] loss_G: 3.216575, loss_D: 0.226028\n",
      "[Epoch 23/200] [Batch 720/938] loss_G: 3.032682, loss_D: 0.151618\n",
      "[Epoch 23/200] [Batch 730/938] loss_G: 3.318285, loss_D: 0.253686\n",
      "[Epoch 23/200] [Batch 740/938] loss_G: 3.113159, loss_D: 0.192685\n",
      "[Epoch 23/200] [Batch 750/938] loss_G: 2.697477, loss_D: 0.178088\n",
      "[Epoch 23/200] [Batch 760/938] loss_G: 3.347020, loss_D: 0.091241\n",
      "[Epoch 23/200] [Batch 770/938] loss_G: 2.641200, loss_D: 0.260792\n",
      "[Epoch 23/200] [Batch 780/938] loss_G: 3.096449, loss_D: 0.129939\n",
      "[Epoch 23/200] [Batch 790/938] loss_G: 3.051711, loss_D: 0.287694\n",
      "[Epoch 23/200] [Batch 800/938] loss_G: 3.179513, loss_D: 0.253416\n",
      "[Epoch 23/200] [Batch 810/938] loss_G: 2.793172, loss_D: 0.219041\n",
      "[Epoch 23/200] [Batch 820/938] loss_G: 3.248314, loss_D: 0.253590\n",
      "[Epoch 23/200] [Batch 830/938] loss_G: 2.642742, loss_D: 0.234517\n",
      "[Epoch 23/200] [Batch 840/938] loss_G: 2.604063, loss_D: 0.240058\n",
      "[Epoch 23/200] [Batch 850/938] loss_G: 3.796605, loss_D: 0.200821\n",
      "[Epoch 23/200] [Batch 860/938] loss_G: 2.903373, loss_D: 0.186173\n",
      "[Epoch 23/200] [Batch 870/938] loss_G: 3.501978, loss_D: 0.250455\n",
      "[Epoch 23/200] [Batch 880/938] loss_G: 3.615295, loss_D: 0.142237\n",
      "[Epoch 23/200] [Batch 890/938] loss_G: 3.561225, loss_D: 0.204571\n",
      "[Epoch 23/200] [Batch 900/938] loss_G: 3.378537, loss_D: 0.075254\n",
      "[Epoch 23/200] [Batch 910/938] loss_G: 3.394623, loss_D: 0.185313\n",
      "[Epoch 23/200] [Batch 920/938] loss_G: 3.370791, loss_D: 0.173457\n",
      "[Epoch 23/200] [Batch 930/938] loss_G: 3.107121, loss_D: 0.163719\n",
      "[Epoch 24/200] [Batch 0/938] loss_G: 3.606090, loss_D: 0.190520\n",
      "[Epoch 24/200] [Batch 10/938] loss_G: 2.863062, loss_D: 0.264394\n",
      "[Epoch 24/200] [Batch 20/938] loss_G: 3.875380, loss_D: 0.269776\n",
      "[Epoch 24/200] [Batch 30/938] loss_G: 3.842471, loss_D: 0.201711\n",
      "[Epoch 24/200] [Batch 40/938] loss_G: 3.263877, loss_D: 0.181330\n",
      "[Epoch 24/200] [Batch 50/938] loss_G: 3.439557, loss_D: 0.129038\n",
      "[Epoch 24/200] [Batch 60/938] loss_G: 3.389069, loss_D: 0.304183\n",
      "[Epoch 24/200] [Batch 70/938] loss_G: 3.162323, loss_D: 0.329398\n",
      "[Epoch 24/200] [Batch 80/938] loss_G: 2.851121, loss_D: 0.215203\n",
      "[Epoch 24/200] [Batch 90/938] loss_G: 2.702986, loss_D: 0.329351\n",
      "[Epoch 24/200] [Batch 100/938] loss_G: 3.667482, loss_D: 0.120499\n",
      "[Epoch 24/200] [Batch 110/938] loss_G: 2.953645, loss_D: 0.114165\n",
      "[Epoch 24/200] [Batch 120/938] loss_G: 3.094440, loss_D: 0.185301\n",
      "[Epoch 24/200] [Batch 130/938] loss_G: 3.106520, loss_D: 0.254235\n",
      "[Epoch 24/200] [Batch 140/938] loss_G: 3.276729, loss_D: 0.216569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24/200] [Batch 150/938] loss_G: 3.163888, loss_D: 0.180879\n",
      "[Epoch 24/200] [Batch 160/938] loss_G: 3.205467, loss_D: 0.169929\n",
      "[Epoch 24/200] [Batch 170/938] loss_G: 3.392800, loss_D: 0.189308\n",
      "[Epoch 24/200] [Batch 180/938] loss_G: 3.188247, loss_D: 0.259659\n",
      "[Epoch 24/200] [Batch 190/938] loss_G: 3.193135, loss_D: 0.219593\n",
      "[Epoch 24/200] [Batch 200/938] loss_G: 3.271545, loss_D: 0.212561\n",
      "[Epoch 24/200] [Batch 210/938] loss_G: 3.420757, loss_D: 0.101467\n",
      "[Epoch 24/200] [Batch 220/938] loss_G: 3.354060, loss_D: 0.186208\n",
      "[Epoch 24/200] [Batch 230/938] loss_G: 3.647651, loss_D: 0.177060\n",
      "[Epoch 24/200] [Batch 240/938] loss_G: 3.629540, loss_D: 0.200172\n",
      "[Epoch 24/200] [Batch 250/938] loss_G: 3.260055, loss_D: 0.157449\n",
      "[Epoch 24/200] [Batch 260/938] loss_G: 2.837533, loss_D: 0.217130\n",
      "[Epoch 24/200] [Batch 270/938] loss_G: 3.207714, loss_D: 0.201717\n",
      "[Epoch 24/200] [Batch 280/938] loss_G: 2.710297, loss_D: 0.189300\n",
      "[Epoch 24/200] [Batch 290/938] loss_G: 3.053362, loss_D: 0.238967\n",
      "[Epoch 24/200] [Batch 300/938] loss_G: 2.830252, loss_D: 0.220280\n",
      "[Epoch 24/200] [Batch 310/938] loss_G: 3.198294, loss_D: 0.199614\n",
      "[Epoch 24/200] [Batch 320/938] loss_G: 2.872807, loss_D: 0.218401\n",
      "[Epoch 24/200] [Batch 330/938] loss_G: 3.105038, loss_D: 0.177798\n",
      "[Epoch 24/200] [Batch 340/938] loss_G: 3.045300, loss_D: 0.220699\n",
      "[Epoch 24/200] [Batch 350/938] loss_G: 3.187537, loss_D: 0.277562\n",
      "[Epoch 24/200] [Batch 360/938] loss_G: 3.131484, loss_D: 0.182626\n",
      "[Epoch 24/200] [Batch 370/938] loss_G: 3.301708, loss_D: 0.211945\n",
      "[Epoch 24/200] [Batch 380/938] loss_G: 3.436393, loss_D: 0.249638\n",
      "[Epoch 24/200] [Batch 390/938] loss_G: 3.265645, loss_D: 0.266564\n",
      "[Epoch 24/200] [Batch 400/938] loss_G: 3.105056, loss_D: 0.387584\n",
      "[Epoch 24/200] [Batch 410/938] loss_G: 3.489697, loss_D: 0.155222\n",
      "[Epoch 24/200] [Batch 420/938] loss_G: 3.743276, loss_D: 0.196852\n",
      "[Epoch 24/200] [Batch 430/938] loss_G: 2.733639, loss_D: 0.151814\n",
      "[Epoch 24/200] [Batch 440/938] loss_G: 3.362668, loss_D: 0.205479\n",
      "[Epoch 24/200] [Batch 450/938] loss_G: 3.086233, loss_D: 0.231234\n",
      "[Epoch 24/200] [Batch 460/938] loss_G: 3.209111, loss_D: 0.128413\n",
      "[Epoch 24/200] [Batch 470/938] loss_G: 3.509629, loss_D: 0.224581\n",
      "[Epoch 24/200] [Batch 480/938] loss_G: 3.506878, loss_D: 0.262663\n",
      "[Epoch 24/200] [Batch 490/938] loss_G: 3.282432, loss_D: 0.206203\n",
      "[Epoch 24/200] [Batch 500/938] loss_G: 2.754763, loss_D: 0.175215\n",
      "[Epoch 24/200] [Batch 510/938] loss_G: 2.813194, loss_D: 0.239449\n",
      "[Epoch 24/200] [Batch 520/938] loss_G: 3.015823, loss_D: 0.231199\n",
      "[Epoch 24/200] [Batch 530/938] loss_G: 2.752644, loss_D: 0.343161\n",
      "[Epoch 24/200] [Batch 540/938] loss_G: 2.963121, loss_D: 0.206288\n",
      "[Epoch 24/200] [Batch 550/938] loss_G: 3.164139, loss_D: 0.234892\n",
      "[Epoch 24/200] [Batch 560/938] loss_G: 3.003607, loss_D: 0.242803\n",
      "[Epoch 24/200] [Batch 570/938] loss_G: 3.409139, loss_D: 0.148701\n",
      "[Epoch 24/200] [Batch 580/938] loss_G: 3.141357, loss_D: 0.186259\n",
      "[Epoch 24/200] [Batch 590/938] loss_G: 2.752076, loss_D: 0.136556\n",
      "[Epoch 24/200] [Batch 600/938] loss_G: 2.715816, loss_D: 0.230225\n",
      "[Epoch 24/200] [Batch 610/938] loss_G: 2.487304, loss_D: 0.213342\n",
      "[Epoch 24/200] [Batch 620/938] loss_G: 3.510636, loss_D: 0.170091\n",
      "[Epoch 24/200] [Batch 630/938] loss_G: 2.341872, loss_D: 0.207491\n",
      "[Epoch 24/200] [Batch 640/938] loss_G: 3.237910, loss_D: 0.189792\n",
      "[Epoch 24/200] [Batch 650/938] loss_G: 3.025461, loss_D: 0.272349\n",
      "[Epoch 24/200] [Batch 660/938] loss_G: 2.932560, loss_D: 0.296476\n",
      "[Epoch 24/200] [Batch 670/938] loss_G: 3.076844, loss_D: 0.175347\n",
      "[Epoch 24/200] [Batch 680/938] loss_G: 2.932864, loss_D: 0.208513\n",
      "[Epoch 24/200] [Batch 690/938] loss_G: 3.507325, loss_D: 0.169648\n",
      "[Epoch 24/200] [Batch 700/938] loss_G: 3.064142, loss_D: 0.178991\n",
      "[Epoch 24/200] [Batch 710/938] loss_G: 2.939370, loss_D: 0.251406\n",
      "[Epoch 24/200] [Batch 720/938] loss_G: 2.841270, loss_D: 0.289659\n",
      "[Epoch 24/200] [Batch 730/938] loss_G: 2.942104, loss_D: 0.207206\n",
      "[Epoch 24/200] [Batch 740/938] loss_G: 3.441297, loss_D: 0.160939\n",
      "[Epoch 24/200] [Batch 750/938] loss_G: 3.261207, loss_D: 0.177183\n",
      "[Epoch 24/200] [Batch 760/938] loss_G: 3.085899, loss_D: 0.137790\n",
      "[Epoch 24/200] [Batch 770/938] loss_G: 3.219176, loss_D: 0.152056\n",
      "[Epoch 24/200] [Batch 780/938] loss_G: 2.542601, loss_D: 0.232510\n",
      "[Epoch 24/200] [Batch 790/938] loss_G: 3.385192, loss_D: 0.228342\n",
      "[Epoch 24/200] [Batch 800/938] loss_G: 3.619487, loss_D: 0.307610\n",
      "[Epoch 24/200] [Batch 810/938] loss_G: 2.960855, loss_D: 0.210257\n",
      "[Epoch 24/200] [Batch 820/938] loss_G: 3.034588, loss_D: 0.197823\n",
      "[Epoch 24/200] [Batch 830/938] loss_G: 2.816232, loss_D: 0.240780\n",
      "[Epoch 24/200] [Batch 840/938] loss_G: 3.179546, loss_D: 0.296405\n",
      "[Epoch 24/200] [Batch 850/938] loss_G: 2.969126, loss_D: 0.269674\n",
      "[Epoch 24/200] [Batch 860/938] loss_G: 2.994462, loss_D: 0.261336\n",
      "[Epoch 24/200] [Batch 870/938] loss_G: 3.168701, loss_D: 0.286818\n",
      "[Epoch 24/200] [Batch 880/938] loss_G: 3.292691, loss_D: 0.121323\n",
      "[Epoch 24/200] [Batch 890/938] loss_G: 2.691356, loss_D: 0.324241\n",
      "[Epoch 24/200] [Batch 900/938] loss_G: 2.623169, loss_D: 0.195495\n",
      "[Epoch 24/200] [Batch 910/938] loss_G: 3.233292, loss_D: 0.153971\n",
      "[Epoch 24/200] [Batch 920/938] loss_G: 3.553792, loss_D: 0.237229\n",
      "[Epoch 24/200] [Batch 930/938] loss_G: 3.059254, loss_D: 0.148089\n",
      "[Epoch 25/200] [Batch 0/938] loss_G: 3.402436, loss_D: 0.213441\n",
      "[Epoch 25/200] [Batch 10/938] loss_G: 3.495552, loss_D: 0.123177\n",
      "[Epoch 25/200] [Batch 20/938] loss_G: 3.298862, loss_D: 0.156678\n",
      "[Epoch 25/200] [Batch 30/938] loss_G: 2.936426, loss_D: 0.171757\n",
      "[Epoch 25/200] [Batch 40/938] loss_G: 3.488062, loss_D: 0.168259\n",
      "[Epoch 25/200] [Batch 50/938] loss_G: 3.087183, loss_D: 0.319504\n",
      "[Epoch 25/200] [Batch 60/938] loss_G: 3.071693, loss_D: 0.226805\n",
      "[Epoch 25/200] [Batch 70/938] loss_G: 3.010918, loss_D: 0.201008\n",
      "[Epoch 25/200] [Batch 80/938] loss_G: 2.779479, loss_D: 0.263840\n",
      "[Epoch 25/200] [Batch 90/938] loss_G: 3.021341, loss_D: 0.167864\n",
      "[Epoch 25/200] [Batch 100/938] loss_G: 3.425763, loss_D: 0.205079\n",
      "[Epoch 25/200] [Batch 110/938] loss_G: 3.093275, loss_D: 0.108544\n",
      "[Epoch 25/200] [Batch 120/938] loss_G: 3.148779, loss_D: 0.173772\n",
      "[Epoch 25/200] [Batch 130/938] loss_G: 3.180679, loss_D: 0.119158\n",
      "[Epoch 25/200] [Batch 140/938] loss_G: 3.005566, loss_D: 0.273416\n",
      "[Epoch 25/200] [Batch 150/938] loss_G: 3.108126, loss_D: 0.187181\n",
      "[Epoch 25/200] [Batch 160/938] loss_G: 2.773067, loss_D: 0.266206\n",
      "[Epoch 25/200] [Batch 170/938] loss_G: 2.723984, loss_D: 0.191943\n",
      "[Epoch 25/200] [Batch 180/938] loss_G: 3.360728, loss_D: 0.222892\n",
      "[Epoch 25/200] [Batch 190/938] loss_G: 2.573975, loss_D: 0.293572\n",
      "[Epoch 25/200] [Batch 200/938] loss_G: 3.310455, loss_D: 0.207633\n",
      "[Epoch 25/200] [Batch 210/938] loss_G: 3.012999, loss_D: 0.203891\n",
      "[Epoch 25/200] [Batch 220/938] loss_G: 3.433047, loss_D: 0.288560\n",
      "[Epoch 25/200] [Batch 230/938] loss_G: 2.806689, loss_D: 0.292533\n",
      "[Epoch 25/200] [Batch 240/938] loss_G: 3.001292, loss_D: 0.130244\n",
      "[Epoch 25/200] [Batch 250/938] loss_G: 2.950866, loss_D: 0.228479\n",
      "[Epoch 25/200] [Batch 260/938] loss_G: 3.246626, loss_D: 0.352916\n",
      "[Epoch 25/200] [Batch 270/938] loss_G: 2.635377, loss_D: 0.199321\n",
      "[Epoch 25/200] [Batch 280/938] loss_G: 3.097197, loss_D: 0.214850\n",
      "[Epoch 25/200] [Batch 290/938] loss_G: 3.215225, loss_D: 0.151542\n",
      "[Epoch 25/200] [Batch 300/938] loss_G: 3.115747, loss_D: 0.223173\n",
      "[Epoch 25/200] [Batch 310/938] loss_G: 3.665365, loss_D: 0.193031\n",
      "[Epoch 25/200] [Batch 320/938] loss_G: 2.987938, loss_D: 0.185077\n",
      "[Epoch 25/200] [Batch 330/938] loss_G: 3.374541, loss_D: 0.182287\n",
      "[Epoch 25/200] [Batch 340/938] loss_G: 2.809170, loss_D: 0.305736\n",
      "[Epoch 25/200] [Batch 350/938] loss_G: 3.013089, loss_D: 0.190624\n",
      "[Epoch 25/200] [Batch 360/938] loss_G: 3.082442, loss_D: 0.210273\n",
      "[Epoch 25/200] [Batch 370/938] loss_G: 2.575742, loss_D: 0.195802\n",
      "[Epoch 25/200] [Batch 380/938] loss_G: 3.067196, loss_D: 0.131015\n",
      "[Epoch 25/200] [Batch 390/938] loss_G: 2.988422, loss_D: 0.233653\n",
      "[Epoch 25/200] [Batch 400/938] loss_G: 3.238319, loss_D: 0.256839\n",
      "[Epoch 25/200] [Batch 410/938] loss_G: 3.350770, loss_D: 0.247866\n",
      "[Epoch 25/200] [Batch 420/938] loss_G: 3.395928, loss_D: 0.126532\n",
      "[Epoch 25/200] [Batch 430/938] loss_G: 2.820084, loss_D: 0.276858\n",
      "[Epoch 25/200] [Batch 440/938] loss_G: 2.588227, loss_D: 0.302563\n",
      "[Epoch 25/200] [Batch 450/938] loss_G: 2.247012, loss_D: 0.341730\n",
      "[Epoch 25/200] [Batch 460/938] loss_G: 2.871420, loss_D: 0.279495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25/200] [Batch 470/938] loss_G: 3.553357, loss_D: 0.219879\n",
      "[Epoch 25/200] [Batch 480/938] loss_G: 3.684595, loss_D: 0.156231\n",
      "[Epoch 25/200] [Batch 490/938] loss_G: 2.712743, loss_D: 0.154949\n",
      "[Epoch 25/200] [Batch 500/938] loss_G: 3.200440, loss_D: 0.208798\n",
      "[Epoch 25/200] [Batch 510/938] loss_G: 3.618430, loss_D: 0.164104\n",
      "[Epoch 25/200] [Batch 520/938] loss_G: 2.820242, loss_D: 0.306950\n",
      "[Epoch 25/200] [Batch 530/938] loss_G: 2.841547, loss_D: 0.265987\n",
      "[Epoch 25/200] [Batch 540/938] loss_G: 3.118074, loss_D: 0.183615\n",
      "[Epoch 25/200] [Batch 550/938] loss_G: 2.344270, loss_D: 0.251024\n",
      "[Epoch 25/200] [Batch 560/938] loss_G: 3.025260, loss_D: 0.232475\n",
      "[Epoch 25/200] [Batch 570/938] loss_G: 3.187537, loss_D: 0.183829\n",
      "[Epoch 25/200] [Batch 580/938] loss_G: 3.673402, loss_D: 0.188197\n",
      "[Epoch 25/200] [Batch 590/938] loss_G: 3.145072, loss_D: 0.172438\n",
      "[Epoch 25/200] [Batch 600/938] loss_G: 3.169080, loss_D: 0.265717\n",
      "[Epoch 25/200] [Batch 610/938] loss_G: 2.887109, loss_D: 0.240358\n",
      "[Epoch 25/200] [Batch 620/938] loss_G: 3.328229, loss_D: 0.151100\n",
      "[Epoch 25/200] [Batch 630/938] loss_G: 2.446488, loss_D: 0.302068\n",
      "[Epoch 25/200] [Batch 640/938] loss_G: 3.486209, loss_D: 0.119337\n",
      "[Epoch 25/200] [Batch 650/938] loss_G: 2.872032, loss_D: 0.170109\n",
      "[Epoch 25/200] [Batch 660/938] loss_G: 2.863047, loss_D: 0.233896\n",
      "[Epoch 25/200] [Batch 670/938] loss_G: 3.375607, loss_D: 0.161449\n",
      "[Epoch 25/200] [Batch 680/938] loss_G: 2.719310, loss_D: 0.323939\n",
      "[Epoch 25/200] [Batch 690/938] loss_G: 3.091098, loss_D: 0.176582\n",
      "[Epoch 25/200] [Batch 700/938] loss_G: 3.169849, loss_D: 0.163064\n",
      "[Epoch 25/200] [Batch 710/938] loss_G: 3.396893, loss_D: 0.138302\n",
      "[Epoch 25/200] [Batch 720/938] loss_G: 3.649473, loss_D: 0.237213\n",
      "[Epoch 25/200] [Batch 730/938] loss_G: 3.259754, loss_D: 0.203058\n",
      "[Epoch 25/200] [Batch 740/938] loss_G: 2.937528, loss_D: 0.210977\n",
      "[Epoch 25/200] [Batch 750/938] loss_G: 2.910373, loss_D: 0.207535\n",
      "[Epoch 25/200] [Batch 760/938] loss_G: 3.363932, loss_D: 0.102181\n",
      "[Epoch 25/200] [Batch 770/938] loss_G: 2.750665, loss_D: 0.258517\n",
      "[Epoch 25/200] [Batch 780/938] loss_G: 2.792361, loss_D: 0.212535\n",
      "[Epoch 25/200] [Batch 790/938] loss_G: 2.796719, loss_D: 0.278337\n",
      "[Epoch 25/200] [Batch 800/938] loss_G: 3.070417, loss_D: 0.134401\n",
      "[Epoch 25/200] [Batch 810/938] loss_G: 3.180644, loss_D: 0.202645\n",
      "[Epoch 25/200] [Batch 820/938] loss_G: 3.201410, loss_D: 0.232280\n",
      "[Epoch 25/200] [Batch 830/938] loss_G: 3.515000, loss_D: 0.161971\n",
      "[Epoch 25/200] [Batch 840/938] loss_G: 3.096942, loss_D: 0.229737\n",
      "[Epoch 25/200] [Batch 850/938] loss_G: 2.910686, loss_D: 0.220915\n",
      "[Epoch 25/200] [Batch 860/938] loss_G: 3.792041, loss_D: 0.150420\n",
      "[Epoch 25/200] [Batch 870/938] loss_G: 3.812353, loss_D: 0.323419\n",
      "[Epoch 25/200] [Batch 880/938] loss_G: 3.088975, loss_D: 0.166879\n",
      "[Epoch 25/200] [Batch 890/938] loss_G: 3.652669, loss_D: 0.116705\n",
      "[Epoch 25/200] [Batch 900/938] loss_G: 3.566080, loss_D: 0.233110\n",
      "[Epoch 25/200] [Batch 910/938] loss_G: 3.026796, loss_D: 0.177797\n",
      "[Epoch 25/200] [Batch 920/938] loss_G: 3.194610, loss_D: 0.309600\n",
      "[Epoch 25/200] [Batch 930/938] loss_G: 2.358123, loss_D: 0.170145\n",
      "[Epoch 26/200] [Batch 0/938] loss_G: 3.635327, loss_D: 0.228384\n",
      "[Epoch 26/200] [Batch 10/938] loss_G: 3.160734, loss_D: 0.133021\n",
      "[Epoch 26/200] [Batch 20/938] loss_G: 3.097463, loss_D: 0.211397\n",
      "[Epoch 26/200] [Batch 30/938] loss_G: 2.976867, loss_D: 0.185495\n",
      "[Epoch 26/200] [Batch 40/938] loss_G: 3.410334, loss_D: 0.241768\n",
      "[Epoch 26/200] [Batch 50/938] loss_G: 3.024268, loss_D: 0.243000\n",
      "[Epoch 26/200] [Batch 60/938] loss_G: 2.457957, loss_D: 0.315302\n",
      "[Epoch 26/200] [Batch 70/938] loss_G: 2.849803, loss_D: 0.300863\n",
      "[Epoch 26/200] [Batch 80/938] loss_G: 3.040898, loss_D: 0.149415\n",
      "[Epoch 26/200] [Batch 90/938] loss_G: 2.811372, loss_D: 0.129995\n",
      "[Epoch 26/200] [Batch 100/938] loss_G: 3.095172, loss_D: 0.211780\n",
      "[Epoch 26/200] [Batch 110/938] loss_G: 3.324802, loss_D: 0.111201\n",
      "[Epoch 26/200] [Batch 120/938] loss_G: 2.935961, loss_D: 0.171293\n",
      "[Epoch 26/200] [Batch 130/938] loss_G: 2.968092, loss_D: 0.239769\n",
      "[Epoch 26/200] [Batch 140/938] loss_G: 3.063962, loss_D: 0.199885\n",
      "[Epoch 26/200] [Batch 150/938] loss_G: 2.098657, loss_D: 0.297335\n",
      "[Epoch 26/200] [Batch 160/938] loss_G: 2.853814, loss_D: 0.143477\n",
      "[Epoch 26/200] [Batch 170/938] loss_G: 3.427068, loss_D: 0.201096\n",
      "[Epoch 26/200] [Batch 180/938] loss_G: 2.917785, loss_D: 0.212155\n",
      "[Epoch 26/200] [Batch 190/938] loss_G: 3.012911, loss_D: 0.167099\n",
      "[Epoch 26/200] [Batch 200/938] loss_G: 3.325001, loss_D: 0.260099\n",
      "[Epoch 26/200] [Batch 210/938] loss_G: 3.835882, loss_D: 0.188882\n",
      "[Epoch 26/200] [Batch 220/938] loss_G: 3.407774, loss_D: 0.146731\n",
      "[Epoch 26/200] [Batch 230/938] loss_G: 2.877042, loss_D: 0.239804\n",
      "[Epoch 26/200] [Batch 240/938] loss_G: 3.379263, loss_D: 0.224168\n",
      "[Epoch 26/200] [Batch 250/938] loss_G: 2.759611, loss_D: 0.240504\n",
      "[Epoch 26/200] [Batch 260/938] loss_G: 2.853278, loss_D: 0.259736\n",
      "[Epoch 26/200] [Batch 270/938] loss_G: 3.135089, loss_D: 0.242238\n",
      "[Epoch 26/200] [Batch 280/938] loss_G: 3.033651, loss_D: 0.223277\n",
      "[Epoch 26/200] [Batch 290/938] loss_G: 2.993512, loss_D: 0.220787\n",
      "[Epoch 26/200] [Batch 300/938] loss_G: 3.052277, loss_D: 0.202530\n",
      "[Epoch 26/200] [Batch 310/938] loss_G: 3.010338, loss_D: 0.200840\n",
      "[Epoch 26/200] [Batch 320/938] loss_G: 3.285193, loss_D: 0.159862\n",
      "[Epoch 26/200] [Batch 330/938] loss_G: 3.361787, loss_D: 0.212498\n",
      "[Epoch 26/200] [Batch 340/938] loss_G: 3.206907, loss_D: 0.246313\n",
      "[Epoch 26/200] [Batch 350/938] loss_G: 2.825221, loss_D: 0.267582\n",
      "[Epoch 26/200] [Batch 360/938] loss_G: 3.185528, loss_D: 0.182525\n",
      "[Epoch 26/200] [Batch 370/938] loss_G: 3.076149, loss_D: 0.241313\n",
      "[Epoch 26/200] [Batch 380/938] loss_G: 3.165789, loss_D: 0.213194\n",
      "[Epoch 26/200] [Batch 390/938] loss_G: 3.044092, loss_D: 0.206393\n",
      "[Epoch 26/200] [Batch 400/938] loss_G: 2.761105, loss_D: 0.192912\n",
      "[Epoch 26/200] [Batch 410/938] loss_G: 2.769716, loss_D: 0.206047\n",
      "[Epoch 26/200] [Batch 420/938] loss_G: 3.367812, loss_D: 0.195397\n",
      "[Epoch 26/200] [Batch 430/938] loss_G: 3.088180, loss_D: 0.167206\n",
      "[Epoch 26/200] [Batch 440/938] loss_G: 3.133550, loss_D: 0.218358\n",
      "[Epoch 26/200] [Batch 450/938] loss_G: 3.253302, loss_D: 0.286421\n",
      "[Epoch 26/200] [Batch 460/938] loss_G: 3.242940, loss_D: 0.248344\n",
      "[Epoch 26/200] [Batch 470/938] loss_G: 2.904076, loss_D: 0.237853\n",
      "[Epoch 26/200] [Batch 480/938] loss_G: 2.735697, loss_D: 0.184247\n",
      "[Epoch 26/200] [Batch 490/938] loss_G: 2.801513, loss_D: 0.180269\n",
      "[Epoch 26/200] [Batch 500/938] loss_G: 3.293656, loss_D: 0.225063\n",
      "[Epoch 26/200] [Batch 510/938] loss_G: 3.626679, loss_D: 0.150260\n",
      "[Epoch 26/200] [Batch 520/938] loss_G: 3.222727, loss_D: 0.201703\n",
      "[Epoch 26/200] [Batch 530/938] loss_G: 3.312093, loss_D: 0.182408\n",
      "[Epoch 26/200] [Batch 540/938] loss_G: 3.400346, loss_D: 0.197334\n",
      "[Epoch 26/200] [Batch 550/938] loss_G: 3.396981, loss_D: 0.185692\n",
      "[Epoch 26/200] [Batch 560/938] loss_G: 2.929055, loss_D: 0.209485\n",
      "[Epoch 26/200] [Batch 570/938] loss_G: 2.973669, loss_D: 0.159602\n",
      "[Epoch 26/200] [Batch 580/938] loss_G: 3.604902, loss_D: 0.176175\n",
      "[Epoch 26/200] [Batch 590/938] loss_G: 3.300030, loss_D: 0.154128\n",
      "[Epoch 26/200] [Batch 600/938] loss_G: 2.965793, loss_D: 0.168297\n",
      "[Epoch 26/200] [Batch 610/938] loss_G: 2.683274, loss_D: 0.297938\n",
      "[Epoch 26/200] [Batch 620/938] loss_G: 2.472790, loss_D: 0.368771\n",
      "[Epoch 26/200] [Batch 630/938] loss_G: 3.096990, loss_D: 0.169024\n",
      "[Epoch 26/200] [Batch 640/938] loss_G: 2.720747, loss_D: 0.235751\n",
      "[Epoch 26/200] [Batch 650/938] loss_G: 3.066382, loss_D: 0.161259\n",
      "[Epoch 26/200] [Batch 660/938] loss_G: 2.931359, loss_D: 0.213943\n",
      "[Epoch 26/200] [Batch 670/938] loss_G: 2.861337, loss_D: 0.209710\n",
      "[Epoch 26/200] [Batch 680/938] loss_G: 3.050643, loss_D: 0.269334\n",
      "[Epoch 26/200] [Batch 690/938] loss_G: 3.598685, loss_D: 0.121247\n",
      "[Epoch 26/200] [Batch 700/938] loss_G: 2.975102, loss_D: 0.107981\n",
      "[Epoch 26/200] [Batch 710/938] loss_G: 3.270016, loss_D: 0.208851\n",
      "[Epoch 26/200] [Batch 720/938] loss_G: 3.280523, loss_D: 0.184092\n",
      "[Epoch 26/200] [Batch 730/938] loss_G: 3.207027, loss_D: 0.174489\n",
      "[Epoch 26/200] [Batch 740/938] loss_G: 3.366529, loss_D: 0.220850\n",
      "[Epoch 26/200] [Batch 750/938] loss_G: 3.594531, loss_D: 0.233772\n",
      "[Epoch 26/200] [Batch 760/938] loss_G: 2.781013, loss_D: 0.130304\n",
      "[Epoch 26/200] [Batch 770/938] loss_G: 2.985451, loss_D: 0.206490\n",
      "[Epoch 26/200] [Batch 780/938] loss_G: 3.031455, loss_D: 0.186538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26/200] [Batch 790/938] loss_G: 2.915374, loss_D: 0.177386\n",
      "[Epoch 26/200] [Batch 800/938] loss_G: 2.534056, loss_D: 0.282840\n",
      "[Epoch 26/200] [Batch 810/938] loss_G: 3.068956, loss_D: 0.137352\n",
      "[Epoch 26/200] [Batch 820/938] loss_G: 3.262421, loss_D: 0.304807\n",
      "[Epoch 26/200] [Batch 830/938] loss_G: 3.258895, loss_D: 0.179100\n",
      "[Epoch 26/200] [Batch 840/938] loss_G: 2.563668, loss_D: 0.219878\n",
      "[Epoch 26/200] [Batch 850/938] loss_G: 3.035392, loss_D: 0.209909\n",
      "[Epoch 26/200] [Batch 860/938] loss_G: 2.781184, loss_D: 0.242073\n",
      "[Epoch 26/200] [Batch 870/938] loss_G: 3.154361, loss_D: 0.181505\n",
      "[Epoch 26/200] [Batch 880/938] loss_G: 2.766191, loss_D: 0.165573\n",
      "[Epoch 26/200] [Batch 890/938] loss_G: 3.273209, loss_D: 0.266694\n",
      "[Epoch 26/200] [Batch 900/938] loss_G: 2.829749, loss_D: 0.264467\n",
      "[Epoch 26/200] [Batch 910/938] loss_G: 3.612828, loss_D: 0.174965\n",
      "[Epoch 26/200] [Batch 920/938] loss_G: 3.004322, loss_D: 0.198178\n",
      "[Epoch 26/200] [Batch 930/938] loss_G: 2.857482, loss_D: 0.205739\n",
      "[Epoch 27/200] [Batch 0/938] loss_G: 2.775549, loss_D: 0.214579\n",
      "[Epoch 27/200] [Batch 10/938] loss_G: 3.025397, loss_D: 0.293340\n",
      "[Epoch 27/200] [Batch 20/938] loss_G: 3.033742, loss_D: 0.247101\n",
      "[Epoch 27/200] [Batch 30/938] loss_G: 2.961661, loss_D: 0.238334\n",
      "[Epoch 27/200] [Batch 40/938] loss_G: 2.806293, loss_D: 0.203494\n",
      "[Epoch 27/200] [Batch 50/938] loss_G: 2.988775, loss_D: 0.166971\n",
      "[Epoch 27/200] [Batch 60/938] loss_G: 3.030223, loss_D: 0.244038\n",
      "[Epoch 27/200] [Batch 70/938] loss_G: 2.450570, loss_D: 0.331171\n",
      "[Epoch 27/200] [Batch 80/938] loss_G: 2.650036, loss_D: 0.276731\n",
      "[Epoch 27/200] [Batch 90/938] loss_G: 2.745759, loss_D: 0.292563\n",
      "[Epoch 27/200] [Batch 100/938] loss_G: 3.362961, loss_D: 0.173399\n",
      "[Epoch 27/200] [Batch 110/938] loss_G: 3.244301, loss_D: 0.205431\n",
      "[Epoch 27/200] [Batch 120/938] loss_G: 2.817303, loss_D: 0.200674\n",
      "[Epoch 27/200] [Batch 130/938] loss_G: 3.125437, loss_D: 0.231466\n",
      "[Epoch 27/200] [Batch 140/938] loss_G: 3.426382, loss_D: 0.291800\n",
      "[Epoch 27/200] [Batch 150/938] loss_G: 3.073944, loss_D: 0.179834\n",
      "[Epoch 27/200] [Batch 160/938] loss_G: 2.702913, loss_D: 0.257477\n",
      "[Epoch 27/200] [Batch 170/938] loss_G: 2.880506, loss_D: 0.234692\n",
      "[Epoch 27/200] [Batch 180/938] loss_G: 2.998940, loss_D: 0.228033\n",
      "[Epoch 27/200] [Batch 190/938] loss_G: 3.282154, loss_D: 0.351178\n",
      "[Epoch 27/200] [Batch 200/938] loss_G: 3.197315, loss_D: 0.247599\n",
      "[Epoch 27/200] [Batch 210/938] loss_G: 2.721549, loss_D: 0.200974\n",
      "[Epoch 27/200] [Batch 220/938] loss_G: 3.037068, loss_D: 0.222962\n",
      "[Epoch 27/200] [Batch 230/938] loss_G: 3.375557, loss_D: 0.190155\n",
      "[Epoch 27/200] [Batch 240/938] loss_G: 2.835351, loss_D: 0.220248\n",
      "[Epoch 27/200] [Batch 250/938] loss_G: 2.645040, loss_D: 0.178342\n",
      "[Epoch 27/200] [Batch 260/938] loss_G: 2.928251, loss_D: 0.253660\n",
      "[Epoch 27/200] [Batch 270/938] loss_G: 2.460146, loss_D: 0.264881\n",
      "[Epoch 27/200] [Batch 280/938] loss_G: 2.751307, loss_D: 0.220824\n",
      "[Epoch 27/200] [Batch 290/938] loss_G: 3.001209, loss_D: 0.226522\n",
      "[Epoch 27/200] [Batch 300/938] loss_G: 3.256140, loss_D: 0.234032\n",
      "[Epoch 27/200] [Batch 310/938] loss_G: 2.681145, loss_D: 0.210709\n",
      "[Epoch 27/200] [Batch 320/938] loss_G: 3.167884, loss_D: 0.202517\n",
      "[Epoch 27/200] [Batch 330/938] loss_G: 2.564308, loss_D: 0.236893\n",
      "[Epoch 27/200] [Batch 340/938] loss_G: 2.588903, loss_D: 0.310349\n",
      "[Epoch 27/200] [Batch 350/938] loss_G: 2.823852, loss_D: 0.252723\n",
      "[Epoch 27/200] [Batch 360/938] loss_G: 3.245407, loss_D: 0.178748\n",
      "[Epoch 27/200] [Batch 370/938] loss_G: 2.932887, loss_D: 0.197469\n",
      "[Epoch 27/200] [Batch 380/938] loss_G: 2.496085, loss_D: 0.279175\n",
      "[Epoch 27/200] [Batch 390/938] loss_G: 3.598872, loss_D: 0.198705\n",
      "[Epoch 27/200] [Batch 400/938] loss_G: 3.187615, loss_D: 0.185239\n",
      "[Epoch 27/200] [Batch 410/938] loss_G: 2.793914, loss_D: 0.220036\n",
      "[Epoch 27/200] [Batch 420/938] loss_G: 3.490593, loss_D: 0.130543\n",
      "[Epoch 27/200] [Batch 430/938] loss_G: 2.911584, loss_D: 0.222779\n",
      "[Epoch 27/200] [Batch 440/938] loss_G: 3.068460, loss_D: 0.155700\n",
      "[Epoch 27/200] [Batch 450/938] loss_G: 3.121213, loss_D: 0.216656\n",
      "[Epoch 27/200] [Batch 460/938] loss_G: 2.676498, loss_D: 0.193009\n",
      "[Epoch 27/200] [Batch 470/938] loss_G: 3.197851, loss_D: 0.200539\n",
      "[Epoch 27/200] [Batch 480/938] loss_G: 3.357494, loss_D: 0.095495\n",
      "[Epoch 27/200] [Batch 490/938] loss_G: 2.676733, loss_D: 0.245825\n",
      "[Epoch 27/200] [Batch 500/938] loss_G: 3.087298, loss_D: 0.168404\n",
      "[Epoch 27/200] [Batch 510/938] loss_G: 2.287959, loss_D: 0.324873\n",
      "[Epoch 27/200] [Batch 520/938] loss_G: 2.938434, loss_D: 0.193208\n",
      "[Epoch 27/200] [Batch 530/938] loss_G: 3.214352, loss_D: 0.125914\n",
      "[Epoch 27/200] [Batch 540/938] loss_G: 2.487994, loss_D: 0.223896\n",
      "[Epoch 27/200] [Batch 550/938] loss_G: 3.063240, loss_D: 0.231055\n",
      "[Epoch 27/200] [Batch 560/938] loss_G: 2.624707, loss_D: 0.207497\n",
      "[Epoch 27/200] [Batch 570/938] loss_G: 2.837005, loss_D: 0.204582\n",
      "[Epoch 27/200] [Batch 580/938] loss_G: 2.569969, loss_D: 0.212942\n",
      "[Epoch 27/200] [Batch 590/938] loss_G: 3.196050, loss_D: 0.184293\n",
      "[Epoch 27/200] [Batch 600/938] loss_G: 3.328118, loss_D: 0.108335\n",
      "[Epoch 27/200] [Batch 610/938] loss_G: 2.947850, loss_D: 0.203697\n",
      "[Epoch 27/200] [Batch 620/938] loss_G: 2.457356, loss_D: 0.364950\n",
      "[Epoch 27/200] [Batch 630/938] loss_G: 3.489305, loss_D: 0.229410\n",
      "[Epoch 27/200] [Batch 640/938] loss_G: 2.695659, loss_D: 0.159025\n",
      "[Epoch 27/200] [Batch 650/938] loss_G: 3.063542, loss_D: 0.282323\n",
      "[Epoch 27/200] [Batch 660/938] loss_G: 3.030392, loss_D: 0.271202\n",
      "[Epoch 27/200] [Batch 670/938] loss_G: 2.942798, loss_D: 0.215782\n",
      "[Epoch 27/200] [Batch 680/938] loss_G: 2.655228, loss_D: 0.244545\n",
      "[Epoch 27/200] [Batch 690/938] loss_G: 2.941864, loss_D: 0.219184\n",
      "[Epoch 27/200] [Batch 700/938] loss_G: 2.575046, loss_D: 0.271669\n",
      "[Epoch 27/200] [Batch 710/938] loss_G: 3.515924, loss_D: 0.253711\n",
      "[Epoch 27/200] [Batch 720/938] loss_G: 3.108248, loss_D: 0.217446\n",
      "[Epoch 27/200] [Batch 730/938] loss_G: 2.774192, loss_D: 0.268900\n",
      "[Epoch 27/200] [Batch 740/938] loss_G: 2.713902, loss_D: 0.183559\n",
      "[Epoch 27/200] [Batch 750/938] loss_G: 3.097174, loss_D: 0.206005\n",
      "[Epoch 27/200] [Batch 760/938] loss_G: 3.013563, loss_D: 0.178068\n",
      "[Epoch 27/200] [Batch 770/938] loss_G: 2.767073, loss_D: 0.196541\n",
      "[Epoch 27/200] [Batch 780/938] loss_G: 3.016865, loss_D: 0.191649\n",
      "[Epoch 27/200] [Batch 790/938] loss_G: 2.590645, loss_D: 0.233376\n",
      "[Epoch 27/200] [Batch 800/938] loss_G: 3.233622, loss_D: 0.258408\n",
      "[Epoch 27/200] [Batch 810/938] loss_G: 2.953085, loss_D: 0.180156\n",
      "[Epoch 27/200] [Batch 820/938] loss_G: 2.829714, loss_D: 0.262456\n",
      "[Epoch 27/200] [Batch 830/938] loss_G: 3.148727, loss_D: 0.269257\n",
      "[Epoch 27/200] [Batch 840/938] loss_G: 2.952684, loss_D: 0.223019\n",
      "[Epoch 27/200] [Batch 850/938] loss_G: 2.723374, loss_D: 0.176435\n",
      "[Epoch 27/200] [Batch 860/938] loss_G: 3.348029, loss_D: 0.154148\n",
      "[Epoch 27/200] [Batch 870/938] loss_G: 2.630674, loss_D: 0.283161\n",
      "[Epoch 27/200] [Batch 880/938] loss_G: 2.876690, loss_D: 0.218918\n",
      "[Epoch 27/200] [Batch 890/938] loss_G: 2.625474, loss_D: 0.234187\n",
      "[Epoch 27/200] [Batch 900/938] loss_G: 3.099115, loss_D: 0.281834\n",
      "[Epoch 27/200] [Batch 910/938] loss_G: 2.955529, loss_D: 0.188493\n",
      "[Epoch 27/200] [Batch 920/938] loss_G: 3.242030, loss_D: 0.189585\n",
      "[Epoch 27/200] [Batch 930/938] loss_G: 2.902199, loss_D: 0.206486\n",
      "[Epoch 28/200] [Batch 0/938] loss_G: 2.685397, loss_D: 0.225670\n",
      "[Epoch 28/200] [Batch 10/938] loss_G: 3.177973, loss_D: 0.162432\n",
      "[Epoch 28/200] [Batch 20/938] loss_G: 2.956452, loss_D: 0.271060\n",
      "[Epoch 28/200] [Batch 30/938] loss_G: 3.048887, loss_D: 0.176732\n",
      "[Epoch 28/200] [Batch 40/938] loss_G: 2.235959, loss_D: 0.271103\n",
      "[Epoch 28/200] [Batch 50/938] loss_G: 2.803469, loss_D: 0.215742\n",
      "[Epoch 28/200] [Batch 60/938] loss_G: 2.834399, loss_D: 0.237005\n",
      "[Epoch 28/200] [Batch 70/938] loss_G: 2.711186, loss_D: 0.265127\n",
      "[Epoch 28/200] [Batch 80/938] loss_G: 2.815895, loss_D: 0.174990\n",
      "[Epoch 28/200] [Batch 90/938] loss_G: 2.828300, loss_D: 0.295769\n",
      "[Epoch 28/200] [Batch 100/938] loss_G: 3.112997, loss_D: 0.167319\n",
      "[Epoch 28/200] [Batch 110/938] loss_G: 3.324483, loss_D: 0.212637\n",
      "[Epoch 28/200] [Batch 120/938] loss_G: 3.125329, loss_D: 0.159310\n",
      "[Epoch 28/200] [Batch 130/938] loss_G: 3.003206, loss_D: 0.162796\n",
      "[Epoch 28/200] [Batch 140/938] loss_G: 3.523675, loss_D: 0.120385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28/200] [Batch 150/938] loss_G: 2.748533, loss_D: 0.223666\n",
      "[Epoch 28/200] [Batch 160/938] loss_G: 2.295841, loss_D: 0.321524\n",
      "[Epoch 28/200] [Batch 170/938] loss_G: 3.148097, loss_D: 0.242015\n",
      "[Epoch 28/200] [Batch 180/938] loss_G: 2.644356, loss_D: 0.246337\n",
      "[Epoch 28/200] [Batch 190/938] loss_G: 2.746782, loss_D: 0.204219\n",
      "[Epoch 28/200] [Batch 200/938] loss_G: 2.908289, loss_D: 0.237572\n",
      "[Epoch 28/200] [Batch 210/938] loss_G: 3.184562, loss_D: 0.246243\n",
      "[Epoch 28/200] [Batch 220/938] loss_G: 2.932584, loss_D: 0.260997\n",
      "[Epoch 28/200] [Batch 230/938] loss_G: 2.353722, loss_D: 0.322602\n",
      "[Epoch 28/200] [Batch 240/938] loss_G: 2.569073, loss_D: 0.197314\n",
      "[Epoch 28/200] [Batch 250/938] loss_G: 2.558690, loss_D: 0.244954\n",
      "[Epoch 28/200] [Batch 260/938] loss_G: 2.935399, loss_D: 0.192873\n",
      "[Epoch 28/200] [Batch 270/938] loss_G: 2.745722, loss_D: 0.235483\n",
      "[Epoch 28/200] [Batch 280/938] loss_G: 2.662150, loss_D: 0.308062\n",
      "[Epoch 28/200] [Batch 290/938] loss_G: 2.341698, loss_D: 0.280218\n",
      "[Epoch 28/200] [Batch 300/938] loss_G: 3.037732, loss_D: 0.174927\n",
      "[Epoch 28/200] [Batch 310/938] loss_G: 3.276087, loss_D: 0.150661\n",
      "[Epoch 28/200] [Batch 320/938] loss_G: 2.685544, loss_D: 0.183934\n",
      "[Epoch 28/200] [Batch 330/938] loss_G: 2.927245, loss_D: 0.164428\n",
      "[Epoch 28/200] [Batch 340/938] loss_G: 2.903533, loss_D: 0.195524\n",
      "[Epoch 28/200] [Batch 350/938] loss_G: 2.711470, loss_D: 0.232008\n",
      "[Epoch 28/200] [Batch 360/938] loss_G: 2.959119, loss_D: 0.179911\n",
      "[Epoch 28/200] [Batch 370/938] loss_G: 3.192353, loss_D: 0.209834\n",
      "[Epoch 28/200] [Batch 380/938] loss_G: 2.822848, loss_D: 0.225241\n",
      "[Epoch 28/200] [Batch 390/938] loss_G: 2.832960, loss_D: 0.273668\n",
      "[Epoch 28/200] [Batch 400/938] loss_G: 2.917202, loss_D: 0.202605\n",
      "[Epoch 28/200] [Batch 410/938] loss_G: 2.852069, loss_D: 0.254175\n",
      "[Epoch 28/200] [Batch 420/938] loss_G: 3.520286, loss_D: 0.183692\n",
      "[Epoch 28/200] [Batch 430/938] loss_G: 2.766507, loss_D: 0.199496\n",
      "[Epoch 28/200] [Batch 440/938] loss_G: 3.377623, loss_D: 0.263589\n",
      "[Epoch 28/200] [Batch 450/938] loss_G: 3.042512, loss_D: 0.202519\n",
      "[Epoch 28/200] [Batch 460/938] loss_G: 2.635176, loss_D: 0.247678\n",
      "[Epoch 28/200] [Batch 470/938] loss_G: 3.480188, loss_D: 0.219274\n",
      "[Epoch 28/200] [Batch 480/938] loss_G: 2.323390, loss_D: 0.258555\n",
      "[Epoch 28/200] [Batch 490/938] loss_G: 2.871965, loss_D: 0.314975\n",
      "[Epoch 28/200] [Batch 500/938] loss_G: 2.718842, loss_D: 0.292227\n",
      "[Epoch 28/200] [Batch 510/938] loss_G: 2.674126, loss_D: 0.346139\n",
      "[Epoch 28/200] [Batch 520/938] loss_G: 2.981424, loss_D: 0.205714\n",
      "[Epoch 28/200] [Batch 530/938] loss_G: 2.951587, loss_D: 0.224563\n",
      "[Epoch 28/200] [Batch 540/938] loss_G: 2.950585, loss_D: 0.233290\n",
      "[Epoch 28/200] [Batch 550/938] loss_G: 2.995942, loss_D: 0.237641\n",
      "[Epoch 28/200] [Batch 560/938] loss_G: 2.915517, loss_D: 0.175431\n",
      "[Epoch 28/200] [Batch 570/938] loss_G: 3.072604, loss_D: 0.217177\n",
      "[Epoch 28/200] [Batch 580/938] loss_G: 2.727208, loss_D: 0.177818\n",
      "[Epoch 28/200] [Batch 590/938] loss_G: 2.777952, loss_D: 0.202020\n",
      "[Epoch 28/200] [Batch 600/938] loss_G: 2.680285, loss_D: 0.272709\n",
      "[Epoch 28/200] [Batch 610/938] loss_G: 3.052121, loss_D: 0.227233\n",
      "[Epoch 28/200] [Batch 620/938] loss_G: 2.704426, loss_D: 0.189951\n",
      "[Epoch 28/200] [Batch 630/938] loss_G: 2.821458, loss_D: 0.229898\n",
      "[Epoch 28/200] [Batch 640/938] loss_G: 2.952854, loss_D: 0.199859\n",
      "[Epoch 28/200] [Batch 650/938] loss_G: 3.150168, loss_D: 0.271034\n",
      "[Epoch 28/200] [Batch 660/938] loss_G: 3.268428, loss_D: 0.121628\n",
      "[Epoch 28/200] [Batch 670/938] loss_G: 2.894371, loss_D: 0.146661\n",
      "[Epoch 28/200] [Batch 680/938] loss_G: 2.889662, loss_D: 0.175471\n",
      "[Epoch 28/200] [Batch 690/938] loss_G: 3.287494, loss_D: 0.209275\n",
      "[Epoch 28/200] [Batch 700/938] loss_G: 3.474114, loss_D: 0.202695\n",
      "[Epoch 28/200] [Batch 710/938] loss_G: 3.106872, loss_D: 0.202728\n",
      "[Epoch 28/200] [Batch 720/938] loss_G: 3.026534, loss_D: 0.210316\n",
      "[Epoch 28/200] [Batch 730/938] loss_G: 3.136158, loss_D: 0.190585\n",
      "[Epoch 28/200] [Batch 740/938] loss_G: 3.283626, loss_D: 0.205339\n",
      "[Epoch 28/200] [Batch 750/938] loss_G: 2.895101, loss_D: 0.232058\n",
      "[Epoch 28/200] [Batch 760/938] loss_G: 3.318240, loss_D: 0.183901\n",
      "[Epoch 28/200] [Batch 770/938] loss_G: 3.255444, loss_D: 0.238217\n",
      "[Epoch 28/200] [Batch 780/938] loss_G: 3.531082, loss_D: 0.231128\n",
      "[Epoch 28/200] [Batch 790/938] loss_G: 2.943326, loss_D: 0.229422\n",
      "[Epoch 28/200] [Batch 800/938] loss_G: 2.955683, loss_D: 0.217201\n",
      "[Epoch 28/200] [Batch 810/938] loss_G: 2.902290, loss_D: 0.224723\n",
      "[Epoch 28/200] [Batch 820/938] loss_G: 2.457726, loss_D: 0.260733\n",
      "[Epoch 28/200] [Batch 830/938] loss_G: 3.133297, loss_D: 0.361026\n",
      "[Epoch 28/200] [Batch 840/938] loss_G: 3.046293, loss_D: 0.216971\n",
      "[Epoch 28/200] [Batch 850/938] loss_G: 2.981736, loss_D: 0.232397\n",
      "[Epoch 28/200] [Batch 860/938] loss_G: 3.566479, loss_D: 0.165103\n",
      "[Epoch 28/200] [Batch 870/938] loss_G: 2.624661, loss_D: 0.262160\n",
      "[Epoch 28/200] [Batch 880/938] loss_G: 3.257260, loss_D: 0.203429\n",
      "[Epoch 28/200] [Batch 890/938] loss_G: 2.253356, loss_D: 0.232154\n",
      "[Epoch 28/200] [Batch 900/938] loss_G: 2.484749, loss_D: 0.306566\n",
      "[Epoch 28/200] [Batch 910/938] loss_G: 3.150751, loss_D: 0.269340\n",
      "[Epoch 28/200] [Batch 920/938] loss_G: 2.995333, loss_D: 0.187014\n",
      "[Epoch 28/200] [Batch 930/938] loss_G: 3.134929, loss_D: 0.199503\n",
      "[Epoch 29/200] [Batch 0/938] loss_G: 2.521509, loss_D: 0.228513\n",
      "[Epoch 29/200] [Batch 10/938] loss_G: 3.063130, loss_D: 0.300048\n",
      "[Epoch 29/200] [Batch 20/938] loss_G: 3.082594, loss_D: 0.193693\n",
      "[Epoch 29/200] [Batch 30/938] loss_G: 2.696150, loss_D: 0.205357\n",
      "[Epoch 29/200] [Batch 40/938] loss_G: 2.805203, loss_D: 0.272477\n",
      "[Epoch 29/200] [Batch 50/938] loss_G: 2.308808, loss_D: 0.304054\n",
      "[Epoch 29/200] [Batch 60/938] loss_G: 3.075618, loss_D: 0.242326\n",
      "[Epoch 29/200] [Batch 70/938] loss_G: 2.885540, loss_D: 0.206169\n",
      "[Epoch 29/200] [Batch 80/938] loss_G: 2.261944, loss_D: 0.244871\n",
      "[Epoch 29/200] [Batch 90/938] loss_G: 2.758652, loss_D: 0.233439\n",
      "[Epoch 29/200] [Batch 100/938] loss_G: 2.820542, loss_D: 0.181658\n",
      "[Epoch 29/200] [Batch 110/938] loss_G: 2.588051, loss_D: 0.246792\n",
      "[Epoch 29/200] [Batch 120/938] loss_G: 2.940580, loss_D: 0.244216\n",
      "[Epoch 29/200] [Batch 130/938] loss_G: 2.604358, loss_D: 0.213296\n",
      "[Epoch 29/200] [Batch 140/938] loss_G: 3.253481, loss_D: 0.254305\n",
      "[Epoch 29/200] [Batch 150/938] loss_G: 2.983393, loss_D: 0.192752\n",
      "[Epoch 29/200] [Batch 160/938] loss_G: 2.981166, loss_D: 0.213966\n",
      "[Epoch 29/200] [Batch 170/938] loss_G: 2.849708, loss_D: 0.224453\n",
      "[Epoch 29/200] [Batch 180/938] loss_G: 2.367017, loss_D: 0.237605\n",
      "[Epoch 29/200] [Batch 190/938] loss_G: 2.710968, loss_D: 0.160143\n",
      "[Epoch 29/200] [Batch 200/938] loss_G: 2.382947, loss_D: 0.331665\n",
      "[Epoch 29/200] [Batch 210/938] loss_G: 3.660651, loss_D: 0.174395\n",
      "[Epoch 29/200] [Batch 220/938] loss_G: 3.055527, loss_D: 0.226540\n",
      "[Epoch 29/200] [Batch 230/938] loss_G: 2.995905, loss_D: 0.187805\n",
      "[Epoch 29/200] [Batch 240/938] loss_G: 3.032668, loss_D: 0.217678\n",
      "[Epoch 29/200] [Batch 250/938] loss_G: 2.772137, loss_D: 0.199255\n",
      "[Epoch 29/200] [Batch 260/938] loss_G: 3.184758, loss_D: 0.223024\n",
      "[Epoch 29/200] [Batch 270/938] loss_G: 2.457762, loss_D: 0.388406\n",
      "[Epoch 29/200] [Batch 280/938] loss_G: 2.585597, loss_D: 0.224427\n",
      "[Epoch 29/200] [Batch 290/938] loss_G: 2.847553, loss_D: 0.195547\n",
      "[Epoch 29/200] [Batch 300/938] loss_G: 3.515677, loss_D: 0.258534\n",
      "[Epoch 29/200] [Batch 310/938] loss_G: 2.572093, loss_D: 0.238000\n",
      "[Epoch 29/200] [Batch 320/938] loss_G: 2.233424, loss_D: 0.229391\n",
      "[Epoch 29/200] [Batch 330/938] loss_G: 3.317779, loss_D: 0.199334\n",
      "[Epoch 29/200] [Batch 340/938] loss_G: 3.376323, loss_D: 0.157786\n",
      "[Epoch 29/200] [Batch 350/938] loss_G: 2.801145, loss_D: 0.289693\n",
      "[Epoch 29/200] [Batch 360/938] loss_G: 3.374849, loss_D: 0.370121\n",
      "[Epoch 29/200] [Batch 370/938] loss_G: 2.719132, loss_D: 0.268619\n",
      "[Epoch 29/200] [Batch 380/938] loss_G: 3.357445, loss_D: 0.162110\n",
      "[Epoch 29/200] [Batch 390/938] loss_G: 2.838037, loss_D: 0.216712\n",
      "[Epoch 29/200] [Batch 400/938] loss_G: 3.262107, loss_D: 0.159543\n",
      "[Epoch 29/200] [Batch 410/938] loss_G: 2.958594, loss_D: 0.242302\n",
      "[Epoch 29/200] [Batch 420/938] loss_G: 3.727843, loss_D: 0.194609\n",
      "[Epoch 29/200] [Batch 430/938] loss_G: 2.208808, loss_D: 0.179674\n",
      "[Epoch 29/200] [Batch 440/938] loss_G: 2.841830, loss_D: 0.315060\n",
      "[Epoch 29/200] [Batch 450/938] loss_G: 2.703915, loss_D: 0.295127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29/200] [Batch 460/938] loss_G: 2.627713, loss_D: 0.289885\n",
      "[Epoch 29/200] [Batch 470/938] loss_G: 3.558956, loss_D: 0.193529\n",
      "[Epoch 29/200] [Batch 480/938] loss_G: 3.002120, loss_D: 0.186178\n",
      "[Epoch 29/200] [Batch 490/938] loss_G: 2.726477, loss_D: 0.241011\n",
      "[Epoch 29/200] [Batch 500/938] loss_G: 3.024873, loss_D: 0.190167\n",
      "[Epoch 29/200] [Batch 510/938] loss_G: 2.577548, loss_D: 0.300578\n",
      "[Epoch 29/200] [Batch 520/938] loss_G: 2.968440, loss_D: 0.224155\n",
      "[Epoch 29/200] [Batch 530/938] loss_G: 2.698305, loss_D: 0.220802\n",
      "[Epoch 29/200] [Batch 540/938] loss_G: 3.293560, loss_D: 0.260827\n",
      "[Epoch 29/200] [Batch 550/938] loss_G: 2.684623, loss_D: 0.229398\n",
      "[Epoch 29/200] [Batch 560/938] loss_G: 2.927305, loss_D: 0.244542\n",
      "[Epoch 29/200] [Batch 570/938] loss_G: 3.082390, loss_D: 0.205880\n",
      "[Epoch 29/200] [Batch 580/938] loss_G: 3.120757, loss_D: 0.217227\n",
      "[Epoch 29/200] [Batch 590/938] loss_G: 2.835092, loss_D: 0.161728\n",
      "[Epoch 29/200] [Batch 600/938] loss_G: 2.754769, loss_D: 0.182223\n",
      "[Epoch 29/200] [Batch 610/938] loss_G: 3.176860, loss_D: 0.172874\n",
      "[Epoch 29/200] [Batch 620/938] loss_G: 2.695008, loss_D: 0.249809\n",
      "[Epoch 29/200] [Batch 630/938] loss_G: 2.201580, loss_D: 0.260670\n",
      "[Epoch 29/200] [Batch 640/938] loss_G: 2.834861, loss_D: 0.212627\n",
      "[Epoch 29/200] [Batch 650/938] loss_G: 2.979557, loss_D: 0.212714\n",
      "[Epoch 29/200] [Batch 660/938] loss_G: 3.231815, loss_D: 0.191412\n",
      "[Epoch 29/200] [Batch 670/938] loss_G: 2.563517, loss_D: 0.269079\n",
      "[Epoch 29/200] [Batch 680/938] loss_G: 3.132988, loss_D: 0.262972\n",
      "[Epoch 29/200] [Batch 690/938] loss_G: 2.805144, loss_D: 0.154013\n",
      "[Epoch 29/200] [Batch 700/938] loss_G: 2.708447, loss_D: 0.200243\n",
      "[Epoch 29/200] [Batch 710/938] loss_G: 2.790407, loss_D: 0.259190\n",
      "[Epoch 29/200] [Batch 720/938] loss_G: 2.825360, loss_D: 0.289502\n",
      "[Epoch 29/200] [Batch 730/938] loss_G: 2.888770, loss_D: 0.200575\n",
      "[Epoch 29/200] [Batch 740/938] loss_G: 3.060338, loss_D: 0.157965\n",
      "[Epoch 29/200] [Batch 750/938] loss_G: 2.389925, loss_D: 0.228408\n",
      "[Epoch 29/200] [Batch 760/938] loss_G: 2.916517, loss_D: 0.230820\n",
      "[Epoch 29/200] [Batch 770/938] loss_G: 2.798477, loss_D: 0.230829\n",
      "[Epoch 29/200] [Batch 780/938] loss_G: 2.520544, loss_D: 0.221741\n",
      "[Epoch 29/200] [Batch 790/938] loss_G: 3.069092, loss_D: 0.166675\n",
      "[Epoch 29/200] [Batch 800/938] loss_G: 3.091813, loss_D: 0.186133\n",
      "[Epoch 29/200] [Batch 810/938] loss_G: 2.612914, loss_D: 0.216418\n",
      "[Epoch 29/200] [Batch 820/938] loss_G: 2.883745, loss_D: 0.164919\n",
      "[Epoch 29/200] [Batch 830/938] loss_G: 2.782018, loss_D: 0.307353\n",
      "[Epoch 29/200] [Batch 840/938] loss_G: 3.047175, loss_D: 0.172872\n",
      "[Epoch 29/200] [Batch 850/938] loss_G: 3.220540, loss_D: 0.199439\n",
      "[Epoch 29/200] [Batch 860/938] loss_G: 2.974481, loss_D: 0.204835\n",
      "[Epoch 29/200] [Batch 870/938] loss_G: 3.241809, loss_D: 0.241020\n",
      "[Epoch 29/200] [Batch 880/938] loss_G: 2.916541, loss_D: 0.234899\n",
      "[Epoch 29/200] [Batch 890/938] loss_G: 2.725605, loss_D: 0.255667\n",
      "[Epoch 29/200] [Batch 900/938] loss_G: 2.282848, loss_D: 0.302505\n",
      "[Epoch 29/200] [Batch 910/938] loss_G: 3.382982, loss_D: 0.194845\n",
      "[Epoch 29/200] [Batch 920/938] loss_G: 2.788651, loss_D: 0.264766\n",
      "[Epoch 29/200] [Batch 930/938] loss_G: 3.232880, loss_D: 0.166715\n",
      "[Epoch 30/200] [Batch 0/938] loss_G: 2.829618, loss_D: 0.304077\n",
      "[Epoch 30/200] [Batch 10/938] loss_G: 3.127383, loss_D: 0.119317\n",
      "[Epoch 30/200] [Batch 20/938] loss_G: 2.577492, loss_D: 0.269398\n",
      "[Epoch 30/200] [Batch 30/938] loss_G: 2.907494, loss_D: 0.283484\n",
      "[Epoch 30/200] [Batch 40/938] loss_G: 2.410035, loss_D: 0.231891\n",
      "[Epoch 30/200] [Batch 50/938] loss_G: 3.421160, loss_D: 0.205564\n",
      "[Epoch 30/200] [Batch 60/938] loss_G: 2.896266, loss_D: 0.188573\n",
      "[Epoch 30/200] [Batch 70/938] loss_G: 2.833456, loss_D: 0.238848\n",
      "[Epoch 30/200] [Batch 80/938] loss_G: 3.367139, loss_D: 0.172386\n",
      "[Epoch 30/200] [Batch 90/938] loss_G: 2.863219, loss_D: 0.146427\n",
      "[Epoch 30/200] [Batch 100/938] loss_G: 3.081707, loss_D: 0.219458\n",
      "[Epoch 30/200] [Batch 110/938] loss_G: 2.829201, loss_D: 0.215152\n",
      "[Epoch 30/200] [Batch 120/938] loss_G: 2.923332, loss_D: 0.246843\n",
      "[Epoch 30/200] [Batch 130/938] loss_G: 3.139534, loss_D: 0.186036\n",
      "[Epoch 30/200] [Batch 140/938] loss_G: 3.003747, loss_D: 0.192759\n",
      "[Epoch 30/200] [Batch 150/938] loss_G: 2.565081, loss_D: 0.184621\n",
      "[Epoch 30/200] [Batch 160/938] loss_G: 2.780285, loss_D: 0.205978\n",
      "[Epoch 30/200] [Batch 170/938] loss_G: 2.787024, loss_D: 0.215500\n",
      "[Epoch 30/200] [Batch 180/938] loss_G: 3.040872, loss_D: 0.175373\n",
      "[Epoch 30/200] [Batch 190/938] loss_G: 2.476476, loss_D: 0.294552\n",
      "[Epoch 30/200] [Batch 200/938] loss_G: 2.576606, loss_D: 0.252783\n",
      "[Epoch 30/200] [Batch 210/938] loss_G: 2.903744, loss_D: 0.203596\n",
      "[Epoch 30/200] [Batch 220/938] loss_G: 3.313190, loss_D: 0.194358\n",
      "[Epoch 30/200] [Batch 230/938] loss_G: 2.530825, loss_D: 0.201315\n",
      "[Epoch 30/200] [Batch 240/938] loss_G: 3.105024, loss_D: 0.186095\n",
      "[Epoch 30/200] [Batch 250/938] loss_G: 2.475205, loss_D: 0.302293\n",
      "[Epoch 30/200] [Batch 260/938] loss_G: 2.924280, loss_D: 0.231825\n",
      "[Epoch 30/200] [Batch 270/938] loss_G: 2.449184, loss_D: 0.209228\n",
      "[Epoch 30/200] [Batch 280/938] loss_G: 2.713174, loss_D: 0.218732\n",
      "[Epoch 30/200] [Batch 290/938] loss_G: 2.548766, loss_D: 0.224446\n",
      "[Epoch 30/200] [Batch 300/938] loss_G: 2.803180, loss_D: 0.188877\n",
      "[Epoch 30/200] [Batch 310/938] loss_G: 3.169945, loss_D: 0.311969\n",
      "[Epoch 30/200] [Batch 320/938] loss_G: 3.054708, loss_D: 0.238564\n",
      "[Epoch 30/200] [Batch 330/938] loss_G: 2.666053, loss_D: 0.334034\n",
      "[Epoch 30/200] [Batch 340/938] loss_G: 2.596998, loss_D: 0.250017\n",
      "[Epoch 30/200] [Batch 350/938] loss_G: 2.397366, loss_D: 0.245783\n",
      "[Epoch 30/200] [Batch 360/938] loss_G: 2.799935, loss_D: 0.265155\n",
      "[Epoch 30/200] [Batch 370/938] loss_G: 3.207474, loss_D: 0.195570\n",
      "[Epoch 30/200] [Batch 380/938] loss_G: 3.288650, loss_D: 0.209028\n",
      "[Epoch 30/200] [Batch 390/938] loss_G: 2.807600, loss_D: 0.210970\n",
      "[Epoch 30/200] [Batch 400/938] loss_G: 3.127561, loss_D: 0.245456\n",
      "[Epoch 30/200] [Batch 410/938] loss_G: 2.666897, loss_D: 0.339490\n",
      "[Epoch 30/200] [Batch 420/938] loss_G: 2.566285, loss_D: 0.191000\n",
      "[Epoch 30/200] [Batch 430/938] loss_G: 3.212256, loss_D: 0.149553\n",
      "[Epoch 30/200] [Batch 440/938] loss_G: 3.512856, loss_D: 0.201471\n",
      "[Epoch 30/200] [Batch 450/938] loss_G: 3.004293, loss_D: 0.192125\n",
      "[Epoch 30/200] [Batch 460/938] loss_G: 3.066492, loss_D: 0.300304\n",
      "[Epoch 30/200] [Batch 470/938] loss_G: 3.008223, loss_D: 0.204310\n",
      "[Epoch 30/200] [Batch 480/938] loss_G: 3.159611, loss_D: 0.155188\n",
      "[Epoch 30/200] [Batch 490/938] loss_G: 2.674396, loss_D: 0.283349\n",
      "[Epoch 30/200] [Batch 500/938] loss_G: 2.822758, loss_D: 0.157577\n",
      "[Epoch 30/200] [Batch 510/938] loss_G: 3.009617, loss_D: 0.174455\n",
      "[Epoch 30/200] [Batch 520/938] loss_G: 2.854660, loss_D: 0.227336\n",
      "[Epoch 30/200] [Batch 530/938] loss_G: 2.966816, loss_D: 0.217235\n",
      "[Epoch 30/200] [Batch 540/938] loss_G: 3.011150, loss_D: 0.206010\n",
      "[Epoch 30/200] [Batch 550/938] loss_G: 2.611858, loss_D: 0.264494\n",
      "[Epoch 30/200] [Batch 560/938] loss_G: 2.489442, loss_D: 0.283161\n",
      "[Epoch 30/200] [Batch 570/938] loss_G: 3.167534, loss_D: 0.219696\n",
      "[Epoch 30/200] [Batch 580/938] loss_G: 2.674418, loss_D: 0.249461\n",
      "[Epoch 30/200] [Batch 590/938] loss_G: 3.381080, loss_D: 0.200930\n",
      "[Epoch 30/200] [Batch 600/938] loss_G: 2.867052, loss_D: 0.207294\n",
      "[Epoch 30/200] [Batch 610/938] loss_G: 3.365792, loss_D: 0.214728\n",
      "[Epoch 30/200] [Batch 620/938] loss_G: 2.977492, loss_D: 0.230765\n",
      "[Epoch 30/200] [Batch 630/938] loss_G: 3.917123, loss_D: 0.105699\n",
      "[Epoch 30/200] [Batch 640/938] loss_G: 3.056211, loss_D: 0.128489\n",
      "[Epoch 30/200] [Batch 650/938] loss_G: 2.943390, loss_D: 0.264661\n",
      "[Epoch 30/200] [Batch 660/938] loss_G: 2.996938, loss_D: 0.199819\n",
      "[Epoch 30/200] [Batch 670/938] loss_G: 2.966190, loss_D: 0.228434\n",
      "[Epoch 30/200] [Batch 680/938] loss_G: 3.032167, loss_D: 0.175706\n",
      "[Epoch 30/200] [Batch 690/938] loss_G: 2.875630, loss_D: 0.233279\n",
      "[Epoch 30/200] [Batch 700/938] loss_G: 3.491872, loss_D: 0.220720\n",
      "[Epoch 30/200] [Batch 710/938] loss_G: 3.080383, loss_D: 0.199681\n",
      "[Epoch 30/200] [Batch 720/938] loss_G: 2.962393, loss_D: 0.180260\n",
      "[Epoch 30/200] [Batch 730/938] loss_G: 2.942803, loss_D: 0.206382\n",
      "[Epoch 30/200] [Batch 740/938] loss_G: 2.439522, loss_D: 0.234609\n",
      "[Epoch 30/200] [Batch 750/938] loss_G: 2.876427, loss_D: 0.244426\n",
      "[Epoch 30/200] [Batch 760/938] loss_G: 2.773819, loss_D: 0.329210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30/200] [Batch 770/938] loss_G: 2.527690, loss_D: 0.273713\n",
      "[Epoch 30/200] [Batch 780/938] loss_G: 2.835059, loss_D: 0.220025\n",
      "[Epoch 30/200] [Batch 790/938] loss_G: 2.655597, loss_D: 0.218376\n",
      "[Epoch 30/200] [Batch 800/938] loss_G: 2.834586, loss_D: 0.375366\n",
      "[Epoch 30/200] [Batch 810/938] loss_G: 3.032706, loss_D: 0.240705\n",
      "[Epoch 30/200] [Batch 820/938] loss_G: 3.226283, loss_D: 0.141317\n",
      "[Epoch 30/200] [Batch 830/938] loss_G: 2.856019, loss_D: 0.155448\n",
      "[Epoch 30/200] [Batch 840/938] loss_G: 2.658917, loss_D: 0.327738\n",
      "[Epoch 30/200] [Batch 850/938] loss_G: 2.460585, loss_D: 0.327878\n",
      "[Epoch 30/200] [Batch 860/938] loss_G: 3.302546, loss_D: 0.249079\n",
      "[Epoch 30/200] [Batch 870/938] loss_G: 2.585501, loss_D: 0.179379\n",
      "[Epoch 30/200] [Batch 880/938] loss_G: 2.646244, loss_D: 0.180901\n",
      "[Epoch 30/200] [Batch 890/938] loss_G: 2.603447, loss_D: 0.208867\n",
      "[Epoch 30/200] [Batch 900/938] loss_G: 2.797356, loss_D: 0.238010\n",
      "[Epoch 30/200] [Batch 910/938] loss_G: 3.087286, loss_D: 0.148483\n",
      "[Epoch 30/200] [Batch 920/938] loss_G: 3.264215, loss_D: 0.205753\n",
      "[Epoch 30/200] [Batch 930/938] loss_G: 3.145881, loss_D: 0.166169\n",
      "[Epoch 31/200] [Batch 0/938] loss_G: 2.832351, loss_D: 0.194709\n",
      "[Epoch 31/200] [Batch 10/938] loss_G: 2.755826, loss_D: 0.316904\n",
      "[Epoch 31/200] [Batch 20/938] loss_G: 2.680656, loss_D: 0.257969\n",
      "[Epoch 31/200] [Batch 30/938] loss_G: 2.708506, loss_D: 0.172609\n",
      "[Epoch 31/200] [Batch 40/938] loss_G: 2.422520, loss_D: 0.306318\n",
      "[Epoch 31/200] [Batch 50/938] loss_G: 2.965510, loss_D: 0.223751\n",
      "[Epoch 31/200] [Batch 60/938] loss_G: 2.686594, loss_D: 0.263375\n",
      "[Epoch 31/200] [Batch 70/938] loss_G: 2.970307, loss_D: 0.248772\n",
      "[Epoch 31/200] [Batch 80/938] loss_G: 3.162533, loss_D: 0.140168\n",
      "[Epoch 31/200] [Batch 90/938] loss_G: 2.499898, loss_D: 0.323100\n",
      "[Epoch 31/200] [Batch 100/938] loss_G: 2.627433, loss_D: 0.288061\n",
      "[Epoch 31/200] [Batch 110/938] loss_G: 3.037164, loss_D: 0.167726\n",
      "[Epoch 31/200] [Batch 120/938] loss_G: 2.553977, loss_D: 0.171057\n",
      "[Epoch 31/200] [Batch 130/938] loss_G: 2.779415, loss_D: 0.146204\n",
      "[Epoch 31/200] [Batch 140/938] loss_G: 3.165389, loss_D: 0.156744\n",
      "[Epoch 31/200] [Batch 150/938] loss_G: 2.579468, loss_D: 0.230983\n",
      "[Epoch 31/200] [Batch 160/938] loss_G: 2.833071, loss_D: 0.210496\n",
      "[Epoch 31/200] [Batch 170/938] loss_G: 3.002575, loss_D: 0.147758\n",
      "[Epoch 31/200] [Batch 180/938] loss_G: 2.991384, loss_D: 0.199853\n",
      "[Epoch 31/200] [Batch 190/938] loss_G: 3.009961, loss_D: 0.219499\n",
      "[Epoch 31/200] [Batch 200/938] loss_G: 2.997278, loss_D: 0.223954\n",
      "[Epoch 31/200] [Batch 210/938] loss_G: 2.627988, loss_D: 0.296026\n",
      "[Epoch 31/200] [Batch 220/938] loss_G: 2.326642, loss_D: 0.302592\n",
      "[Epoch 31/200] [Batch 230/938] loss_G: 3.196118, loss_D: 0.322587\n",
      "[Epoch 31/200] [Batch 240/938] loss_G: 2.623246, loss_D: 0.279926\n",
      "[Epoch 31/200] [Batch 250/938] loss_G: 2.747020, loss_D: 0.345926\n",
      "[Epoch 31/200] [Batch 260/938] loss_G: 2.041614, loss_D: 0.281811\n",
      "[Epoch 31/200] [Batch 270/938] loss_G: 3.189288, loss_D: 0.227838\n",
      "[Epoch 31/200] [Batch 280/938] loss_G: 2.867328, loss_D: 0.233094\n",
      "[Epoch 31/200] [Batch 290/938] loss_G: 2.830724, loss_D: 0.221661\n",
      "[Epoch 31/200] [Batch 300/938] loss_G: 2.569412, loss_D: 0.269268\n",
      "[Epoch 31/200] [Batch 310/938] loss_G: 3.356518, loss_D: 0.218439\n",
      "[Epoch 31/200] [Batch 320/938] loss_G: 3.067209, loss_D: 0.180571\n",
      "[Epoch 31/200] [Batch 330/938] loss_G: 2.746461, loss_D: 0.222690\n",
      "[Epoch 31/200] [Batch 340/938] loss_G: 2.832157, loss_D: 0.342813\n",
      "[Epoch 31/200] [Batch 350/938] loss_G: 3.104549, loss_D: 0.202782\n",
      "[Epoch 31/200] [Batch 360/938] loss_G: 2.493248, loss_D: 0.193436\n",
      "[Epoch 31/200] [Batch 370/938] loss_G: 2.577248, loss_D: 0.256607\n",
      "[Epoch 31/200] [Batch 380/938] loss_G: 2.798046, loss_D: 0.188800\n",
      "[Epoch 31/200] [Batch 390/938] loss_G: 2.469702, loss_D: 0.262884\n",
      "[Epoch 31/200] [Batch 400/938] loss_G: 2.725044, loss_D: 0.156664\n",
      "[Epoch 31/200] [Batch 410/938] loss_G: 2.892619, loss_D: 0.217449\n",
      "[Epoch 31/200] [Batch 420/938] loss_G: 2.595158, loss_D: 0.228051\n",
      "[Epoch 31/200] [Batch 430/938] loss_G: 2.739253, loss_D: 0.243024\n",
      "[Epoch 31/200] [Batch 440/938] loss_G: 2.861605, loss_D: 0.197820\n",
      "[Epoch 31/200] [Batch 450/938] loss_G: 2.844811, loss_D: 0.160474\n",
      "[Epoch 31/200] [Batch 460/938] loss_G: 2.581520, loss_D: 0.204468\n",
      "[Epoch 31/200] [Batch 470/938] loss_G: 2.693022, loss_D: 0.201780\n",
      "[Epoch 31/200] [Batch 480/938] loss_G: 2.550853, loss_D: 0.227317\n",
      "[Epoch 31/200] [Batch 490/938] loss_G: 3.108082, loss_D: 0.267549\n",
      "[Epoch 31/200] [Batch 500/938] loss_G: 2.637562, loss_D: 0.204341\n",
      "[Epoch 31/200] [Batch 510/938] loss_G: 2.727584, loss_D: 0.208845\n",
      "[Epoch 31/200] [Batch 520/938] loss_G: 2.843761, loss_D: 0.198219\n",
      "[Epoch 31/200] [Batch 530/938] loss_G: 2.653418, loss_D: 0.189398\n",
      "[Epoch 31/200] [Batch 540/938] loss_G: 2.912919, loss_D: 0.171949\n",
      "[Epoch 31/200] [Batch 550/938] loss_G: 2.477579, loss_D: 0.256660\n",
      "[Epoch 31/200] [Batch 560/938] loss_G: 2.628280, loss_D: 0.255877\n",
      "[Epoch 31/200] [Batch 570/938] loss_G: 2.967066, loss_D: 0.126642\n",
      "[Epoch 31/200] [Batch 580/938] loss_G: 2.711038, loss_D: 0.283148\n",
      "[Epoch 31/200] [Batch 590/938] loss_G: 2.662140, loss_D: 0.157424\n",
      "[Epoch 31/200] [Batch 600/938] loss_G: 2.463460, loss_D: 0.282919\n",
      "[Epoch 31/200] [Batch 610/938] loss_G: 2.735646, loss_D: 0.170761\n",
      "[Epoch 31/200] [Batch 620/938] loss_G: 2.897168, loss_D: 0.191923\n",
      "[Epoch 31/200] [Batch 630/938] loss_G: 2.869686, loss_D: 0.175117\n",
      "[Epoch 31/200] [Batch 640/938] loss_G: 2.935454, loss_D: 0.151820\n",
      "[Epoch 31/200] [Batch 650/938] loss_G: 2.833766, loss_D: 0.222352\n",
      "[Epoch 31/200] [Batch 660/938] loss_G: 3.227368, loss_D: 0.191825\n",
      "[Epoch 31/200] [Batch 670/938] loss_G: 2.535874, loss_D: 0.136401\n",
      "[Epoch 31/200] [Batch 680/938] loss_G: 3.211716, loss_D: 0.202153\n",
      "[Epoch 31/200] [Batch 690/938] loss_G: 2.611513, loss_D: 0.171680\n",
      "[Epoch 31/200] [Batch 700/938] loss_G: 2.252351, loss_D: 0.198928\n",
      "[Epoch 31/200] [Batch 710/938] loss_G: 3.190425, loss_D: 0.242133\n",
      "[Epoch 31/200] [Batch 720/938] loss_G: 2.396821, loss_D: 0.220585\n",
      "[Epoch 31/200] [Batch 730/938] loss_G: 2.694476, loss_D: 0.263033\n",
      "[Epoch 31/200] [Batch 740/938] loss_G: 2.500707, loss_D: 0.224655\n",
      "[Epoch 31/200] [Batch 750/938] loss_G: 2.797917, loss_D: 0.251933\n",
      "[Epoch 31/200] [Batch 760/938] loss_G: 2.924347, loss_D: 0.183298\n",
      "[Epoch 31/200] [Batch 770/938] loss_G: 3.213272, loss_D: 0.181421\n",
      "[Epoch 31/200] [Batch 780/938] loss_G: 3.053721, loss_D: 0.205729\n",
      "[Epoch 31/200] [Batch 790/938] loss_G: 2.545347, loss_D: 0.243819\n",
      "[Epoch 31/200] [Batch 800/938] loss_G: 2.783792, loss_D: 0.297468\n",
      "[Epoch 31/200] [Batch 810/938] loss_G: 3.386917, loss_D: 0.237338\n",
      "[Epoch 31/200] [Batch 820/938] loss_G: 3.265582, loss_D: 0.201476\n",
      "[Epoch 31/200] [Batch 830/938] loss_G: 3.142338, loss_D: 0.260609\n",
      "[Epoch 31/200] [Batch 840/938] loss_G: 2.417243, loss_D: 0.262294\n",
      "[Epoch 31/200] [Batch 850/938] loss_G: 2.707901, loss_D: 0.305134\n",
      "[Epoch 31/200] [Batch 860/938] loss_G: 2.962253, loss_D: 0.327781\n",
      "[Epoch 31/200] [Batch 870/938] loss_G: 2.443564, loss_D: 0.247638\n",
      "[Epoch 31/200] [Batch 880/938] loss_G: 3.111110, loss_D: 0.286519\n",
      "[Epoch 31/200] [Batch 890/938] loss_G: 2.686768, loss_D: 0.226957\n",
      "[Epoch 31/200] [Batch 900/938] loss_G: 3.265330, loss_D: 0.173773\n",
      "[Epoch 31/200] [Batch 910/938] loss_G: 2.852646, loss_D: 0.173420\n",
      "[Epoch 31/200] [Batch 920/938] loss_G: 2.651439, loss_D: 0.251475\n",
      "[Epoch 31/200] [Batch 930/938] loss_G: 2.738015, loss_D: 0.208799\n",
      "[Epoch 32/200] [Batch 0/938] loss_G: 2.425265, loss_D: 0.207155\n",
      "[Epoch 32/200] [Batch 10/938] loss_G: 2.969188, loss_D: 0.168413\n",
      "[Epoch 32/200] [Batch 20/938] loss_G: 2.477457, loss_D: 0.207506\n",
      "[Epoch 32/200] [Batch 30/938] loss_G: 2.912134, loss_D: 0.283975\n",
      "[Epoch 32/200] [Batch 40/938] loss_G: 2.417593, loss_D: 0.327907\n",
      "[Epoch 32/200] [Batch 50/938] loss_G: 3.027128, loss_D: 0.159876\n",
      "[Epoch 32/200] [Batch 60/938] loss_G: 2.893439, loss_D: 0.180736\n",
      "[Epoch 32/200] [Batch 70/938] loss_G: 2.459361, loss_D: 0.243168\n",
      "[Epoch 32/200] [Batch 80/938] loss_G: 2.085744, loss_D: 0.187644\n",
      "[Epoch 32/200] [Batch 90/938] loss_G: 2.980378, loss_D: 0.207766\n",
      "[Epoch 32/200] [Batch 100/938] loss_G: 2.597970, loss_D: 0.215334\n",
      "[Epoch 32/200] [Batch 110/938] loss_G: 2.820287, loss_D: 0.238437\n",
      "[Epoch 32/200] [Batch 120/938] loss_G: 2.513140, loss_D: 0.284838\n",
      "[Epoch 32/200] [Batch 130/938] loss_G: 2.484831, loss_D: 0.236726\n",
      "[Epoch 32/200] [Batch 140/938] loss_G: 2.636499, loss_D: 0.154630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 32/200] [Batch 150/938] loss_G: 2.925403, loss_D: 0.139957\n",
      "[Epoch 32/200] [Batch 160/938] loss_G: 2.801319, loss_D: 0.167915\n",
      "[Epoch 32/200] [Batch 170/938] loss_G: 2.826536, loss_D: 0.254841\n",
      "[Epoch 32/200] [Batch 180/938] loss_G: 2.556324, loss_D: 0.245851\n",
      "[Epoch 32/200] [Batch 190/938] loss_G: 2.684803, loss_D: 0.258549\n",
      "[Epoch 32/200] [Batch 200/938] loss_G: 2.802197, loss_D: 0.193531\n",
      "[Epoch 32/200] [Batch 210/938] loss_G: 2.573351, loss_D: 0.314888\n",
      "[Epoch 32/200] [Batch 220/938] loss_G: 2.996039, loss_D: 0.154520\n",
      "[Epoch 32/200] [Batch 230/938] loss_G: 2.643986, loss_D: 0.164587\n",
      "[Epoch 32/200] [Batch 240/938] loss_G: 2.794402, loss_D: 0.241931\n",
      "[Epoch 32/200] [Batch 250/938] loss_G: 2.439889, loss_D: 0.298495\n",
      "[Epoch 32/200] [Batch 260/938] loss_G: 3.017892, loss_D: 0.214443\n",
      "[Epoch 32/200] [Batch 270/938] loss_G: 2.927761, loss_D: 0.238817\n",
      "[Epoch 32/200] [Batch 280/938] loss_G: 2.414921, loss_D: 0.236529\n",
      "[Epoch 32/200] [Batch 290/938] loss_G: 2.622998, loss_D: 0.246079\n",
      "[Epoch 32/200] [Batch 300/938] loss_G: 3.037031, loss_D: 0.275798\n",
      "[Epoch 32/200] [Batch 310/938] loss_G: 2.640293, loss_D: 0.303050\n",
      "[Epoch 32/200] [Batch 320/938] loss_G: 2.745094, loss_D: 0.229392\n",
      "[Epoch 32/200] [Batch 330/938] loss_G: 2.818217, loss_D: 0.199237\n",
      "[Epoch 32/200] [Batch 340/938] loss_G: 2.809650, loss_D: 0.195386\n",
      "[Epoch 32/200] [Batch 350/938] loss_G: 2.779582, loss_D: 0.251413\n",
      "[Epoch 32/200] [Batch 360/938] loss_G: 2.752069, loss_D: 0.222008\n",
      "[Epoch 32/200] [Batch 370/938] loss_G: 3.096329, loss_D: 0.141920\n",
      "[Epoch 32/200] [Batch 380/938] loss_G: 2.980180, loss_D: 0.238406\n",
      "[Epoch 32/200] [Batch 390/938] loss_G: 3.492641, loss_D: 0.189180\n",
      "[Epoch 32/200] [Batch 400/938] loss_G: 2.727023, loss_D: 0.329815\n",
      "[Epoch 32/200] [Batch 410/938] loss_G: 2.943083, loss_D: 0.211588\n",
      "[Epoch 32/200] [Batch 420/938] loss_G: 2.930829, loss_D: 0.232436\n",
      "[Epoch 32/200] [Batch 430/938] loss_G: 2.724453, loss_D: 0.214499\n",
      "[Epoch 32/200] [Batch 440/938] loss_G: 3.091378, loss_D: 0.206570\n",
      "[Epoch 32/200] [Batch 450/938] loss_G: 2.636793, loss_D: 0.312306\n",
      "[Epoch 32/200] [Batch 460/938] loss_G: 3.024726, loss_D: 0.197226\n",
      "[Epoch 32/200] [Batch 470/938] loss_G: 2.761182, loss_D: 0.264446\n",
      "[Epoch 32/200] [Batch 480/938] loss_G: 2.670903, loss_D: 0.231151\n",
      "[Epoch 32/200] [Batch 490/938] loss_G: 2.832414, loss_D: 0.322070\n",
      "[Epoch 32/200] [Batch 500/938] loss_G: 2.397079, loss_D: 0.386093\n",
      "[Epoch 32/200] [Batch 510/938] loss_G: 2.668766, loss_D: 0.278501\n",
      "[Epoch 32/200] [Batch 520/938] loss_G: 2.462373, loss_D: 0.285588\n",
      "[Epoch 32/200] [Batch 530/938] loss_G: 2.776090, loss_D: 0.235622\n",
      "[Epoch 32/200] [Batch 540/938] loss_G: 1.973407, loss_D: 0.390878\n",
      "[Epoch 32/200] [Batch 550/938] loss_G: 2.345783, loss_D: 0.271737\n",
      "[Epoch 32/200] [Batch 560/938] loss_G: 2.651055, loss_D: 0.160703\n",
      "[Epoch 32/200] [Batch 570/938] loss_G: 2.542440, loss_D: 0.190381\n",
      "[Epoch 32/200] [Batch 580/938] loss_G: 2.445207, loss_D: 0.268458\n",
      "[Epoch 32/200] [Batch 590/938] loss_G: 2.684901, loss_D: 0.237735\n",
      "[Epoch 32/200] [Batch 600/938] loss_G: 2.491716, loss_D: 0.382418\n",
      "[Epoch 32/200] [Batch 610/938] loss_G: 2.700032, loss_D: 0.198991\n",
      "[Epoch 32/200] [Batch 620/938] loss_G: 3.057416, loss_D: 0.267600\n",
      "[Epoch 32/200] [Batch 630/938] loss_G: 2.326484, loss_D: 0.241171\n",
      "[Epoch 32/200] [Batch 640/938] loss_G: 2.357932, loss_D: 0.337611\n",
      "[Epoch 32/200] [Batch 650/938] loss_G: 2.803056, loss_D: 0.181861\n",
      "[Epoch 32/200] [Batch 660/938] loss_G: 2.794229, loss_D: 0.182680\n",
      "[Epoch 32/200] [Batch 670/938] loss_G: 2.911314, loss_D: 0.174799\n",
      "[Epoch 32/200] [Batch 680/938] loss_G: 2.891619, loss_D: 0.174626\n",
      "[Epoch 32/200] [Batch 690/938] loss_G: 2.885102, loss_D: 0.333098\n",
      "[Epoch 32/200] [Batch 700/938] loss_G: 2.253658, loss_D: 0.263059\n",
      "[Epoch 32/200] [Batch 710/938] loss_G: 3.546617, loss_D: 0.223647\n",
      "[Epoch 32/200] [Batch 720/938] loss_G: 2.752540, loss_D: 0.237084\n",
      "[Epoch 32/200] [Batch 730/938] loss_G: 2.812994, loss_D: 0.230800\n",
      "[Epoch 32/200] [Batch 740/938] loss_G: 2.880459, loss_D: 0.179700\n",
      "[Epoch 32/200] [Batch 750/938] loss_G: 2.689270, loss_D: 0.258404\n",
      "[Epoch 32/200] [Batch 760/938] loss_G: 3.196295, loss_D: 0.198599\n",
      "[Epoch 32/200] [Batch 770/938] loss_G: 2.593063, loss_D: 0.238673\n",
      "[Epoch 32/200] [Batch 780/938] loss_G: 2.632119, loss_D: 0.221210\n",
      "[Epoch 32/200] [Batch 790/938] loss_G: 2.812620, loss_D: 0.258003\n",
      "[Epoch 32/200] [Batch 800/938] loss_G: 2.426086, loss_D: 0.296899\n",
      "[Epoch 32/200] [Batch 810/938] loss_G: 2.597640, loss_D: 0.288193\n",
      "[Epoch 32/200] [Batch 820/938] loss_G: 3.046045, loss_D: 0.265013\n",
      "[Epoch 32/200] [Batch 830/938] loss_G: 2.771611, loss_D: 0.178896\n",
      "[Epoch 32/200] [Batch 840/938] loss_G: 2.672124, loss_D: 0.281259\n",
      "[Epoch 32/200] [Batch 850/938] loss_G: 2.765213, loss_D: 0.214407\n",
      "[Epoch 32/200] [Batch 860/938] loss_G: 2.424819, loss_D: 0.300000\n",
      "[Epoch 32/200] [Batch 870/938] loss_G: 2.802542, loss_D: 0.312991\n",
      "[Epoch 32/200] [Batch 880/938] loss_G: 2.369218, loss_D: 0.221018\n",
      "[Epoch 32/200] [Batch 890/938] loss_G: 2.722500, loss_D: 0.288495\n",
      "[Epoch 32/200] [Batch 900/938] loss_G: 2.396532, loss_D: 0.258141\n",
      "[Epoch 32/200] [Batch 910/938] loss_G: 2.698952, loss_D: 0.209673\n",
      "[Epoch 32/200] [Batch 920/938] loss_G: 2.264680, loss_D: 0.234711\n",
      "[Epoch 32/200] [Batch 930/938] loss_G: 2.724062, loss_D: 0.213640\n",
      "[Epoch 33/200] [Batch 0/938] loss_G: 3.026021, loss_D: 0.258941\n",
      "[Epoch 33/200] [Batch 10/938] loss_G: 2.605783, loss_D: 0.234250\n",
      "[Epoch 33/200] [Batch 20/938] loss_G: 2.707543, loss_D: 0.227637\n",
      "[Epoch 33/200] [Batch 30/938] loss_G: 2.495818, loss_D: 0.273970\n",
      "[Epoch 33/200] [Batch 40/938] loss_G: 2.582085, loss_D: 0.201613\n",
      "[Epoch 33/200] [Batch 50/938] loss_G: 3.004989, loss_D: 0.194997\n",
      "[Epoch 33/200] [Batch 60/938] loss_G: 3.007755, loss_D: 0.228404\n",
      "[Epoch 33/200] [Batch 70/938] loss_G: 2.605178, loss_D: 0.295474\n",
      "[Epoch 33/200] [Batch 80/938] loss_G: 2.961270, loss_D: 0.214608\n",
      "[Epoch 33/200] [Batch 90/938] loss_G: 3.115230, loss_D: 0.170980\n",
      "[Epoch 33/200] [Batch 100/938] loss_G: 2.955283, loss_D: 0.114232\n",
      "[Epoch 33/200] [Batch 110/938] loss_G: 2.303929, loss_D: 0.195710\n",
      "[Epoch 33/200] [Batch 120/938] loss_G: 2.872814, loss_D: 0.305135\n",
      "[Epoch 33/200] [Batch 130/938] loss_G: 2.942221, loss_D: 0.258403\n",
      "[Epoch 33/200] [Batch 140/938] loss_G: 2.503997, loss_D: 0.251785\n",
      "[Epoch 33/200] [Batch 150/938] loss_G: 3.097030, loss_D: 0.296692\n",
      "[Epoch 33/200] [Batch 160/938] loss_G: 2.520612, loss_D: 0.197300\n",
      "[Epoch 33/200] [Batch 170/938] loss_G: 2.447674, loss_D: 0.293587\n",
      "[Epoch 33/200] [Batch 180/938] loss_G: 2.796820, loss_D: 0.308840\n",
      "[Epoch 33/200] [Batch 190/938] loss_G: 3.146526, loss_D: 0.208434\n",
      "[Epoch 33/200] [Batch 200/938] loss_G: 2.763830, loss_D: 0.168668\n",
      "[Epoch 33/200] [Batch 210/938] loss_G: 2.561974, loss_D: 0.222251\n",
      "[Epoch 33/200] [Batch 220/938] loss_G: 2.167978, loss_D: 0.266599\n",
      "[Epoch 33/200] [Batch 230/938] loss_G: 2.842847, loss_D: 0.188338\n",
      "[Epoch 33/200] [Batch 240/938] loss_G: 2.380948, loss_D: 0.291304\n",
      "[Epoch 33/200] [Batch 250/938] loss_G: 2.789111, loss_D: 0.204602\n",
      "[Epoch 33/200] [Batch 260/938] loss_G: 2.759491, loss_D: 0.216173\n",
      "[Epoch 33/200] [Batch 270/938] loss_G: 2.714111, loss_D: 0.270093\n",
      "[Epoch 33/200] [Batch 280/938] loss_G: 2.625731, loss_D: 0.359996\n",
      "[Epoch 33/200] [Batch 290/938] loss_G: 2.582703, loss_D: 0.316492\n",
      "[Epoch 33/200] [Batch 300/938] loss_G: 2.687084, loss_D: 0.258996\n",
      "[Epoch 33/200] [Batch 310/938] loss_G: 2.649069, loss_D: 0.197297\n",
      "[Epoch 33/200] [Batch 320/938] loss_G: 2.260580, loss_D: 0.327093\n",
      "[Epoch 33/200] [Batch 330/938] loss_G: 2.382577, loss_D: 0.251227\n",
      "[Epoch 33/200] [Batch 340/938] loss_G: 2.643816, loss_D: 0.243471\n",
      "[Epoch 33/200] [Batch 350/938] loss_G: 2.635395, loss_D: 0.289518\n",
      "[Epoch 33/200] [Batch 360/938] loss_G: 2.252515, loss_D: 0.292814\n",
      "[Epoch 33/200] [Batch 370/938] loss_G: 2.715644, loss_D: 0.192606\n",
      "[Epoch 33/200] [Batch 380/938] loss_G: 2.817684, loss_D: 0.243843\n",
      "[Epoch 33/200] [Batch 390/938] loss_G: 2.818845, loss_D: 0.186324\n",
      "[Epoch 33/200] [Batch 400/938] loss_G: 2.907023, loss_D: 0.166689\n",
      "[Epoch 33/200] [Batch 410/938] loss_G: 2.423872, loss_D: 0.233128\n",
      "[Epoch 33/200] [Batch 420/938] loss_G: 2.584313, loss_D: 0.272880\n",
      "[Epoch 33/200] [Batch 430/938] loss_G: 2.668152, loss_D: 0.289856\n",
      "[Epoch 33/200] [Batch 440/938] loss_G: 2.575460, loss_D: 0.157856\n",
      "[Epoch 33/200] [Batch 450/938] loss_G: 3.392023, loss_D: 0.224920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 33/200] [Batch 460/938] loss_G: 2.317158, loss_D: 0.271298\n",
      "[Epoch 33/200] [Batch 470/938] loss_G: 2.755260, loss_D: 0.229332\n",
      "[Epoch 33/200] [Batch 480/938] loss_G: 2.896756, loss_D: 0.177556\n",
      "[Epoch 33/200] [Batch 490/938] loss_G: 3.237106, loss_D: 0.173405\n",
      "[Epoch 33/200] [Batch 500/938] loss_G: 3.143956, loss_D: 0.228812\n",
      "[Epoch 33/200] [Batch 510/938] loss_G: 2.725667, loss_D: 0.180809\n",
      "[Epoch 33/200] [Batch 520/938] loss_G: 3.131960, loss_D: 0.212238\n",
      "[Epoch 33/200] [Batch 530/938] loss_G: 2.731277, loss_D: 0.181173\n",
      "[Epoch 33/200] [Batch 540/938] loss_G: 2.994507, loss_D: 0.186838\n",
      "[Epoch 33/200] [Batch 550/938] loss_G: 2.421289, loss_D: 0.247263\n",
      "[Epoch 33/200] [Batch 560/938] loss_G: 2.730783, loss_D: 0.275471\n",
      "[Epoch 33/200] [Batch 570/938] loss_G: 2.717715, loss_D: 0.191302\n",
      "[Epoch 33/200] [Batch 580/938] loss_G: 2.517495, loss_D: 0.217888\n",
      "[Epoch 33/200] [Batch 590/938] loss_G: 2.871112, loss_D: 0.267225\n",
      "[Epoch 33/200] [Batch 600/938] loss_G: 2.568758, loss_D: 0.313666\n",
      "[Epoch 33/200] [Batch 610/938] loss_G: 2.624947, loss_D: 0.194314\n",
      "[Epoch 33/200] [Batch 620/938] loss_G: 2.857524, loss_D: 0.145121\n",
      "[Epoch 33/200] [Batch 630/938] loss_G: 2.804254, loss_D: 0.180549\n",
      "[Epoch 33/200] [Batch 640/938] loss_G: 2.946667, loss_D: 0.235985\n",
      "[Epoch 33/200] [Batch 650/938] loss_G: 2.343495, loss_D: 0.324886\n",
      "[Epoch 33/200] [Batch 660/938] loss_G: 2.742427, loss_D: 0.250987\n",
      "[Epoch 33/200] [Batch 670/938] loss_G: 3.056502, loss_D: 0.229887\n",
      "[Epoch 33/200] [Batch 680/938] loss_G: 2.871903, loss_D: 0.196597\n",
      "[Epoch 33/200] [Batch 690/938] loss_G: 2.651628, loss_D: 0.273863\n",
      "[Epoch 33/200] [Batch 700/938] loss_G: 2.678808, loss_D: 0.289008\n",
      "[Epoch 33/200] [Batch 710/938] loss_G: 2.631091, loss_D: 0.199151\n",
      "[Epoch 33/200] [Batch 720/938] loss_G: 2.928804, loss_D: 0.205473\n",
      "[Epoch 33/200] [Batch 730/938] loss_G: 2.374327, loss_D: 0.289389\n",
      "[Epoch 33/200] [Batch 740/938] loss_G: 2.964808, loss_D: 0.289772\n",
      "[Epoch 33/200] [Batch 750/938] loss_G: 2.166050, loss_D: 0.364405\n",
      "[Epoch 33/200] [Batch 760/938] loss_G: 2.973256, loss_D: 0.317703\n",
      "[Epoch 33/200] [Batch 770/938] loss_G: 2.804563, loss_D: 0.307396\n",
      "[Epoch 33/200] [Batch 780/938] loss_G: 2.951842, loss_D: 0.199619\n",
      "[Epoch 33/200] [Batch 790/938] loss_G: 2.557943, loss_D: 0.220430\n",
      "[Epoch 33/200] [Batch 800/938] loss_G: 2.670116, loss_D: 0.261395\n",
      "[Epoch 33/200] [Batch 810/938] loss_G: 3.221015, loss_D: 0.207356\n",
      "[Epoch 33/200] [Batch 820/938] loss_G: 2.845829, loss_D: 0.215218\n",
      "[Epoch 33/200] [Batch 830/938] loss_G: 2.424963, loss_D: 0.302193\n",
      "[Epoch 33/200] [Batch 840/938] loss_G: 2.221821, loss_D: 0.306419\n",
      "[Epoch 33/200] [Batch 850/938] loss_G: 2.747424, loss_D: 0.219315\n",
      "[Epoch 33/200] [Batch 860/938] loss_G: 2.682829, loss_D: 0.179610\n",
      "[Epoch 33/200] [Batch 870/938] loss_G: 3.229272, loss_D: 0.199697\n",
      "[Epoch 33/200] [Batch 880/938] loss_G: 2.230431, loss_D: 0.306834\n",
      "[Epoch 33/200] [Batch 890/938] loss_G: 2.483238, loss_D: 0.260916\n",
      "[Epoch 33/200] [Batch 900/938] loss_G: 2.968470, loss_D: 0.129215\n",
      "[Epoch 33/200] [Batch 910/938] loss_G: 2.383189, loss_D: 0.319639\n",
      "[Epoch 33/200] [Batch 920/938] loss_G: 2.915540, loss_D: 0.216443\n",
      "[Epoch 33/200] [Batch 930/938] loss_G: 2.935288, loss_D: 0.223537\n",
      "[Epoch 34/200] [Batch 0/938] loss_G: 2.904416, loss_D: 0.268903\n",
      "[Epoch 34/200] [Batch 10/938] loss_G: 2.562006, loss_D: 0.213054\n",
      "[Epoch 34/200] [Batch 20/938] loss_G: 2.628333, loss_D: 0.261641\n",
      "[Epoch 34/200] [Batch 30/938] loss_G: 2.939579, loss_D: 0.186161\n",
      "[Epoch 34/200] [Batch 40/938] loss_G: 2.570920, loss_D: 0.187070\n",
      "[Epoch 34/200] [Batch 50/938] loss_G: 2.984040, loss_D: 0.205552\n",
      "[Epoch 34/200] [Batch 60/938] loss_G: 2.369709, loss_D: 0.223972\n",
      "[Epoch 34/200] [Batch 70/938] loss_G: 2.351685, loss_D: 0.334102\n",
      "[Epoch 34/200] [Batch 80/938] loss_G: 2.741003, loss_D: 0.207751\n",
      "[Epoch 34/200] [Batch 90/938] loss_G: 2.434646, loss_D: 0.250062\n",
      "[Epoch 34/200] [Batch 100/938] loss_G: 2.435277, loss_D: 0.366340\n",
      "[Epoch 34/200] [Batch 110/938] loss_G: 2.365361, loss_D: 0.217167\n",
      "[Epoch 34/200] [Batch 120/938] loss_G: 2.346710, loss_D: 0.165752\n",
      "[Epoch 34/200] [Batch 130/938] loss_G: 2.501877, loss_D: 0.241435\n",
      "[Epoch 34/200] [Batch 140/938] loss_G: 2.467414, loss_D: 0.381876\n",
      "[Epoch 34/200] [Batch 150/938] loss_G: 2.735563, loss_D: 0.217644\n",
      "[Epoch 34/200] [Batch 160/938] loss_G: 2.980865, loss_D: 0.269880\n",
      "[Epoch 34/200] [Batch 170/938] loss_G: 2.567679, loss_D: 0.295571\n",
      "[Epoch 34/200] [Batch 180/938] loss_G: 2.447547, loss_D: 0.270860\n",
      "[Epoch 34/200] [Batch 190/938] loss_G: 2.539469, loss_D: 0.213644\n",
      "[Epoch 34/200] [Batch 200/938] loss_G: 2.636508, loss_D: 0.336332\n",
      "[Epoch 34/200] [Batch 210/938] loss_G: 2.492845, loss_D: 0.246005\n",
      "[Epoch 34/200] [Batch 220/938] loss_G: 2.884412, loss_D: 0.232859\n",
      "[Epoch 34/200] [Batch 230/938] loss_G: 2.466503, loss_D: 0.216047\n",
      "[Epoch 34/200] [Batch 240/938] loss_G: 2.331984, loss_D: 0.297286\n",
      "[Epoch 34/200] [Batch 250/938] loss_G: 2.768970, loss_D: 0.209046\n",
      "[Epoch 34/200] [Batch 260/938] loss_G: 2.904805, loss_D: 0.213560\n",
      "[Epoch 34/200] [Batch 270/938] loss_G: 2.562935, loss_D: 0.316049\n",
      "[Epoch 34/200] [Batch 280/938] loss_G: 2.510941, loss_D: 0.232016\n",
      "[Epoch 34/200] [Batch 290/938] loss_G: 2.783064, loss_D: 0.192557\n",
      "[Epoch 34/200] [Batch 300/938] loss_G: 2.679611, loss_D: 0.180960\n",
      "[Epoch 34/200] [Batch 310/938] loss_G: 2.432884, loss_D: 0.215279\n",
      "[Epoch 34/200] [Batch 320/938] loss_G: 2.346686, loss_D: 0.289936\n",
      "[Epoch 34/200] [Batch 330/938] loss_G: 2.773915, loss_D: 0.259328\n",
      "[Epoch 34/200] [Batch 340/938] loss_G: 2.739063, loss_D: 0.212017\n",
      "[Epoch 34/200] [Batch 350/938] loss_G: 3.070409, loss_D: 0.216323\n",
      "[Epoch 34/200] [Batch 360/938] loss_G: 2.818726, loss_D: 0.265072\n",
      "[Epoch 34/200] [Batch 370/938] loss_G: 2.698380, loss_D: 0.282843\n",
      "[Epoch 34/200] [Batch 380/938] loss_G: 2.715383, loss_D: 0.329158\n",
      "[Epoch 34/200] [Batch 390/938] loss_G: 3.228247, loss_D: 0.257388\n",
      "[Epoch 34/200] [Batch 400/938] loss_G: 2.128132, loss_D: 0.216257\n",
      "[Epoch 34/200] [Batch 410/938] loss_G: 2.727552, loss_D: 0.212957\n",
      "[Epoch 34/200] [Batch 420/938] loss_G: 2.396058, loss_D: 0.236851\n",
      "[Epoch 34/200] [Batch 430/938] loss_G: 2.790034, loss_D: 0.236354\n",
      "[Epoch 34/200] [Batch 440/938] loss_G: 2.748046, loss_D: 0.191879\n",
      "[Epoch 34/200] [Batch 450/938] loss_G: 2.872160, loss_D: 0.264456\n",
      "[Epoch 34/200] [Batch 460/938] loss_G: 2.863350, loss_D: 0.303722\n",
      "[Epoch 34/200] [Batch 470/938] loss_G: 2.462023, loss_D: 0.290529\n",
      "[Epoch 34/200] [Batch 480/938] loss_G: 2.777722, loss_D: 0.301203\n",
      "[Epoch 34/200] [Batch 490/938] loss_G: 2.761083, loss_D: 0.232654\n",
      "[Epoch 34/200] [Batch 500/938] loss_G: 2.627824, loss_D: 0.272693\n",
      "[Epoch 34/200] [Batch 510/938] loss_G: 2.634491, loss_D: 0.349489\n",
      "[Epoch 34/200] [Batch 520/938] loss_G: 2.656433, loss_D: 0.193279\n",
      "[Epoch 34/200] [Batch 530/938] loss_G: 2.625483, loss_D: 0.258322\n",
      "[Epoch 34/200] [Batch 540/938] loss_G: 2.381351, loss_D: 0.223164\n",
      "[Epoch 34/200] [Batch 550/938] loss_G: 2.830463, loss_D: 0.264881\n",
      "[Epoch 34/200] [Batch 560/938] loss_G: 2.783242, loss_D: 0.249259\n",
      "[Epoch 34/200] [Batch 570/938] loss_G: 2.224645, loss_D: 0.293376\n",
      "[Epoch 34/200] [Batch 580/938] loss_G: 2.939876, loss_D: 0.191242\n",
      "[Epoch 34/200] [Batch 590/938] loss_G: 3.309143, loss_D: 0.223928\n",
      "[Epoch 34/200] [Batch 600/938] loss_G: 2.915649, loss_D: 0.229056\n",
      "[Epoch 34/200] [Batch 610/938] loss_G: 2.954208, loss_D: 0.221404\n",
      "[Epoch 34/200] [Batch 620/938] loss_G: 3.143580, loss_D: 0.270865\n",
      "[Epoch 34/200] [Batch 630/938] loss_G: 2.518936, loss_D: 0.335177\n",
      "[Epoch 34/200] [Batch 640/938] loss_G: 2.775229, loss_D: 0.275806\n",
      "[Epoch 34/200] [Batch 650/938] loss_G: 2.398963, loss_D: 0.326314\n",
      "[Epoch 34/200] [Batch 660/938] loss_G: 3.025421, loss_D: 0.248168\n",
      "[Epoch 34/200] [Batch 670/938] loss_G: 2.712349, loss_D: 0.220871\n",
      "[Epoch 34/200] [Batch 680/938] loss_G: 2.728843, loss_D: 0.329365\n",
      "[Epoch 34/200] [Batch 690/938] loss_G: 2.952707, loss_D: 0.247634\n",
      "[Epoch 34/200] [Batch 700/938] loss_G: 2.719806, loss_D: 0.199370\n",
      "[Epoch 34/200] [Batch 710/938] loss_G: 2.705616, loss_D: 0.190783\n",
      "[Epoch 34/200] [Batch 720/938] loss_G: 2.978924, loss_D: 0.221500\n",
      "[Epoch 34/200] [Batch 730/938] loss_G: 2.397902, loss_D: 0.282053\n",
      "[Epoch 34/200] [Batch 740/938] loss_G: 2.249002, loss_D: 0.350056\n",
      "[Epoch 34/200] [Batch 750/938] loss_G: 2.139996, loss_D: 0.302790\n",
      "[Epoch 34/200] [Batch 760/938] loss_G: 2.507812, loss_D: 0.241015\n",
      "[Epoch 34/200] [Batch 770/938] loss_G: 2.793567, loss_D: 0.245356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34/200] [Batch 780/938] loss_G: 2.676486, loss_D: 0.210200\n",
      "[Epoch 34/200] [Batch 790/938] loss_G: 2.463436, loss_D: 0.204731\n",
      "[Epoch 34/200] [Batch 800/938] loss_G: 2.492912, loss_D: 0.273537\n",
      "[Epoch 34/200] [Batch 810/938] loss_G: 2.511773, loss_D: 0.225649\n",
      "[Epoch 34/200] [Batch 820/938] loss_G: 2.582704, loss_D: 0.277434\n",
      "[Epoch 34/200] [Batch 830/938] loss_G: 2.529335, loss_D: 0.198080\n",
      "[Epoch 34/200] [Batch 840/938] loss_G: 2.278398, loss_D: 0.315172\n",
      "[Epoch 34/200] [Batch 850/938] loss_G: 2.676563, loss_D: 0.235278\n",
      "[Epoch 34/200] [Batch 860/938] loss_G: 2.685179, loss_D: 0.216932\n",
      "[Epoch 34/200] [Batch 870/938] loss_G: 2.582068, loss_D: 0.181213\n",
      "[Epoch 34/200] [Batch 880/938] loss_G: 2.757614, loss_D: 0.188249\n",
      "[Epoch 34/200] [Batch 890/938] loss_G: 2.483466, loss_D: 0.320040\n",
      "[Epoch 34/200] [Batch 900/938] loss_G: 2.565458, loss_D: 0.162541\n",
      "[Epoch 34/200] [Batch 910/938] loss_G: 2.511847, loss_D: 0.225124\n",
      "[Epoch 34/200] [Batch 920/938] loss_G: 2.921714, loss_D: 0.240676\n",
      "[Epoch 34/200] [Batch 930/938] loss_G: 2.591915, loss_D: 0.229591\n",
      "[Epoch 35/200] [Batch 0/938] loss_G: 2.671576, loss_D: 0.283980\n",
      "[Epoch 35/200] [Batch 10/938] loss_G: 2.533048, loss_D: 0.195121\n",
      "[Epoch 35/200] [Batch 20/938] loss_G: 2.836245, loss_D: 0.229998\n",
      "[Epoch 35/200] [Batch 30/938] loss_G: 2.366374, loss_D: 0.220061\n",
      "[Epoch 35/200] [Batch 40/938] loss_G: 2.685000, loss_D: 0.219366\n",
      "[Epoch 35/200] [Batch 50/938] loss_G: 2.780038, loss_D: 0.185049\n",
      "[Epoch 35/200] [Batch 60/938] loss_G: 2.522668, loss_D: 0.238730\n",
      "[Epoch 35/200] [Batch 70/938] loss_G: 2.456253, loss_D: 0.206119\n",
      "[Epoch 35/200] [Batch 80/938] loss_G: 2.588146, loss_D: 0.287908\n",
      "[Epoch 35/200] [Batch 90/938] loss_G: 2.090578, loss_D: 0.315884\n",
      "[Epoch 35/200] [Batch 100/938] loss_G: 2.983057, loss_D: 0.265522\n",
      "[Epoch 35/200] [Batch 110/938] loss_G: 2.411834, loss_D: 0.239468\n",
      "[Epoch 35/200] [Batch 120/938] loss_G: 2.905180, loss_D: 0.253063\n",
      "[Epoch 35/200] [Batch 130/938] loss_G: 2.772033, loss_D: 0.186666\n",
      "[Epoch 35/200] [Batch 140/938] loss_G: 2.550280, loss_D: 0.227612\n",
      "[Epoch 35/200] [Batch 150/938] loss_G: 2.522561, loss_D: 0.280565\n",
      "[Epoch 35/200] [Batch 160/938] loss_G: 2.834524, loss_D: 0.315240\n",
      "[Epoch 35/200] [Batch 170/938] loss_G: 2.529408, loss_D: 0.307475\n",
      "[Epoch 35/200] [Batch 180/938] loss_G: 2.981886, loss_D: 0.265382\n",
      "[Epoch 35/200] [Batch 190/938] loss_G: 2.789264, loss_D: 0.253601\n",
      "[Epoch 35/200] [Batch 200/938] loss_G: 2.506423, loss_D: 0.306656\n",
      "[Epoch 35/200] [Batch 210/938] loss_G: 3.094188, loss_D: 0.358872\n",
      "[Epoch 35/200] [Batch 220/938] loss_G: 2.472852, loss_D: 0.362580\n",
      "[Epoch 35/200] [Batch 230/938] loss_G: 1.964463, loss_D: 0.272419\n",
      "[Epoch 35/200] [Batch 240/938] loss_G: 2.876160, loss_D: 0.212007\n",
      "[Epoch 35/200] [Batch 250/938] loss_G: 2.914215, loss_D: 0.287038\n",
      "[Epoch 35/200] [Batch 260/938] loss_G: 2.652260, loss_D: 0.223219\n",
      "[Epoch 35/200] [Batch 270/938] loss_G: 2.454788, loss_D: 0.252727\n",
      "[Epoch 35/200] [Batch 280/938] loss_G: 2.727235, loss_D: 0.313422\n",
      "[Epoch 35/200] [Batch 290/938] loss_G: 2.318041, loss_D: 0.287523\n",
      "[Epoch 35/200] [Batch 300/938] loss_G: 2.863169, loss_D: 0.165724\n",
      "[Epoch 35/200] [Batch 310/938] loss_G: 2.592844, loss_D: 0.225849\n",
      "[Epoch 35/200] [Batch 320/938] loss_G: 2.923160, loss_D: 0.283179\n",
      "[Epoch 35/200] [Batch 330/938] loss_G: 2.298043, loss_D: 0.309983\n",
      "[Epoch 35/200] [Batch 340/938] loss_G: 3.074715, loss_D: 0.275559\n",
      "[Epoch 35/200] [Batch 350/938] loss_G: 2.400157, loss_D: 0.234386\n",
      "[Epoch 35/200] [Batch 360/938] loss_G: 2.471855, loss_D: 0.232370\n",
      "[Epoch 35/200] [Batch 370/938] loss_G: 2.527350, loss_D: 0.244630\n",
      "[Epoch 35/200] [Batch 380/938] loss_G: 2.863870, loss_D: 0.223821\n",
      "[Epoch 35/200] [Batch 390/938] loss_G: 2.636363, loss_D: 0.171007\n",
      "[Epoch 35/200] [Batch 400/938] loss_G: 2.493041, loss_D: 0.205274\n",
      "[Epoch 35/200] [Batch 410/938] loss_G: 2.347158, loss_D: 0.294840\n",
      "[Epoch 35/200] [Batch 420/938] loss_G: 2.442585, loss_D: 0.222258\n",
      "[Epoch 35/200] [Batch 430/938] loss_G: 2.577496, loss_D: 0.210464\n",
      "[Epoch 35/200] [Batch 440/938] loss_G: 2.506984, loss_D: 0.249327\n",
      "[Epoch 35/200] [Batch 450/938] loss_G: 2.767556, loss_D: 0.171873\n",
      "[Epoch 35/200] [Batch 460/938] loss_G: 2.494862, loss_D: 0.214689\n",
      "[Epoch 35/200] [Batch 470/938] loss_G: 2.980643, loss_D: 0.151594\n",
      "[Epoch 35/200] [Batch 480/938] loss_G: 2.727473, loss_D: 0.161669\n",
      "[Epoch 35/200] [Batch 490/938] loss_G: 3.057354, loss_D: 0.200063\n",
      "[Epoch 35/200] [Batch 500/938] loss_G: 2.577852, loss_D: 0.190862\n",
      "[Epoch 35/200] [Batch 510/938] loss_G: 2.504756, loss_D: 0.313572\n",
      "[Epoch 35/200] [Batch 520/938] loss_G: 2.780244, loss_D: 0.197709\n",
      "[Epoch 35/200] [Batch 530/938] loss_G: 2.441134, loss_D: 0.190627\n",
      "[Epoch 35/200] [Batch 540/938] loss_G: 2.525418, loss_D: 0.229862\n",
      "[Epoch 35/200] [Batch 550/938] loss_G: 2.498732, loss_D: 0.255802\n",
      "[Epoch 35/200] [Batch 560/938] loss_G: 2.619231, loss_D: 0.246326\n",
      "[Epoch 35/200] [Batch 570/938] loss_G: 2.426302, loss_D: 0.235244\n",
      "[Epoch 35/200] [Batch 580/938] loss_G: 2.638609, loss_D: 0.241460\n",
      "[Epoch 35/200] [Batch 590/938] loss_G: 2.668297, loss_D: 0.196756\n",
      "[Epoch 35/200] [Batch 600/938] loss_G: 2.817660, loss_D: 0.325825\n",
      "[Epoch 35/200] [Batch 610/938] loss_G: 2.250911, loss_D: 0.290885\n",
      "[Epoch 35/200] [Batch 620/938] loss_G: 2.559299, loss_D: 0.279014\n",
      "[Epoch 35/200] [Batch 630/938] loss_G: 2.763683, loss_D: 0.211419\n",
      "[Epoch 35/200] [Batch 640/938] loss_G: 2.732105, loss_D: 0.232619\n",
      "[Epoch 35/200] [Batch 650/938] loss_G: 2.595468, loss_D: 0.190844\n",
      "[Epoch 35/200] [Batch 660/938] loss_G: 2.375939, loss_D: 0.233716\n",
      "[Epoch 35/200] [Batch 670/938] loss_G: 2.706824, loss_D: 0.213214\n",
      "[Epoch 35/200] [Batch 680/938] loss_G: 2.728922, loss_D: 0.257828\n",
      "[Epoch 35/200] [Batch 690/938] loss_G: 2.512091, loss_D: 0.316385\n",
      "[Epoch 35/200] [Batch 700/938] loss_G: 2.673725, loss_D: 0.213536\n",
      "[Epoch 35/200] [Batch 710/938] loss_G: 2.900548, loss_D: 0.205584\n",
      "[Epoch 35/200] [Batch 720/938] loss_G: 2.557157, loss_D: 0.168943\n",
      "[Epoch 35/200] [Batch 730/938] loss_G: 2.572237, loss_D: 0.233724\n",
      "[Epoch 35/200] [Batch 740/938] loss_G: 2.753101, loss_D: 0.229463\n",
      "[Epoch 35/200] [Batch 750/938] loss_G: 2.682803, loss_D: 0.204739\n",
      "[Epoch 35/200] [Batch 760/938] loss_G: 2.850680, loss_D: 0.299429\n",
      "[Epoch 35/200] [Batch 770/938] loss_G: 2.514139, loss_D: 0.160716\n",
      "[Epoch 35/200] [Batch 780/938] loss_G: 2.857666, loss_D: 0.251253\n",
      "[Epoch 35/200] [Batch 790/938] loss_G: 2.897080, loss_D: 0.239320\n",
      "[Epoch 35/200] [Batch 800/938] loss_G: 2.718859, loss_D: 0.241369\n",
      "[Epoch 35/200] [Batch 810/938] loss_G: 3.030067, loss_D: 0.167494\n",
      "[Epoch 35/200] [Batch 820/938] loss_G: 2.821882, loss_D: 0.264735\n",
      "[Epoch 35/200] [Batch 830/938] loss_G: 2.913725, loss_D: 0.336708\n",
      "[Epoch 35/200] [Batch 840/938] loss_G: 2.358965, loss_D: 0.305682\n",
      "[Epoch 35/200] [Batch 850/938] loss_G: 2.544948, loss_D: 0.336054\n",
      "[Epoch 35/200] [Batch 860/938] loss_G: 2.721932, loss_D: 0.255963\n",
      "[Epoch 35/200] [Batch 870/938] loss_G: 2.626593, loss_D: 0.238457\n",
      "[Epoch 35/200] [Batch 880/938] loss_G: 3.492525, loss_D: 0.176048\n",
      "[Epoch 35/200] [Batch 890/938] loss_G: 2.793705, loss_D: 0.209693\n",
      "[Epoch 35/200] [Batch 900/938] loss_G: 3.235674, loss_D: 0.289163\n",
      "[Epoch 35/200] [Batch 910/938] loss_G: 3.136781, loss_D: 0.197516\n",
      "[Epoch 35/200] [Batch 920/938] loss_G: 3.249545, loss_D: 0.215616\n",
      "[Epoch 35/200] [Batch 930/938] loss_G: 2.755845, loss_D: 0.198497\n",
      "[Epoch 36/200] [Batch 0/938] loss_G: 3.155142, loss_D: 0.179883\n",
      "[Epoch 36/200] [Batch 10/938] loss_G: 3.042323, loss_D: 0.163740\n",
      "[Epoch 36/200] [Batch 20/938] loss_G: 2.773271, loss_D: 0.198538\n",
      "[Epoch 36/200] [Batch 30/938] loss_G: 2.524586, loss_D: 0.202362\n",
      "[Epoch 36/200] [Batch 40/938] loss_G: 2.394897, loss_D: 0.246589\n",
      "[Epoch 36/200] [Batch 50/938] loss_G: 2.635043, loss_D: 0.222670\n",
      "[Epoch 36/200] [Batch 60/938] loss_G: 2.891776, loss_D: 0.217187\n",
      "[Epoch 36/200] [Batch 70/938] loss_G: 2.522605, loss_D: 0.277381\n",
      "[Epoch 36/200] [Batch 80/938] loss_G: 2.540162, loss_D: 0.264004\n",
      "[Epoch 36/200] [Batch 90/938] loss_G: 2.813641, loss_D: 0.220268\n",
      "[Epoch 36/200] [Batch 100/938] loss_G: 2.887149, loss_D: 0.366489\n",
      "[Epoch 36/200] [Batch 110/938] loss_G: 2.645903, loss_D: 0.157822\n",
      "[Epoch 36/200] [Batch 120/938] loss_G: 2.694691, loss_D: 0.276361\n",
      "[Epoch 36/200] [Batch 130/938] loss_G: 2.699444, loss_D: 0.197025\n",
      "[Epoch 36/200] [Batch 140/938] loss_G: 2.397655, loss_D: 0.354443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 36/200] [Batch 150/938] loss_G: 2.686544, loss_D: 0.252497\n",
      "[Epoch 36/200] [Batch 160/938] loss_G: 2.397257, loss_D: 0.265533\n",
      "[Epoch 36/200] [Batch 170/938] loss_G: 2.800379, loss_D: 0.235718\n",
      "[Epoch 36/200] [Batch 180/938] loss_G: 2.501925, loss_D: 0.293553\n",
      "[Epoch 36/200] [Batch 190/938] loss_G: 2.448155, loss_D: 0.207915\n",
      "[Epoch 36/200] [Batch 200/938] loss_G: 2.507419, loss_D: 0.356441\n",
      "[Epoch 36/200] [Batch 210/938] loss_G: 2.036206, loss_D: 0.241294\n",
      "[Epoch 36/200] [Batch 220/938] loss_G: 2.590175, loss_D: 0.329781\n",
      "[Epoch 36/200] [Batch 230/938] loss_G: 2.821570, loss_D: 0.324110\n",
      "[Epoch 36/200] [Batch 240/938] loss_G: 2.573799, loss_D: 0.304469\n",
      "[Epoch 36/200] [Batch 250/938] loss_G: 2.859697, loss_D: 0.213370\n",
      "[Epoch 36/200] [Batch 260/938] loss_G: 2.367641, loss_D: 0.254550\n",
      "[Epoch 36/200] [Batch 270/938] loss_G: 2.351463, loss_D: 0.228262\n",
      "[Epoch 36/200] [Batch 280/938] loss_G: 2.481036, loss_D: 0.216880\n",
      "[Epoch 36/200] [Batch 290/938] loss_G: 2.777157, loss_D: 0.193053\n",
      "[Epoch 36/200] [Batch 300/938] loss_G: 2.319839, loss_D: 0.207275\n",
      "[Epoch 36/200] [Batch 310/938] loss_G: 2.292944, loss_D: 0.317100\n",
      "[Epoch 36/200] [Batch 320/938] loss_G: 2.673418, loss_D: 0.246166\n",
      "[Epoch 36/200] [Batch 330/938] loss_G: 2.768077, loss_D: 0.227354\n",
      "[Epoch 36/200] [Batch 340/938] loss_G: 2.679373, loss_D: 0.256639\n",
      "[Epoch 36/200] [Batch 350/938] loss_G: 2.530551, loss_D: 0.265939\n",
      "[Epoch 36/200] [Batch 360/938] loss_G: 2.299157, loss_D: 0.267193\n",
      "[Epoch 36/200] [Batch 370/938] loss_G: 2.724146, loss_D: 0.190430\n",
      "[Epoch 36/200] [Batch 380/938] loss_G: 2.718552, loss_D: 0.238760\n",
      "[Epoch 36/200] [Batch 390/938] loss_G: 2.659585, loss_D: 0.314459\n",
      "[Epoch 36/200] [Batch 400/938] loss_G: 2.404673, loss_D: 0.249441\n",
      "[Epoch 36/200] [Batch 410/938] loss_G: 2.750814, loss_D: 0.172823\n",
      "[Epoch 36/200] [Batch 420/938] loss_G: 2.522191, loss_D: 0.264500\n",
      "[Epoch 36/200] [Batch 430/938] loss_G: 2.542824, loss_D: 0.210550\n",
      "[Epoch 36/200] [Batch 440/938] loss_G: 2.471060, loss_D: 0.258310\n",
      "[Epoch 36/200] [Batch 450/938] loss_G: 2.654598, loss_D: 0.191524\n",
      "[Epoch 36/200] [Batch 460/938] loss_G: 2.521718, loss_D: 0.210403\n",
      "[Epoch 36/200] [Batch 470/938] loss_G: 3.323608, loss_D: 0.166562\n",
      "[Epoch 36/200] [Batch 480/938] loss_G: 2.789289, loss_D: 0.265199\n",
      "[Epoch 36/200] [Batch 490/938] loss_G: 2.786193, loss_D: 0.246832\n",
      "[Epoch 36/200] [Batch 500/938] loss_G: 2.854997, loss_D: 0.277308\n",
      "[Epoch 36/200] [Batch 510/938] loss_G: 2.563951, loss_D: 0.285679\n",
      "[Epoch 36/200] [Batch 520/938] loss_G: 2.877277, loss_D: 0.292855\n",
      "[Epoch 36/200] [Batch 530/938] loss_G: 2.510661, loss_D: 0.192306\n",
      "[Epoch 36/200] [Batch 540/938] loss_G: 2.259306, loss_D: 0.244125\n",
      "[Epoch 36/200] [Batch 550/938] loss_G: 3.086013, loss_D: 0.166232\n",
      "[Epoch 36/200] [Batch 560/938] loss_G: 2.576741, loss_D: 0.189131\n",
      "[Epoch 36/200] [Batch 570/938] loss_G: 2.800213, loss_D: 0.169005\n",
      "[Epoch 36/200] [Batch 580/938] loss_G: 2.677817, loss_D: 0.229460\n",
      "[Epoch 36/200] [Batch 590/938] loss_G: 2.442253, loss_D: 0.243472\n",
      "[Epoch 36/200] [Batch 600/938] loss_G: 2.587271, loss_D: 0.190084\n",
      "[Epoch 36/200] [Batch 610/938] loss_G: 2.448980, loss_D: 0.256990\n",
      "[Epoch 36/200] [Batch 620/938] loss_G: 3.123776, loss_D: 0.209545\n",
      "[Epoch 36/200] [Batch 630/938] loss_G: 2.884670, loss_D: 0.260671\n",
      "[Epoch 36/200] [Batch 640/938] loss_G: 2.639467, loss_D: 0.215004\n",
      "[Epoch 36/200] [Batch 650/938] loss_G: 2.543754, loss_D: 0.269130\n",
      "[Epoch 36/200] [Batch 660/938] loss_G: 2.997839, loss_D: 0.214749\n",
      "[Epoch 36/200] [Batch 670/938] loss_G: 2.623458, loss_D: 0.320276\n",
      "[Epoch 36/200] [Batch 680/938] loss_G: 2.732628, loss_D: 0.180342\n",
      "[Epoch 36/200] [Batch 690/938] loss_G: 2.809283, loss_D: 0.230840\n",
      "[Epoch 36/200] [Batch 700/938] loss_G: 2.551552, loss_D: 0.307868\n",
      "[Epoch 36/200] [Batch 710/938] loss_G: 2.381481, loss_D: 0.232265\n",
      "[Epoch 36/200] [Batch 720/938] loss_G: 3.208331, loss_D: 0.183748\n",
      "[Epoch 36/200] [Batch 730/938] loss_G: 2.448073, loss_D: 0.256564\n",
      "[Epoch 36/200] [Batch 740/938] loss_G: 2.943453, loss_D: 0.273307\n",
      "[Epoch 36/200] [Batch 750/938] loss_G: 2.914463, loss_D: 0.237610\n",
      "[Epoch 36/200] [Batch 760/938] loss_G: 2.953817, loss_D: 0.205401\n",
      "[Epoch 36/200] [Batch 770/938] loss_G: 3.071127, loss_D: 0.206954\n",
      "[Epoch 36/200] [Batch 780/938] loss_G: 2.928109, loss_D: 0.201240\n",
      "[Epoch 36/200] [Batch 790/938] loss_G: 2.519763, loss_D: 0.201163\n",
      "[Epoch 36/200] [Batch 800/938] loss_G: 3.039136, loss_D: 0.190912\n",
      "[Epoch 36/200] [Batch 810/938] loss_G: 2.427454, loss_D: 0.185894\n",
      "[Epoch 36/200] [Batch 820/938] loss_G: 2.833998, loss_D: 0.261693\n",
      "[Epoch 36/200] [Batch 830/938] loss_G: 2.616161, loss_D: 0.218877\n",
      "[Epoch 36/200] [Batch 840/938] loss_G: 2.580117, loss_D: 0.314672\n",
      "[Epoch 36/200] [Batch 850/938] loss_G: 3.100722, loss_D: 0.230553\n",
      "[Epoch 36/200] [Batch 860/938] loss_G: 2.853199, loss_D: 0.161629\n",
      "[Epoch 36/200] [Batch 870/938] loss_G: 2.955818, loss_D: 0.173554\n",
      "[Epoch 36/200] [Batch 880/938] loss_G: 3.041250, loss_D: 0.194518\n",
      "[Epoch 36/200] [Batch 890/938] loss_G: 3.180681, loss_D: 0.300978\n",
      "[Epoch 36/200] [Batch 900/938] loss_G: 2.749070, loss_D: 0.178025\n",
      "[Epoch 36/200] [Batch 910/938] loss_G: 2.882376, loss_D: 0.318626\n",
      "[Epoch 36/200] [Batch 920/938] loss_G: 2.478199, loss_D: 0.236353\n",
      "[Epoch 36/200] [Batch 930/938] loss_G: 2.868738, loss_D: 0.278106\n",
      "[Epoch 37/200] [Batch 0/938] loss_G: 2.693951, loss_D: 0.248406\n",
      "[Epoch 37/200] [Batch 10/938] loss_G: 2.708007, loss_D: 0.308109\n",
      "[Epoch 37/200] [Batch 20/938] loss_G: 2.797132, loss_D: 0.234467\n",
      "[Epoch 37/200] [Batch 30/938] loss_G: 2.646471, loss_D: 0.212298\n",
      "[Epoch 37/200] [Batch 40/938] loss_G: 2.378238, loss_D: 0.321601\n",
      "[Epoch 37/200] [Batch 50/938] loss_G: 2.301968, loss_D: 0.209940\n",
      "[Epoch 37/200] [Batch 60/938] loss_G: 2.595786, loss_D: 0.228439\n",
      "[Epoch 37/200] [Batch 70/938] loss_G: 3.082193, loss_D: 0.182468\n",
      "[Epoch 37/200] [Batch 80/938] loss_G: 2.368413, loss_D: 0.231670\n",
      "[Epoch 37/200] [Batch 90/938] loss_G: 2.467717, loss_D: 0.269497\n",
      "[Epoch 37/200] [Batch 100/938] loss_G: 2.771053, loss_D: 0.207761\n",
      "[Epoch 37/200] [Batch 110/938] loss_G: 2.855930, loss_D: 0.249718\n",
      "[Epoch 37/200] [Batch 120/938] loss_G: 2.630818, loss_D: 0.197412\n",
      "[Epoch 37/200] [Batch 130/938] loss_G: 2.410797, loss_D: 0.227713\n",
      "[Epoch 37/200] [Batch 140/938] loss_G: 2.192851, loss_D: 0.389313\n",
      "[Epoch 37/200] [Batch 150/938] loss_G: 2.172654, loss_D: 0.364508\n",
      "[Epoch 37/200] [Batch 160/938] loss_G: 2.606293, loss_D: 0.204075\n",
      "[Epoch 37/200] [Batch 170/938] loss_G: 2.536055, loss_D: 0.245352\n",
      "[Epoch 37/200] [Batch 180/938] loss_G: 2.234886, loss_D: 0.302545\n",
      "[Epoch 37/200] [Batch 190/938] loss_G: 2.674993, loss_D: 0.330582\n",
      "[Epoch 37/200] [Batch 200/938] loss_G: 2.732741, loss_D: 0.229217\n",
      "[Epoch 37/200] [Batch 210/938] loss_G: 2.706557, loss_D: 0.241296\n",
      "[Epoch 37/200] [Batch 220/938] loss_G: 2.500087, loss_D: 0.206892\n",
      "[Epoch 37/200] [Batch 230/938] loss_G: 2.951721, loss_D: 0.220965\n",
      "[Epoch 37/200] [Batch 240/938] loss_G: 2.249210, loss_D: 0.218271\n",
      "[Epoch 37/200] [Batch 250/938] loss_G: 2.789579, loss_D: 0.204645\n",
      "[Epoch 37/200] [Batch 260/938] loss_G: 2.471573, loss_D: 0.256102\n",
      "[Epoch 37/200] [Batch 270/938] loss_G: 2.322969, loss_D: 0.255974\n",
      "[Epoch 37/200] [Batch 280/938] loss_G: 2.611552, loss_D: 0.284208\n",
      "[Epoch 37/200] [Batch 290/938] loss_G: 2.701668, loss_D: 0.269403\n",
      "[Epoch 37/200] [Batch 300/938] loss_G: 2.232074, loss_D: 0.276873\n",
      "[Epoch 37/200] [Batch 310/938] loss_G: 2.677069, loss_D: 0.175248\n",
      "[Epoch 37/200] [Batch 320/938] loss_G: 2.431925, loss_D: 0.200375\n",
      "[Epoch 37/200] [Batch 330/938] loss_G: 2.793623, loss_D: 0.232198\n",
      "[Epoch 37/200] [Batch 340/938] loss_G: 2.385356, loss_D: 0.272439\n",
      "[Epoch 37/200] [Batch 350/938] loss_G: 2.447328, loss_D: 0.253806\n",
      "[Epoch 37/200] [Batch 360/938] loss_G: 2.625896, loss_D: 0.246855\n",
      "[Epoch 37/200] [Batch 370/938] loss_G: 2.293780, loss_D: 0.294386\n",
      "[Epoch 37/200] [Batch 380/938] loss_G: 2.345933, loss_D: 0.311545\n",
      "[Epoch 37/200] [Batch 390/938] loss_G: 2.965311, loss_D: 0.249044\n",
      "[Epoch 37/200] [Batch 400/938] loss_G: 2.915411, loss_D: 0.218529\n",
      "[Epoch 37/200] [Batch 410/938] loss_G: 2.949408, loss_D: 0.212927\n",
      "[Epoch 37/200] [Batch 420/938] loss_G: 2.847859, loss_D: 0.252276\n",
      "[Epoch 37/200] [Batch 430/938] loss_G: 2.412792, loss_D: 0.188782\n",
      "[Epoch 37/200] [Batch 440/938] loss_G: 2.550020, loss_D: 0.295065\n",
      "[Epoch 37/200] [Batch 450/938] loss_G: 3.103337, loss_D: 0.166869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 37/200] [Batch 460/938] loss_G: 2.721802, loss_D: 0.359538\n",
      "[Epoch 37/200] [Batch 470/938] loss_G: 2.651651, loss_D: 0.269380\n",
      "[Epoch 37/200] [Batch 480/938] loss_G: 2.442097, loss_D: 0.277048\n",
      "[Epoch 37/200] [Batch 490/938] loss_G: 2.554589, loss_D: 0.250543\n",
      "[Epoch 37/200] [Batch 500/938] loss_G: 2.938012, loss_D: 0.287950\n",
      "[Epoch 37/200] [Batch 510/938] loss_G: 2.948942, loss_D: 0.183667\n",
      "[Epoch 37/200] [Batch 520/938] loss_G: 2.643715, loss_D: 0.233688\n",
      "[Epoch 37/200] [Batch 530/938] loss_G: 2.898401, loss_D: 0.286627\n",
      "[Epoch 37/200] [Batch 540/938] loss_G: 2.887231, loss_D: 0.225497\n",
      "[Epoch 37/200] [Batch 550/938] loss_G: 2.806679, loss_D: 0.245322\n",
      "[Epoch 37/200] [Batch 560/938] loss_G: 2.877526, loss_D: 0.133191\n",
      "[Epoch 37/200] [Batch 570/938] loss_G: 2.528756, loss_D: 0.238014\n",
      "[Epoch 37/200] [Batch 580/938] loss_G: 2.069751, loss_D: 0.282141\n",
      "[Epoch 37/200] [Batch 590/938] loss_G: 2.709064, loss_D: 0.225040\n",
      "[Epoch 37/200] [Batch 600/938] loss_G: 2.860110, loss_D: 0.248181\n",
      "[Epoch 37/200] [Batch 610/938] loss_G: 2.931310, loss_D: 0.192873\n",
      "[Epoch 37/200] [Batch 620/938] loss_G: 2.919139, loss_D: 0.386692\n",
      "[Epoch 37/200] [Batch 630/938] loss_G: 2.506916, loss_D: 0.226855\n",
      "[Epoch 37/200] [Batch 640/938] loss_G: 2.705854, loss_D: 0.207208\n",
      "[Epoch 37/200] [Batch 650/938] loss_G: 2.521772, loss_D: 0.251221\n",
      "[Epoch 37/200] [Batch 660/938] loss_G: 2.714541, loss_D: 0.297468\n",
      "[Epoch 37/200] [Batch 670/938] loss_G: 2.907601, loss_D: 0.201215\n",
      "[Epoch 37/200] [Batch 680/938] loss_G: 2.458421, loss_D: 0.267876\n",
      "[Epoch 37/200] [Batch 690/938] loss_G: 2.930781, loss_D: 0.216627\n",
      "[Epoch 37/200] [Batch 700/938] loss_G: 2.489371, loss_D: 0.351934\n",
      "[Epoch 37/200] [Batch 710/938] loss_G: 2.239776, loss_D: 0.241326\n",
      "[Epoch 37/200] [Batch 720/938] loss_G: 2.106992, loss_D: 0.238349\n",
      "[Epoch 37/200] [Batch 730/938] loss_G: 2.818099, loss_D: 0.227316\n",
      "[Epoch 37/200] [Batch 740/938] loss_G: 2.377754, loss_D: 0.237479\n",
      "[Epoch 37/200] [Batch 750/938] loss_G: 2.662401, loss_D: 0.211784\n",
      "[Epoch 37/200] [Batch 760/938] loss_G: 2.382560, loss_D: 0.219369\n",
      "[Epoch 37/200] [Batch 770/938] loss_G: 2.657390, loss_D: 0.269787\n",
      "[Epoch 37/200] [Batch 780/938] loss_G: 2.849085, loss_D: 0.230508\n",
      "[Epoch 37/200] [Batch 790/938] loss_G: 2.542431, loss_D: 0.258515\n",
      "[Epoch 37/200] [Batch 800/938] loss_G: 2.649757, loss_D: 0.216372\n",
      "[Epoch 37/200] [Batch 810/938] loss_G: 3.067717, loss_D: 0.219166\n",
      "[Epoch 37/200] [Batch 820/938] loss_G: 2.923510, loss_D: 0.247418\n",
      "[Epoch 37/200] [Batch 830/938] loss_G: 2.557355, loss_D: 0.241559\n",
      "[Epoch 37/200] [Batch 840/938] loss_G: 2.877428, loss_D: 0.222924\n",
      "[Epoch 37/200] [Batch 850/938] loss_G: 2.868511, loss_D: 0.262215\n",
      "[Epoch 37/200] [Batch 860/938] loss_G: 2.465961, loss_D: 0.171492\n",
      "[Epoch 37/200] [Batch 870/938] loss_G: 2.601032, loss_D: 0.302051\n",
      "[Epoch 37/200] [Batch 880/938] loss_G: 2.646035, loss_D: 0.146526\n",
      "[Epoch 37/200] [Batch 890/938] loss_G: 2.909066, loss_D: 0.152747\n",
      "[Epoch 37/200] [Batch 900/938] loss_G: 2.420899, loss_D: 0.237622\n",
      "[Epoch 37/200] [Batch 910/938] loss_G: 2.750950, loss_D: 0.280529\n",
      "[Epoch 37/200] [Batch 920/938] loss_G: 2.424413, loss_D: 0.269133\n",
      "[Epoch 37/200] [Batch 930/938] loss_G: 2.672503, loss_D: 0.202313\n",
      "[Epoch 38/200] [Batch 0/938] loss_G: 2.789491, loss_D: 0.199029\n",
      "[Epoch 38/200] [Batch 10/938] loss_G: 2.704673, loss_D: 0.188743\n",
      "[Epoch 38/200] [Batch 20/938] loss_G: 2.624918, loss_D: 0.198276\n",
      "[Epoch 38/200] [Batch 30/938] loss_G: 2.596706, loss_D: 0.253773\n",
      "[Epoch 38/200] [Batch 40/938] loss_G: 2.590387, loss_D: 0.267006\n",
      "[Epoch 38/200] [Batch 50/938] loss_G: 2.517614, loss_D: 0.160712\n",
      "[Epoch 38/200] [Batch 60/938] loss_G: 2.422751, loss_D: 0.114988\n",
      "[Epoch 38/200] [Batch 70/938] loss_G: 2.806204, loss_D: 0.298657\n",
      "[Epoch 38/200] [Batch 80/938] loss_G: 2.798959, loss_D: 0.299920\n",
      "[Epoch 38/200] [Batch 90/938] loss_G: 2.877836, loss_D: 0.220401\n",
      "[Epoch 38/200] [Batch 100/938] loss_G: 2.557640, loss_D: 0.210671\n",
      "[Epoch 38/200] [Batch 110/938] loss_G: 2.563996, loss_D: 0.201760\n",
      "[Epoch 38/200] [Batch 120/938] loss_G: 2.820456, loss_D: 0.242197\n",
      "[Epoch 38/200] [Batch 130/938] loss_G: 2.607620, loss_D: 0.333361\n",
      "[Epoch 38/200] [Batch 140/938] loss_G: 2.406985, loss_D: 0.262748\n",
      "[Epoch 38/200] [Batch 150/938] loss_G: 2.736820, loss_D: 0.200235\n",
      "[Epoch 38/200] [Batch 160/938] loss_G: 2.543564, loss_D: 0.282302\n",
      "[Epoch 38/200] [Batch 170/938] loss_G: 2.853671, loss_D: 0.220784\n",
      "[Epoch 38/200] [Batch 180/938] loss_G: 2.860035, loss_D: 0.314389\n",
      "[Epoch 38/200] [Batch 190/938] loss_G: 2.404948, loss_D: 0.253655\n",
      "[Epoch 38/200] [Batch 200/938] loss_G: 2.597437, loss_D: 0.335721\n",
      "[Epoch 38/200] [Batch 210/938] loss_G: 2.370320, loss_D: 0.241751\n",
      "[Epoch 38/200] [Batch 220/938] loss_G: 2.916672, loss_D: 0.190596\n",
      "[Epoch 38/200] [Batch 230/938] loss_G: 2.831517, loss_D: 0.256143\n",
      "[Epoch 38/200] [Batch 240/938] loss_G: 2.686637, loss_D: 0.348129\n",
      "[Epoch 38/200] [Batch 250/938] loss_G: 2.761298, loss_D: 0.167190\n",
      "[Epoch 38/200] [Batch 260/938] loss_G: 2.976942, loss_D: 0.267783\n",
      "[Epoch 38/200] [Batch 270/938] loss_G: 2.958757, loss_D: 0.191175\n",
      "[Epoch 38/200] [Batch 280/938] loss_G: 2.572425, loss_D: 0.235051\n",
      "[Epoch 38/200] [Batch 290/938] loss_G: 3.164855, loss_D: 0.124734\n",
      "[Epoch 38/200] [Batch 300/938] loss_G: 2.299900, loss_D: 0.188140\n",
      "[Epoch 38/200] [Batch 310/938] loss_G: 2.281478, loss_D: 0.300626\n",
      "[Epoch 38/200] [Batch 320/938] loss_G: 2.729371, loss_D: 0.247247\n",
      "[Epoch 38/200] [Batch 330/938] loss_G: 2.743879, loss_D: 0.242047\n",
      "[Epoch 38/200] [Batch 340/938] loss_G: 2.756970, loss_D: 0.270487\n",
      "[Epoch 38/200] [Batch 350/938] loss_G: 2.567770, loss_D: 0.266468\n",
      "[Epoch 38/200] [Batch 360/938] loss_G: 2.573400, loss_D: 0.297442\n",
      "[Epoch 38/200] [Batch 370/938] loss_G: 2.379766, loss_D: 0.269836\n",
      "[Epoch 38/200] [Batch 380/938] loss_G: 2.794967, loss_D: 0.285442\n",
      "[Epoch 38/200] [Batch 390/938] loss_G: 2.477724, loss_D: 0.226996\n",
      "[Epoch 38/200] [Batch 400/938] loss_G: 2.533673, loss_D: 0.156548\n",
      "[Epoch 38/200] [Batch 410/938] loss_G: 2.615317, loss_D: 0.175660\n",
      "[Epoch 38/200] [Batch 420/938] loss_G: 2.901917, loss_D: 0.214789\n",
      "[Epoch 38/200] [Batch 430/938] loss_G: 2.496558, loss_D: 0.207654\n",
      "[Epoch 38/200] [Batch 440/938] loss_G: 2.514065, loss_D: 0.343313\n",
      "[Epoch 38/200] [Batch 450/938] loss_G: 2.301667, loss_D: 0.405606\n",
      "[Epoch 38/200] [Batch 460/938] loss_G: 2.233806, loss_D: 0.240563\n",
      "[Epoch 38/200] [Batch 470/938] loss_G: 2.385325, loss_D: 0.221210\n",
      "[Epoch 38/200] [Batch 480/938] loss_G: 2.239225, loss_D: 0.271020\n",
      "[Epoch 38/200] [Batch 490/938] loss_G: 3.079578, loss_D: 0.218141\n",
      "[Epoch 38/200] [Batch 500/938] loss_G: 2.313498, loss_D: 0.146547\n",
      "[Epoch 38/200] [Batch 510/938] loss_G: 2.502886, loss_D: 0.337598\n",
      "[Epoch 38/200] [Batch 520/938] loss_G: 2.541344, loss_D: 0.321056\n",
      "[Epoch 38/200] [Batch 530/938] loss_G: 3.180020, loss_D: 0.174565\n",
      "[Epoch 38/200] [Batch 540/938] loss_G: 2.675509, loss_D: 0.244088\n",
      "[Epoch 38/200] [Batch 550/938] loss_G: 2.418542, loss_D: 0.236344\n",
      "[Epoch 38/200] [Batch 560/938] loss_G: 2.682631, loss_D: 0.189587\n",
      "[Epoch 38/200] [Batch 570/938] loss_G: 2.755698, loss_D: 0.191940\n",
      "[Epoch 38/200] [Batch 580/938] loss_G: 2.668306, loss_D: 0.200311\n",
      "[Epoch 38/200] [Batch 590/938] loss_G: 2.344632, loss_D: 0.163398\n",
      "[Epoch 38/200] [Batch 600/938] loss_G: 2.775156, loss_D: 0.208667\n",
      "[Epoch 38/200] [Batch 610/938] loss_G: 2.693886, loss_D: 0.243042\n",
      "[Epoch 38/200] [Batch 620/938] loss_G: 2.648587, loss_D: 0.233855\n",
      "[Epoch 38/200] [Batch 630/938] loss_G: 3.180680, loss_D: 0.233053\n",
      "[Epoch 38/200] [Batch 640/938] loss_G: 2.927182, loss_D: 0.134989\n",
      "[Epoch 38/200] [Batch 650/938] loss_G: 2.873891, loss_D: 0.230997\n",
      "[Epoch 38/200] [Batch 660/938] loss_G: 2.391023, loss_D: 0.280200\n",
      "[Epoch 38/200] [Batch 670/938] loss_G: 2.955654, loss_D: 0.233474\n",
      "[Epoch 38/200] [Batch 680/938] loss_G: 2.543803, loss_D: 0.273849\n",
      "[Epoch 38/200] [Batch 690/938] loss_G: 2.809415, loss_D: 0.194152\n",
      "[Epoch 38/200] [Batch 700/938] loss_G: 2.780351, loss_D: 0.220446\n",
      "[Epoch 38/200] [Batch 710/938] loss_G: 2.476949, loss_D: 0.208751\n",
      "[Epoch 38/200] [Batch 720/938] loss_G: 2.659727, loss_D: 0.249745\n",
      "[Epoch 38/200] [Batch 730/938] loss_G: 2.051816, loss_D: 0.293368\n",
      "[Epoch 38/200] [Batch 740/938] loss_G: 2.384695, loss_D: 0.367662\n",
      "[Epoch 38/200] [Batch 750/938] loss_G: 2.410001, loss_D: 0.243162\n",
      "[Epoch 38/200] [Batch 760/938] loss_G: 2.646579, loss_D: 0.230018\n",
      "[Epoch 38/200] [Batch 770/938] loss_G: 2.882847, loss_D: 0.215177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 38/200] [Batch 780/938] loss_G: 2.895980, loss_D: 0.251522\n",
      "[Epoch 38/200] [Batch 790/938] loss_G: 2.459040, loss_D: 0.212523\n",
      "[Epoch 38/200] [Batch 800/938] loss_G: 2.950991, loss_D: 0.329127\n",
      "[Epoch 38/200] [Batch 810/938] loss_G: 2.679066, loss_D: 0.348010\n",
      "[Epoch 38/200] [Batch 820/938] loss_G: 2.683614, loss_D: 0.364541\n",
      "[Epoch 38/200] [Batch 830/938] loss_G: 3.409369, loss_D: 0.188874\n",
      "[Epoch 38/200] [Batch 840/938] loss_G: 2.610685, loss_D: 0.207207\n",
      "[Epoch 38/200] [Batch 850/938] loss_G: 2.839977, loss_D: 0.264073\n",
      "[Epoch 38/200] [Batch 860/938] loss_G: 2.765032, loss_D: 0.204322\n",
      "[Epoch 38/200] [Batch 870/938] loss_G: 2.570085, loss_D: 0.291369\n",
      "[Epoch 38/200] [Batch 880/938] loss_G: 2.628937, loss_D: 0.185159\n",
      "[Epoch 38/200] [Batch 890/938] loss_G: 3.035974, loss_D: 0.259635\n",
      "[Epoch 38/200] [Batch 900/938] loss_G: 2.800040, loss_D: 0.198230\n",
      "[Epoch 38/200] [Batch 910/938] loss_G: 2.817527, loss_D: 0.195253\n",
      "[Epoch 38/200] [Batch 920/938] loss_G: 2.163257, loss_D: 0.341598\n",
      "[Epoch 38/200] [Batch 930/938] loss_G: 3.021665, loss_D: 0.192226\n",
      "[Epoch 39/200] [Batch 0/938] loss_G: 2.670172, loss_D: 0.172831\n",
      "[Epoch 39/200] [Batch 10/938] loss_G: 3.187949, loss_D: 0.175875\n",
      "[Epoch 39/200] [Batch 20/938] loss_G: 2.344718, loss_D: 0.245319\n",
      "[Epoch 39/200] [Batch 30/938] loss_G: 2.636905, loss_D: 0.320414\n",
      "[Epoch 39/200] [Batch 40/938] loss_G: 2.361312, loss_D: 0.285759\n",
      "[Epoch 39/200] [Batch 50/938] loss_G: 2.701384, loss_D: 0.173997\n",
      "[Epoch 39/200] [Batch 60/938] loss_G: 2.672336, loss_D: 0.224744\n",
      "[Epoch 39/200] [Batch 70/938] loss_G: 2.746290, loss_D: 0.286116\n",
      "[Epoch 39/200] [Batch 80/938] loss_G: 2.392239, loss_D: 0.205763\n",
      "[Epoch 39/200] [Batch 90/938] loss_G: 2.841173, loss_D: 0.173501\n",
      "[Epoch 39/200] [Batch 100/938] loss_G: 2.789544, loss_D: 0.178205\n",
      "[Epoch 39/200] [Batch 110/938] loss_G: 2.791558, loss_D: 0.191782\n",
      "[Epoch 39/200] [Batch 120/938] loss_G: 2.243506, loss_D: 0.188311\n",
      "[Epoch 39/200] [Batch 130/938] loss_G: 2.365107, loss_D: 0.248750\n",
      "[Epoch 39/200] [Batch 140/938] loss_G: 2.728582, loss_D: 0.237580\n",
      "[Epoch 39/200] [Batch 150/938] loss_G: 2.586016, loss_D: 0.226305\n",
      "[Epoch 39/200] [Batch 160/938] loss_G: 2.759234, loss_D: 0.212015\n",
      "[Epoch 39/200] [Batch 170/938] loss_G: 2.578695, loss_D: 0.210864\n",
      "[Epoch 39/200] [Batch 180/938] loss_G: 2.533794, loss_D: 0.213530\n",
      "[Epoch 39/200] [Batch 190/938] loss_G: 2.569534, loss_D: 0.154549\n",
      "[Epoch 39/200] [Batch 200/938] loss_G: 2.857507, loss_D: 0.219116\n",
      "[Epoch 39/200] [Batch 210/938] loss_G: 2.666182, loss_D: 0.226036\n",
      "[Epoch 39/200] [Batch 220/938] loss_G: 2.320299, loss_D: 0.177325\n",
      "[Epoch 39/200] [Batch 230/938] loss_G: 2.668145, loss_D: 0.169661\n",
      "[Epoch 39/200] [Batch 240/938] loss_G: 2.543210, loss_D: 0.145365\n",
      "[Epoch 39/200] [Batch 250/938] loss_G: 2.315926, loss_D: 0.254837\n",
      "[Epoch 39/200] [Batch 260/938] loss_G: 2.626712, loss_D: 0.246656\n",
      "[Epoch 39/200] [Batch 270/938] loss_G: 2.664086, loss_D: 0.229154\n",
      "[Epoch 39/200] [Batch 280/938] loss_G: 2.680709, loss_D: 0.180354\n",
      "[Epoch 39/200] [Batch 290/938] loss_G: 2.733170, loss_D: 0.252004\n",
      "[Epoch 39/200] [Batch 300/938] loss_G: 2.628011, loss_D: 0.223685\n",
      "[Epoch 39/200] [Batch 310/938] loss_G: 3.111989, loss_D: 0.201651\n",
      "[Epoch 39/200] [Batch 320/938] loss_G: 2.885496, loss_D: 0.155236\n",
      "[Epoch 39/200] [Batch 330/938] loss_G: 2.715832, loss_D: 0.212091\n",
      "[Epoch 39/200] [Batch 340/938] loss_G: 2.607306, loss_D: 0.173139\n",
      "[Epoch 39/200] [Batch 350/938] loss_G: 2.524115, loss_D: 0.232334\n",
      "[Epoch 39/200] [Batch 360/938] loss_G: 2.244089, loss_D: 0.225670\n",
      "[Epoch 39/200] [Batch 370/938] loss_G: 2.822521, loss_D: 0.166612\n",
      "[Epoch 39/200] [Batch 380/938] loss_G: 2.678122, loss_D: 0.259177\n",
      "[Epoch 39/200] [Batch 390/938] loss_G: 2.705435, loss_D: 0.197974\n",
      "[Epoch 39/200] [Batch 400/938] loss_G: 2.980494, loss_D: 0.133845\n",
      "[Epoch 39/200] [Batch 410/938] loss_G: 2.683212, loss_D: 0.227301\n",
      "[Epoch 39/200] [Batch 420/938] loss_G: 2.641812, loss_D: 0.247265\n",
      "[Epoch 39/200] [Batch 430/938] loss_G: 2.569347, loss_D: 0.274921\n",
      "[Epoch 39/200] [Batch 440/938] loss_G: 2.624760, loss_D: 0.297809\n",
      "[Epoch 39/200] [Batch 450/938] loss_G: 2.778557, loss_D: 0.234144\n",
      "[Epoch 39/200] [Batch 460/938] loss_G: 2.522018, loss_D: 0.218824\n",
      "[Epoch 39/200] [Batch 470/938] loss_G: 3.108520, loss_D: 0.229961\n",
      "[Epoch 39/200] [Batch 480/938] loss_G: 2.576938, loss_D: 0.159904\n",
      "[Epoch 39/200] [Batch 490/938] loss_G: 3.125788, loss_D: 0.214432\n",
      "[Epoch 39/200] [Batch 500/938] loss_G: 2.529381, loss_D: 0.309033\n",
      "[Epoch 39/200] [Batch 510/938] loss_G: 2.819306, loss_D: 0.205585\n",
      "[Epoch 39/200] [Batch 520/938] loss_G: 2.862289, loss_D: 0.212933\n",
      "[Epoch 39/200] [Batch 530/938] loss_G: 2.755622, loss_D: 0.220317\n",
      "[Epoch 39/200] [Batch 540/938] loss_G: 2.917295, loss_D: 0.294051\n",
      "[Epoch 39/200] [Batch 550/938] loss_G: 2.347699, loss_D: 0.216883\n",
      "[Epoch 39/200] [Batch 560/938] loss_G: 3.007962, loss_D: 0.196484\n",
      "[Epoch 39/200] [Batch 570/938] loss_G: 2.680385, loss_D: 0.192885\n",
      "[Epoch 39/200] [Batch 580/938] loss_G: 2.779964, loss_D: 0.168089\n",
      "[Epoch 39/200] [Batch 590/938] loss_G: 2.513933, loss_D: 0.241431\n",
      "[Epoch 39/200] [Batch 600/938] loss_G: 2.134252, loss_D: 0.288617\n",
      "[Epoch 39/200] [Batch 610/938] loss_G: 2.781783, loss_D: 0.225290\n",
      "[Epoch 39/200] [Batch 620/938] loss_G: 2.819988, loss_D: 0.240446\n",
      "[Epoch 39/200] [Batch 630/938] loss_G: 2.242008, loss_D: 0.258420\n",
      "[Epoch 39/200] [Batch 640/938] loss_G: 2.720802, loss_D: 0.167555\n",
      "[Epoch 39/200] [Batch 650/938] loss_G: 2.539599, loss_D: 0.228767\n",
      "[Epoch 39/200] [Batch 660/938] loss_G: 2.297643, loss_D: 0.196685\n",
      "[Epoch 39/200] [Batch 670/938] loss_G: 2.375555, loss_D: 0.242955\n",
      "[Epoch 39/200] [Batch 680/938] loss_G: 2.432620, loss_D: 0.274236\n",
      "[Epoch 39/200] [Batch 690/938] loss_G: 2.356866, loss_D: 0.264508\n",
      "[Epoch 39/200] [Batch 700/938] loss_G: 2.710774, loss_D: 0.246599\n",
      "[Epoch 39/200] [Batch 710/938] loss_G: 2.481455, loss_D: 0.245282\n",
      "[Epoch 39/200] [Batch 720/938] loss_G: 2.541183, loss_D: 0.248057\n",
      "[Epoch 39/200] [Batch 730/938] loss_G: 2.860100, loss_D: 0.187207\n",
      "[Epoch 39/200] [Batch 740/938] loss_G: 2.678795, loss_D: 0.273054\n",
      "[Epoch 39/200] [Batch 750/938] loss_G: 3.190179, loss_D: 0.111527\n",
      "[Epoch 39/200] [Batch 760/938] loss_G: 2.586546, loss_D: 0.198716\n",
      "[Epoch 39/200] [Batch 770/938] loss_G: 2.983763, loss_D: 0.274898\n",
      "[Epoch 39/200] [Batch 780/938] loss_G: 3.073488, loss_D: 0.227193\n",
      "[Epoch 39/200] [Batch 790/938] loss_G: 2.686072, loss_D: 0.190057\n",
      "[Epoch 39/200] [Batch 800/938] loss_G: 2.767156, loss_D: 0.160791\n",
      "[Epoch 39/200] [Batch 810/938] loss_G: 2.414885, loss_D: 0.286909\n",
      "[Epoch 39/200] [Batch 820/938] loss_G: 2.841379, loss_D: 0.225366\n",
      "[Epoch 39/200] [Batch 830/938] loss_G: 2.383564, loss_D: 0.217780\n",
      "[Epoch 39/200] [Batch 840/938] loss_G: 2.940357, loss_D: 0.215678\n",
      "[Epoch 39/200] [Batch 850/938] loss_G: 2.517851, loss_D: 0.237526\n",
      "[Epoch 39/200] [Batch 860/938] loss_G: 2.389500, loss_D: 0.314626\n",
      "[Epoch 39/200] [Batch 870/938] loss_G: 2.533937, loss_D: 0.189169\n",
      "[Epoch 39/200] [Batch 880/938] loss_G: 2.745767, loss_D: 0.253768\n",
      "[Epoch 39/200] [Batch 890/938] loss_G: 2.700212, loss_D: 0.248396\n",
      "[Epoch 39/200] [Batch 900/938] loss_G: 2.688595, loss_D: 0.229149\n",
      "[Epoch 39/200] [Batch 910/938] loss_G: 2.316234, loss_D: 0.311064\n",
      "[Epoch 39/200] [Batch 920/938] loss_G: 2.788388, loss_D: 0.184106\n",
      "[Epoch 39/200] [Batch 930/938] loss_G: 2.822983, loss_D: 0.244451\n",
      "[Epoch 40/200] [Batch 0/938] loss_G: 2.458868, loss_D: 0.195573\n",
      "[Epoch 40/200] [Batch 10/938] loss_G: 2.608229, loss_D: 0.258986\n",
      "[Epoch 40/200] [Batch 20/938] loss_G: 2.751912, loss_D: 0.170036\n",
      "[Epoch 40/200] [Batch 30/938] loss_G: 2.777347, loss_D: 0.253391\n",
      "[Epoch 40/200] [Batch 40/938] loss_G: 2.692060, loss_D: 0.194778\n",
      "[Epoch 40/200] [Batch 50/938] loss_G: 2.883936, loss_D: 0.207657\n",
      "[Epoch 40/200] [Batch 60/938] loss_G: 2.662211, loss_D: 0.216470\n",
      "[Epoch 40/200] [Batch 70/938] loss_G: 2.706315, loss_D: 0.198399\n",
      "[Epoch 40/200] [Batch 80/938] loss_G: 2.568662, loss_D: 0.197922\n",
      "[Epoch 40/200] [Batch 90/938] loss_G: 2.838179, loss_D: 0.205300\n",
      "[Epoch 40/200] [Batch 100/938] loss_G: 2.825319, loss_D: 0.265291\n",
      "[Epoch 40/200] [Batch 110/938] loss_G: 2.545328, loss_D: 0.294331\n",
      "[Epoch 40/200] [Batch 120/938] loss_G: 2.682805, loss_D: 0.215649\n",
      "[Epoch 40/200] [Batch 130/938] loss_G: 2.465655, loss_D: 0.251519\n",
      "[Epoch 40/200] [Batch 140/938] loss_G: 2.985116, loss_D: 0.204359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 40/200] [Batch 150/938] loss_G: 2.966887, loss_D: 0.161430\n",
      "[Epoch 40/200] [Batch 160/938] loss_G: 2.430051, loss_D: 0.282072\n",
      "[Epoch 40/200] [Batch 170/938] loss_G: 2.597975, loss_D: 0.206522\n",
      "[Epoch 40/200] [Batch 180/938] loss_G: 2.753675, loss_D: 0.290228\n",
      "[Epoch 40/200] [Batch 190/938] loss_G: 3.092645, loss_D: 0.146814\n",
      "[Epoch 40/200] [Batch 200/938] loss_G: 2.978350, loss_D: 0.225122\n",
      "[Epoch 40/200] [Batch 210/938] loss_G: 2.900235, loss_D: 0.207163\n",
      "[Epoch 40/200] [Batch 220/938] loss_G: 2.353932, loss_D: 0.222183\n",
      "[Epoch 40/200] [Batch 230/938] loss_G: 2.514705, loss_D: 0.284832\n",
      "[Epoch 40/200] [Batch 240/938] loss_G: 2.889993, loss_D: 0.212498\n",
      "[Epoch 40/200] [Batch 250/938] loss_G: 3.192811, loss_D: 0.168268\n",
      "[Epoch 40/200] [Batch 260/938] loss_G: 2.667226, loss_D: 0.236779\n",
      "[Epoch 40/200] [Batch 270/938] loss_G: 2.566757, loss_D: 0.195087\n",
      "[Epoch 40/200] [Batch 280/938] loss_G: 2.616083, loss_D: 0.182657\n",
      "[Epoch 40/200] [Batch 290/938] loss_G: 2.260487, loss_D: 0.221974\n",
      "[Epoch 40/200] [Batch 300/938] loss_G: 3.173355, loss_D: 0.180381\n",
      "[Epoch 40/200] [Batch 310/938] loss_G: 2.721478, loss_D: 0.266527\n",
      "[Epoch 40/200] [Batch 320/938] loss_G: 2.443372, loss_D: 0.179459\n",
      "[Epoch 40/200] [Batch 330/938] loss_G: 2.551922, loss_D: 0.289276\n",
      "[Epoch 40/200] [Batch 340/938] loss_G: 2.591856, loss_D: 0.284591\n",
      "[Epoch 40/200] [Batch 350/938] loss_G: 2.733171, loss_D: 0.164560\n",
      "[Epoch 40/200] [Batch 360/938] loss_G: 2.673634, loss_D: 0.259541\n",
      "[Epoch 40/200] [Batch 370/938] loss_G: 2.896312, loss_D: 0.221482\n",
      "[Epoch 40/200] [Batch 380/938] loss_G: 2.699471, loss_D: 0.207387\n",
      "[Epoch 40/200] [Batch 390/938] loss_G: 2.913262, loss_D: 0.284196\n",
      "[Epoch 40/200] [Batch 400/938] loss_G: 2.843418, loss_D: 0.187659\n",
      "[Epoch 40/200] [Batch 410/938] loss_G: 2.988569, loss_D: 0.174194\n",
      "[Epoch 40/200] [Batch 420/938] loss_G: 3.190251, loss_D: 0.242951\n",
      "[Epoch 40/200] [Batch 430/938] loss_G: 2.993188, loss_D: 0.229263\n",
      "[Epoch 40/200] [Batch 440/938] loss_G: 2.944661, loss_D: 0.341094\n",
      "[Epoch 40/200] [Batch 450/938] loss_G: 3.429274, loss_D: 0.169762\n",
      "[Epoch 40/200] [Batch 460/938] loss_G: 2.909521, loss_D: 0.150859\n",
      "[Epoch 40/200] [Batch 470/938] loss_G: 2.596090, loss_D: 0.276236\n",
      "[Epoch 40/200] [Batch 480/938] loss_G: 2.903252, loss_D: 0.195467\n",
      "[Epoch 40/200] [Batch 490/938] loss_G: 2.871715, loss_D: 0.214275\n",
      "[Epoch 40/200] [Batch 500/938] loss_G: 3.176356, loss_D: 0.212901\n",
      "[Epoch 40/200] [Batch 510/938] loss_G: 2.734495, loss_D: 0.281014\n",
      "[Epoch 40/200] [Batch 520/938] loss_G: 2.861139, loss_D: 0.277512\n",
      "[Epoch 40/200] [Batch 530/938] loss_G: 2.593098, loss_D: 0.240871\n",
      "[Epoch 40/200] [Batch 540/938] loss_G: 2.646419, loss_D: 0.274470\n",
      "[Epoch 40/200] [Batch 550/938] loss_G: 2.945410, loss_D: 0.182089\n",
      "[Epoch 40/200] [Batch 560/938] loss_G: 2.722816, loss_D: 0.268368\n",
      "[Epoch 40/200] [Batch 570/938] loss_G: 2.681072, loss_D: 0.274747\n",
      "[Epoch 40/200] [Batch 580/938] loss_G: 2.483506, loss_D: 0.248241\n",
      "[Epoch 40/200] [Batch 590/938] loss_G: 2.941644, loss_D: 0.229675\n",
      "[Epoch 40/200] [Batch 600/938] loss_G: 2.871740, loss_D: 0.179579\n",
      "[Epoch 40/200] [Batch 610/938] loss_G: 2.696916, loss_D: 0.250765\n",
      "[Epoch 40/200] [Batch 620/938] loss_G: 2.520622, loss_D: 0.170605\n",
      "[Epoch 40/200] [Batch 630/938] loss_G: 2.463919, loss_D: 0.170656\n",
      "[Epoch 40/200] [Batch 640/938] loss_G: 2.525242, loss_D: 0.256547\n",
      "[Epoch 40/200] [Batch 650/938] loss_G: 2.714431, loss_D: 0.144354\n",
      "[Epoch 40/200] [Batch 660/938] loss_G: 2.755029, loss_D: 0.174685\n",
      "[Epoch 40/200] [Batch 670/938] loss_G: 2.562518, loss_D: 0.252474\n",
      "[Epoch 40/200] [Batch 680/938] loss_G: 2.453775, loss_D: 0.282707\n",
      "[Epoch 40/200] [Batch 690/938] loss_G: 2.620725, loss_D: 0.354637\n",
      "[Epoch 40/200] [Batch 700/938] loss_G: 2.662068, loss_D: 0.255462\n",
      "[Epoch 40/200] [Batch 710/938] loss_G: 3.039221, loss_D: 0.209290\n",
      "[Epoch 40/200] [Batch 720/938] loss_G: 2.736012, loss_D: 0.195059\n",
      "[Epoch 40/200] [Batch 730/938] loss_G: 2.896618, loss_D: 0.203800\n",
      "[Epoch 40/200] [Batch 740/938] loss_G: 2.506361, loss_D: 0.214291\n",
      "[Epoch 40/200] [Batch 750/938] loss_G: 2.601230, loss_D: 0.239306\n",
      "[Epoch 40/200] [Batch 760/938] loss_G: 2.167639, loss_D: 0.227448\n",
      "[Epoch 40/200] [Batch 770/938] loss_G: 2.866185, loss_D: 0.217628\n",
      "[Epoch 40/200] [Batch 780/938] loss_G: 2.709215, loss_D: 0.150976\n",
      "[Epoch 40/200] [Batch 790/938] loss_G: 2.710193, loss_D: 0.276388\n",
      "[Epoch 40/200] [Batch 800/938] loss_G: 2.795541, loss_D: 0.267183\n",
      "[Epoch 40/200] [Batch 810/938] loss_G: 2.781360, loss_D: 0.227303\n",
      "[Epoch 40/200] [Batch 820/938] loss_G: 2.741960, loss_D: 0.185846\n",
      "[Epoch 40/200] [Batch 830/938] loss_G: 2.829980, loss_D: 0.267136\n",
      "[Epoch 40/200] [Batch 840/938] loss_G: 3.062432, loss_D: 0.146718\n",
      "[Epoch 40/200] [Batch 850/938] loss_G: 2.672329, loss_D: 0.207109\n",
      "[Epoch 40/200] [Batch 860/938] loss_G: 2.696966, loss_D: 0.268533\n",
      "[Epoch 40/200] [Batch 870/938] loss_G: 2.672688, loss_D: 0.197304\n",
      "[Epoch 40/200] [Batch 880/938] loss_G: 2.772401, loss_D: 0.209742\n",
      "[Epoch 40/200] [Batch 890/938] loss_G: 2.979861, loss_D: 0.235457\n",
      "[Epoch 40/200] [Batch 900/938] loss_G: 2.713831, loss_D: 0.194269\n",
      "[Epoch 40/200] [Batch 910/938] loss_G: 2.771689, loss_D: 0.211040\n",
      "[Epoch 40/200] [Batch 920/938] loss_G: 2.930190, loss_D: 0.299873\n",
      "[Epoch 40/200] [Batch 930/938] loss_G: 2.701550, loss_D: 0.209892\n",
      "[Epoch 41/200] [Batch 0/938] loss_G: 3.398373, loss_D: 0.180319\n",
      "[Epoch 41/200] [Batch 10/938] loss_G: 2.736274, loss_D: 0.324620\n",
      "[Epoch 41/200] [Batch 20/938] loss_G: 2.820502, loss_D: 0.289186\n",
      "[Epoch 41/200] [Batch 30/938] loss_G: 2.825892, loss_D: 0.328141\n",
      "[Epoch 41/200] [Batch 40/938] loss_G: 2.498069, loss_D: 0.283995\n",
      "[Epoch 41/200] [Batch 50/938] loss_G: 2.814895, loss_D: 0.229446\n",
      "[Epoch 41/200] [Batch 60/938] loss_G: 2.740890, loss_D: 0.120040\n",
      "[Epoch 41/200] [Batch 70/938] loss_G: 2.733989, loss_D: 0.245764\n",
      "[Epoch 41/200] [Batch 80/938] loss_G: 2.768912, loss_D: 0.274266\n",
      "[Epoch 41/200] [Batch 90/938] loss_G: 2.949463, loss_D: 0.240151\n",
      "[Epoch 41/200] [Batch 100/938] loss_G: 2.650373, loss_D: 0.193094\n",
      "[Epoch 41/200] [Batch 110/938] loss_G: 2.504306, loss_D: 0.268799\n",
      "[Epoch 41/200] [Batch 120/938] loss_G: 2.495522, loss_D: 0.180741\n",
      "[Epoch 41/200] [Batch 130/938] loss_G: 2.405087, loss_D: 0.289831\n",
      "[Epoch 41/200] [Batch 140/938] loss_G: 2.942981, loss_D: 0.195873\n",
      "[Epoch 41/200] [Batch 150/938] loss_G: 3.080190, loss_D: 0.200840\n",
      "[Epoch 41/200] [Batch 160/938] loss_G: 2.914331, loss_D: 0.251494\n",
      "[Epoch 41/200] [Batch 170/938] loss_G: 2.809860, loss_D: 0.275660\n",
      "[Epoch 41/200] [Batch 180/938] loss_G: 3.173077, loss_D: 0.193301\n",
      "[Epoch 41/200] [Batch 190/938] loss_G: 2.734443, loss_D: 0.217677\n",
      "[Epoch 41/200] [Batch 200/938] loss_G: 2.745414, loss_D: 0.166075\n",
      "[Epoch 41/200] [Batch 210/938] loss_G: 3.087962, loss_D: 0.192831\n",
      "[Epoch 41/200] [Batch 220/938] loss_G: 2.718554, loss_D: 0.206617\n",
      "[Epoch 41/200] [Batch 230/938] loss_G: 2.761934, loss_D: 0.211534\n",
      "[Epoch 41/200] [Batch 240/938] loss_G: 2.501468, loss_D: 0.196577\n",
      "[Epoch 41/200] [Batch 250/938] loss_G: 2.806278, loss_D: 0.282512\n",
      "[Epoch 41/200] [Batch 260/938] loss_G: 2.520692, loss_D: 0.295681\n",
      "[Epoch 41/200] [Batch 270/938] loss_G: 2.832569, loss_D: 0.286146\n",
      "[Epoch 41/200] [Batch 280/938] loss_G: 3.290930, loss_D: 0.301682\n",
      "[Epoch 41/200] [Batch 290/938] loss_G: 2.650314, loss_D: 0.327166\n",
      "[Epoch 41/200] [Batch 300/938] loss_G: 2.820123, loss_D: 0.163141\n",
      "[Epoch 41/200] [Batch 310/938] loss_G: 2.500088, loss_D: 0.316619\n",
      "[Epoch 41/200] [Batch 320/938] loss_G: 2.586555, loss_D: 0.223565\n",
      "[Epoch 41/200] [Batch 330/938] loss_G: 2.580788, loss_D: 0.244816\n",
      "[Epoch 41/200] [Batch 340/938] loss_G: 2.581161, loss_D: 0.256281\n",
      "[Epoch 41/200] [Batch 350/938] loss_G: 2.649800, loss_D: 0.218614\n",
      "[Epoch 41/200] [Batch 360/938] loss_G: 2.749793, loss_D: 0.176486\n",
      "[Epoch 41/200] [Batch 370/938] loss_G: 2.871793, loss_D: 0.180951\n",
      "[Epoch 41/200] [Batch 380/938] loss_G: 2.541125, loss_D: 0.229006\n",
      "[Epoch 41/200] [Batch 390/938] loss_G: 2.432387, loss_D: 0.250634\n",
      "[Epoch 41/200] [Batch 400/938] loss_G: 2.509414, loss_D: 0.204686\n",
      "[Epoch 41/200] [Batch 410/938] loss_G: 2.338512, loss_D: 0.239348\n",
      "[Epoch 41/200] [Batch 420/938] loss_G: 2.716473, loss_D: 0.281518\n",
      "[Epoch 41/200] [Batch 430/938] loss_G: 2.788049, loss_D: 0.148846\n",
      "[Epoch 41/200] [Batch 440/938] loss_G: 2.327710, loss_D: 0.272362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 41/200] [Batch 450/938] loss_G: 2.772327, loss_D: 0.273945\n",
      "[Epoch 41/200] [Batch 460/938] loss_G: 3.056582, loss_D: 0.192671\n",
      "[Epoch 41/200] [Batch 470/938] loss_G: 2.842668, loss_D: 0.168402\n",
      "[Epoch 41/200] [Batch 480/938] loss_G: 3.088208, loss_D: 0.109913\n",
      "[Epoch 41/200] [Batch 490/938] loss_G: 2.789269, loss_D: 0.186388\n",
      "[Epoch 41/200] [Batch 500/938] loss_G: 2.910290, loss_D: 0.208796\n",
      "[Epoch 41/200] [Batch 510/938] loss_G: 2.605013, loss_D: 0.277770\n",
      "[Epoch 41/200] [Batch 520/938] loss_G: 3.216395, loss_D: 0.225479\n",
      "[Epoch 41/200] [Batch 530/938] loss_G: 2.370950, loss_D: 0.215290\n",
      "[Epoch 41/200] [Batch 540/938] loss_G: 2.355207, loss_D: 0.236309\n",
      "[Epoch 41/200] [Batch 550/938] loss_G: 3.052815, loss_D: 0.387284\n",
      "[Epoch 41/200] [Batch 560/938] loss_G: 2.397005, loss_D: 0.241052\n",
      "[Epoch 41/200] [Batch 570/938] loss_G: 3.400435, loss_D: 0.151075\n",
      "[Epoch 41/200] [Batch 580/938] loss_G: 2.570992, loss_D: 0.264577\n",
      "[Epoch 41/200] [Batch 590/938] loss_G: 2.628506, loss_D: 0.274779\n",
      "[Epoch 41/200] [Batch 600/938] loss_G: 2.799226, loss_D: 0.190646\n",
      "[Epoch 41/200] [Batch 610/938] loss_G: 2.159130, loss_D: 0.295847\n",
      "[Epoch 41/200] [Batch 620/938] loss_G: 2.764320, loss_D: 0.208146\n",
      "[Epoch 41/200] [Batch 630/938] loss_G: 2.951093, loss_D: 0.142338\n",
      "[Epoch 41/200] [Batch 640/938] loss_G: 2.761784, loss_D: 0.269224\n",
      "[Epoch 41/200] [Batch 650/938] loss_G: 2.839996, loss_D: 0.210208\n",
      "[Epoch 41/200] [Batch 660/938] loss_G: 2.787310, loss_D: 0.248707\n",
      "[Epoch 41/200] [Batch 670/938] loss_G: 2.273979, loss_D: 0.260068\n",
      "[Epoch 41/200] [Batch 680/938] loss_G: 2.482660, loss_D: 0.282773\n",
      "[Epoch 41/200] [Batch 690/938] loss_G: 2.949713, loss_D: 0.206289\n",
      "[Epoch 41/200] [Batch 700/938] loss_G: 2.563042, loss_D: 0.257662\n",
      "[Epoch 41/200] [Batch 710/938] loss_G: 2.977524, loss_D: 0.331655\n",
      "[Epoch 41/200] [Batch 720/938] loss_G: 2.613911, loss_D: 0.185104\n",
      "[Epoch 41/200] [Batch 730/938] loss_G: 2.931046, loss_D: 0.215663\n",
      "[Epoch 41/200] [Batch 740/938] loss_G: 2.482586, loss_D: 0.217545\n",
      "[Epoch 41/200] [Batch 750/938] loss_G: 2.455244, loss_D: 0.194727\n",
      "[Epoch 41/200] [Batch 760/938] loss_G: 2.633474, loss_D: 0.282770\n",
      "[Epoch 41/200] [Batch 770/938] loss_G: 3.148276, loss_D: 0.219312\n",
      "[Epoch 41/200] [Batch 780/938] loss_G: 2.581202, loss_D: 0.196101\n",
      "[Epoch 41/200] [Batch 790/938] loss_G: 2.882920, loss_D: 0.234970\n",
      "[Epoch 41/200] [Batch 800/938] loss_G: 2.494531, loss_D: 0.334079\n",
      "[Epoch 41/200] [Batch 810/938] loss_G: 2.979363, loss_D: 0.266676\n",
      "[Epoch 41/200] [Batch 820/938] loss_G: 2.935076, loss_D: 0.121231\n",
      "[Epoch 41/200] [Batch 830/938] loss_G: 2.876633, loss_D: 0.261744\n",
      "[Epoch 41/200] [Batch 840/938] loss_G: 2.556861, loss_D: 0.196111\n",
      "[Epoch 41/200] [Batch 850/938] loss_G: 3.088343, loss_D: 0.253061\n",
      "[Epoch 41/200] [Batch 860/938] loss_G: 2.911921, loss_D: 0.224859\n",
      "[Epoch 41/200] [Batch 870/938] loss_G: 2.621694, loss_D: 0.172841\n",
      "[Epoch 41/200] [Batch 880/938] loss_G: 2.938026, loss_D: 0.212207\n",
      "[Epoch 41/200] [Batch 890/938] loss_G: 2.887105, loss_D: 0.230609\n",
      "[Epoch 41/200] [Batch 900/938] loss_G: 2.674291, loss_D: 0.186903\n",
      "[Epoch 41/200] [Batch 910/938] loss_G: 2.562500, loss_D: 0.316997\n",
      "[Epoch 41/200] [Batch 920/938] loss_G: 2.386603, loss_D: 0.251560\n",
      "[Epoch 41/200] [Batch 930/938] loss_G: 2.540129, loss_D: 0.315267\n",
      "[Epoch 42/200] [Batch 0/938] loss_G: 2.737044, loss_D: 0.257466\n",
      "[Epoch 42/200] [Batch 10/938] loss_G: 2.295990, loss_D: 0.246274\n",
      "[Epoch 42/200] [Batch 20/938] loss_G: 2.583158, loss_D: 0.309584\n",
      "[Epoch 42/200] [Batch 30/938] loss_G: 2.351426, loss_D: 0.189436\n",
      "[Epoch 42/200] [Batch 40/938] loss_G: 2.666427, loss_D: 0.266178\n",
      "[Epoch 42/200] [Batch 50/938] loss_G: 2.291251, loss_D: 0.258391\n",
      "[Epoch 42/200] [Batch 60/938] loss_G: 2.679628, loss_D: 0.274248\n",
      "[Epoch 42/200] [Batch 70/938] loss_G: 2.624265, loss_D: 0.202360\n",
      "[Epoch 42/200] [Batch 80/938] loss_G: 3.103793, loss_D: 0.164088\n",
      "[Epoch 42/200] [Batch 90/938] loss_G: 2.363420, loss_D: 0.230125\n",
      "[Epoch 42/200] [Batch 100/938] loss_G: 2.441201, loss_D: 0.222290\n",
      "[Epoch 42/200] [Batch 110/938] loss_G: 2.818520, loss_D: 0.186363\n",
      "[Epoch 42/200] [Batch 120/938] loss_G: 2.648274, loss_D: 0.235772\n",
      "[Epoch 42/200] [Batch 130/938] loss_G: 2.566366, loss_D: 0.199107\n",
      "[Epoch 42/200] [Batch 140/938] loss_G: 2.620050, loss_D: 0.233459\n",
      "[Epoch 42/200] [Batch 150/938] loss_G: 2.473278, loss_D: 0.170503\n",
      "[Epoch 42/200] [Batch 160/938] loss_G: 2.673072, loss_D: 0.263412\n",
      "[Epoch 42/200] [Batch 170/938] loss_G: 2.681765, loss_D: 0.303343\n",
      "[Epoch 42/200] [Batch 180/938] loss_G: 2.658879, loss_D: 0.237820\n",
      "[Epoch 42/200] [Batch 190/938] loss_G: 2.834830, loss_D: 0.223739\n",
      "[Epoch 42/200] [Batch 200/938] loss_G: 2.690883, loss_D: 0.124977\n",
      "[Epoch 42/200] [Batch 210/938] loss_G: 2.824956, loss_D: 0.195625\n",
      "[Epoch 42/200] [Batch 220/938] loss_G: 2.571909, loss_D: 0.169688\n",
      "[Epoch 42/200] [Batch 230/938] loss_G: 2.727517, loss_D: 0.221245\n",
      "[Epoch 42/200] [Batch 240/938] loss_G: 2.803944, loss_D: 0.237861\n",
      "[Epoch 42/200] [Batch 250/938] loss_G: 2.434088, loss_D: 0.166857\n",
      "[Epoch 42/200] [Batch 260/938] loss_G: 3.019593, loss_D: 0.201818\n",
      "[Epoch 42/200] [Batch 270/938] loss_G: 2.932275, loss_D: 0.204199\n",
      "[Epoch 42/200] [Batch 280/938] loss_G: 2.717219, loss_D: 0.295129\n",
      "[Epoch 42/200] [Batch 290/938] loss_G: 2.800987, loss_D: 0.308943\n",
      "[Epoch 42/200] [Batch 300/938] loss_G: 2.746808, loss_D: 0.240720\n",
      "[Epoch 42/200] [Batch 310/938] loss_G: 2.631602, loss_D: 0.276354\n",
      "[Epoch 42/200] [Batch 320/938] loss_G: 2.546356, loss_D: 0.212858\n",
      "[Epoch 42/200] [Batch 330/938] loss_G: 2.544002, loss_D: 0.234535\n",
      "[Epoch 42/200] [Batch 340/938] loss_G: 2.507574, loss_D: 0.261425\n",
      "[Epoch 42/200] [Batch 350/938] loss_G: 2.611952, loss_D: 0.234372\n",
      "[Epoch 42/200] [Batch 360/938] loss_G: 2.473335, loss_D: 0.193284\n",
      "[Epoch 42/200] [Batch 370/938] loss_G: 2.825358, loss_D: 0.243645\n",
      "[Epoch 42/200] [Batch 380/938] loss_G: 2.874487, loss_D: 0.190248\n",
      "[Epoch 42/200] [Batch 390/938] loss_G: 2.622744, loss_D: 0.357944\n",
      "[Epoch 42/200] [Batch 400/938] loss_G: 2.775543, loss_D: 0.248926\n",
      "[Epoch 42/200] [Batch 410/938] loss_G: 2.654085, loss_D: 0.217740\n",
      "[Epoch 42/200] [Batch 420/938] loss_G: 3.035619, loss_D: 0.204114\n",
      "[Epoch 42/200] [Batch 430/938] loss_G: 2.816872, loss_D: 0.268990\n",
      "[Epoch 42/200] [Batch 440/938] loss_G: 2.831930, loss_D: 0.180532\n",
      "[Epoch 42/200] [Batch 450/938] loss_G: 2.590423, loss_D: 0.207366\n",
      "[Epoch 42/200] [Batch 460/938] loss_G: 2.773287, loss_D: 0.166878\n",
      "[Epoch 42/200] [Batch 470/938] loss_G: 2.870486, loss_D: 0.207919\n",
      "[Epoch 42/200] [Batch 480/938] loss_G: 2.542249, loss_D: 0.306819\n",
      "[Epoch 42/200] [Batch 490/938] loss_G: 2.640100, loss_D: 0.215041\n",
      "[Epoch 42/200] [Batch 500/938] loss_G: 2.915677, loss_D: 0.204877\n",
      "[Epoch 42/200] [Batch 510/938] loss_G: 3.088021, loss_D: 0.191257\n",
      "[Epoch 42/200] [Batch 520/938] loss_G: 2.892488, loss_D: 0.144106\n",
      "[Epoch 42/200] [Batch 530/938] loss_G: 2.707001, loss_D: 0.208814\n",
      "[Epoch 42/200] [Batch 540/938] loss_G: 2.943514, loss_D: 0.262121\n",
      "[Epoch 42/200] [Batch 550/938] loss_G: 2.583721, loss_D: 0.206517\n",
      "[Epoch 42/200] [Batch 560/938] loss_G: 2.839546, loss_D: 0.153805\n",
      "[Epoch 42/200] [Batch 570/938] loss_G: 2.550738, loss_D: 0.199232\n",
      "[Epoch 42/200] [Batch 580/938] loss_G: 2.750046, loss_D: 0.230476\n",
      "[Epoch 42/200] [Batch 590/938] loss_G: 2.443834, loss_D: 0.288692\n",
      "[Epoch 42/200] [Batch 600/938] loss_G: 3.091736, loss_D: 0.181399\n",
      "[Epoch 42/200] [Batch 610/938] loss_G: 2.588420, loss_D: 0.295905\n",
      "[Epoch 42/200] [Batch 620/938] loss_G: 2.795283, loss_D: 0.207953\n",
      "[Epoch 42/200] [Batch 630/938] loss_G: 2.700711, loss_D: 0.288007\n",
      "[Epoch 42/200] [Batch 640/938] loss_G: 2.828763, loss_D: 0.232918\n",
      "[Epoch 42/200] [Batch 650/938] loss_G: 2.743742, loss_D: 0.207754\n",
      "[Epoch 42/200] [Batch 660/938] loss_G: 3.045907, loss_D: 0.185123\n",
      "[Epoch 42/200] [Batch 670/938] loss_G: 2.780411, loss_D: 0.233522\n",
      "[Epoch 42/200] [Batch 680/938] loss_G: 2.737600, loss_D: 0.233279\n",
      "[Epoch 42/200] [Batch 690/938] loss_G: 2.790429, loss_D: 0.221447\n",
      "[Epoch 42/200] [Batch 700/938] loss_G: 2.866115, loss_D: 0.195767\n",
      "[Epoch 42/200] [Batch 710/938] loss_G: 2.727517, loss_D: 0.244214\n",
      "[Epoch 42/200] [Batch 720/938] loss_G: 2.704870, loss_D: 0.308957\n",
      "[Epoch 42/200] [Batch 730/938] loss_G: 2.931078, loss_D: 0.209447\n",
      "[Epoch 42/200] [Batch 740/938] loss_G: 2.871014, loss_D: 0.252795\n",
      "[Epoch 42/200] [Batch 750/938] loss_G: 2.496964, loss_D: 0.129515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 42/200] [Batch 760/938] loss_G: 2.858001, loss_D: 0.210605\n",
      "[Epoch 42/200] [Batch 770/938] loss_G: 2.510348, loss_D: 0.302672\n",
      "[Epoch 42/200] [Batch 780/938] loss_G: 2.823065, loss_D: 0.276393\n",
      "[Epoch 42/200] [Batch 790/938] loss_G: 2.051834, loss_D: 0.278174\n",
      "[Epoch 42/200] [Batch 800/938] loss_G: 3.219998, loss_D: 0.248397\n",
      "[Epoch 42/200] [Batch 810/938] loss_G: 2.135252, loss_D: 0.361285\n",
      "[Epoch 42/200] [Batch 820/938] loss_G: 2.461481, loss_D: 0.297071\n",
      "[Epoch 42/200] [Batch 830/938] loss_G: 2.831064, loss_D: 0.173691\n",
      "[Epoch 42/200] [Batch 840/938] loss_G: 2.642066, loss_D: 0.203171\n",
      "[Epoch 42/200] [Batch 850/938] loss_G: 2.358410, loss_D: 0.219699\n",
      "[Epoch 42/200] [Batch 860/938] loss_G: 2.631019, loss_D: 0.219192\n",
      "[Epoch 42/200] [Batch 870/938] loss_G: 2.690803, loss_D: 0.275132\n",
      "[Epoch 42/200] [Batch 880/938] loss_G: 2.623370, loss_D: 0.258509\n",
      "[Epoch 42/200] [Batch 890/938] loss_G: 2.478351, loss_D: 0.318571\n",
      "[Epoch 42/200] [Batch 900/938] loss_G: 2.705905, loss_D: 0.226734\n",
      "[Epoch 42/200] [Batch 910/938] loss_G: 2.380452, loss_D: 0.226159\n",
      "[Epoch 42/200] [Batch 920/938] loss_G: 2.470973, loss_D: 0.240075\n",
      "[Epoch 42/200] [Batch 930/938] loss_G: 2.369914, loss_D: 0.316211\n",
      "[Epoch 43/200] [Batch 0/938] loss_G: 2.337850, loss_D: 0.259948\n",
      "[Epoch 43/200] [Batch 10/938] loss_G: 2.745391, loss_D: 0.307017\n",
      "[Epoch 43/200] [Batch 20/938] loss_G: 2.596151, loss_D: 0.170518\n",
      "[Epoch 43/200] [Batch 30/938] loss_G: 2.741284, loss_D: 0.194171\n",
      "[Epoch 43/200] [Batch 40/938] loss_G: 3.007440, loss_D: 0.198070\n",
      "[Epoch 43/200] [Batch 50/938] loss_G: 2.489398, loss_D: 0.243972\n",
      "[Epoch 43/200] [Batch 60/938] loss_G: 2.541153, loss_D: 0.220191\n",
      "[Epoch 43/200] [Batch 70/938] loss_G: 2.595714, loss_D: 0.187427\n",
      "[Epoch 43/200] [Batch 80/938] loss_G: 2.635112, loss_D: 0.239182\n",
      "[Epoch 43/200] [Batch 90/938] loss_G: 2.630978, loss_D: 0.184961\n",
      "[Epoch 43/200] [Batch 100/938] loss_G: 2.658020, loss_D: 0.224939\n",
      "[Epoch 43/200] [Batch 110/938] loss_G: 2.497693, loss_D: 0.231247\n",
      "[Epoch 43/200] [Batch 120/938] loss_G: 2.710928, loss_D: 0.244034\n",
      "[Epoch 43/200] [Batch 130/938] loss_G: 2.768715, loss_D: 0.160933\n",
      "[Epoch 43/200] [Batch 140/938] loss_G: 2.796596, loss_D: 0.184991\n",
      "[Epoch 43/200] [Batch 150/938] loss_G: 2.598319, loss_D: 0.241789\n",
      "[Epoch 43/200] [Batch 160/938] loss_G: 2.779602, loss_D: 0.209475\n",
      "[Epoch 43/200] [Batch 170/938] loss_G: 2.611555, loss_D: 0.265199\n",
      "[Epoch 43/200] [Batch 180/938] loss_G: 2.966144, loss_D: 0.135156\n",
      "[Epoch 43/200] [Batch 190/938] loss_G: 2.861635, loss_D: 0.216509\n",
      "[Epoch 43/200] [Batch 200/938] loss_G: 2.636713, loss_D: 0.212494\n",
      "[Epoch 43/200] [Batch 210/938] loss_G: 2.881155, loss_D: 0.202307\n",
      "[Epoch 43/200] [Batch 220/938] loss_G: 2.769719, loss_D: 0.250902\n",
      "[Epoch 43/200] [Batch 230/938] loss_G: 2.397269, loss_D: 0.280991\n",
      "[Epoch 43/200] [Batch 240/938] loss_G: 2.573219, loss_D: 0.248242\n",
      "[Epoch 43/200] [Batch 250/938] loss_G: 2.397290, loss_D: 0.278543\n",
      "[Epoch 43/200] [Batch 260/938] loss_G: 2.911443, loss_D: 0.283592\n",
      "[Epoch 43/200] [Batch 270/938] loss_G: 2.529696, loss_D: 0.264435\n",
      "[Epoch 43/200] [Batch 280/938] loss_G: 2.651469, loss_D: 0.234129\n",
      "[Epoch 43/200] [Batch 290/938] loss_G: 3.031549, loss_D: 0.149198\n",
      "[Epoch 43/200] [Batch 300/938] loss_G: 2.972294, loss_D: 0.236199\n",
      "[Epoch 43/200] [Batch 310/938] loss_G: 2.974774, loss_D: 0.132002\n",
      "[Epoch 43/200] [Batch 320/938] loss_G: 2.458435, loss_D: 0.329868\n",
      "[Epoch 43/200] [Batch 330/938] loss_G: 2.359612, loss_D: 0.384281\n",
      "[Epoch 43/200] [Batch 340/938] loss_G: 2.865245, loss_D: 0.261689\n",
      "[Epoch 43/200] [Batch 350/938] loss_G: 2.540836, loss_D: 0.249465\n",
      "[Epoch 43/200] [Batch 360/938] loss_G: 2.686208, loss_D: 0.187156\n",
      "[Epoch 43/200] [Batch 370/938] loss_G: 2.595188, loss_D: 0.331454\n",
      "[Epoch 43/200] [Batch 380/938] loss_G: 2.673518, loss_D: 0.188234\n",
      "[Epoch 43/200] [Batch 390/938] loss_G: 2.834803, loss_D: 0.248644\n",
      "[Epoch 43/200] [Batch 400/938] loss_G: 2.383436, loss_D: 0.264417\n",
      "[Epoch 43/200] [Batch 410/938] loss_G: 2.221458, loss_D: 0.344050\n",
      "[Epoch 43/200] [Batch 420/938] loss_G: 2.731378, loss_D: 0.224418\n",
      "[Epoch 43/200] [Batch 430/938] loss_G: 2.628359, loss_D: 0.352152\n",
      "[Epoch 43/200] [Batch 440/938] loss_G: 2.329928, loss_D: 0.294908\n",
      "[Epoch 43/200] [Batch 450/938] loss_G: 2.693286, loss_D: 0.255043\n",
      "[Epoch 43/200] [Batch 460/938] loss_G: 2.589009, loss_D: 0.219397\n",
      "[Epoch 43/200] [Batch 470/938] loss_G: 2.171176, loss_D: 0.248052\n",
      "[Epoch 43/200] [Batch 480/938] loss_G: 2.617633, loss_D: 0.260009\n",
      "[Epoch 43/200] [Batch 490/938] loss_G: 2.505738, loss_D: 0.257986\n",
      "[Epoch 43/200] [Batch 500/938] loss_G: 2.599626, loss_D: 0.290560\n",
      "[Epoch 43/200] [Batch 510/938] loss_G: 2.511871, loss_D: 0.240145\n",
      "[Epoch 43/200] [Batch 520/938] loss_G: 2.372449, loss_D: 0.226164\n",
      "[Epoch 43/200] [Batch 530/938] loss_G: 2.829757, loss_D: 0.237746\n",
      "[Epoch 43/200] [Batch 540/938] loss_G: 2.768660, loss_D: 0.281820\n",
      "[Epoch 43/200] [Batch 550/938] loss_G: 2.670408, loss_D: 0.200679\n",
      "[Epoch 43/200] [Batch 560/938] loss_G: 2.367617, loss_D: 0.250862\n",
      "[Epoch 43/200] [Batch 570/938] loss_G: 2.820838, loss_D: 0.191765\n",
      "[Epoch 43/200] [Batch 580/938] loss_G: 2.442200, loss_D: 0.208966\n",
      "[Epoch 43/200] [Batch 590/938] loss_G: 2.633763, loss_D: 0.259063\n",
      "[Epoch 43/200] [Batch 600/938] loss_G: 2.472960, loss_D: 0.211453\n",
      "[Epoch 43/200] [Batch 610/938] loss_G: 2.416433, loss_D: 0.256757\n",
      "[Epoch 43/200] [Batch 620/938] loss_G: 2.456072, loss_D: 0.194986\n",
      "[Epoch 43/200] [Batch 630/938] loss_G: 2.658107, loss_D: 0.221037\n",
      "[Epoch 43/200] [Batch 640/938] loss_G: 2.610065, loss_D: 0.219795\n",
      "[Epoch 43/200] [Batch 650/938] loss_G: 2.733521, loss_D: 0.226506\n",
      "[Epoch 43/200] [Batch 660/938] loss_G: 2.771437, loss_D: 0.226595\n",
      "[Epoch 43/200] [Batch 670/938] loss_G: 3.042349, loss_D: 0.147109\n",
      "[Epoch 43/200] [Batch 680/938] loss_G: 2.503069, loss_D: 0.186376\n",
      "[Epoch 43/200] [Batch 690/938] loss_G: 2.822671, loss_D: 0.191014\n",
      "[Epoch 43/200] [Batch 700/938] loss_G: 2.545421, loss_D: 0.247031\n",
      "[Epoch 43/200] [Batch 710/938] loss_G: 2.744199, loss_D: 0.204480\n",
      "[Epoch 43/200] [Batch 720/938] loss_G: 2.615298, loss_D: 0.185858\n",
      "[Epoch 43/200] [Batch 730/938] loss_G: 2.175893, loss_D: 0.289438\n",
      "[Epoch 43/200] [Batch 740/938] loss_G: 3.043374, loss_D: 0.140817\n",
      "[Epoch 43/200] [Batch 750/938] loss_G: 2.600151, loss_D: 0.255361\n",
      "[Epoch 43/200] [Batch 760/938] loss_G: 2.825595, loss_D: 0.208650\n",
      "[Epoch 43/200] [Batch 770/938] loss_G: 2.400871, loss_D: 0.209033\n",
      "[Epoch 43/200] [Batch 780/938] loss_G: 2.899582, loss_D: 0.211825\n",
      "[Epoch 43/200] [Batch 790/938] loss_G: 2.871036, loss_D: 0.189251\n",
      "[Epoch 43/200] [Batch 800/938] loss_G: 2.266467, loss_D: 0.318976\n",
      "[Epoch 43/200] [Batch 810/938] loss_G: 2.666339, loss_D: 0.184721\n",
      "[Epoch 43/200] [Batch 820/938] loss_G: 3.131204, loss_D: 0.195255\n",
      "[Epoch 43/200] [Batch 830/938] loss_G: 2.614744, loss_D: 0.321815\n",
      "[Epoch 43/200] [Batch 840/938] loss_G: 2.561784, loss_D: 0.361604\n",
      "[Epoch 43/200] [Batch 850/938] loss_G: 2.275218, loss_D: 0.238958\n",
      "[Epoch 43/200] [Batch 860/938] loss_G: 2.756556, loss_D: 0.200281\n",
      "[Epoch 43/200] [Batch 870/938] loss_G: 2.733614, loss_D: 0.178648\n",
      "[Epoch 43/200] [Batch 880/938] loss_G: 2.725974, loss_D: 0.175087\n",
      "[Epoch 43/200] [Batch 890/938] loss_G: 2.424974, loss_D: 0.218449\n",
      "[Epoch 43/200] [Batch 900/938] loss_G: 2.974900, loss_D: 0.247363\n",
      "[Epoch 43/200] [Batch 910/938] loss_G: 2.716652, loss_D: 0.230017\n",
      "[Epoch 43/200] [Batch 920/938] loss_G: 2.647440, loss_D: 0.261137\n",
      "[Epoch 43/200] [Batch 930/938] loss_G: 2.807905, loss_D: 0.198053\n",
      "[Epoch 44/200] [Batch 0/938] loss_G: 2.601351, loss_D: 0.261224\n",
      "[Epoch 44/200] [Batch 10/938] loss_G: 2.982161, loss_D: 0.143149\n",
      "[Epoch 44/200] [Batch 20/938] loss_G: 2.511735, loss_D: 0.266580\n",
      "[Epoch 44/200] [Batch 30/938] loss_G: 2.935567, loss_D: 0.152777\n",
      "[Epoch 44/200] [Batch 40/938] loss_G: 2.968276, loss_D: 0.144888\n",
      "[Epoch 44/200] [Batch 50/938] loss_G: 2.569247, loss_D: 0.192819\n",
      "[Epoch 44/200] [Batch 60/938] loss_G: 2.999467, loss_D: 0.330557\n",
      "[Epoch 44/200] [Batch 70/938] loss_G: 2.579044, loss_D: 0.248059\n",
      "[Epoch 44/200] [Batch 80/938] loss_G: 2.632622, loss_D: 0.227751\n",
      "[Epoch 44/200] [Batch 90/938] loss_G: 2.732988, loss_D: 0.221093\n",
      "[Epoch 44/200] [Batch 100/938] loss_G: 2.919147, loss_D: 0.205724\n",
      "[Epoch 44/200] [Batch 110/938] loss_G: 2.543680, loss_D: 0.231236\n",
      "[Epoch 44/200] [Batch 120/938] loss_G: 2.429958, loss_D: 0.271583\n",
      "[Epoch 44/200] [Batch 130/938] loss_G: 2.472262, loss_D: 0.330029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 44/200] [Batch 140/938] loss_G: 2.587782, loss_D: 0.211370\n",
      "[Epoch 44/200] [Batch 150/938] loss_G: 2.578367, loss_D: 0.223991\n",
      "[Epoch 44/200] [Batch 160/938] loss_G: 2.959040, loss_D: 0.228320\n",
      "[Epoch 44/200] [Batch 170/938] loss_G: 2.452665, loss_D: 0.373235\n",
      "[Epoch 44/200] [Batch 180/938] loss_G: 2.622456, loss_D: 0.309270\n",
      "[Epoch 44/200] [Batch 190/938] loss_G: 2.523554, loss_D: 0.289834\n",
      "[Epoch 44/200] [Batch 200/938] loss_G: 3.111114, loss_D: 0.285423\n",
      "[Epoch 44/200] [Batch 210/938] loss_G: 2.509195, loss_D: 0.313608\n",
      "[Epoch 44/200] [Batch 220/938] loss_G: 2.507475, loss_D: 0.232521\n",
      "[Epoch 44/200] [Batch 230/938] loss_G: 2.639519, loss_D: 0.190525\n",
      "[Epoch 44/200] [Batch 240/938] loss_G: 2.946257, loss_D: 0.196791\n",
      "[Epoch 44/200] [Batch 250/938] loss_G: 2.914620, loss_D: 0.236830\n",
      "[Epoch 44/200] [Batch 260/938] loss_G: 2.712726, loss_D: 0.214503\n",
      "[Epoch 44/200] [Batch 270/938] loss_G: 2.954132, loss_D: 0.182706\n",
      "[Epoch 44/200] [Batch 280/938] loss_G: 2.768169, loss_D: 0.250938\n",
      "[Epoch 44/200] [Batch 290/938] loss_G: 2.304523, loss_D: 0.331415\n",
      "[Epoch 44/200] [Batch 300/938] loss_G: 3.094610, loss_D: 0.174975\n",
      "[Epoch 44/200] [Batch 310/938] loss_G: 2.564154, loss_D: 0.230406\n",
      "[Epoch 44/200] [Batch 320/938] loss_G: 3.336807, loss_D: 0.197541\n",
      "[Epoch 44/200] [Batch 330/938] loss_G: 2.475523, loss_D: 0.138761\n",
      "[Epoch 44/200] [Batch 340/938] loss_G: 2.531702, loss_D: 0.206924\n",
      "[Epoch 44/200] [Batch 350/938] loss_G: 2.635283, loss_D: 0.185099\n",
      "[Epoch 44/200] [Batch 360/938] loss_G: 2.389211, loss_D: 0.210119\n",
      "[Epoch 44/200] [Batch 370/938] loss_G: 2.588170, loss_D: 0.228634\n",
      "[Epoch 44/200] [Batch 380/938] loss_G: 2.626236, loss_D: 0.192719\n",
      "[Epoch 44/200] [Batch 390/938] loss_G: 2.754226, loss_D: 0.244243\n",
      "[Epoch 44/200] [Batch 400/938] loss_G: 2.388359, loss_D: 0.254815\n",
      "[Epoch 44/200] [Batch 410/938] loss_G: 2.298074, loss_D: 0.286946\n",
      "[Epoch 44/200] [Batch 420/938] loss_G: 2.190744, loss_D: 0.357640\n",
      "[Epoch 44/200] [Batch 430/938] loss_G: 2.363960, loss_D: 0.188232\n",
      "[Epoch 44/200] [Batch 440/938] loss_G: 2.314319, loss_D: 0.230136\n",
      "[Epoch 44/200] [Batch 450/938] loss_G: 2.864437, loss_D: 0.152885\n",
      "[Epoch 44/200] [Batch 460/938] loss_G: 2.400231, loss_D: 0.211245\n",
      "[Epoch 44/200] [Batch 470/938] loss_G: 2.828102, loss_D: 0.259493\n",
      "[Epoch 44/200] [Batch 480/938] loss_G: 2.804350, loss_D: 0.244920\n",
      "[Epoch 44/200] [Batch 490/938] loss_G: 2.035565, loss_D: 0.332273\n",
      "[Epoch 44/200] [Batch 500/938] loss_G: 2.545408, loss_D: 0.275390\n",
      "[Epoch 44/200] [Batch 510/938] loss_G: 2.075313, loss_D: 0.257253\n",
      "[Epoch 44/200] [Batch 520/938] loss_G: 2.505732, loss_D: 0.230300\n",
      "[Epoch 44/200] [Batch 530/938] loss_G: 2.266928, loss_D: 0.304786\n",
      "[Epoch 44/200] [Batch 540/938] loss_G: 2.523400, loss_D: 0.249043\n",
      "[Epoch 44/200] [Batch 550/938] loss_G: 2.719449, loss_D: 0.152051\n",
      "[Epoch 44/200] [Batch 560/938] loss_G: 2.566499, loss_D: 0.280065\n",
      "[Epoch 44/200] [Batch 570/938] loss_G: 2.765493, loss_D: 0.138289\n",
      "[Epoch 44/200] [Batch 580/938] loss_G: 2.794671, loss_D: 0.158757\n",
      "[Epoch 44/200] [Batch 590/938] loss_G: 2.758012, loss_D: 0.180749\n",
      "[Epoch 44/200] [Batch 600/938] loss_G: 2.362983, loss_D: 0.188401\n",
      "[Epoch 44/200] [Batch 610/938] loss_G: 2.828772, loss_D: 0.349710\n",
      "[Epoch 44/200] [Batch 620/938] loss_G: 2.727836, loss_D: 0.306801\n",
      "[Epoch 44/200] [Batch 630/938] loss_G: 2.473481, loss_D: 0.157359\n",
      "[Epoch 44/200] [Batch 640/938] loss_G: 2.367833, loss_D: 0.239325\n",
      "[Epoch 44/200] [Batch 650/938] loss_G: 2.592716, loss_D: 0.261974\n",
      "[Epoch 44/200] [Batch 660/938] loss_G: 2.399564, loss_D: 0.189615\n",
      "[Epoch 44/200] [Batch 670/938] loss_G: 2.495409, loss_D: 0.193814\n",
      "[Epoch 44/200] [Batch 680/938] loss_G: 2.595169, loss_D: 0.208091\n",
      "[Epoch 44/200] [Batch 690/938] loss_G: 2.704981, loss_D: 0.244018\n",
      "[Epoch 44/200] [Batch 700/938] loss_G: 2.457061, loss_D: 0.192859\n",
      "[Epoch 44/200] [Batch 710/938] loss_G: 3.056811, loss_D: 0.225496\n",
      "[Epoch 44/200] [Batch 720/938] loss_G: 2.810706, loss_D: 0.145748\n",
      "[Epoch 44/200] [Batch 730/938] loss_G: 2.680727, loss_D: 0.312700\n",
      "[Epoch 44/200] [Batch 740/938] loss_G: 2.368403, loss_D: 0.241966\n",
      "[Epoch 44/200] [Batch 750/938] loss_G: 2.639252, loss_D: 0.287536\n",
      "[Epoch 44/200] [Batch 760/938] loss_G: 2.804826, loss_D: 0.226777\n",
      "[Epoch 44/200] [Batch 770/938] loss_G: 2.695063, loss_D: 0.229245\n",
      "[Epoch 44/200] [Batch 780/938] loss_G: 2.531747, loss_D: 0.209840\n",
      "[Epoch 44/200] [Batch 790/938] loss_G: 2.497826, loss_D: 0.234176\n",
      "[Epoch 44/200] [Batch 800/938] loss_G: 2.602563, loss_D: 0.257270\n",
      "[Epoch 44/200] [Batch 810/938] loss_G: 2.646327, loss_D: 0.205025\n",
      "[Epoch 44/200] [Batch 820/938] loss_G: 3.010948, loss_D: 0.188341\n",
      "[Epoch 44/200] [Batch 830/938] loss_G: 2.543109, loss_D: 0.176579\n",
      "[Epoch 44/200] [Batch 840/938] loss_G: 2.844421, loss_D: 0.225512\n",
      "[Epoch 44/200] [Batch 850/938] loss_G: 2.481821, loss_D: 0.275857\n",
      "[Epoch 44/200] [Batch 860/938] loss_G: 3.096927, loss_D: 0.185157\n",
      "[Epoch 44/200] [Batch 870/938] loss_G: 2.521153, loss_D: 0.219762\n",
      "[Epoch 44/200] [Batch 880/938] loss_G: 2.409539, loss_D: 0.214610\n",
      "[Epoch 44/200] [Batch 890/938] loss_G: 2.820833, loss_D: 0.250786\n",
      "[Epoch 44/200] [Batch 900/938] loss_G: 2.345137, loss_D: 0.218544\n",
      "[Epoch 44/200] [Batch 910/938] loss_G: 2.248257, loss_D: 0.324257\n",
      "[Epoch 44/200] [Batch 920/938] loss_G: 2.898875, loss_D: 0.167866\n",
      "[Epoch 44/200] [Batch 930/938] loss_G: 2.552463, loss_D: 0.302952\n",
      "[Epoch 45/200] [Batch 0/938] loss_G: 2.446169, loss_D: 0.277415\n",
      "[Epoch 45/200] [Batch 10/938] loss_G: 2.572466, loss_D: 0.302756\n",
      "[Epoch 45/200] [Batch 20/938] loss_G: 2.675075, loss_D: 0.224901\n",
      "[Epoch 45/200] [Batch 30/938] loss_G: 2.571555, loss_D: 0.178911\n",
      "[Epoch 45/200] [Batch 40/938] loss_G: 2.557705, loss_D: 0.239026\n",
      "[Epoch 45/200] [Batch 50/938] loss_G: 2.761805, loss_D: 0.291898\n",
      "[Epoch 45/200] [Batch 60/938] loss_G: 2.491558, loss_D: 0.223668\n",
      "[Epoch 45/200] [Batch 70/938] loss_G: 2.548471, loss_D: 0.191025\n",
      "[Epoch 45/200] [Batch 80/938] loss_G: 2.767906, loss_D: 0.155234\n",
      "[Epoch 45/200] [Batch 90/938] loss_G: 2.517706, loss_D: 0.357568\n",
      "[Epoch 45/200] [Batch 100/938] loss_G: 2.562124, loss_D: 0.202864\n",
      "[Epoch 45/200] [Batch 110/938] loss_G: 2.441346, loss_D: 0.269889\n",
      "[Epoch 45/200] [Batch 120/938] loss_G: 3.176001, loss_D: 0.157814\n",
      "[Epoch 45/200] [Batch 130/938] loss_G: 2.540650, loss_D: 0.218446\n",
      "[Epoch 45/200] [Batch 140/938] loss_G: 2.889959, loss_D: 0.229393\n",
      "[Epoch 45/200] [Batch 150/938] loss_G: 2.661582, loss_D: 0.253016\n",
      "[Epoch 45/200] [Batch 160/938] loss_G: 2.435671, loss_D: 0.225422\n",
      "[Epoch 45/200] [Batch 170/938] loss_G: 3.341462, loss_D: 0.150074\n",
      "[Epoch 45/200] [Batch 180/938] loss_G: 2.242244, loss_D: 0.250096\n",
      "[Epoch 45/200] [Batch 190/938] loss_G: 2.757223, loss_D: 0.344901\n",
      "[Epoch 45/200] [Batch 200/938] loss_G: 2.672637, loss_D: 0.251944\n",
      "[Epoch 45/200] [Batch 210/938] loss_G: 2.987559, loss_D: 0.239251\n",
      "[Epoch 45/200] [Batch 220/938] loss_G: 2.624412, loss_D: 0.174804\n",
      "[Epoch 45/200] [Batch 230/938] loss_G: 2.625004, loss_D: 0.154684\n",
      "[Epoch 45/200] [Batch 240/938] loss_G: 2.788153, loss_D: 0.201544\n",
      "[Epoch 45/200] [Batch 250/938] loss_G: 2.377350, loss_D: 0.319507\n",
      "[Epoch 45/200] [Batch 260/938] loss_G: 2.969555, loss_D: 0.193226\n",
      "[Epoch 45/200] [Batch 270/938] loss_G: 2.414832, loss_D: 0.295498\n",
      "[Epoch 45/200] [Batch 280/938] loss_G: 3.082758, loss_D: 0.204091\n",
      "[Epoch 45/200] [Batch 290/938] loss_G: 2.650982, loss_D: 0.265986\n",
      "[Epoch 45/200] [Batch 300/938] loss_G: 2.678502, loss_D: 0.221229\n",
      "[Epoch 45/200] [Batch 310/938] loss_G: 2.329281, loss_D: 0.247146\n",
      "[Epoch 45/200] [Batch 320/938] loss_G: 2.771640, loss_D: 0.327087\n",
      "[Epoch 45/200] [Batch 330/938] loss_G: 2.402170, loss_D: 0.270694\n",
      "[Epoch 45/200] [Batch 340/938] loss_G: 2.535634, loss_D: 0.191392\n",
      "[Epoch 45/200] [Batch 350/938] loss_G: 2.752726, loss_D: 0.300441\n",
      "[Epoch 45/200] [Batch 360/938] loss_G: 2.432822, loss_D: 0.199228\n",
      "[Epoch 45/200] [Batch 370/938] loss_G: 2.701563, loss_D: 0.254439\n",
      "[Epoch 45/200] [Batch 380/938] loss_G: 2.869212, loss_D: 0.204135\n",
      "[Epoch 45/200] [Batch 390/938] loss_G: 2.788738, loss_D: 0.219591\n",
      "[Epoch 45/200] [Batch 400/938] loss_G: 2.916917, loss_D: 0.203477\n",
      "[Epoch 45/200] [Batch 410/938] loss_G: 2.919474, loss_D: 0.179862\n",
      "[Epoch 45/200] [Batch 420/938] loss_G: 2.419919, loss_D: 0.313521\n",
      "[Epoch 45/200] [Batch 430/938] loss_G: 2.972290, loss_D: 0.270954\n",
      "[Epoch 45/200] [Batch 440/938] loss_G: 2.599356, loss_D: 0.214814\n",
      "[Epoch 45/200] [Batch 450/938] loss_G: 2.811833, loss_D: 0.190562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 45/200] [Batch 460/938] loss_G: 2.524708, loss_D: 0.264878\n",
      "[Epoch 45/200] [Batch 470/938] loss_G: 2.457988, loss_D: 0.228365\n",
      "[Epoch 45/200] [Batch 480/938] loss_G: 2.620099, loss_D: 0.157428\n",
      "[Epoch 45/200] [Batch 490/938] loss_G: 2.326632, loss_D: 0.239187\n",
      "[Epoch 45/200] [Batch 500/938] loss_G: 2.776795, loss_D: 0.199285\n",
      "[Epoch 45/200] [Batch 510/938] loss_G: 2.750920, loss_D: 0.221845\n",
      "[Epoch 45/200] [Batch 520/938] loss_G: 2.602321, loss_D: 0.292528\n",
      "[Epoch 45/200] [Batch 530/938] loss_G: 2.830069, loss_D: 0.193220\n",
      "[Epoch 45/200] [Batch 540/938] loss_G: 2.675224, loss_D: 0.189630\n",
      "[Epoch 45/200] [Batch 550/938] loss_G: 3.062443, loss_D: 0.165006\n",
      "[Epoch 45/200] [Batch 560/938] loss_G: 2.371498, loss_D: 0.211430\n",
      "[Epoch 45/200] [Batch 570/938] loss_G: 2.992721, loss_D: 0.281408\n",
      "[Epoch 45/200] [Batch 580/938] loss_G: 2.640002, loss_D: 0.226356\n",
      "[Epoch 45/200] [Batch 590/938] loss_G: 2.718758, loss_D: 0.295101\n",
      "[Epoch 45/200] [Batch 600/938] loss_G: 2.487280, loss_D: 0.258627\n",
      "[Epoch 45/200] [Batch 610/938] loss_G: 3.027721, loss_D: 0.294621\n",
      "[Epoch 45/200] [Batch 620/938] loss_G: 2.610843, loss_D: 0.182216\n",
      "[Epoch 45/200] [Batch 630/938] loss_G: 2.724710, loss_D: 0.273098\n",
      "[Epoch 45/200] [Batch 640/938] loss_G: 2.482387, loss_D: 0.311616\n",
      "[Epoch 45/200] [Batch 650/938] loss_G: 2.846138, loss_D: 0.308791\n",
      "[Epoch 45/200] [Batch 660/938] loss_G: 2.546247, loss_D: 0.285981\n",
      "[Epoch 45/200] [Batch 670/938] loss_G: 2.128242, loss_D: 0.246249\n",
      "[Epoch 45/200] [Batch 680/938] loss_G: 2.577089, loss_D: 0.400951\n",
      "[Epoch 45/200] [Batch 690/938] loss_G: 2.594881, loss_D: 0.175577\n",
      "[Epoch 45/200] [Batch 700/938] loss_G: 2.394937, loss_D: 0.259895\n",
      "[Epoch 45/200] [Batch 710/938] loss_G: 2.501966, loss_D: 0.357924\n",
      "[Epoch 45/200] [Batch 720/938] loss_G: 2.469463, loss_D: 0.283245\n",
      "[Epoch 45/200] [Batch 730/938] loss_G: 3.098132, loss_D: 0.221223\n",
      "[Epoch 45/200] [Batch 740/938] loss_G: 2.780801, loss_D: 0.225489\n",
      "[Epoch 45/200] [Batch 750/938] loss_G: 2.302186, loss_D: 0.290901\n",
      "[Epoch 45/200] [Batch 760/938] loss_G: 2.601996, loss_D: 0.176639\n",
      "[Epoch 45/200] [Batch 770/938] loss_G: 2.292068, loss_D: 0.320386\n",
      "[Epoch 45/200] [Batch 780/938] loss_G: 2.500269, loss_D: 0.187682\n",
      "[Epoch 45/200] [Batch 790/938] loss_G: 2.556212, loss_D: 0.297389\n",
      "[Epoch 45/200] [Batch 800/938] loss_G: 2.820607, loss_D: 0.203541\n",
      "[Epoch 45/200] [Batch 810/938] loss_G: 2.562926, loss_D: 0.231975\n",
      "[Epoch 45/200] [Batch 820/938] loss_G: 2.574661, loss_D: 0.304287\n",
      "[Epoch 45/200] [Batch 830/938] loss_G: 2.578425, loss_D: 0.233781\n",
      "[Epoch 45/200] [Batch 840/938] loss_G: 2.811028, loss_D: 0.200660\n",
      "[Epoch 45/200] [Batch 850/938] loss_G: 2.572161, loss_D: 0.273172\n",
      "[Epoch 45/200] [Batch 860/938] loss_G: 2.632658, loss_D: 0.228925\n",
      "[Epoch 45/200] [Batch 870/938] loss_G: 2.368096, loss_D: 0.206536\n",
      "[Epoch 45/200] [Batch 880/938] loss_G: 2.480967, loss_D: 0.258916\n",
      "[Epoch 45/200] [Batch 890/938] loss_G: 2.478916, loss_D: 0.230720\n",
      "[Epoch 45/200] [Batch 900/938] loss_G: 2.696356, loss_D: 0.237968\n",
      "[Epoch 45/200] [Batch 910/938] loss_G: 2.382361, loss_D: 0.162219\n",
      "[Epoch 45/200] [Batch 920/938] loss_G: 2.479907, loss_D: 0.231948\n",
      "[Epoch 45/200] [Batch 930/938] loss_G: 2.440866, loss_D: 0.310457\n",
      "[Epoch 46/200] [Batch 0/938] loss_G: 2.749454, loss_D: 0.225047\n",
      "[Epoch 46/200] [Batch 10/938] loss_G: 2.778565, loss_D: 0.283633\n",
      "[Epoch 46/200] [Batch 20/938] loss_G: 2.608981, loss_D: 0.257703\n",
      "[Epoch 46/200] [Batch 30/938] loss_G: 2.828132, loss_D: 0.261080\n",
      "[Epoch 46/200] [Batch 40/938] loss_G: 2.570991, loss_D: 0.221844\n",
      "[Epoch 46/200] [Batch 50/938] loss_G: 2.277865, loss_D: 0.295248\n",
      "[Epoch 46/200] [Batch 60/938] loss_G: 2.653504, loss_D: 0.213743\n",
      "[Epoch 46/200] [Batch 70/938] loss_G: 2.452226, loss_D: 0.219172\n",
      "[Epoch 46/200] [Batch 80/938] loss_G: 2.730757, loss_D: 0.156383\n",
      "[Epoch 46/200] [Batch 90/938] loss_G: 2.671846, loss_D: 0.262800\n",
      "[Epoch 46/200] [Batch 100/938] loss_G: 2.461115, loss_D: 0.292902\n",
      "[Epoch 46/200] [Batch 110/938] loss_G: 2.513637, loss_D: 0.196229\n",
      "[Epoch 46/200] [Batch 120/938] loss_G: 3.014565, loss_D: 0.118670\n",
      "[Epoch 46/200] [Batch 130/938] loss_G: 2.713620, loss_D: 0.236209\n",
      "[Epoch 46/200] [Batch 140/938] loss_G: 2.236532, loss_D: 0.314237\n",
      "[Epoch 46/200] [Batch 150/938] loss_G: 3.036384, loss_D: 0.209291\n",
      "[Epoch 46/200] [Batch 160/938] loss_G: 2.862136, loss_D: 0.151934\n",
      "[Epoch 46/200] [Batch 170/938] loss_G: 2.633493, loss_D: 0.227585\n",
      "[Epoch 46/200] [Batch 180/938] loss_G: 2.496609, loss_D: 0.235067\n",
      "[Epoch 46/200] [Batch 190/938] loss_G: 2.813205, loss_D: 0.263379\n",
      "[Epoch 46/200] [Batch 200/938] loss_G: 2.530366, loss_D: 0.204480\n",
      "[Epoch 46/200] [Batch 210/938] loss_G: 2.543365, loss_D: 0.147140\n",
      "[Epoch 46/200] [Batch 220/938] loss_G: 2.672710, loss_D: 0.243052\n",
      "[Epoch 46/200] [Batch 230/938] loss_G: 2.566388, loss_D: 0.270636\n",
      "[Epoch 46/200] [Batch 240/938] loss_G: 2.919325, loss_D: 0.196473\n",
      "[Epoch 46/200] [Batch 250/938] loss_G: 2.449121, loss_D: 0.273261\n",
      "[Epoch 46/200] [Batch 260/938] loss_G: 2.812433, loss_D: 0.241697\n",
      "[Epoch 46/200] [Batch 270/938] loss_G: 2.690394, loss_D: 0.221306\n",
      "[Epoch 46/200] [Batch 280/938] loss_G: 2.683197, loss_D: 0.277794\n",
      "[Epoch 46/200] [Batch 290/938] loss_G: 2.616866, loss_D: 0.208210\n",
      "[Epoch 46/200] [Batch 300/938] loss_G: 2.649788, loss_D: 0.255158\n",
      "[Epoch 46/200] [Batch 310/938] loss_G: 2.266178, loss_D: 0.289061\n",
      "[Epoch 46/200] [Batch 320/938] loss_G: 2.792535, loss_D: 0.232735\n",
      "[Epoch 46/200] [Batch 330/938] loss_G: 2.489841, loss_D: 0.256386\n",
      "[Epoch 46/200] [Batch 340/938] loss_G: 2.623619, loss_D: 0.220439\n",
      "[Epoch 46/200] [Batch 350/938] loss_G: 2.641387, loss_D: 0.314579\n",
      "[Epoch 46/200] [Batch 360/938] loss_G: 2.815619, loss_D: 0.233844\n",
      "[Epoch 46/200] [Batch 370/938] loss_G: 2.793189, loss_D: 0.152977\n",
      "[Epoch 46/200] [Batch 380/938] loss_G: 3.001510, loss_D: 0.183774\n",
      "[Epoch 46/200] [Batch 390/938] loss_G: 2.704754, loss_D: 0.212988\n",
      "[Epoch 46/200] [Batch 400/938] loss_G: 2.692698, loss_D: 0.321498\n",
      "[Epoch 46/200] [Batch 410/938] loss_G: 2.566635, loss_D: 0.219218\n",
      "[Epoch 46/200] [Batch 420/938] loss_G: 2.693192, loss_D: 0.206549\n",
      "[Epoch 46/200] [Batch 430/938] loss_G: 2.346102, loss_D: 0.259091\n",
      "[Epoch 46/200] [Batch 440/938] loss_G: 2.922734, loss_D: 0.198478\n",
      "[Epoch 46/200] [Batch 450/938] loss_G: 2.842313, loss_D: 0.253433\n",
      "[Epoch 46/200] [Batch 460/938] loss_G: 2.665941, loss_D: 0.242227\n",
      "[Epoch 46/200] [Batch 470/938] loss_G: 2.735106, loss_D: 0.225724\n",
      "[Epoch 46/200] [Batch 480/938] loss_G: 2.930957, loss_D: 0.228254\n",
      "[Epoch 46/200] [Batch 490/938] loss_G: 2.514471, loss_D: 0.230172\n",
      "[Epoch 46/200] [Batch 500/938] loss_G: 2.504819, loss_D: 0.385418\n",
      "[Epoch 46/200] [Batch 510/938] loss_G: 2.506489, loss_D: 0.437691\n",
      "[Epoch 46/200] [Batch 520/938] loss_G: 2.831835, loss_D: 0.168856\n",
      "[Epoch 46/200] [Batch 530/938] loss_G: 2.661969, loss_D: 0.251735\n",
      "[Epoch 46/200] [Batch 540/938] loss_G: 2.447778, loss_D: 0.271804\n",
      "[Epoch 46/200] [Batch 550/938] loss_G: 2.954731, loss_D: 0.288113\n",
      "[Epoch 46/200] [Batch 560/938] loss_G: 2.492465, loss_D: 0.252735\n",
      "[Epoch 46/200] [Batch 570/938] loss_G: 3.042878, loss_D: 0.206839\n",
      "[Epoch 46/200] [Batch 580/938] loss_G: 2.661775, loss_D: 0.181496\n",
      "[Epoch 46/200] [Batch 590/938] loss_G: 2.914311, loss_D: 0.271746\n",
      "[Epoch 46/200] [Batch 600/938] loss_G: 2.906666, loss_D: 0.173535\n",
      "[Epoch 46/200] [Batch 610/938] loss_G: 2.796864, loss_D: 0.287939\n",
      "[Epoch 46/200] [Batch 620/938] loss_G: 2.543063, loss_D: 0.205488\n",
      "[Epoch 46/200] [Batch 630/938] loss_G: 2.864286, loss_D: 0.268080\n",
      "[Epoch 46/200] [Batch 640/938] loss_G: 2.740915, loss_D: 0.150214\n",
      "[Epoch 46/200] [Batch 650/938] loss_G: 3.081189, loss_D: 0.192983\n",
      "[Epoch 46/200] [Batch 660/938] loss_G: 2.807500, loss_D: 0.203837\n",
      "[Epoch 46/200] [Batch 670/938] loss_G: 2.700706, loss_D: 0.262007\n",
      "[Epoch 46/200] [Batch 680/938] loss_G: 2.742989, loss_D: 0.312363\n",
      "[Epoch 46/200] [Batch 690/938] loss_G: 2.678248, loss_D: 0.269700\n",
      "[Epoch 46/200] [Batch 700/938] loss_G: 2.947320, loss_D: 0.218696\n",
      "[Epoch 46/200] [Batch 710/938] loss_G: 2.522574, loss_D: 0.372831\n",
      "[Epoch 46/200] [Batch 720/938] loss_G: 2.836048, loss_D: 0.186243\n",
      "[Epoch 46/200] [Batch 730/938] loss_G: 2.697483, loss_D: 0.276538\n",
      "[Epoch 46/200] [Batch 740/938] loss_G: 2.975317, loss_D: 0.183113\n",
      "[Epoch 46/200] [Batch 750/938] loss_G: 2.811237, loss_D: 0.216814\n",
      "[Epoch 46/200] [Batch 760/938] loss_G: 3.047839, loss_D: 0.133604\n",
      "[Epoch 46/200] [Batch 770/938] loss_G: 2.922637, loss_D: 0.153412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 46/200] [Batch 780/938] loss_G: 2.772754, loss_D: 0.205509\n",
      "[Epoch 46/200] [Batch 790/938] loss_G: 2.710302, loss_D: 0.265599\n",
      "[Epoch 46/200] [Batch 800/938] loss_G: 2.469561, loss_D: 0.290451\n",
      "[Epoch 46/200] [Batch 810/938] loss_G: 2.945345, loss_D: 0.267262\n",
      "[Epoch 46/200] [Batch 820/938] loss_G: 2.449940, loss_D: 0.238520\n",
      "[Epoch 46/200] [Batch 830/938] loss_G: 2.642153, loss_D: 0.242401\n",
      "[Epoch 46/200] [Batch 840/938] loss_G: 2.778497, loss_D: 0.170309\n",
      "[Epoch 46/200] [Batch 850/938] loss_G: 2.978249, loss_D: 0.174616\n",
      "[Epoch 46/200] [Batch 860/938] loss_G: 2.868576, loss_D: 0.247223\n",
      "[Epoch 46/200] [Batch 870/938] loss_G: 2.883824, loss_D: 0.229204\n",
      "[Epoch 46/200] [Batch 880/938] loss_G: 2.635539, loss_D: 0.159868\n",
      "[Epoch 46/200] [Batch 890/938] loss_G: 2.720565, loss_D: 0.191877\n",
      "[Epoch 46/200] [Batch 900/938] loss_G: 2.719769, loss_D: 0.180448\n",
      "[Epoch 46/200] [Batch 910/938] loss_G: 2.657613, loss_D: 0.279169\n",
      "[Epoch 46/200] [Batch 920/938] loss_G: 2.438317, loss_D: 0.224500\n",
      "[Epoch 46/200] [Batch 930/938] loss_G: 2.250986, loss_D: 0.236752\n",
      "[Epoch 47/200] [Batch 0/938] loss_G: 2.459863, loss_D: 0.259816\n",
      "[Epoch 47/200] [Batch 10/938] loss_G: 2.787761, loss_D: 0.212839\n",
      "[Epoch 47/200] [Batch 20/938] loss_G: 2.313996, loss_D: 0.265051\n",
      "[Epoch 47/200] [Batch 30/938] loss_G: 2.578732, loss_D: 0.284737\n",
      "[Epoch 47/200] [Batch 40/938] loss_G: 2.550576, loss_D: 0.212918\n",
      "[Epoch 47/200] [Batch 50/938] loss_G: 2.800324, loss_D: 0.184496\n",
      "[Epoch 47/200] [Batch 60/938] loss_G: 2.540815, loss_D: 0.211865\n",
      "[Epoch 47/200] [Batch 70/938] loss_G: 2.720829, loss_D: 0.257485\n",
      "[Epoch 47/200] [Batch 80/938] loss_G: 2.367472, loss_D: 0.239334\n",
      "[Epoch 47/200] [Batch 90/938] loss_G: 2.801464, loss_D: 0.193612\n",
      "[Epoch 47/200] [Batch 100/938] loss_G: 2.326591, loss_D: 0.279855\n",
      "[Epoch 47/200] [Batch 110/938] loss_G: 2.570654, loss_D: 0.307745\n",
      "[Epoch 47/200] [Batch 120/938] loss_G: 2.200575, loss_D: 0.202607\n",
      "[Epoch 47/200] [Batch 130/938] loss_G: 2.504771, loss_D: 0.294020\n",
      "[Epoch 47/200] [Batch 140/938] loss_G: 2.377699, loss_D: 0.269779\n",
      "[Epoch 47/200] [Batch 150/938] loss_G: 2.842545, loss_D: 0.171615\n",
      "[Epoch 47/200] [Batch 160/938] loss_G: 2.641450, loss_D: 0.210542\n",
      "[Epoch 47/200] [Batch 170/938] loss_G: 2.509729, loss_D: 0.224162\n",
      "[Epoch 47/200] [Batch 180/938] loss_G: 2.668250, loss_D: 0.288390\n",
      "[Epoch 47/200] [Batch 190/938] loss_G: 2.406408, loss_D: 0.253036\n",
      "[Epoch 47/200] [Batch 200/938] loss_G: 2.392579, loss_D: 0.256432\n",
      "[Epoch 47/200] [Batch 210/938] loss_G: 2.296160, loss_D: 0.292077\n",
      "[Epoch 47/200] [Batch 220/938] loss_G: 2.826464, loss_D: 0.223046\n",
      "[Epoch 47/200] [Batch 230/938] loss_G: 2.413304, loss_D: 0.378797\n",
      "[Epoch 47/200] [Batch 240/938] loss_G: 2.844605, loss_D: 0.207003\n",
      "[Epoch 47/200] [Batch 250/938] loss_G: 2.914666, loss_D: 0.211032\n",
      "[Epoch 47/200] [Batch 260/938] loss_G: 2.515459, loss_D: 0.219600\n",
      "[Epoch 47/200] [Batch 270/938] loss_G: 2.853258, loss_D: 0.237801\n",
      "[Epoch 47/200] [Batch 280/938] loss_G: 2.612641, loss_D: 0.286272\n",
      "[Epoch 47/200] [Batch 290/938] loss_G: 2.799575, loss_D: 0.249686\n",
      "[Epoch 47/200] [Batch 300/938] loss_G: 2.774149, loss_D: 0.182456\n",
      "[Epoch 47/200] [Batch 310/938] loss_G: 2.917791, loss_D: 0.170170\n",
      "[Epoch 47/200] [Batch 320/938] loss_G: 2.917633, loss_D: 0.246634\n",
      "[Epoch 47/200] [Batch 330/938] loss_G: 2.470770, loss_D: 0.246759\n",
      "[Epoch 47/200] [Batch 340/938] loss_G: 2.703484, loss_D: 0.198173\n",
      "[Epoch 47/200] [Batch 350/938] loss_G: 2.782158, loss_D: 0.199520\n",
      "[Epoch 47/200] [Batch 360/938] loss_G: 2.980879, loss_D: 0.220769\n",
      "[Epoch 47/200] [Batch 370/938] loss_G: 2.501999, loss_D: 0.260803\n",
      "[Epoch 47/200] [Batch 380/938] loss_G: 3.033652, loss_D: 0.262904\n",
      "[Epoch 47/200] [Batch 390/938] loss_G: 2.901191, loss_D: 0.195364\n",
      "[Epoch 47/200] [Batch 400/938] loss_G: 3.287039, loss_D: 0.159458\n",
      "[Epoch 47/200] [Batch 410/938] loss_G: 2.705841, loss_D: 0.175120\n",
      "[Epoch 47/200] [Batch 420/938] loss_G: 2.839496, loss_D: 0.236541\n",
      "[Epoch 47/200] [Batch 430/938] loss_G: 2.800614, loss_D: 0.171912\n",
      "[Epoch 47/200] [Batch 440/938] loss_G: 2.498633, loss_D: 0.237508\n",
      "[Epoch 47/200] [Batch 450/938] loss_G: 2.727093, loss_D: 0.162347\n",
      "[Epoch 47/200] [Batch 460/938] loss_G: 2.437107, loss_D: 0.202903\n",
      "[Epoch 47/200] [Batch 470/938] loss_G: 2.582280, loss_D: 0.186905\n",
      "[Epoch 47/200] [Batch 480/938] loss_G: 2.420205, loss_D: 0.217913\n",
      "[Epoch 47/200] [Batch 490/938] loss_G: 2.422842, loss_D: 0.188655\n",
      "[Epoch 47/200] [Batch 500/938] loss_G: 3.035658, loss_D: 0.232680\n",
      "[Epoch 47/200] [Batch 510/938] loss_G: 2.445002, loss_D: 0.236615\n",
      "[Epoch 47/200] [Batch 520/938] loss_G: 2.662184, loss_D: 0.180165\n",
      "[Epoch 47/200] [Batch 530/938] loss_G: 2.766729, loss_D: 0.195614\n",
      "[Epoch 47/200] [Batch 540/938] loss_G: 2.605099, loss_D: 0.212785\n",
      "[Epoch 47/200] [Batch 550/938] loss_G: 2.812774, loss_D: 0.244099\n",
      "[Epoch 47/200] [Batch 560/938] loss_G: 2.815305, loss_D: 0.166115\n",
      "[Epoch 47/200] [Batch 570/938] loss_G: 2.621026, loss_D: 0.173006\n",
      "[Epoch 47/200] [Batch 580/938] loss_G: 2.459962, loss_D: 0.263519\n",
      "[Epoch 47/200] [Batch 590/938] loss_G: 2.353215, loss_D: 0.266940\n",
      "[Epoch 47/200] [Batch 600/938] loss_G: 2.730812, loss_D: 0.267655\n",
      "[Epoch 47/200] [Batch 610/938] loss_G: 2.526232, loss_D: 0.298459\n",
      "[Epoch 47/200] [Batch 620/938] loss_G: 2.773214, loss_D: 0.226408\n",
      "[Epoch 47/200] [Batch 630/938] loss_G: 2.496616, loss_D: 0.279577\n",
      "[Epoch 47/200] [Batch 640/938] loss_G: 2.733300, loss_D: 0.306601\n",
      "[Epoch 47/200] [Batch 650/938] loss_G: 2.975865, loss_D: 0.272476\n",
      "[Epoch 47/200] [Batch 660/938] loss_G: 2.500264, loss_D: 0.256987\n",
      "[Epoch 47/200] [Batch 670/938] loss_G: 2.643929, loss_D: 0.227817\n",
      "[Epoch 47/200] [Batch 680/938] loss_G: 2.962880, loss_D: 0.207148\n",
      "[Epoch 47/200] [Batch 690/938] loss_G: 2.640773, loss_D: 0.231743\n",
      "[Epoch 47/200] [Batch 700/938] loss_G: 2.749133, loss_D: 0.261495\n",
      "[Epoch 47/200] [Batch 710/938] loss_G: 2.811826, loss_D: 0.216695\n",
      "[Epoch 47/200] [Batch 720/938] loss_G: 2.816989, loss_D: 0.189260\n",
      "[Epoch 47/200] [Batch 730/938] loss_G: 2.595181, loss_D: 0.150849\n",
      "[Epoch 47/200] [Batch 740/938] loss_G: 2.519942, loss_D: 0.229892\n",
      "[Epoch 47/200] [Batch 750/938] loss_G: 2.660194, loss_D: 0.309960\n",
      "[Epoch 47/200] [Batch 760/938] loss_G: 2.500021, loss_D: 0.237895\n",
      "[Epoch 47/200] [Batch 770/938] loss_G: 2.639377, loss_D: 0.205257\n",
      "[Epoch 47/200] [Batch 780/938] loss_G: 2.907552, loss_D: 0.282922\n",
      "[Epoch 47/200] [Batch 790/938] loss_G: 2.182260, loss_D: 0.264460\n",
      "[Epoch 47/200] [Batch 800/938] loss_G: 2.882014, loss_D: 0.210357\n",
      "[Epoch 47/200] [Batch 810/938] loss_G: 2.656188, loss_D: 0.122728\n",
      "[Epoch 47/200] [Batch 820/938] loss_G: 2.343643, loss_D: 0.228533\n",
      "[Epoch 47/200] [Batch 830/938] loss_G: 2.740206, loss_D: 0.174954\n",
      "[Epoch 47/200] [Batch 840/938] loss_G: 2.735402, loss_D: 0.165069\n",
      "[Epoch 47/200] [Batch 850/938] loss_G: 2.482389, loss_D: 0.218118\n",
      "[Epoch 47/200] [Batch 860/938] loss_G: 2.432913, loss_D: 0.224901\n",
      "[Epoch 47/200] [Batch 870/938] loss_G: 2.541174, loss_D: 0.208039\n",
      "[Epoch 47/200] [Batch 880/938] loss_G: 2.562107, loss_D: 0.271196\n",
      "[Epoch 47/200] [Batch 890/938] loss_G: 3.299333, loss_D: 0.280178\n",
      "[Epoch 47/200] [Batch 900/938] loss_G: 2.595703, loss_D: 0.181991\n",
      "[Epoch 47/200] [Batch 910/938] loss_G: 2.470250, loss_D: 0.409757\n",
      "[Epoch 47/200] [Batch 920/938] loss_G: 2.825079, loss_D: 0.252739\n",
      "[Epoch 47/200] [Batch 930/938] loss_G: 2.889770, loss_D: 0.247166\n",
      "[Epoch 48/200] [Batch 0/938] loss_G: 3.047124, loss_D: 0.280199\n",
      "[Epoch 48/200] [Batch 10/938] loss_G: 2.534986, loss_D: 0.286128\n",
      "[Epoch 48/200] [Batch 20/938] loss_G: 2.753185, loss_D: 0.251272\n",
      "[Epoch 48/200] [Batch 30/938] loss_G: 2.787619, loss_D: 0.167943\n",
      "[Epoch 48/200] [Batch 40/938] loss_G: 2.659164, loss_D: 0.198130\n",
      "[Epoch 48/200] [Batch 50/938] loss_G: 3.002602, loss_D: 0.159285\n",
      "[Epoch 48/200] [Batch 60/938] loss_G: 2.310951, loss_D: 0.257617\n",
      "[Epoch 48/200] [Batch 70/938] loss_G: 3.152863, loss_D: 0.308033\n",
      "[Epoch 48/200] [Batch 80/938] loss_G: 2.512899, loss_D: 0.233142\n",
      "[Epoch 48/200] [Batch 90/938] loss_G: 2.969931, loss_D: 0.209701\n",
      "[Epoch 48/200] [Batch 100/938] loss_G: 2.462062, loss_D: 0.216210\n",
      "[Epoch 48/200] [Batch 110/938] loss_G: 2.798224, loss_D: 0.210032\n",
      "[Epoch 48/200] [Batch 120/938] loss_G: 2.854806, loss_D: 0.156573\n",
      "[Epoch 48/200] [Batch 130/938] loss_G: 2.951442, loss_D: 0.231461\n",
      "[Epoch 48/200] [Batch 140/938] loss_G: 2.448177, loss_D: 0.316376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 48/200] [Batch 150/938] loss_G: 2.664372, loss_D: 0.168682\n",
      "[Epoch 48/200] [Batch 160/938] loss_G: 2.401378, loss_D: 0.252263\n",
      "[Epoch 48/200] [Batch 170/938] loss_G: 2.686144, loss_D: 0.248336\n",
      "[Epoch 48/200] [Batch 180/938] loss_G: 2.339721, loss_D: 0.246681\n",
      "[Epoch 48/200] [Batch 190/938] loss_G: 2.917212, loss_D: 0.295018\n",
      "[Epoch 48/200] [Batch 200/938] loss_G: 2.623089, loss_D: 0.183249\n",
      "[Epoch 48/200] [Batch 210/938] loss_G: 2.543669, loss_D: 0.247510\n",
      "[Epoch 48/200] [Batch 220/938] loss_G: 2.949126, loss_D: 0.191476\n",
      "[Epoch 48/200] [Batch 230/938] loss_G: 2.519926, loss_D: 0.168646\n",
      "[Epoch 48/200] [Batch 240/938] loss_G: 2.549115, loss_D: 0.205786\n",
      "[Epoch 48/200] [Batch 250/938] loss_G: 2.195827, loss_D: 0.235794\n",
      "[Epoch 48/200] [Batch 260/938] loss_G: 2.764948, loss_D: 0.244107\n",
      "[Epoch 48/200] [Batch 270/938] loss_G: 2.447537, loss_D: 0.241959\n",
      "[Epoch 48/200] [Batch 280/938] loss_G: 2.486515, loss_D: 0.295227\n",
      "[Epoch 48/200] [Batch 290/938] loss_G: 2.706742, loss_D: 0.202713\n",
      "[Epoch 48/200] [Batch 300/938] loss_G: 2.282765, loss_D: 0.257404\n",
      "[Epoch 48/200] [Batch 310/938] loss_G: 3.012570, loss_D: 0.198753\n",
      "[Epoch 48/200] [Batch 320/938] loss_G: 2.541795, loss_D: 0.294323\n",
      "[Epoch 48/200] [Batch 330/938] loss_G: 2.699682, loss_D: 0.212701\n",
      "[Epoch 48/200] [Batch 340/938] loss_G: 2.528608, loss_D: 0.286131\n",
      "[Epoch 48/200] [Batch 350/938] loss_G: 2.113913, loss_D: 0.289216\n",
      "[Epoch 48/200] [Batch 360/938] loss_G: 2.602544, loss_D: 0.229602\n",
      "[Epoch 48/200] [Batch 370/938] loss_G: 2.967153, loss_D: 0.285068\n",
      "[Epoch 48/200] [Batch 380/938] loss_G: 2.528917, loss_D: 0.264620\n",
      "[Epoch 48/200] [Batch 390/938] loss_G: 2.752548, loss_D: 0.288691\n",
      "[Epoch 48/200] [Batch 400/938] loss_G: 2.959548, loss_D: 0.211540\n",
      "[Epoch 48/200] [Batch 410/938] loss_G: 2.807889, loss_D: 0.233978\n",
      "[Epoch 48/200] [Batch 420/938] loss_G: 2.822231, loss_D: 0.202957\n",
      "[Epoch 48/200] [Batch 430/938] loss_G: 2.841504, loss_D: 0.194323\n",
      "[Epoch 48/200] [Batch 440/938] loss_G: 2.850343, loss_D: 0.236169\n",
      "[Epoch 48/200] [Batch 450/938] loss_G: 2.694849, loss_D: 0.188892\n",
      "[Epoch 48/200] [Batch 460/938] loss_G: 2.732343, loss_D: 0.210226\n",
      "[Epoch 48/200] [Batch 470/938] loss_G: 3.068944, loss_D: 0.191946\n",
      "[Epoch 48/200] [Batch 480/938] loss_G: 2.725659, loss_D: 0.236602\n",
      "[Epoch 48/200] [Batch 490/938] loss_G: 3.049220, loss_D: 0.168888\n",
      "[Epoch 48/200] [Batch 500/938] loss_G: 2.657022, loss_D: 0.223760\n",
      "[Epoch 48/200] [Batch 510/938] loss_G: 2.637743, loss_D: 0.214387\n",
      "[Epoch 48/200] [Batch 520/938] loss_G: 2.870212, loss_D: 0.254162\n",
      "[Epoch 48/200] [Batch 530/938] loss_G: 2.994922, loss_D: 0.191211\n",
      "[Epoch 48/200] [Batch 540/938] loss_G: 2.763960, loss_D: 0.204519\n",
      "[Epoch 48/200] [Batch 550/938] loss_G: 2.602443, loss_D: 0.192072\n",
      "[Epoch 48/200] [Batch 560/938] loss_G: 2.536972, loss_D: 0.263204\n",
      "[Epoch 48/200] [Batch 570/938] loss_G: 2.627449, loss_D: 0.226832\n",
      "[Epoch 48/200] [Batch 580/938] loss_G: 2.866930, loss_D: 0.220977\n",
      "[Epoch 48/200] [Batch 590/938] loss_G: 2.707906, loss_D: 0.214105\n",
      "[Epoch 48/200] [Batch 600/938] loss_G: 2.758790, loss_D: 0.290074\n",
      "[Epoch 48/200] [Batch 610/938] loss_G: 2.517038, loss_D: 0.293178\n",
      "[Epoch 48/200] [Batch 620/938] loss_G: 2.571199, loss_D: 0.209794\n",
      "[Epoch 48/200] [Batch 630/938] loss_G: 2.797366, loss_D: 0.244559\n",
      "[Epoch 48/200] [Batch 640/938] loss_G: 2.814835, loss_D: 0.184269\n",
      "[Epoch 48/200] [Batch 650/938] loss_G: 3.058225, loss_D: 0.248710\n",
      "[Epoch 48/200] [Batch 660/938] loss_G: 2.472557, loss_D: 0.282278\n",
      "[Epoch 48/200] [Batch 670/938] loss_G: 2.934739, loss_D: 0.250366\n",
      "[Epoch 48/200] [Batch 680/938] loss_G: 3.148857, loss_D: 0.211853\n",
      "[Epoch 48/200] [Batch 690/938] loss_G: 2.667686, loss_D: 0.291515\n",
      "[Epoch 48/200] [Batch 700/938] loss_G: 2.913574, loss_D: 0.264406\n",
      "[Epoch 48/200] [Batch 710/938] loss_G: 2.513215, loss_D: 0.197344\n",
      "[Epoch 48/200] [Batch 720/938] loss_G: 3.001405, loss_D: 0.289439\n",
      "[Epoch 48/200] [Batch 730/938] loss_G: 2.854023, loss_D: 0.194581\n",
      "[Epoch 48/200] [Batch 740/938] loss_G: 2.986589, loss_D: 0.300987\n",
      "[Epoch 48/200] [Batch 750/938] loss_G: 2.630643, loss_D: 0.299907\n",
      "[Epoch 48/200] [Batch 760/938] loss_G: 2.898075, loss_D: 0.201833\n",
      "[Epoch 48/200] [Batch 770/938] loss_G: 2.770613, loss_D: 0.163916\n",
      "[Epoch 48/200] [Batch 780/938] loss_G: 2.628502, loss_D: 0.257096\n",
      "[Epoch 48/200] [Batch 790/938] loss_G: 2.603667, loss_D: 0.253946\n",
      "[Epoch 48/200] [Batch 800/938] loss_G: 3.149976, loss_D: 0.178864\n",
      "[Epoch 48/200] [Batch 810/938] loss_G: 2.538684, loss_D: 0.168738\n",
      "[Epoch 48/200] [Batch 820/938] loss_G: 3.041559, loss_D: 0.177776\n",
      "[Epoch 48/200] [Batch 830/938] loss_G: 2.753848, loss_D: 0.227649\n",
      "[Epoch 48/200] [Batch 840/938] loss_G: 2.543098, loss_D: 0.269379\n",
      "[Epoch 48/200] [Batch 850/938] loss_G: 2.891412, loss_D: 0.247754\n",
      "[Epoch 48/200] [Batch 860/938] loss_G: 2.477385, loss_D: 0.254277\n",
      "[Epoch 48/200] [Batch 870/938] loss_G: 2.893386, loss_D: 0.161418\n",
      "[Epoch 48/200] [Batch 880/938] loss_G: 2.709734, loss_D: 0.214268\n",
      "[Epoch 48/200] [Batch 890/938] loss_G: 2.695240, loss_D: 0.293747\n",
      "[Epoch 48/200] [Batch 900/938] loss_G: 2.482090, loss_D: 0.235999\n",
      "[Epoch 48/200] [Batch 910/938] loss_G: 2.573133, loss_D: 0.146506\n",
      "[Epoch 48/200] [Batch 920/938] loss_G: 2.716274, loss_D: 0.157794\n",
      "[Epoch 48/200] [Batch 930/938] loss_G: 2.450343, loss_D: 0.323646\n",
      "[Epoch 49/200] [Batch 0/938] loss_G: 2.625060, loss_D: 0.244548\n",
      "[Epoch 49/200] [Batch 10/938] loss_G: 2.548940, loss_D: 0.229120\n",
      "[Epoch 49/200] [Batch 20/938] loss_G: 2.743021, loss_D: 0.205354\n",
      "[Epoch 49/200] [Batch 30/938] loss_G: 2.744725, loss_D: 0.187377\n",
      "[Epoch 49/200] [Batch 40/938] loss_G: 2.658244, loss_D: 0.181612\n",
      "[Epoch 49/200] [Batch 50/938] loss_G: 2.917282, loss_D: 0.222816\n",
      "[Epoch 49/200] [Batch 60/938] loss_G: 2.352302, loss_D: 0.296054\n",
      "[Epoch 49/200] [Batch 70/938] loss_G: 2.764202, loss_D: 0.221663\n",
      "[Epoch 49/200] [Batch 80/938] loss_G: 2.975960, loss_D: 0.285280\n",
      "[Epoch 49/200] [Batch 90/938] loss_G: 3.047403, loss_D: 0.182231\n",
      "[Epoch 49/200] [Batch 100/938] loss_G: 2.670265, loss_D: 0.196609\n",
      "[Epoch 49/200] [Batch 110/938] loss_G: 2.377338, loss_D: 0.212233\n",
      "[Epoch 49/200] [Batch 120/938] loss_G: 2.758749, loss_D: 0.277453\n",
      "[Epoch 49/200] [Batch 130/938] loss_G: 2.489133, loss_D: 0.247566\n",
      "[Epoch 49/200] [Batch 140/938] loss_G: 2.462111, loss_D: 0.209051\n",
      "[Epoch 49/200] [Batch 150/938] loss_G: 2.399927, loss_D: 0.212259\n",
      "[Epoch 49/200] [Batch 160/938] loss_G: 2.655245, loss_D: 0.315169\n",
      "[Epoch 49/200] [Batch 170/938] loss_G: 2.582291, loss_D: 0.228664\n",
      "[Epoch 49/200] [Batch 180/938] loss_G: 3.016459, loss_D: 0.209947\n",
      "[Epoch 49/200] [Batch 190/938] loss_G: 2.899459, loss_D: 0.149890\n",
      "[Epoch 49/200] [Batch 200/938] loss_G: 2.838768, loss_D: 0.218237\n",
      "[Epoch 49/200] [Batch 210/938] loss_G: 2.268094, loss_D: 0.284310\n",
      "[Epoch 49/200] [Batch 220/938] loss_G: 2.905399, loss_D: 0.157230\n",
      "[Epoch 49/200] [Batch 230/938] loss_G: 2.836657, loss_D: 0.153387\n",
      "[Epoch 49/200] [Batch 240/938] loss_G: 2.847982, loss_D: 0.250932\n",
      "[Epoch 49/200] [Batch 250/938] loss_G: 2.439829, loss_D: 0.187746\n",
      "[Epoch 49/200] [Batch 260/938] loss_G: 2.338349, loss_D: 0.266505\n",
      "[Epoch 49/200] [Batch 270/938] loss_G: 2.668098, loss_D: 0.182423\n",
      "[Epoch 49/200] [Batch 280/938] loss_G: 3.114458, loss_D: 0.194128\n",
      "[Epoch 49/200] [Batch 290/938] loss_G: 2.409200, loss_D: 0.172912\n",
      "[Epoch 49/200] [Batch 300/938] loss_G: 2.977216, loss_D: 0.226307\n",
      "[Epoch 49/200] [Batch 310/938] loss_G: 2.669415, loss_D: 0.189802\n",
      "[Epoch 49/200] [Batch 320/938] loss_G: 2.834093, loss_D: 0.302492\n",
      "[Epoch 49/200] [Batch 330/938] loss_G: 2.531556, loss_D: 0.204941\n",
      "[Epoch 49/200] [Batch 340/938] loss_G: 2.785523, loss_D: 0.229330\n",
      "[Epoch 49/200] [Batch 350/938] loss_G: 2.784403, loss_D: 0.243011\n",
      "[Epoch 49/200] [Batch 360/938] loss_G: 2.808121, loss_D: 0.245730\n",
      "[Epoch 49/200] [Batch 370/938] loss_G: 3.053362, loss_D: 0.226087\n",
      "[Epoch 49/200] [Batch 380/938] loss_G: 2.398792, loss_D: 0.307839\n",
      "[Epoch 49/200] [Batch 390/938] loss_G: 2.748076, loss_D: 0.268128\n",
      "[Epoch 49/200] [Batch 400/938] loss_G: 2.270075, loss_D: 0.232191\n",
      "[Epoch 49/200] [Batch 410/938] loss_G: 2.554518, loss_D: 0.249738\n",
      "[Epoch 49/200] [Batch 420/938] loss_G: 2.977109, loss_D: 0.297480\n",
      "[Epoch 49/200] [Batch 430/938] loss_G: 2.777174, loss_D: 0.192295\n",
      "[Epoch 49/200] [Batch 440/938] loss_G: 2.560359, loss_D: 0.242527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 49/200] [Batch 450/938] loss_G: 2.807999, loss_D: 0.138218\n",
      "[Epoch 49/200] [Batch 460/938] loss_G: 2.854302, loss_D: 0.363013\n",
      "[Epoch 49/200] [Batch 470/938] loss_G: 2.857556, loss_D: 0.241758\n",
      "[Epoch 49/200] [Batch 480/938] loss_G: 2.589518, loss_D: 0.159004\n",
      "[Epoch 49/200] [Batch 490/938] loss_G: 2.470772, loss_D: 0.316486\n",
      "[Epoch 49/200] [Batch 500/938] loss_G: 2.653674, loss_D: 0.284147\n",
      "[Epoch 49/200] [Batch 510/938] loss_G: 3.146258, loss_D: 0.181775\n",
      "[Epoch 49/200] [Batch 520/938] loss_G: 2.366115, loss_D: 0.255488\n",
      "[Epoch 49/200] [Batch 530/938] loss_G: 2.897908, loss_D: 0.241528\n",
      "[Epoch 49/200] [Batch 540/938] loss_G: 2.751724, loss_D: 0.270307\n",
      "[Epoch 49/200] [Batch 550/938] loss_G: 2.729876, loss_D: 0.219009\n",
      "[Epoch 49/200] [Batch 560/938] loss_G: 3.122802, loss_D: 0.216924\n",
      "[Epoch 49/200] [Batch 570/938] loss_G: 2.771283, loss_D: 0.223875\n",
      "[Epoch 49/200] [Batch 580/938] loss_G: 2.546557, loss_D: 0.243741\n",
      "[Epoch 49/200] [Batch 590/938] loss_G: 2.523178, loss_D: 0.288056\n",
      "[Epoch 49/200] [Batch 600/938] loss_G: 2.800702, loss_D: 0.203274\n",
      "[Epoch 49/200] [Batch 610/938] loss_G: 3.128250, loss_D: 0.158355\n",
      "[Epoch 49/200] [Batch 620/938] loss_G: 2.999303, loss_D: 0.215866\n",
      "[Epoch 49/200] [Batch 630/938] loss_G: 2.943308, loss_D: 0.247445\n",
      "[Epoch 49/200] [Batch 640/938] loss_G: 2.477209, loss_D: 0.232412\n",
      "[Epoch 49/200] [Batch 650/938] loss_G: 3.079898, loss_D: 0.275536\n",
      "[Epoch 49/200] [Batch 660/938] loss_G: 2.674440, loss_D: 0.279198\n",
      "[Epoch 49/200] [Batch 670/938] loss_G: 2.508024, loss_D: 0.262721\n",
      "[Epoch 49/200] [Batch 680/938] loss_G: 2.980790, loss_D: 0.214339\n",
      "[Epoch 49/200] [Batch 690/938] loss_G: 2.458188, loss_D: 0.246025\n",
      "[Epoch 49/200] [Batch 700/938] loss_G: 2.738109, loss_D: 0.280438\n",
      "[Epoch 49/200] [Batch 710/938] loss_G: 2.506517, loss_D: 0.295487\n",
      "[Epoch 49/200] [Batch 720/938] loss_G: 2.782400, loss_D: 0.131455\n",
      "[Epoch 49/200] [Batch 730/938] loss_G: 2.300305, loss_D: 0.222076\n",
      "[Epoch 49/200] [Batch 740/938] loss_G: 2.802399, loss_D: 0.160694\n",
      "[Epoch 49/200] [Batch 750/938] loss_G: 2.375376, loss_D: 0.264096\n",
      "[Epoch 49/200] [Batch 760/938] loss_G: 2.540538, loss_D: 0.222219\n",
      "[Epoch 49/200] [Batch 770/938] loss_G: 2.533632, loss_D: 0.244382\n",
      "[Epoch 49/200] [Batch 780/938] loss_G: 2.676866, loss_D: 0.251435\n",
      "[Epoch 49/200] [Batch 790/938] loss_G: 2.492451, loss_D: 0.236492\n",
      "[Epoch 49/200] [Batch 800/938] loss_G: 2.116206, loss_D: 0.269718\n",
      "[Epoch 49/200] [Batch 810/938] loss_G: 2.743627, loss_D: 0.223425\n",
      "[Epoch 49/200] [Batch 820/938] loss_G: 2.899802, loss_D: 0.183681\n",
      "[Epoch 49/200] [Batch 830/938] loss_G: 2.524949, loss_D: 0.142308\n",
      "[Epoch 49/200] [Batch 840/938] loss_G: 2.694923, loss_D: 0.231400\n",
      "[Epoch 49/200] [Batch 850/938] loss_G: 2.884674, loss_D: 0.242999\n",
      "[Epoch 49/200] [Batch 860/938] loss_G: 2.730575, loss_D: 0.204823\n",
      "[Epoch 49/200] [Batch 870/938] loss_G: 2.711802, loss_D: 0.233168\n",
      "[Epoch 49/200] [Batch 880/938] loss_G: 2.506652, loss_D: 0.291776\n",
      "[Epoch 49/200] [Batch 890/938] loss_G: 2.810677, loss_D: 0.230505\n",
      "[Epoch 49/200] [Batch 900/938] loss_G: 2.843347, loss_D: 0.236119\n",
      "[Epoch 49/200] [Batch 910/938] loss_G: 2.945193, loss_D: 0.179583\n",
      "[Epoch 49/200] [Batch 920/938] loss_G: 2.759292, loss_D: 0.171665\n",
      "[Epoch 49/200] [Batch 930/938] loss_G: 2.638300, loss_D: 0.318060\n",
      "[Epoch 50/200] [Batch 0/938] loss_G: 2.878746, loss_D: 0.178014\n",
      "[Epoch 50/200] [Batch 10/938] loss_G: 2.555096, loss_D: 0.312868\n",
      "[Epoch 50/200] [Batch 20/938] loss_G: 2.845138, loss_D: 0.179341\n",
      "[Epoch 50/200] [Batch 30/938] loss_G: 2.682533, loss_D: 0.264640\n",
      "[Epoch 50/200] [Batch 40/938] loss_G: 2.701314, loss_D: 0.264162\n",
      "[Epoch 50/200] [Batch 50/938] loss_G: 2.579705, loss_D: 0.162422\n",
      "[Epoch 50/200] [Batch 60/938] loss_G: 2.352574, loss_D: 0.215565\n",
      "[Epoch 50/200] [Batch 70/938] loss_G: 2.384841, loss_D: 0.265492\n",
      "[Epoch 50/200] [Batch 80/938] loss_G: 2.377706, loss_D: 0.232055\n",
      "[Epoch 50/200] [Batch 90/938] loss_G: 2.567393, loss_D: 0.201101\n",
      "[Epoch 50/200] [Batch 100/938] loss_G: 2.802253, loss_D: 0.201141\n",
      "[Epoch 50/200] [Batch 110/938] loss_G: 2.403248, loss_D: 0.181371\n",
      "[Epoch 50/200] [Batch 120/938] loss_G: 2.728904, loss_D: 0.162414\n",
      "[Epoch 50/200] [Batch 130/938] loss_G: 2.690027, loss_D: 0.188059\n",
      "[Epoch 50/200] [Batch 140/938] loss_G: 2.825355, loss_D: 0.231025\n",
      "[Epoch 50/200] [Batch 150/938] loss_G: 2.535958, loss_D: 0.222756\n",
      "[Epoch 50/200] [Batch 160/938] loss_G: 2.872559, loss_D: 0.275079\n",
      "[Epoch 50/200] [Batch 170/938] loss_G: 2.658383, loss_D: 0.294257\n",
      "[Epoch 50/200] [Batch 180/938] loss_G: 2.773153, loss_D: 0.252224\n",
      "[Epoch 50/200] [Batch 190/938] loss_G: 2.514193, loss_D: 0.256316\n",
      "[Epoch 50/200] [Batch 200/938] loss_G: 2.495515, loss_D: 0.315516\n",
      "[Epoch 50/200] [Batch 210/938] loss_G: 2.818498, loss_D: 0.185733\n",
      "[Epoch 50/200] [Batch 220/938] loss_G: 2.525489, loss_D: 0.271316\n",
      "[Epoch 50/200] [Batch 230/938] loss_G: 2.757008, loss_D: 0.257837\n",
      "[Epoch 50/200] [Batch 240/938] loss_G: 2.738845, loss_D: 0.211743\n",
      "[Epoch 50/200] [Batch 250/938] loss_G: 2.422129, loss_D: 0.244048\n",
      "[Epoch 50/200] [Batch 260/938] loss_G: 2.611287, loss_D: 0.289126\n",
      "[Epoch 50/200] [Batch 270/938] loss_G: 2.369112, loss_D: 0.295088\n",
      "[Epoch 50/200] [Batch 280/938] loss_G: 2.732195, loss_D: 0.240591\n",
      "[Epoch 50/200] [Batch 290/938] loss_G: 2.967890, loss_D: 0.217574\n",
      "[Epoch 50/200] [Batch 300/938] loss_G: 2.705000, loss_D: 0.197229\n",
      "[Epoch 50/200] [Batch 310/938] loss_G: 2.891433, loss_D: 0.165570\n",
      "[Epoch 50/200] [Batch 320/938] loss_G: 2.748362, loss_D: 0.334583\n",
      "[Epoch 50/200] [Batch 330/938] loss_G: 2.833499, loss_D: 0.274248\n",
      "[Epoch 50/200] [Batch 340/938] loss_G: 2.524714, loss_D: 0.281806\n",
      "[Epoch 50/200] [Batch 350/938] loss_G: 2.498339, loss_D: 0.278498\n",
      "[Epoch 50/200] [Batch 360/938] loss_G: 2.988474, loss_D: 0.145168\n",
      "[Epoch 50/200] [Batch 370/938] loss_G: 2.277124, loss_D: 0.214190\n",
      "[Epoch 50/200] [Batch 380/938] loss_G: 2.605911, loss_D: 0.283535\n",
      "[Epoch 50/200] [Batch 390/938] loss_G: 2.594410, loss_D: 0.159089\n",
      "[Epoch 50/200] [Batch 400/938] loss_G: 2.858283, loss_D: 0.147211\n",
      "[Epoch 50/200] [Batch 410/938] loss_G: 2.728102, loss_D: 0.209837\n",
      "[Epoch 50/200] [Batch 420/938] loss_G: 2.803612, loss_D: 0.192137\n",
      "[Epoch 50/200] [Batch 430/938] loss_G: 2.564686, loss_D: 0.203659\n",
      "[Epoch 50/200] [Batch 440/938] loss_G: 2.477165, loss_D: 0.228175\n",
      "[Epoch 50/200] [Batch 450/938] loss_G: 2.544658, loss_D: 0.235788\n",
      "[Epoch 50/200] [Batch 460/938] loss_G: 2.730273, loss_D: 0.173017\n",
      "[Epoch 50/200] [Batch 470/938] loss_G: 2.464499, loss_D: 0.259500\n",
      "[Epoch 50/200] [Batch 480/938] loss_G: 2.477126, loss_D: 0.249517\n",
      "[Epoch 50/200] [Batch 490/938] loss_G: 2.498335, loss_D: 0.348529\n",
      "[Epoch 50/200] [Batch 500/938] loss_G: 2.465103, loss_D: 0.226716\n",
      "[Epoch 50/200] [Batch 510/938] loss_G: 2.699592, loss_D: 0.229304\n",
      "[Epoch 50/200] [Batch 520/938] loss_G: 2.705150, loss_D: 0.175018\n",
      "[Epoch 50/200] [Batch 530/938] loss_G: 2.406066, loss_D: 0.153103\n",
      "[Epoch 50/200] [Batch 540/938] loss_G: 2.486272, loss_D: 0.229974\n",
      "[Epoch 50/200] [Batch 550/938] loss_G: 2.751819, loss_D: 0.174742\n",
      "[Epoch 50/200] [Batch 560/938] loss_G: 2.820956, loss_D: 0.215854\n",
      "[Epoch 50/200] [Batch 570/938] loss_G: 2.330613, loss_D: 0.282847\n",
      "[Epoch 50/200] [Batch 580/938] loss_G: 2.351963, loss_D: 0.300357\n",
      "[Epoch 50/200] [Batch 590/938] loss_G: 2.740100, loss_D: 0.256774\n",
      "[Epoch 50/200] [Batch 600/938] loss_G: 2.741364, loss_D: 0.211757\n",
      "[Epoch 50/200] [Batch 610/938] loss_G: 3.069435, loss_D: 0.294942\n",
      "[Epoch 50/200] [Batch 620/938] loss_G: 3.039847, loss_D: 0.260478\n",
      "[Epoch 50/200] [Batch 630/938] loss_G: 2.469448, loss_D: 0.257270\n",
      "[Epoch 50/200] [Batch 640/938] loss_G: 2.558091, loss_D: 0.246394\n",
      "[Epoch 50/200] [Batch 650/938] loss_G: 2.481000, loss_D: 0.194888\n",
      "[Epoch 50/200] [Batch 660/938] loss_G: 2.992886, loss_D: 0.214058\n",
      "[Epoch 50/200] [Batch 670/938] loss_G: 2.774462, loss_D: 0.226185\n",
      "[Epoch 50/200] [Batch 680/938] loss_G: 2.737631, loss_D: 0.238352\n",
      "[Epoch 50/200] [Batch 690/938] loss_G: 2.756133, loss_D: 0.183703\n",
      "[Epoch 50/200] [Batch 700/938] loss_G: 3.128194, loss_D: 0.189702\n",
      "[Epoch 50/200] [Batch 710/938] loss_G: 2.534328, loss_D: 0.265951\n",
      "[Epoch 50/200] [Batch 720/938] loss_G: 2.966729, loss_D: 0.190224\n",
      "[Epoch 50/200] [Batch 730/938] loss_G: 2.682673, loss_D: 0.224946\n",
      "[Epoch 50/200] [Batch 740/938] loss_G: 2.596726, loss_D: 0.318193\n",
      "[Epoch 50/200] [Batch 750/938] loss_G: 3.017892, loss_D: 0.163401\n",
      "[Epoch 50/200] [Batch 760/938] loss_G: 2.669013, loss_D: 0.227985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 50/200] [Batch 770/938] loss_G: 2.362025, loss_D: 0.249173\n",
      "[Epoch 50/200] [Batch 780/938] loss_G: 2.838730, loss_D: 0.223556\n",
      "[Epoch 50/200] [Batch 790/938] loss_G: 2.741769, loss_D: 0.260243\n",
      "[Epoch 50/200] [Batch 800/938] loss_G: 2.789641, loss_D: 0.342097\n",
      "[Epoch 50/200] [Batch 810/938] loss_G: 2.903910, loss_D: 0.225256\n",
      "[Epoch 50/200] [Batch 820/938] loss_G: 2.761029, loss_D: 0.152833\n",
      "[Epoch 50/200] [Batch 830/938] loss_G: 2.430757, loss_D: 0.232972\n",
      "[Epoch 50/200] [Batch 840/938] loss_G: 2.547880, loss_D: 0.290671\n",
      "[Epoch 50/200] [Batch 850/938] loss_G: 2.206297, loss_D: 0.227151\n",
      "[Epoch 50/200] [Batch 860/938] loss_G: 2.479418, loss_D: 0.315694\n",
      "[Epoch 50/200] [Batch 870/938] loss_G: 3.343211, loss_D: 0.265544\n",
      "[Epoch 50/200] [Batch 880/938] loss_G: 3.211113, loss_D: 0.159473\n",
      "[Epoch 50/200] [Batch 890/938] loss_G: 2.780016, loss_D: 0.194208\n",
      "[Epoch 50/200] [Batch 900/938] loss_G: 2.571035, loss_D: 0.203472\n",
      "[Epoch 50/200] [Batch 910/938] loss_G: 2.211319, loss_D: 0.265232\n",
      "[Epoch 50/200] [Batch 920/938] loss_G: 2.846654, loss_D: 0.151699\n",
      "[Epoch 50/200] [Batch 930/938] loss_G: 2.574879, loss_D: 0.256801\n",
      "[Epoch 51/200] [Batch 0/938] loss_G: 2.647120, loss_D: 0.227276\n",
      "[Epoch 51/200] [Batch 10/938] loss_G: 2.599228, loss_D: 0.277353\n",
      "[Epoch 51/200] [Batch 20/938] loss_G: 2.455178, loss_D: 0.309447\n",
      "[Epoch 51/200] [Batch 30/938] loss_G: 2.449759, loss_D: 0.308378\n",
      "[Epoch 51/200] [Batch 40/938] loss_G: 3.048526, loss_D: 0.234561\n",
      "[Epoch 51/200] [Batch 50/938] loss_G: 2.886054, loss_D: 0.154177\n",
      "[Epoch 51/200] [Batch 60/938] loss_G: 2.753581, loss_D: 0.252156\n",
      "[Epoch 51/200] [Batch 70/938] loss_G: 2.372073, loss_D: 0.216377\n",
      "[Epoch 51/200] [Batch 80/938] loss_G: 2.538342, loss_D: 0.304591\n",
      "[Epoch 51/200] [Batch 90/938] loss_G: 2.849693, loss_D: 0.180502\n",
      "[Epoch 51/200] [Batch 100/938] loss_G: 3.040577, loss_D: 0.221080\n",
      "[Epoch 51/200] [Batch 110/938] loss_G: 2.757191, loss_D: 0.255095\n",
      "[Epoch 51/200] [Batch 120/938] loss_G: 2.546822, loss_D: 0.293135\n",
      "[Epoch 51/200] [Batch 130/938] loss_G: 2.729182, loss_D: 0.265758\n",
      "[Epoch 51/200] [Batch 140/938] loss_G: 2.788923, loss_D: 0.304751\n",
      "[Epoch 51/200] [Batch 150/938] loss_G: 2.343241, loss_D: 0.211991\n",
      "[Epoch 51/200] [Batch 160/938] loss_G: 2.762137, loss_D: 0.228956\n",
      "[Epoch 51/200] [Batch 170/938] loss_G: 2.639890, loss_D: 0.261633\n",
      "[Epoch 51/200] [Batch 180/938] loss_G: 2.696265, loss_D: 0.170162\n",
      "[Epoch 51/200] [Batch 190/938] loss_G: 3.097075, loss_D: 0.215767\n",
      "[Epoch 51/200] [Batch 200/938] loss_G: 2.594437, loss_D: 0.307037\n",
      "[Epoch 51/200] [Batch 210/938] loss_G: 2.497981, loss_D: 0.252233\n",
      "[Epoch 51/200] [Batch 220/938] loss_G: 2.562162, loss_D: 0.218944\n",
      "[Epoch 51/200] [Batch 230/938] loss_G: 2.721671, loss_D: 0.222677\n",
      "[Epoch 51/200] [Batch 240/938] loss_G: 2.621063, loss_D: 0.194073\n",
      "[Epoch 51/200] [Batch 250/938] loss_G: 2.825006, loss_D: 0.219455\n",
      "[Epoch 51/200] [Batch 260/938] loss_G: 2.386114, loss_D: 0.272587\n",
      "[Epoch 51/200] [Batch 270/938] loss_G: 2.333001, loss_D: 0.248076\n",
      "[Epoch 51/200] [Batch 280/938] loss_G: 3.046897, loss_D: 0.142913\n",
      "[Epoch 51/200] [Batch 290/938] loss_G: 2.624241, loss_D: 0.233784\n",
      "[Epoch 51/200] [Batch 300/938] loss_G: 2.787249, loss_D: 0.178917\n",
      "[Epoch 51/200] [Batch 310/938] loss_G: 2.702314, loss_D: 0.219255\n",
      "[Epoch 51/200] [Batch 320/938] loss_G: 2.846447, loss_D: 0.257884\n",
      "[Epoch 51/200] [Batch 330/938] loss_G: 2.725141, loss_D: 0.205430\n",
      "[Epoch 51/200] [Batch 340/938] loss_G: 2.604331, loss_D: 0.230274\n",
      "[Epoch 51/200] [Batch 350/938] loss_G: 2.551499, loss_D: 0.239314\n",
      "[Epoch 51/200] [Batch 360/938] loss_G: 2.167483, loss_D: 0.328163\n",
      "[Epoch 51/200] [Batch 370/938] loss_G: 2.416780, loss_D: 0.336662\n",
      "[Epoch 51/200] [Batch 380/938] loss_G: 2.420460, loss_D: 0.245235\n",
      "[Epoch 51/200] [Batch 390/938] loss_G: 2.633818, loss_D: 0.215206\n",
      "[Epoch 51/200] [Batch 400/938] loss_G: 2.429802, loss_D: 0.205872\n",
      "[Epoch 51/200] [Batch 410/938] loss_G: 2.534395, loss_D: 0.233250\n",
      "[Epoch 51/200] [Batch 420/938] loss_G: 2.415627, loss_D: 0.211752\n",
      "[Epoch 51/200] [Batch 430/938] loss_G: 2.499591, loss_D: 0.152122\n",
      "[Epoch 51/200] [Batch 440/938] loss_G: 2.664298, loss_D: 0.192106\n",
      "[Epoch 51/200] [Batch 450/938] loss_G: 2.513875, loss_D: 0.154608\n",
      "[Epoch 51/200] [Batch 460/938] loss_G: 2.923127, loss_D: 0.149554\n",
      "[Epoch 51/200] [Batch 470/938] loss_G: 2.403035, loss_D: 0.204466\n",
      "[Epoch 51/200] [Batch 480/938] loss_G: 2.628851, loss_D: 0.271369\n",
      "[Epoch 51/200] [Batch 490/938] loss_G: 2.531202, loss_D: 0.243573\n",
      "[Epoch 51/200] [Batch 500/938] loss_G: 2.463394, loss_D: 0.245642\n",
      "[Epoch 51/200] [Batch 510/938] loss_G: 2.332334, loss_D: 0.297969\n",
      "[Epoch 51/200] [Batch 520/938] loss_G: 2.633575, loss_D: 0.211883\n",
      "[Epoch 51/200] [Batch 530/938] loss_G: 2.703794, loss_D: 0.214253\n",
      "[Epoch 51/200] [Batch 540/938] loss_G: 2.674724, loss_D: 0.203967\n",
      "[Epoch 51/200] [Batch 550/938] loss_G: 2.720517, loss_D: 0.142262\n",
      "[Epoch 51/200] [Batch 560/938] loss_G: 2.528461, loss_D: 0.253089\n",
      "[Epoch 51/200] [Batch 570/938] loss_G: 2.857529, loss_D: 0.220249\n",
      "[Epoch 51/200] [Batch 580/938] loss_G: 2.530550, loss_D: 0.199831\n",
      "[Epoch 51/200] [Batch 590/938] loss_G: 3.065367, loss_D: 0.261390\n",
      "[Epoch 51/200] [Batch 600/938] loss_G: 2.621311, loss_D: 0.235860\n",
      "[Epoch 51/200] [Batch 610/938] loss_G: 2.872806, loss_D: 0.340936\n",
      "[Epoch 51/200] [Batch 620/938] loss_G: 2.342513, loss_D: 0.282994\n",
      "[Epoch 51/200] [Batch 630/938] loss_G: 2.378598, loss_D: 0.207441\n",
      "[Epoch 51/200] [Batch 640/938] loss_G: 2.756300, loss_D: 0.249813\n",
      "[Epoch 51/200] [Batch 650/938] loss_G: 3.036127, loss_D: 0.184289\n",
      "[Epoch 51/200] [Batch 660/938] loss_G: 2.780180, loss_D: 0.287368\n",
      "[Epoch 51/200] [Batch 670/938] loss_G: 2.884722, loss_D: 0.274284\n",
      "[Epoch 51/200] [Batch 680/938] loss_G: 2.441811, loss_D: 0.313986\n",
      "[Epoch 51/200] [Batch 690/938] loss_G: 2.597962, loss_D: 0.241268\n",
      "[Epoch 51/200] [Batch 700/938] loss_G: 2.776749, loss_D: 0.128916\n",
      "[Epoch 51/200] [Batch 710/938] loss_G: 2.543839, loss_D: 0.273091\n",
      "[Epoch 51/200] [Batch 720/938] loss_G: 2.666474, loss_D: 0.217500\n",
      "[Epoch 51/200] [Batch 730/938] loss_G: 2.748222, loss_D: 0.155350\n",
      "[Epoch 51/200] [Batch 740/938] loss_G: 2.869464, loss_D: 0.164139\n",
      "[Epoch 51/200] [Batch 750/938] loss_G: 2.768395, loss_D: 0.223142\n",
      "[Epoch 51/200] [Batch 760/938] loss_G: 2.249468, loss_D: 0.246406\n",
      "[Epoch 51/200] [Batch 770/938] loss_G: 2.495548, loss_D: 0.230315\n",
      "[Epoch 51/200] [Batch 780/938] loss_G: 2.653193, loss_D: 0.202530\n",
      "[Epoch 51/200] [Batch 790/938] loss_G: 2.638746, loss_D: 0.147300\n",
      "[Epoch 51/200] [Batch 800/938] loss_G: 2.775214, loss_D: 0.223991\n",
      "[Epoch 51/200] [Batch 810/938] loss_G: 2.466127, loss_D: 0.139809\n",
      "[Epoch 51/200] [Batch 820/938] loss_G: 2.552075, loss_D: 0.232826\n",
      "[Epoch 51/200] [Batch 830/938] loss_G: 2.462900, loss_D: 0.410279\n",
      "[Epoch 51/200] [Batch 840/938] loss_G: 2.641404, loss_D: 0.281390\n",
      "[Epoch 51/200] [Batch 850/938] loss_G: 2.691315, loss_D: 0.252710\n",
      "[Epoch 51/200] [Batch 860/938] loss_G: 2.840181, loss_D: 0.238302\n",
      "[Epoch 51/200] [Batch 870/938] loss_G: 2.267636, loss_D: 0.249003\n",
      "[Epoch 51/200] [Batch 880/938] loss_G: 2.781783, loss_D: 0.219721\n",
      "[Epoch 51/200] [Batch 890/938] loss_G: 2.265198, loss_D: 0.341452\n",
      "[Epoch 51/200] [Batch 900/938] loss_G: 2.217472, loss_D: 0.219770\n",
      "[Epoch 51/200] [Batch 910/938] loss_G: 2.554218, loss_D: 0.188515\n",
      "[Epoch 51/200] [Batch 920/938] loss_G: 2.748681, loss_D: 0.268208\n",
      "[Epoch 51/200] [Batch 930/938] loss_G: 2.387602, loss_D: 0.188701\n",
      "[Epoch 52/200] [Batch 0/938] loss_G: 2.113887, loss_D: 0.351576\n",
      "[Epoch 52/200] [Batch 10/938] loss_G: 2.460044, loss_D: 0.326812\n",
      "[Epoch 52/200] [Batch 20/938] loss_G: 2.509422, loss_D: 0.361126\n",
      "[Epoch 52/200] [Batch 30/938] loss_G: 2.809590, loss_D: 0.208914\n",
      "[Epoch 52/200] [Batch 40/938] loss_G: 2.113868, loss_D: 0.326500\n",
      "[Epoch 52/200] [Batch 50/938] loss_G: 2.486523, loss_D: 0.182866\n",
      "[Epoch 52/200] [Batch 60/938] loss_G: 2.668397, loss_D: 0.236865\n",
      "[Epoch 52/200] [Batch 70/938] loss_G: 2.863614, loss_D: 0.234035\n",
      "[Epoch 52/200] [Batch 80/938] loss_G: 2.241468, loss_D: 0.246858\n",
      "[Epoch 52/200] [Batch 90/938] loss_G: 2.507737, loss_D: 0.227295\n",
      "[Epoch 52/200] [Batch 100/938] loss_G: 2.439532, loss_D: 0.307583\n",
      "[Epoch 52/200] [Batch 110/938] loss_G: 2.764530, loss_D: 0.191268\n",
      "[Epoch 52/200] [Batch 120/938] loss_G: 2.426618, loss_D: 0.344685\n",
      "[Epoch 52/200] [Batch 130/938] loss_G: 2.834678, loss_D: 0.193507\n",
      "[Epoch 52/200] [Batch 140/938] loss_G: 2.991639, loss_D: 0.140773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 52/200] [Batch 150/938] loss_G: 2.907311, loss_D: 0.216007\n",
      "[Epoch 52/200] [Batch 160/938] loss_G: 2.637236, loss_D: 0.287461\n",
      "[Epoch 52/200] [Batch 170/938] loss_G: 2.544741, loss_D: 0.196172\n",
      "[Epoch 52/200] [Batch 180/938] loss_G: 2.468002, loss_D: 0.331241\n",
      "[Epoch 52/200] [Batch 190/938] loss_G: 2.836036, loss_D: 0.157965\n",
      "[Epoch 52/200] [Batch 200/938] loss_G: 2.592569, loss_D: 0.192792\n",
      "[Epoch 52/200] [Batch 210/938] loss_G: 2.690790, loss_D: 0.221553\n",
      "[Epoch 52/200] [Batch 220/938] loss_G: 3.041942, loss_D: 0.317876\n",
      "[Epoch 52/200] [Batch 230/938] loss_G: 2.737962, loss_D: 0.325222\n",
      "[Epoch 52/200] [Batch 240/938] loss_G: 2.934289, loss_D: 0.207607\n",
      "[Epoch 52/200] [Batch 250/938] loss_G: 3.213874, loss_D: 0.225160\n",
      "[Epoch 52/200] [Batch 260/938] loss_G: 2.479337, loss_D: 0.166754\n",
      "[Epoch 52/200] [Batch 270/938] loss_G: 2.890788, loss_D: 0.265683\n",
      "[Epoch 52/200] [Batch 280/938] loss_G: 2.893543, loss_D: 0.204030\n",
      "[Epoch 52/200] [Batch 290/938] loss_G: 2.766189, loss_D: 0.286391\n",
      "[Epoch 52/200] [Batch 300/938] loss_G: 2.952322, loss_D: 0.243881\n",
      "[Epoch 52/200] [Batch 310/938] loss_G: 2.467477, loss_D: 0.287845\n",
      "[Epoch 52/200] [Batch 320/938] loss_G: 2.835820, loss_D: 0.241731\n",
      "[Epoch 52/200] [Batch 330/938] loss_G: 2.495908, loss_D: 0.249593\n",
      "[Epoch 52/200] [Batch 340/938] loss_G: 2.464366, loss_D: 0.274192\n",
      "[Epoch 52/200] [Batch 350/938] loss_G: 2.900030, loss_D: 0.215943\n",
      "[Epoch 52/200] [Batch 360/938] loss_G: 2.905918, loss_D: 0.214048\n",
      "[Epoch 52/200] [Batch 370/938] loss_G: 2.539337, loss_D: 0.197123\n",
      "[Epoch 52/200] [Batch 380/938] loss_G: 3.040059, loss_D: 0.238617\n",
      "[Epoch 52/200] [Batch 390/938] loss_G: 2.554206, loss_D: 0.192106\n",
      "[Epoch 52/200] [Batch 400/938] loss_G: 2.553681, loss_D: 0.296216\n",
      "[Epoch 52/200] [Batch 410/938] loss_G: 2.693257, loss_D: 0.345762\n",
      "[Epoch 52/200] [Batch 420/938] loss_G: 3.069682, loss_D: 0.147452\n",
      "[Epoch 52/200] [Batch 430/938] loss_G: 2.566802, loss_D: 0.208213\n",
      "[Epoch 52/200] [Batch 440/938] loss_G: 2.644235, loss_D: 0.201298\n",
      "[Epoch 52/200] [Batch 450/938] loss_G: 2.396758, loss_D: 0.254534\n",
      "[Epoch 52/200] [Batch 460/938] loss_G: 2.134965, loss_D: 0.392811\n",
      "[Epoch 52/200] [Batch 470/938] loss_G: 2.887553, loss_D: 0.214840\n",
      "[Epoch 52/200] [Batch 480/938] loss_G: 2.948290, loss_D: 0.165983\n",
      "[Epoch 52/200] [Batch 490/938] loss_G: 2.848946, loss_D: 0.259329\n",
      "[Epoch 52/200] [Batch 500/938] loss_G: 2.820905, loss_D: 0.271691\n",
      "[Epoch 52/200] [Batch 510/938] loss_G: 2.736116, loss_D: 0.321262\n",
      "[Epoch 52/200] [Batch 520/938] loss_G: 2.439535, loss_D: 0.235369\n",
      "[Epoch 52/200] [Batch 530/938] loss_G: 2.660108, loss_D: 0.289051\n",
      "[Epoch 52/200] [Batch 540/938] loss_G: 2.654192, loss_D: 0.184880\n",
      "[Epoch 52/200] [Batch 550/938] loss_G: 2.806300, loss_D: 0.185383\n",
      "[Epoch 52/200] [Batch 560/938] loss_G: 2.677008, loss_D: 0.267986\n",
      "[Epoch 52/200] [Batch 570/938] loss_G: 2.649413, loss_D: 0.195721\n",
      "[Epoch 52/200] [Batch 580/938] loss_G: 2.976273, loss_D: 0.255382\n",
      "[Epoch 52/200] [Batch 590/938] loss_G: 2.862861, loss_D: 0.259042\n",
      "[Epoch 52/200] [Batch 600/938] loss_G: 2.842278, loss_D: 0.176258\n",
      "[Epoch 52/200] [Batch 610/938] loss_G: 2.896552, loss_D: 0.202576\n",
      "[Epoch 52/200] [Batch 620/938] loss_G: 2.562114, loss_D: 0.308267\n",
      "[Epoch 52/200] [Batch 630/938] loss_G: 2.699182, loss_D: 0.264030\n",
      "[Epoch 52/200] [Batch 640/938] loss_G: 2.827273, loss_D: 0.186729\n",
      "[Epoch 52/200] [Batch 650/938] loss_G: 2.771400, loss_D: 0.219128\n",
      "[Epoch 52/200] [Batch 660/938] loss_G: 2.898466, loss_D: 0.209123\n",
      "[Epoch 52/200] [Batch 670/938] loss_G: 2.207941, loss_D: 0.186436\n",
      "[Epoch 52/200] [Batch 680/938] loss_G: 2.555799, loss_D: 0.228282\n",
      "[Epoch 52/200] [Batch 690/938] loss_G: 2.347773, loss_D: 0.249961\n",
      "[Epoch 52/200] [Batch 700/938] loss_G: 2.567401, loss_D: 0.294765\n",
      "[Epoch 52/200] [Batch 710/938] loss_G: 2.720912, loss_D: 0.238527\n",
      "[Epoch 52/200] [Batch 720/938] loss_G: 2.642510, loss_D: 0.135629\n",
      "[Epoch 52/200] [Batch 730/938] loss_G: 2.759683, loss_D: 0.207069\n",
      "[Epoch 52/200] [Batch 740/938] loss_G: 2.614869, loss_D: 0.195580\n",
      "[Epoch 52/200] [Batch 750/938] loss_G: 2.823529, loss_D: 0.225734\n",
      "[Epoch 52/200] [Batch 760/938] loss_G: 2.873689, loss_D: 0.269976\n",
      "[Epoch 52/200] [Batch 770/938] loss_G: 2.738359, loss_D: 0.143028\n",
      "[Epoch 52/200] [Batch 780/938] loss_G: 2.883514, loss_D: 0.213120\n",
      "[Epoch 52/200] [Batch 790/938] loss_G: 2.582018, loss_D: 0.305027\n",
      "[Epoch 52/200] [Batch 800/938] loss_G: 2.265181, loss_D: 0.200293\n",
      "[Epoch 52/200] [Batch 810/938] loss_G: 2.869096, loss_D: 0.276100\n",
      "[Epoch 52/200] [Batch 820/938] loss_G: 2.332729, loss_D: 0.183055\n",
      "[Epoch 52/200] [Batch 830/938] loss_G: 2.748225, loss_D: 0.217834\n",
      "[Epoch 52/200] [Batch 840/938] loss_G: 2.840011, loss_D: 0.316144\n",
      "[Epoch 52/200] [Batch 850/938] loss_G: 2.546631, loss_D: 0.243596\n",
      "[Epoch 52/200] [Batch 860/938] loss_G: 2.883554, loss_D: 0.168328\n",
      "[Epoch 52/200] [Batch 870/938] loss_G: 2.041653, loss_D: 0.280913\n",
      "[Epoch 52/200] [Batch 880/938] loss_G: 3.046831, loss_D: 0.320610\n",
      "[Epoch 52/200] [Batch 890/938] loss_G: 2.437967, loss_D: 0.226666\n",
      "[Epoch 52/200] [Batch 900/938] loss_G: 2.530103, loss_D: 0.212960\n",
      "[Epoch 52/200] [Batch 910/938] loss_G: 2.308526, loss_D: 0.231143\n",
      "[Epoch 52/200] [Batch 920/938] loss_G: 2.669935, loss_D: 0.206788\n",
      "[Epoch 52/200] [Batch 930/938] loss_G: 2.395796, loss_D: 0.254187\n",
      "[Epoch 53/200] [Batch 0/938] loss_G: 2.892909, loss_D: 0.312152\n",
      "[Epoch 53/200] [Batch 10/938] loss_G: 2.244724, loss_D: 0.288533\n",
      "[Epoch 53/200] [Batch 20/938] loss_G: 2.639558, loss_D: 0.226304\n",
      "[Epoch 53/200] [Batch 30/938] loss_G: 2.746057, loss_D: 0.184972\n",
      "[Epoch 53/200] [Batch 40/938] loss_G: 2.485506, loss_D: 0.275707\n",
      "[Epoch 53/200] [Batch 50/938] loss_G: 2.493305, loss_D: 0.330568\n",
      "[Epoch 53/200] [Batch 60/938] loss_G: 2.734972, loss_D: 0.290281\n",
      "[Epoch 53/200] [Batch 70/938] loss_G: 2.736751, loss_D: 0.199213\n",
      "[Epoch 53/200] [Batch 80/938] loss_G: 2.391736, loss_D: 0.196699\n",
      "[Epoch 53/200] [Batch 90/938] loss_G: 2.536792, loss_D: 0.242809\n",
      "[Epoch 53/200] [Batch 100/938] loss_G: 2.399829, loss_D: 0.214404\n",
      "[Epoch 53/200] [Batch 110/938] loss_G: 2.456836, loss_D: 0.250039\n",
      "[Epoch 53/200] [Batch 120/938] loss_G: 2.676043, loss_D: 0.274776\n",
      "[Epoch 53/200] [Batch 130/938] loss_G: 2.646842, loss_D: 0.273349\n",
      "[Epoch 53/200] [Batch 140/938] loss_G: 2.931442, loss_D: 0.183267\n",
      "[Epoch 53/200] [Batch 150/938] loss_G: 2.703436, loss_D: 0.170636\n",
      "[Epoch 53/200] [Batch 160/938] loss_G: 2.534759, loss_D: 0.213954\n",
      "[Epoch 53/200] [Batch 170/938] loss_G: 2.748887, loss_D: 0.266659\n",
      "[Epoch 53/200] [Batch 180/938] loss_G: 2.581379, loss_D: 0.156604\n",
      "[Epoch 53/200] [Batch 190/938] loss_G: 2.749124, loss_D: 0.259614\n",
      "[Epoch 53/200] [Batch 200/938] loss_G: 2.432680, loss_D: 0.267339\n",
      "[Epoch 53/200] [Batch 210/938] loss_G: 2.786136, loss_D: 0.262960\n",
      "[Epoch 53/200] [Batch 220/938] loss_G: 2.618176, loss_D: 0.245968\n",
      "[Epoch 53/200] [Batch 230/938] loss_G: 2.904259, loss_D: 0.238723\n",
      "[Epoch 53/200] [Batch 240/938] loss_G: 2.684257, loss_D: 0.273790\n",
      "[Epoch 53/200] [Batch 250/938] loss_G: 2.349315, loss_D: 0.248420\n",
      "[Epoch 53/200] [Batch 260/938] loss_G: 2.650468, loss_D: 0.229103\n",
      "[Epoch 53/200] [Batch 270/938] loss_G: 2.638883, loss_D: 0.172395\n",
      "[Epoch 53/200] [Batch 280/938] loss_G: 2.351367, loss_D: 0.238570\n",
      "[Epoch 53/200] [Batch 290/938] loss_G: 2.487374, loss_D: 0.205225\n",
      "[Epoch 53/200] [Batch 300/938] loss_G: 2.550294, loss_D: 0.293757\n",
      "[Epoch 53/200] [Batch 310/938] loss_G: 2.587849, loss_D: 0.180423\n",
      "[Epoch 53/200] [Batch 320/938] loss_G: 2.516978, loss_D: 0.257624\n",
      "[Epoch 53/200] [Batch 330/938] loss_G: 2.617657, loss_D: 0.242071\n",
      "[Epoch 53/200] [Batch 340/938] loss_G: 2.989533, loss_D: 0.198774\n",
      "[Epoch 53/200] [Batch 350/938] loss_G: 2.741862, loss_D: 0.200180\n",
      "[Epoch 53/200] [Batch 360/938] loss_G: 2.461322, loss_D: 0.283979\n",
      "[Epoch 53/200] [Batch 370/938] loss_G: 2.609214, loss_D: 0.295165\n",
      "[Epoch 53/200] [Batch 380/938] loss_G: 2.610488, loss_D: 0.262465\n",
      "[Epoch 53/200] [Batch 390/938] loss_G: 2.571376, loss_D: 0.239146\n",
      "[Epoch 53/200] [Batch 400/938] loss_G: 2.946844, loss_D: 0.142030\n",
      "[Epoch 53/200] [Batch 410/938] loss_G: 2.709157, loss_D: 0.267085\n",
      "[Epoch 53/200] [Batch 420/938] loss_G: 2.401611, loss_D: 0.229000\n",
      "[Epoch 53/200] [Batch 430/938] loss_G: 2.620106, loss_D: 0.207140\n",
      "[Epoch 53/200] [Batch 440/938] loss_G: 2.601363, loss_D: 0.300468\n",
      "[Epoch 53/200] [Batch 450/938] loss_G: 2.537172, loss_D: 0.199602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 53/200] [Batch 460/938] loss_G: 2.680360, loss_D: 0.302488\n",
      "[Epoch 53/200] [Batch 470/938] loss_G: 2.741510, loss_D: 0.269712\n",
      "[Epoch 53/200] [Batch 480/938] loss_G: 2.690144, loss_D: 0.151207\n",
      "[Epoch 53/200] [Batch 490/938] loss_G: 2.510491, loss_D: 0.187068\n",
      "[Epoch 53/200] [Batch 500/938] loss_G: 2.577234, loss_D: 0.277366\n",
      "[Epoch 53/200] [Batch 510/938] loss_G: 2.170424, loss_D: 0.358723\n",
      "[Epoch 53/200] [Batch 520/938] loss_G: 2.863464, loss_D: 0.280621\n",
      "[Epoch 53/200] [Batch 530/938] loss_G: 2.360864, loss_D: 0.270764\n",
      "[Epoch 53/200] [Batch 540/938] loss_G: 2.472685, loss_D: 0.223786\n",
      "[Epoch 53/200] [Batch 550/938] loss_G: 2.712875, loss_D: 0.226843\n",
      "[Epoch 53/200] [Batch 560/938] loss_G: 2.674537, loss_D: 0.203136\n",
      "[Epoch 53/200] [Batch 570/938] loss_G: 2.706969, loss_D: 0.210027\n",
      "[Epoch 53/200] [Batch 580/938] loss_G: 2.867821, loss_D: 0.239720\n",
      "[Epoch 53/200] [Batch 590/938] loss_G: 2.543270, loss_D: 0.224900\n",
      "[Epoch 53/200] [Batch 600/938] loss_G: 2.754328, loss_D: 0.247218\n",
      "[Epoch 53/200] [Batch 610/938] loss_G: 2.419151, loss_D: 0.244333\n",
      "[Epoch 53/200] [Batch 620/938] loss_G: 2.811109, loss_D: 0.194467\n",
      "[Epoch 53/200] [Batch 630/938] loss_G: 2.716633, loss_D: 0.310483\n",
      "[Epoch 53/200] [Batch 640/938] loss_G: 2.793681, loss_D: 0.297214\n",
      "[Epoch 53/200] [Batch 650/938] loss_G: 2.457962, loss_D: 0.252871\n",
      "[Epoch 53/200] [Batch 660/938] loss_G: 2.585463, loss_D: 0.245973\n",
      "[Epoch 53/200] [Batch 670/938] loss_G: 2.524638, loss_D: 0.221335\n",
      "[Epoch 53/200] [Batch 680/938] loss_G: 2.672911, loss_D: 0.178401\n",
      "[Epoch 53/200] [Batch 690/938] loss_G: 2.418681, loss_D: 0.293048\n",
      "[Epoch 53/200] [Batch 700/938] loss_G: 2.440183, loss_D: 0.216771\n",
      "[Epoch 53/200] [Batch 710/938] loss_G: 2.466977, loss_D: 0.269853\n",
      "[Epoch 53/200] [Batch 720/938] loss_G: 2.691995, loss_D: 0.222536\n",
      "[Epoch 53/200] [Batch 730/938] loss_G: 2.704400, loss_D: 0.198335\n",
      "[Epoch 53/200] [Batch 740/938] loss_G: 2.381378, loss_D: 0.391163\n",
      "[Epoch 53/200] [Batch 750/938] loss_G: 2.818484, loss_D: 0.268817\n",
      "[Epoch 53/200] [Batch 760/938] loss_G: 2.697139, loss_D: 0.211297\n",
      "[Epoch 53/200] [Batch 770/938] loss_G: 2.915745, loss_D: 0.269384\n",
      "[Epoch 53/200] [Batch 780/938] loss_G: 3.006289, loss_D: 0.255921\n",
      "[Epoch 53/200] [Batch 790/938] loss_G: 2.663364, loss_D: 0.259068\n",
      "[Epoch 53/200] [Batch 800/938] loss_G: 2.715083, loss_D: 0.219429\n",
      "[Epoch 53/200] [Batch 810/938] loss_G: 2.972765, loss_D: 0.222058\n",
      "[Epoch 53/200] [Batch 820/938] loss_G: 2.572776, loss_D: 0.280897\n",
      "[Epoch 53/200] [Batch 830/938] loss_G: 2.816370, loss_D: 0.285920\n",
      "[Epoch 53/200] [Batch 840/938] loss_G: 2.385834, loss_D: 0.249612\n",
      "[Epoch 53/200] [Batch 850/938] loss_G: 2.564508, loss_D: 0.223410\n",
      "[Epoch 53/200] [Batch 860/938] loss_G: 3.005912, loss_D: 0.269640\n",
      "[Epoch 53/200] [Batch 870/938] loss_G: 2.818366, loss_D: 0.231513\n",
      "[Epoch 53/200] [Batch 880/938] loss_G: 2.762608, loss_D: 0.152178\n",
      "[Epoch 53/200] [Batch 890/938] loss_G: 2.328732, loss_D: 0.241751\n",
      "[Epoch 53/200] [Batch 900/938] loss_G: 2.319093, loss_D: 0.316087\n",
      "[Epoch 53/200] [Batch 910/938] loss_G: 2.468634, loss_D: 0.233640\n",
      "[Epoch 53/200] [Batch 920/938] loss_G: 2.862649, loss_D: 0.199055\n",
      "[Epoch 53/200] [Batch 930/938] loss_G: 2.590640, loss_D: 0.187391\n",
      "[Epoch 54/200] [Batch 0/938] loss_G: 2.105770, loss_D: 0.257469\n",
      "[Epoch 54/200] [Batch 10/938] loss_G: 2.896023, loss_D: 0.174355\n",
      "[Epoch 54/200] [Batch 20/938] loss_G: 2.218323, loss_D: 0.238652\n",
      "[Epoch 54/200] [Batch 30/938] loss_G: 2.824333, loss_D: 0.286781\n",
      "[Epoch 54/200] [Batch 40/938] loss_G: 2.617491, loss_D: 0.277093\n",
      "[Epoch 54/200] [Batch 50/938] loss_G: 2.441138, loss_D: 0.284203\n",
      "[Epoch 54/200] [Batch 60/938] loss_G: 2.477639, loss_D: 0.256452\n",
      "[Epoch 54/200] [Batch 70/938] loss_G: 2.629213, loss_D: 0.186394\n",
      "[Epoch 54/200] [Batch 80/938] loss_G: 2.772895, loss_D: 0.221997\n",
      "[Epoch 54/200] [Batch 90/938] loss_G: 2.587595, loss_D: 0.242504\n",
      "[Epoch 54/200] [Batch 100/938] loss_G: 2.395609, loss_D: 0.243019\n",
      "[Epoch 54/200] [Batch 110/938] loss_G: 2.657413, loss_D: 0.329153\n",
      "[Epoch 54/200] [Batch 120/938] loss_G: 2.508661, loss_D: 0.257091\n",
      "[Epoch 54/200] [Batch 130/938] loss_G: 2.591371, loss_D: 0.222177\n",
      "[Epoch 54/200] [Batch 140/938] loss_G: 2.763185, loss_D: 0.273555\n",
      "[Epoch 54/200] [Batch 150/938] loss_G: 2.347270, loss_D: 0.334139\n",
      "[Epoch 54/200] [Batch 160/938] loss_G: 2.517575, loss_D: 0.256541\n",
      "[Epoch 54/200] [Batch 170/938] loss_G: 2.256997, loss_D: 0.207620\n",
      "[Epoch 54/200] [Batch 180/938] loss_G: 2.400474, loss_D: 0.260008\n",
      "[Epoch 54/200] [Batch 190/938] loss_G: 2.671090, loss_D: 0.235085\n",
      "[Epoch 54/200] [Batch 200/938] loss_G: 2.040413, loss_D: 0.252915\n",
      "[Epoch 54/200] [Batch 210/938] loss_G: 2.563027, loss_D: 0.242522\n",
      "[Epoch 54/200] [Batch 220/938] loss_G: 2.459645, loss_D: 0.222343\n",
      "[Epoch 54/200] [Batch 230/938] loss_G: 2.515927, loss_D: 0.254888\n",
      "[Epoch 54/200] [Batch 240/938] loss_G: 2.386461, loss_D: 0.238644\n",
      "[Epoch 54/200] [Batch 250/938] loss_G: 2.963442, loss_D: 0.101886\n",
      "[Epoch 54/200] [Batch 260/938] loss_G: 2.306502, loss_D: 0.460602\n",
      "[Epoch 54/200] [Batch 270/938] loss_G: 2.658579, loss_D: 0.208526\n",
      "[Epoch 54/200] [Batch 280/938] loss_G: 2.621284, loss_D: 0.223746\n",
      "[Epoch 54/200] [Batch 290/938] loss_G: 2.346792, loss_D: 0.241101\n",
      "[Epoch 54/200] [Batch 300/938] loss_G: 2.833164, loss_D: 0.228444\n",
      "[Epoch 54/200] [Batch 310/938] loss_G: 2.519064, loss_D: 0.277409\n",
      "[Epoch 54/200] [Batch 320/938] loss_G: 2.599903, loss_D: 0.324562\n",
      "[Epoch 54/200] [Batch 330/938] loss_G: 2.834316, loss_D: 0.293904\n",
      "[Epoch 54/200] [Batch 340/938] loss_G: 2.515984, loss_D: 0.291788\n",
      "[Epoch 54/200] [Batch 350/938] loss_G: 2.864263, loss_D: 0.218549\n",
      "[Epoch 54/200] [Batch 360/938] loss_G: 2.384669, loss_D: 0.166983\n",
      "[Epoch 54/200] [Batch 370/938] loss_G: 2.726067, loss_D: 0.290405\n",
      "[Epoch 54/200] [Batch 380/938] loss_G: 2.212177, loss_D: 0.286056\n",
      "[Epoch 54/200] [Batch 390/938] loss_G: 2.768008, loss_D: 0.163153\n",
      "[Epoch 54/200] [Batch 400/938] loss_G: 2.180987, loss_D: 0.215652\n",
      "[Epoch 54/200] [Batch 410/938] loss_G: 2.721128, loss_D: 0.237825\n",
      "[Epoch 54/200] [Batch 420/938] loss_G: 2.764289, loss_D: 0.179631\n",
      "[Epoch 54/200] [Batch 430/938] loss_G: 2.768473, loss_D: 0.259007\n",
      "[Epoch 54/200] [Batch 440/938] loss_G: 2.878992, loss_D: 0.282735\n",
      "[Epoch 54/200] [Batch 450/938] loss_G: 2.647651, loss_D: 0.208655\n",
      "[Epoch 54/200] [Batch 460/938] loss_G: 2.661749, loss_D: 0.232360\n",
      "[Epoch 54/200] [Batch 470/938] loss_G: 2.708258, loss_D: 0.189690\n",
      "[Epoch 54/200] [Batch 480/938] loss_G: 2.437485, loss_D: 0.225745\n",
      "[Epoch 54/200] [Batch 490/938] loss_G: 2.868117, loss_D: 0.369287\n",
      "[Epoch 54/200] [Batch 500/938] loss_G: 2.782408, loss_D: 0.230099\n",
      "[Epoch 54/200] [Batch 510/938] loss_G: 2.712172, loss_D: 0.179086\n",
      "[Epoch 54/200] [Batch 520/938] loss_G: 2.733036, loss_D: 0.149010\n",
      "[Epoch 54/200] [Batch 530/938] loss_G: 2.417754, loss_D: 0.204439\n",
      "[Epoch 54/200] [Batch 540/938] loss_G: 2.298630, loss_D: 0.306822\n",
      "[Epoch 54/200] [Batch 550/938] loss_G: 2.397775, loss_D: 0.322856\n",
      "[Epoch 54/200] [Batch 560/938] loss_G: 2.456685, loss_D: 0.274411\n",
      "[Epoch 54/200] [Batch 570/938] loss_G: 2.512371, loss_D: 0.242215\n",
      "[Epoch 54/200] [Batch 580/938] loss_G: 3.008574, loss_D: 0.281189\n",
      "[Epoch 54/200] [Batch 590/938] loss_G: 2.385892, loss_D: 0.258252\n",
      "[Epoch 54/200] [Batch 600/938] loss_G: 2.389705, loss_D: 0.277216\n",
      "[Epoch 54/200] [Batch 610/938] loss_G: 2.444849, loss_D: 0.214321\n",
      "[Epoch 54/200] [Batch 620/938] loss_G: 2.880416, loss_D: 0.314596\n",
      "[Epoch 54/200] [Batch 630/938] loss_G: 2.548810, loss_D: 0.311861\n",
      "[Epoch 54/200] [Batch 640/938] loss_G: 2.826759, loss_D: 0.262219\n",
      "[Epoch 54/200] [Batch 650/938] loss_G: 2.325167, loss_D: 0.300377\n",
      "[Epoch 54/200] [Batch 660/938] loss_G: 2.759293, loss_D: 0.209477\n",
      "[Epoch 54/200] [Batch 670/938] loss_G: 2.253902, loss_D: 0.285154\n",
      "[Epoch 54/200] [Batch 680/938] loss_G: 2.783226, loss_D: 0.218484\n",
      "[Epoch 54/200] [Batch 690/938] loss_G: 2.176316, loss_D: 0.305746\n",
      "[Epoch 54/200] [Batch 700/938] loss_G: 2.829231, loss_D: 0.195459\n",
      "[Epoch 54/200] [Batch 710/938] loss_G: 2.446434, loss_D: 0.208264\n",
      "[Epoch 54/200] [Batch 720/938] loss_G: 2.620477, loss_D: 0.223067\n",
      "[Epoch 54/200] [Batch 730/938] loss_G: 2.488403, loss_D: 0.156765\n",
      "[Epoch 54/200] [Batch 740/938] loss_G: 2.283292, loss_D: 0.296991\n",
      "[Epoch 54/200] [Batch 750/938] loss_G: 2.452520, loss_D: 0.252794\n",
      "[Epoch 54/200] [Batch 760/938] loss_G: 2.659051, loss_D: 0.180043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 54/200] [Batch 770/938] loss_G: 2.576199, loss_D: 0.219212\n",
      "[Epoch 54/200] [Batch 780/938] loss_G: 2.480273, loss_D: 0.217300\n",
      "[Epoch 54/200] [Batch 790/938] loss_G: 2.342659, loss_D: 0.304289\n",
      "[Epoch 54/200] [Batch 800/938] loss_G: 2.644583, loss_D: 0.260749\n",
      "[Epoch 54/200] [Batch 810/938] loss_G: 2.579787, loss_D: 0.225998\n",
      "[Epoch 54/200] [Batch 820/938] loss_G: 2.656249, loss_D: 0.252334\n",
      "[Epoch 54/200] [Batch 830/938] loss_G: 2.524757, loss_D: 0.210340\n",
      "[Epoch 54/200] [Batch 840/938] loss_G: 2.563843, loss_D: 0.259804\n",
      "[Epoch 54/200] [Batch 850/938] loss_G: 2.403238, loss_D: 0.192139\n",
      "[Epoch 54/200] [Batch 860/938] loss_G: 2.591897, loss_D: 0.205647\n",
      "[Epoch 54/200] [Batch 870/938] loss_G: 2.764099, loss_D: 0.214778\n",
      "[Epoch 54/200] [Batch 880/938] loss_G: 2.565482, loss_D: 0.239496\n",
      "[Epoch 54/200] [Batch 890/938] loss_G: 2.713836, loss_D: 0.231187\n",
      "[Epoch 54/200] [Batch 900/938] loss_G: 2.565101, loss_D: 0.334534\n",
      "[Epoch 54/200] [Batch 910/938] loss_G: 2.532517, loss_D: 0.260385\n",
      "[Epoch 54/200] [Batch 920/938] loss_G: 2.591295, loss_D: 0.235200\n",
      "[Epoch 54/200] [Batch 930/938] loss_G: 2.469524, loss_D: 0.283675\n",
      "[Epoch 55/200] [Batch 0/938] loss_G: 2.727127, loss_D: 0.235068\n",
      "[Epoch 55/200] [Batch 10/938] loss_G: 2.483807, loss_D: 0.260677\n",
      "[Epoch 55/200] [Batch 20/938] loss_G: 2.079405, loss_D: 0.240682\n",
      "[Epoch 55/200] [Batch 30/938] loss_G: 2.607011, loss_D: 0.353256\n",
      "[Epoch 55/200] [Batch 40/938] loss_G: 2.810048, loss_D: 0.226601\n",
      "[Epoch 55/200] [Batch 50/938] loss_G: 2.329684, loss_D: 0.250068\n",
      "[Epoch 55/200] [Batch 60/938] loss_G: 2.685773, loss_D: 0.268759\n",
      "[Epoch 55/200] [Batch 70/938] loss_G: 2.539355, loss_D: 0.284595\n",
      "[Epoch 55/200] [Batch 80/938] loss_G: 2.598704, loss_D: 0.270855\n",
      "[Epoch 55/200] [Batch 90/938] loss_G: 2.577114, loss_D: 0.365603\n",
      "[Epoch 55/200] [Batch 100/938] loss_G: 2.716583, loss_D: 0.251617\n",
      "[Epoch 55/200] [Batch 110/938] loss_G: 2.671733, loss_D: 0.294451\n",
      "[Epoch 55/200] [Batch 120/938] loss_G: 2.550099, loss_D: 0.287407\n",
      "[Epoch 55/200] [Batch 130/938] loss_G: 2.395425, loss_D: 0.192699\n",
      "[Epoch 55/200] [Batch 140/938] loss_G: 2.569149, loss_D: 0.176523\n",
      "[Epoch 55/200] [Batch 150/938] loss_G: 2.447213, loss_D: 0.218957\n",
      "[Epoch 55/200] [Batch 160/938] loss_G: 2.975466, loss_D: 0.206294\n",
      "[Epoch 55/200] [Batch 170/938] loss_G: 2.534823, loss_D: 0.197516\n",
      "[Epoch 55/200] [Batch 180/938] loss_G: 2.669014, loss_D: 0.131800\n",
      "[Epoch 55/200] [Batch 190/938] loss_G: 2.721710, loss_D: 0.250942\n",
      "[Epoch 55/200] [Batch 200/938] loss_G: 2.692396, loss_D: 0.200565\n",
      "[Epoch 55/200] [Batch 210/938] loss_G: 2.429574, loss_D: 0.313054\n",
      "[Epoch 55/200] [Batch 220/938] loss_G: 2.635244, loss_D: 0.235838\n",
      "[Epoch 55/200] [Batch 230/938] loss_G: 2.710469, loss_D: 0.275198\n",
      "[Epoch 55/200] [Batch 240/938] loss_G: 2.582141, loss_D: 0.282463\n",
      "[Epoch 55/200] [Batch 250/938] loss_G: 2.653307, loss_D: 0.254932\n",
      "[Epoch 55/200] [Batch 260/938] loss_G: 2.272356, loss_D: 0.306757\n",
      "[Epoch 55/200] [Batch 270/938] loss_G: 2.563828, loss_D: 0.195649\n",
      "[Epoch 55/200] [Batch 280/938] loss_G: 2.481519, loss_D: 0.257563\n",
      "[Epoch 55/200] [Batch 290/938] loss_G: 2.690840, loss_D: 0.158662\n",
      "[Epoch 55/200] [Batch 300/938] loss_G: 2.528305, loss_D: 0.196754\n",
      "[Epoch 55/200] [Batch 310/938] loss_G: 2.643648, loss_D: 0.214843\n",
      "[Epoch 55/200] [Batch 320/938] loss_G: 2.797788, loss_D: 0.164239\n",
      "[Epoch 55/200] [Batch 330/938] loss_G: 2.344089, loss_D: 0.280888\n",
      "[Epoch 55/200] [Batch 340/938] loss_G: 2.259940, loss_D: 0.285639\n",
      "[Epoch 55/200] [Batch 350/938] loss_G: 2.451844, loss_D: 0.219559\n",
      "[Epoch 55/200] [Batch 360/938] loss_G: 2.579216, loss_D: 0.144841\n",
      "[Epoch 55/200] [Batch 370/938] loss_G: 2.981140, loss_D: 0.194258\n",
      "[Epoch 55/200] [Batch 380/938] loss_G: 2.349379, loss_D: 0.269538\n",
      "[Epoch 55/200] [Batch 390/938] loss_G: 2.609604, loss_D: 0.158728\n",
      "[Epoch 55/200] [Batch 400/938] loss_G: 2.241981, loss_D: 0.232599\n",
      "[Epoch 55/200] [Batch 410/938] loss_G: 2.437040, loss_D: 0.176945\n",
      "[Epoch 55/200] [Batch 420/938] loss_G: 2.515852, loss_D: 0.212210\n",
      "[Epoch 55/200] [Batch 430/938] loss_G: 2.573647, loss_D: 0.171374\n",
      "[Epoch 55/200] [Batch 440/938] loss_G: 2.636491, loss_D: 0.239062\n",
      "[Epoch 55/200] [Batch 450/938] loss_G: 2.552379, loss_D: 0.245277\n",
      "[Epoch 55/200] [Batch 460/938] loss_G: 2.719338, loss_D: 0.242650\n",
      "[Epoch 55/200] [Batch 470/938] loss_G: 2.654009, loss_D: 0.200197\n",
      "[Epoch 55/200] [Batch 480/938] loss_G: 2.810365, loss_D: 0.166522\n",
      "[Epoch 55/200] [Batch 490/938] loss_G: 2.481926, loss_D: 0.214533\n",
      "[Epoch 55/200] [Batch 500/938] loss_G: 2.875186, loss_D: 0.270350\n",
      "[Epoch 55/200] [Batch 510/938] loss_G: 2.263342, loss_D: 0.271306\n",
      "[Epoch 55/200] [Batch 520/938] loss_G: 2.626986, loss_D: 0.268650\n",
      "[Epoch 55/200] [Batch 530/938] loss_G: 2.559781, loss_D: 0.238069\n",
      "[Epoch 55/200] [Batch 540/938] loss_G: 2.904152, loss_D: 0.249381\n",
      "[Epoch 55/200] [Batch 550/938] loss_G: 2.744058, loss_D: 0.198107\n",
      "[Epoch 55/200] [Batch 560/938] loss_G: 2.177756, loss_D: 0.273030\n",
      "[Epoch 55/200] [Batch 570/938] loss_G: 2.403968, loss_D: 0.297276\n",
      "[Epoch 55/200] [Batch 580/938] loss_G: 2.300777, loss_D: 0.268244\n",
      "[Epoch 55/200] [Batch 590/938] loss_G: 2.718904, loss_D: 0.217501\n",
      "[Epoch 55/200] [Batch 600/938] loss_G: 2.813341, loss_D: 0.198876\n",
      "[Epoch 55/200] [Batch 610/938] loss_G: 2.536756, loss_D: 0.300286\n",
      "[Epoch 55/200] [Batch 620/938] loss_G: 2.861650, loss_D: 0.273964\n",
      "[Epoch 55/200] [Batch 630/938] loss_G: 2.349937, loss_D: 0.257748\n",
      "[Epoch 55/200] [Batch 640/938] loss_G: 2.841375, loss_D: 0.200420\n",
      "[Epoch 55/200] [Batch 650/938] loss_G: 2.622164, loss_D: 0.147329\n",
      "[Epoch 55/200] [Batch 660/938] loss_G: 2.404451, loss_D: 0.272171\n",
      "[Epoch 55/200] [Batch 670/938] loss_G: 2.481328, loss_D: 0.289783\n",
      "[Epoch 55/200] [Batch 680/938] loss_G: 2.370835, loss_D: 0.212475\n",
      "[Epoch 55/200] [Batch 690/938] loss_G: 2.563779, loss_D: 0.240079\n",
      "[Epoch 55/200] [Batch 700/938] loss_G: 2.769827, loss_D: 0.210925\n",
      "[Epoch 55/200] [Batch 710/938] loss_G: 2.681024, loss_D: 0.203059\n",
      "[Epoch 55/200] [Batch 720/938] loss_G: 2.712765, loss_D: 0.210767\n",
      "[Epoch 55/200] [Batch 730/938] loss_G: 2.478587, loss_D: 0.249426\n",
      "[Epoch 55/200] [Batch 740/938] loss_G: 2.600568, loss_D: 0.268133\n",
      "[Epoch 55/200] [Batch 750/938] loss_G: 2.430843, loss_D: 0.152771\n",
      "[Epoch 55/200] [Batch 760/938] loss_G: 2.619213, loss_D: 0.230068\n",
      "[Epoch 55/200] [Batch 770/938] loss_G: 2.528614, loss_D: 0.231101\n",
      "[Epoch 55/200] [Batch 780/938] loss_G: 2.634671, loss_D: 0.261217\n",
      "[Epoch 55/200] [Batch 790/938] loss_G: 2.313748, loss_D: 0.234044\n",
      "[Epoch 55/200] [Batch 800/938] loss_G: 2.395859, loss_D: 0.204280\n",
      "[Epoch 55/200] [Batch 810/938] loss_G: 2.066016, loss_D: 0.260954\n",
      "[Epoch 55/200] [Batch 820/938] loss_G: 2.301162, loss_D: 0.216406\n",
      "[Epoch 55/200] [Batch 830/938] loss_G: 2.559149, loss_D: 0.232830\n",
      "[Epoch 55/200] [Batch 840/938] loss_G: 2.252335, loss_D: 0.295369\n",
      "[Epoch 55/200] [Batch 850/938] loss_G: 2.487703, loss_D: 0.290839\n",
      "[Epoch 55/200] [Batch 860/938] loss_G: 2.511552, loss_D: 0.214539\n",
      "[Epoch 55/200] [Batch 870/938] loss_G: 2.599348, loss_D: 0.262497\n",
      "[Epoch 55/200] [Batch 880/938] loss_G: 2.578600, loss_D: 0.210383\n",
      "[Epoch 55/200] [Batch 890/938] loss_G: 2.427551, loss_D: 0.238737\n",
      "[Epoch 55/200] [Batch 900/938] loss_G: 2.589452, loss_D: 0.212322\n",
      "[Epoch 55/200] [Batch 910/938] loss_G: 2.444382, loss_D: 0.216801\n",
      "[Epoch 55/200] [Batch 920/938] loss_G: 2.654351, loss_D: 0.245599\n",
      "[Epoch 55/200] [Batch 930/938] loss_G: 2.671928, loss_D: 0.198397\n",
      "[Epoch 56/200] [Batch 0/938] loss_G: 2.477110, loss_D: 0.261255\n",
      "[Epoch 56/200] [Batch 10/938] loss_G: 2.312074, loss_D: 0.203284\n",
      "[Epoch 56/200] [Batch 20/938] loss_G: 2.695172, loss_D: 0.221112\n",
      "[Epoch 56/200] [Batch 30/938] loss_G: 2.601619, loss_D: 0.312252\n",
      "[Epoch 56/200] [Batch 40/938] loss_G: 2.605803, loss_D: 0.259174\n",
      "[Epoch 56/200] [Batch 50/938] loss_G: 2.603680, loss_D: 0.243928\n",
      "[Epoch 56/200] [Batch 60/938] loss_G: 2.433423, loss_D: 0.220221\n",
      "[Epoch 56/200] [Batch 70/938] loss_G: 2.642895, loss_D: 0.243859\n",
      "[Epoch 56/200] [Batch 80/938] loss_G: 2.878731, loss_D: 0.133443\n",
      "[Epoch 56/200] [Batch 90/938] loss_G: 2.814804, loss_D: 0.235470\n",
      "[Epoch 56/200] [Batch 100/938] loss_G: 2.789818, loss_D: 0.169856\n",
      "[Epoch 56/200] [Batch 110/938] loss_G: 2.391997, loss_D: 0.222514\n",
      "[Epoch 56/200] [Batch 120/938] loss_G: 2.568138, loss_D: 0.207757\n",
      "[Epoch 56/200] [Batch 130/938] loss_G: 2.768239, loss_D: 0.276607\n",
      "[Epoch 56/200] [Batch 140/938] loss_G: 2.796322, loss_D: 0.192329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 56/200] [Batch 150/938] loss_G: 2.667697, loss_D: 0.214060\n",
      "[Epoch 56/200] [Batch 160/938] loss_G: 2.394461, loss_D: 0.296528\n",
      "[Epoch 56/200] [Batch 170/938] loss_G: 2.413459, loss_D: 0.264526\n",
      "[Epoch 56/200] [Batch 180/938] loss_G: 2.537825, loss_D: 0.207194\n",
      "[Epoch 56/200] [Batch 190/938] loss_G: 2.630429, loss_D: 0.234884\n",
      "[Epoch 56/200] [Batch 200/938] loss_G: 2.275810, loss_D: 0.257678\n",
      "[Epoch 56/200] [Batch 210/938] loss_G: 2.634860, loss_D: 0.235537\n",
      "[Epoch 56/200] [Batch 220/938] loss_G: 2.721488, loss_D: 0.209011\n",
      "[Epoch 56/200] [Batch 230/938] loss_G: 2.954195, loss_D: 0.183638\n",
      "[Epoch 56/200] [Batch 240/938] loss_G: 2.696894, loss_D: 0.254963\n",
      "[Epoch 56/200] [Batch 250/938] loss_G: 2.635717, loss_D: 0.284450\n",
      "[Epoch 56/200] [Batch 260/938] loss_G: 3.112620, loss_D: 0.184301\n",
      "[Epoch 56/200] [Batch 270/938] loss_G: 2.311208, loss_D: 0.302824\n",
      "[Epoch 56/200] [Batch 280/938] loss_G: 2.607036, loss_D: 0.242396\n",
      "[Epoch 56/200] [Batch 290/938] loss_G: 2.469074, loss_D: 0.248382\n",
      "[Epoch 56/200] [Batch 300/938] loss_G: 2.578650, loss_D: 0.290251\n",
      "[Epoch 56/200] [Batch 310/938] loss_G: 2.535715, loss_D: 0.218530\n",
      "[Epoch 56/200] [Batch 320/938] loss_G: 2.827921, loss_D: 0.189770\n",
      "[Epoch 56/200] [Batch 330/938] loss_G: 2.361130, loss_D: 0.173475\n",
      "[Epoch 56/200] [Batch 340/938] loss_G: 2.813875, loss_D: 0.192434\n",
      "[Epoch 56/200] [Batch 350/938] loss_G: 2.445805, loss_D: 0.337922\n",
      "[Epoch 56/200] [Batch 360/938] loss_G: 2.567197, loss_D: 0.193686\n",
      "[Epoch 56/200] [Batch 370/938] loss_G: 2.497142, loss_D: 0.284819\n",
      "[Epoch 56/200] [Batch 380/938] loss_G: 2.794369, loss_D: 0.249859\n",
      "[Epoch 56/200] [Batch 390/938] loss_G: 2.383911, loss_D: 0.184502\n",
      "[Epoch 56/200] [Batch 400/938] loss_G: 3.278311, loss_D: 0.194106\n",
      "[Epoch 56/200] [Batch 410/938] loss_G: 2.865041, loss_D: 0.167498\n",
      "[Epoch 56/200] [Batch 420/938] loss_G: 2.890342, loss_D: 0.210256\n",
      "[Epoch 56/200] [Batch 430/938] loss_G: 2.539005, loss_D: 0.250510\n",
      "[Epoch 56/200] [Batch 440/938] loss_G: 2.870787, loss_D: 0.306098\n",
      "[Epoch 56/200] [Batch 450/938] loss_G: 2.417191, loss_D: 0.242513\n",
      "[Epoch 56/200] [Batch 460/938] loss_G: 3.125351, loss_D: 0.161277\n",
      "[Epoch 56/200] [Batch 470/938] loss_G: 2.659350, loss_D: 0.206415\n",
      "[Epoch 56/200] [Batch 480/938] loss_G: 2.761303, loss_D: 0.230149\n",
      "[Epoch 56/200] [Batch 490/938] loss_G: 2.572854, loss_D: 0.216307\n",
      "[Epoch 56/200] [Batch 500/938] loss_G: 2.559890, loss_D: 0.216173\n",
      "[Epoch 56/200] [Batch 510/938] loss_G: 2.413821, loss_D: 0.264226\n",
      "[Epoch 56/200] [Batch 520/938] loss_G: 2.961566, loss_D: 0.152627\n",
      "[Epoch 56/200] [Batch 530/938] loss_G: 2.590919, loss_D: 0.289292\n",
      "[Epoch 56/200] [Batch 540/938] loss_G: 2.771033, loss_D: 0.152340\n",
      "[Epoch 56/200] [Batch 550/938] loss_G: 2.433891, loss_D: 0.230604\n",
      "[Epoch 56/200] [Batch 560/938] loss_G: 2.501069, loss_D: 0.300861\n",
      "[Epoch 56/200] [Batch 570/938] loss_G: 2.494946, loss_D: 0.280340\n",
      "[Epoch 56/200] [Batch 580/938] loss_G: 2.486919, loss_D: 0.289220\n",
      "[Epoch 56/200] [Batch 590/938] loss_G: 2.781806, loss_D: 0.255894\n",
      "[Epoch 56/200] [Batch 600/938] loss_G: 2.431343, loss_D: 0.244481\n",
      "[Epoch 56/200] [Batch 610/938] loss_G: 2.347568, loss_D: 0.262471\n",
      "[Epoch 56/200] [Batch 620/938] loss_G: 2.461609, loss_D: 0.274079\n",
      "[Epoch 56/200] [Batch 630/938] loss_G: 2.659758, loss_D: 0.201702\n",
      "[Epoch 56/200] [Batch 640/938] loss_G: 2.358881, loss_D: 0.231604\n",
      "[Epoch 56/200] [Batch 650/938] loss_G: 2.883966, loss_D: 0.212579\n",
      "[Epoch 56/200] [Batch 660/938] loss_G: 2.261811, loss_D: 0.305794\n",
      "[Epoch 56/200] [Batch 670/938] loss_G: 2.557937, loss_D: 0.211518\n",
      "[Epoch 56/200] [Batch 680/938] loss_G: 2.643287, loss_D: 0.176256\n",
      "[Epoch 56/200] [Batch 690/938] loss_G: 2.727106, loss_D: 0.182852\n",
      "[Epoch 56/200] [Batch 700/938] loss_G: 3.010302, loss_D: 0.194722\n",
      "[Epoch 56/200] [Batch 710/938] loss_G: 2.603893, loss_D: 0.286149\n",
      "[Epoch 56/200] [Batch 720/938] loss_G: 2.437175, loss_D: 0.238340\n",
      "[Epoch 56/200] [Batch 730/938] loss_G: 2.658877, loss_D: 0.224697\n",
      "[Epoch 56/200] [Batch 740/938] loss_G: 2.581401, loss_D: 0.129818\n",
      "[Epoch 56/200] [Batch 750/938] loss_G: 2.746688, loss_D: 0.193045\n",
      "[Epoch 56/200] [Batch 760/938] loss_G: 2.447749, loss_D: 0.285713\n",
      "[Epoch 56/200] [Batch 770/938] loss_G: 2.784306, loss_D: 0.193462\n",
      "[Epoch 56/200] [Batch 780/938] loss_G: 2.811104, loss_D: 0.154067\n",
      "[Epoch 56/200] [Batch 790/938] loss_G: 2.588139, loss_D: 0.253213\n",
      "[Epoch 56/200] [Batch 800/938] loss_G: 2.482039, loss_D: 0.175845\n",
      "[Epoch 56/200] [Batch 810/938] loss_G: 2.818017, loss_D: 0.196908\n",
      "[Epoch 56/200] [Batch 820/938] loss_G: 2.328114, loss_D: 0.203816\n",
      "[Epoch 56/200] [Batch 830/938] loss_G: 2.722332, loss_D: 0.152559\n",
      "[Epoch 56/200] [Batch 840/938] loss_G: 2.707505, loss_D: 0.163585\n",
      "[Epoch 56/200] [Batch 850/938] loss_G: 2.611881, loss_D: 0.238621\n",
      "[Epoch 56/200] [Batch 860/938] loss_G: 2.362764, loss_D: 0.279833\n",
      "[Epoch 56/200] [Batch 870/938] loss_G: 2.864866, loss_D: 0.170101\n",
      "[Epoch 56/200] [Batch 880/938] loss_G: 2.664474, loss_D: 0.228747\n",
      "[Epoch 56/200] [Batch 890/938] loss_G: 2.462686, loss_D: 0.246516\n",
      "[Epoch 56/200] [Batch 900/938] loss_G: 2.846006, loss_D: 0.193205\n",
      "[Epoch 56/200] [Batch 910/938] loss_G: 2.633723, loss_D: 0.231291\n",
      "[Epoch 56/200] [Batch 920/938] loss_G: 2.505019, loss_D: 0.262290\n",
      "[Epoch 56/200] [Batch 930/938] loss_G: 2.470051, loss_D: 0.212624\n",
      "[Epoch 57/200] [Batch 0/938] loss_G: 2.964960, loss_D: 0.173054\n",
      "[Epoch 57/200] [Batch 10/938] loss_G: 2.378403, loss_D: 0.231623\n",
      "[Epoch 57/200] [Batch 20/938] loss_G: 2.953221, loss_D: 0.197421\n",
      "[Epoch 57/200] [Batch 30/938] loss_G: 2.817212, loss_D: 0.276750\n",
      "[Epoch 57/200] [Batch 40/938] loss_G: 2.637956, loss_D: 0.234741\n",
      "[Epoch 57/200] [Batch 50/938] loss_G: 2.482104, loss_D: 0.232560\n",
      "[Epoch 57/200] [Batch 60/938] loss_G: 2.855718, loss_D: 0.273460\n",
      "[Epoch 57/200] [Batch 70/938] loss_G: 2.580075, loss_D: 0.260105\n",
      "[Epoch 57/200] [Batch 80/938] loss_G: 2.454875, loss_D: 0.209679\n",
      "[Epoch 57/200] [Batch 90/938] loss_G: 2.653431, loss_D: 0.187163\n",
      "[Epoch 57/200] [Batch 100/938] loss_G: 2.865759, loss_D: 0.233466\n",
      "[Epoch 57/200] [Batch 110/938] loss_G: 2.394704, loss_D: 0.233495\n",
      "[Epoch 57/200] [Batch 120/938] loss_G: 2.643370, loss_D: 0.164731\n",
      "[Epoch 57/200] [Batch 130/938] loss_G: 2.404430, loss_D: 0.242750\n",
      "[Epoch 57/200] [Batch 140/938] loss_G: 2.494416, loss_D: 0.215319\n",
      "[Epoch 57/200] [Batch 150/938] loss_G: 2.551630, loss_D: 0.273559\n",
      "[Epoch 57/200] [Batch 160/938] loss_G: 2.266877, loss_D: 0.265907\n",
      "[Epoch 57/200] [Batch 170/938] loss_G: 2.781975, loss_D: 0.232113\n",
      "[Epoch 57/200] [Batch 180/938] loss_G: 2.317076, loss_D: 0.274007\n",
      "[Epoch 57/200] [Batch 190/938] loss_G: 2.791916, loss_D: 0.208825\n",
      "[Epoch 57/200] [Batch 200/938] loss_G: 2.402254, loss_D: 0.243506\n",
      "[Epoch 57/200] [Batch 210/938] loss_G: 2.520919, loss_D: 0.247687\n",
      "[Epoch 57/200] [Batch 220/938] loss_G: 2.880633, loss_D: 0.201708\n",
      "[Epoch 57/200] [Batch 230/938] loss_G: 2.708674, loss_D: 0.343648\n",
      "[Epoch 57/200] [Batch 240/938] loss_G: 2.637021, loss_D: 0.240952\n",
      "[Epoch 57/200] [Batch 250/938] loss_G: 2.707157, loss_D: 0.198187\n",
      "[Epoch 57/200] [Batch 260/938] loss_G: 2.591351, loss_D: 0.283078\n",
      "[Epoch 57/200] [Batch 270/938] loss_G: 2.755464, loss_D: 0.206772\n",
      "[Epoch 57/200] [Batch 280/938] loss_G: 2.289170, loss_D: 0.221844\n",
      "[Epoch 57/200] [Batch 290/938] loss_G: 2.674820, loss_D: 0.223465\n",
      "[Epoch 57/200] [Batch 300/938] loss_G: 2.620419, loss_D: 0.201199\n",
      "[Epoch 57/200] [Batch 310/938] loss_G: 2.518665, loss_D: 0.310002\n",
      "[Epoch 57/200] [Batch 320/938] loss_G: 2.612942, loss_D: 0.300975\n",
      "[Epoch 57/200] [Batch 330/938] loss_G: 2.498411, loss_D: 0.149668\n",
      "[Epoch 57/200] [Batch 340/938] loss_G: 2.378774, loss_D: 0.200166\n",
      "[Epoch 57/200] [Batch 350/938] loss_G: 2.768009, loss_D: 0.207065\n",
      "[Epoch 57/200] [Batch 360/938] loss_G: 2.431172, loss_D: 0.263439\n",
      "[Epoch 57/200] [Batch 370/938] loss_G: 2.465015, loss_D: 0.272481\n",
      "[Epoch 57/200] [Batch 380/938] loss_G: 2.543969, loss_D: 0.329550\n",
      "[Epoch 57/200] [Batch 390/938] loss_G: 2.745706, loss_D: 0.176327\n",
      "[Epoch 57/200] [Batch 400/938] loss_G: 2.671655, loss_D: 0.203843\n",
      "[Epoch 57/200] [Batch 410/938] loss_G: 2.307283, loss_D: 0.234891\n",
      "[Epoch 57/200] [Batch 420/938] loss_G: 2.784768, loss_D: 0.253829\n",
      "[Epoch 57/200] [Batch 430/938] loss_G: 2.514143, loss_D: 0.197099\n",
      "[Epoch 57/200] [Batch 440/938] loss_G: 2.637426, loss_D: 0.267074\n",
      "[Epoch 57/200] [Batch 450/938] loss_G: 2.938709, loss_D: 0.214389\n",
      "[Epoch 57/200] [Batch 460/938] loss_G: 2.511476, loss_D: 0.188131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 57/200] [Batch 470/938] loss_G: 2.524168, loss_D: 0.221509\n",
      "[Epoch 57/200] [Batch 480/938] loss_G: 2.415474, loss_D: 0.300893\n",
      "[Epoch 57/200] [Batch 490/938] loss_G: 2.603935, loss_D: 0.221008\n",
      "[Epoch 57/200] [Batch 500/938] loss_G: 2.660717, loss_D: 0.244164\n",
      "[Epoch 57/200] [Batch 510/938] loss_G: 2.843532, loss_D: 0.196146\n",
      "[Epoch 57/200] [Batch 520/938] loss_G: 2.450048, loss_D: 0.235389\n",
      "[Epoch 57/200] [Batch 530/938] loss_G: 2.733704, loss_D: 0.361387\n",
      "[Epoch 57/200] [Batch 540/938] loss_G: 2.455066, loss_D: 0.301539\n",
      "[Epoch 57/200] [Batch 550/938] loss_G: 2.295591, loss_D: 0.244336\n",
      "[Epoch 57/200] [Batch 560/938] loss_G: 2.856287, loss_D: 0.208606\n",
      "[Epoch 57/200] [Batch 570/938] loss_G: 2.607748, loss_D: 0.291827\n",
      "[Epoch 57/200] [Batch 580/938] loss_G: 2.862431, loss_D: 0.169097\n",
      "[Epoch 57/200] [Batch 590/938] loss_G: 2.828424, loss_D: 0.176358\n",
      "[Epoch 57/200] [Batch 600/938] loss_G: 2.612671, loss_D: 0.202845\n",
      "[Epoch 57/200] [Batch 610/938] loss_G: 2.423030, loss_D: 0.224538\n",
      "[Epoch 57/200] [Batch 620/938] loss_G: 2.081251, loss_D: 0.359516\n",
      "[Epoch 57/200] [Batch 630/938] loss_G: 2.657211, loss_D: 0.315503\n",
      "[Epoch 57/200] [Batch 640/938] loss_G: 2.495443, loss_D: 0.172486\n",
      "[Epoch 57/200] [Batch 650/938] loss_G: 2.504191, loss_D: 0.203070\n",
      "[Epoch 57/200] [Batch 660/938] loss_G: 3.044077, loss_D: 0.215546\n",
      "[Epoch 57/200] [Batch 670/938] loss_G: 2.935165, loss_D: 0.122533\n",
      "[Epoch 57/200] [Batch 680/938] loss_G: 2.345390, loss_D: 0.293368\n",
      "[Epoch 57/200] [Batch 690/938] loss_G: 2.441113, loss_D: 0.231515\n",
      "[Epoch 57/200] [Batch 700/938] loss_G: 2.665476, loss_D: 0.267704\n",
      "[Epoch 57/200] [Batch 710/938] loss_G: 2.495277, loss_D: 0.190099\n",
      "[Epoch 57/200] [Batch 720/938] loss_G: 2.459204, loss_D: 0.296246\n",
      "[Epoch 57/200] [Batch 730/938] loss_G: 2.582053, loss_D: 0.242359\n",
      "[Epoch 57/200] [Batch 740/938] loss_G: 2.708742, loss_D: 0.158970\n",
      "[Epoch 57/200] [Batch 750/938] loss_G: 2.635384, loss_D: 0.225959\n",
      "[Epoch 57/200] [Batch 760/938] loss_G: 2.502418, loss_D: 0.286276\n",
      "[Epoch 57/200] [Batch 770/938] loss_G: 2.490729, loss_D: 0.237044\n",
      "[Epoch 57/200] [Batch 780/938] loss_G: 2.800584, loss_D: 0.247988\n",
      "[Epoch 57/200] [Batch 790/938] loss_G: 2.489463, loss_D: 0.245956\n",
      "[Epoch 57/200] [Batch 800/938] loss_G: 2.419479, loss_D: 0.255307\n",
      "[Epoch 57/200] [Batch 810/938] loss_G: 2.770207, loss_D: 0.314441\n",
      "[Epoch 57/200] [Batch 820/938] loss_G: 2.801053, loss_D: 0.217044\n",
      "[Epoch 57/200] [Batch 830/938] loss_G: 2.484964, loss_D: 0.318737\n",
      "[Epoch 57/200] [Batch 840/938] loss_G: 2.448301, loss_D: 0.270657\n",
      "[Epoch 57/200] [Batch 850/938] loss_G: 2.676943, loss_D: 0.210367\n",
      "[Epoch 57/200] [Batch 860/938] loss_G: 2.636724, loss_D: 0.202538\n",
      "[Epoch 57/200] [Batch 870/938] loss_G: 2.399538, loss_D: 0.209522\n",
      "[Epoch 57/200] [Batch 880/938] loss_G: 2.606524, loss_D: 0.218187\n",
      "[Epoch 57/200] [Batch 890/938] loss_G: 2.755808, loss_D: 0.207522\n",
      "[Epoch 57/200] [Batch 900/938] loss_G: 2.434307, loss_D: 0.227439\n",
      "[Epoch 57/200] [Batch 910/938] loss_G: 2.594704, loss_D: 0.164979\n",
      "[Epoch 57/200] [Batch 920/938] loss_G: 2.569523, loss_D: 0.241853\n",
      "[Epoch 57/200] [Batch 930/938] loss_G: 2.799706, loss_D: 0.147893\n",
      "[Epoch 58/200] [Batch 0/938] loss_G: 2.681791, loss_D: 0.155023\n",
      "[Epoch 58/200] [Batch 10/938] loss_G: 2.703760, loss_D: 0.266637\n",
      "[Epoch 58/200] [Batch 20/938] loss_G: 2.698677, loss_D: 0.231361\n",
      "[Epoch 58/200] [Batch 30/938] loss_G: 2.207562, loss_D: 0.258656\n",
      "[Epoch 58/200] [Batch 40/938] loss_G: 2.706464, loss_D: 0.204287\n",
      "[Epoch 58/200] [Batch 50/938] loss_G: 2.289823, loss_D: 0.260385\n",
      "[Epoch 58/200] [Batch 60/938] loss_G: 3.136131, loss_D: 0.237704\n",
      "[Epoch 58/200] [Batch 70/938] loss_G: 2.342559, loss_D: 0.322547\n",
      "[Epoch 58/200] [Batch 80/938] loss_G: 2.710186, loss_D: 0.258274\n",
      "[Epoch 58/200] [Batch 90/938] loss_G: 2.660819, loss_D: 0.207782\n",
      "[Epoch 58/200] [Batch 100/938] loss_G: 2.430781, loss_D: 0.203107\n",
      "[Epoch 58/200] [Batch 110/938] loss_G: 2.645682, loss_D: 0.218371\n",
      "[Epoch 58/200] [Batch 120/938] loss_G: 2.497165, loss_D: 0.236769\n",
      "[Epoch 58/200] [Batch 130/938] loss_G: 3.046648, loss_D: 0.253195\n",
      "[Epoch 58/200] [Batch 140/938] loss_G: 2.877093, loss_D: 0.277318\n",
      "[Epoch 58/200] [Batch 150/938] loss_G: 2.489764, loss_D: 0.222656\n",
      "[Epoch 58/200] [Batch 160/938] loss_G: 2.618313, loss_D: 0.181529\n",
      "[Epoch 58/200] [Batch 170/938] loss_G: 2.556664, loss_D: 0.320704\n",
      "[Epoch 58/200] [Batch 180/938] loss_G: 2.667516, loss_D: 0.223745\n",
      "[Epoch 58/200] [Batch 190/938] loss_G: 2.815643, loss_D: 0.228480\n",
      "[Epoch 58/200] [Batch 200/938] loss_G: 2.797938, loss_D: 0.205560\n",
      "[Epoch 58/200] [Batch 210/938] loss_G: 2.281635, loss_D: 0.250606\n",
      "[Epoch 58/200] [Batch 220/938] loss_G: 2.906133, loss_D: 0.293636\n",
      "[Epoch 58/200] [Batch 230/938] loss_G: 2.272124, loss_D: 0.203711\n",
      "[Epoch 58/200] [Batch 240/938] loss_G: 2.834620, loss_D: 0.297173\n",
      "[Epoch 58/200] [Batch 250/938] loss_G: 2.547023, loss_D: 0.283827\n",
      "[Epoch 58/200] [Batch 260/938] loss_G: 2.463583, loss_D: 0.175348\n",
      "[Epoch 58/200] [Batch 270/938] loss_G: 2.619896, loss_D: 0.227504\n",
      "[Epoch 58/200] [Batch 280/938] loss_G: 2.739691, loss_D: 0.169520\n",
      "[Epoch 58/200] [Batch 290/938] loss_G: 2.512778, loss_D: 0.190385\n",
      "[Epoch 58/200] [Batch 300/938] loss_G: 2.357140, loss_D: 0.258075\n",
      "[Epoch 58/200] [Batch 310/938] loss_G: 3.066127, loss_D: 0.213177\n",
      "[Epoch 58/200] [Batch 320/938] loss_G: 2.878181, loss_D: 0.174420\n",
      "[Epoch 58/200] [Batch 330/938] loss_G: 2.653433, loss_D: 0.254310\n",
      "[Epoch 58/200] [Batch 340/938] loss_G: 2.705632, loss_D: 0.233605\n",
      "[Epoch 58/200] [Batch 350/938] loss_G: 2.635372, loss_D: 0.217389\n",
      "[Epoch 58/200] [Batch 360/938] loss_G: 2.746015, loss_D: 0.241772\n",
      "[Epoch 58/200] [Batch 370/938] loss_G: 2.589001, loss_D: 0.249895\n",
      "[Epoch 58/200] [Batch 380/938] loss_G: 2.801278, loss_D: 0.205467\n",
      "[Epoch 58/200] [Batch 390/938] loss_G: 2.582301, loss_D: 0.219303\n",
      "[Epoch 58/200] [Batch 400/938] loss_G: 2.608364, loss_D: 0.262407\n",
      "[Epoch 58/200] [Batch 410/938] loss_G: 2.655932, loss_D: 0.181207\n",
      "[Epoch 58/200] [Batch 420/938] loss_G: 2.349086, loss_D: 0.400816\n",
      "[Epoch 58/200] [Batch 430/938] loss_G: 2.579578, loss_D: 0.310760\n",
      "[Epoch 58/200] [Batch 440/938] loss_G: 2.536115, loss_D: 0.278890\n",
      "[Epoch 58/200] [Batch 450/938] loss_G: 2.605386, loss_D: 0.239075\n",
      "[Epoch 58/200] [Batch 460/938] loss_G: 2.193276, loss_D: 0.247075\n",
      "[Epoch 58/200] [Batch 470/938] loss_G: 2.331072, loss_D: 0.257924\n",
      "[Epoch 58/200] [Batch 480/938] loss_G: 2.272457, loss_D: 0.273479\n",
      "[Epoch 58/200] [Batch 490/938] loss_G: 2.691330, loss_D: 0.296676\n",
      "[Epoch 58/200] [Batch 500/938] loss_G: 2.312835, loss_D: 0.285584\n",
      "[Epoch 58/200] [Batch 510/938] loss_G: 2.961255, loss_D: 0.276690\n",
      "[Epoch 58/200] [Batch 520/938] loss_G: 2.254283, loss_D: 0.253074\n",
      "[Epoch 58/200] [Batch 530/938] loss_G: 2.789280, loss_D: 0.172011\n",
      "[Epoch 58/200] [Batch 540/938] loss_G: 2.602258, loss_D: 0.202561\n",
      "[Epoch 58/200] [Batch 550/938] loss_G: 2.478131, loss_D: 0.311929\n",
      "[Epoch 58/200] [Batch 560/938] loss_G: 2.946809, loss_D: 0.158096\n",
      "[Epoch 58/200] [Batch 570/938] loss_G: 2.724157, loss_D: 0.219367\n",
      "[Epoch 58/200] [Batch 580/938] loss_G: 2.475871, loss_D: 0.215374\n",
      "[Epoch 58/200] [Batch 590/938] loss_G: 2.621725, loss_D: 0.279593\n",
      "[Epoch 58/200] [Batch 600/938] loss_G: 2.812637, loss_D: 0.240240\n",
      "[Epoch 58/200] [Batch 610/938] loss_G: 2.414191, loss_D: 0.239340\n",
      "[Epoch 58/200] [Batch 620/938] loss_G: 2.626096, loss_D: 0.287730\n",
      "[Epoch 58/200] [Batch 630/938] loss_G: 2.728634, loss_D: 0.212841\n",
      "[Epoch 58/200] [Batch 640/938] loss_G: 2.235783, loss_D: 0.261549\n",
      "[Epoch 58/200] [Batch 650/938] loss_G: 2.719021, loss_D: 0.201739\n",
      "[Epoch 58/200] [Batch 660/938] loss_G: 2.565699, loss_D: 0.223896\n",
      "[Epoch 58/200] [Batch 670/938] loss_G: 2.477072, loss_D: 0.322270\n",
      "[Epoch 58/200] [Batch 680/938] loss_G: 2.688981, loss_D: 0.305979\n",
      "[Epoch 58/200] [Batch 690/938] loss_G: 2.396343, loss_D: 0.285177\n",
      "[Epoch 58/200] [Batch 700/938] loss_G: 2.790923, loss_D: 0.199190\n",
      "[Epoch 58/200] [Batch 710/938] loss_G: 2.632182, loss_D: 0.194966\n",
      "[Epoch 58/200] [Batch 720/938] loss_G: 2.946442, loss_D: 0.300176\n",
      "[Epoch 58/200] [Batch 730/938] loss_G: 2.368457, loss_D: 0.205733\n",
      "[Epoch 58/200] [Batch 740/938] loss_G: 2.435629, loss_D: 0.201361\n",
      "[Epoch 58/200] [Batch 750/938] loss_G: 2.309399, loss_D: 0.264411\n",
      "[Epoch 58/200] [Batch 760/938] loss_G: 2.926407, loss_D: 0.180624\n",
      "[Epoch 58/200] [Batch 770/938] loss_G: 2.723866, loss_D: 0.177932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 58/200] [Batch 780/938] loss_G: 2.256721, loss_D: 0.235270\n",
      "[Epoch 58/200] [Batch 790/938] loss_G: 2.335446, loss_D: 0.222456\n",
      "[Epoch 58/200] [Batch 800/938] loss_G: 2.452948, loss_D: 0.275017\n",
      "[Epoch 58/200] [Batch 810/938] loss_G: 3.482194, loss_D: 0.200518\n",
      "[Epoch 58/200] [Batch 820/938] loss_G: 2.774192, loss_D: 0.175228\n",
      "[Epoch 58/200] [Batch 830/938] loss_G: 2.700113, loss_D: 0.264905\n",
      "[Epoch 58/200] [Batch 840/938] loss_G: 2.446052, loss_D: 0.270055\n",
      "[Epoch 58/200] [Batch 850/938] loss_G: 2.374052, loss_D: 0.278358\n",
      "[Epoch 58/200] [Batch 860/938] loss_G: 2.669229, loss_D: 0.232931\n",
      "[Epoch 58/200] [Batch 870/938] loss_G: 2.649069, loss_D: 0.218159\n",
      "[Epoch 58/200] [Batch 880/938] loss_G: 2.569388, loss_D: 0.195153\n",
      "[Epoch 58/200] [Batch 890/938] loss_G: 2.853562, loss_D: 0.195066\n",
      "[Epoch 58/200] [Batch 900/938] loss_G: 3.100708, loss_D: 0.248995\n",
      "[Epoch 58/200] [Batch 910/938] loss_G: 2.638626, loss_D: 0.273490\n",
      "[Epoch 58/200] [Batch 920/938] loss_G: 2.596707, loss_D: 0.178708\n",
      "[Epoch 58/200] [Batch 930/938] loss_G: 2.681199, loss_D: 0.254612\n",
      "[Epoch 59/200] [Batch 0/938] loss_G: 2.503329, loss_D: 0.284296\n",
      "[Epoch 59/200] [Batch 10/938] loss_G: 2.856869, loss_D: 0.245293\n",
      "[Epoch 59/200] [Batch 20/938] loss_G: 2.565059, loss_D: 0.234904\n",
      "[Epoch 59/200] [Batch 30/938] loss_G: 2.218432, loss_D: 0.213844\n",
      "[Epoch 59/200] [Batch 40/938] loss_G: 2.435686, loss_D: 0.225805\n",
      "[Epoch 59/200] [Batch 50/938] loss_G: 2.763109, loss_D: 0.209785\n",
      "[Epoch 59/200] [Batch 60/938] loss_G: 2.405207, loss_D: 0.269213\n",
      "[Epoch 59/200] [Batch 70/938] loss_G: 2.561716, loss_D: 0.246437\n",
      "[Epoch 59/200] [Batch 80/938] loss_G: 2.290039, loss_D: 0.294786\n",
      "[Epoch 59/200] [Batch 90/938] loss_G: 2.872961, loss_D: 0.162878\n",
      "[Epoch 59/200] [Batch 100/938] loss_G: 2.224377, loss_D: 0.297528\n",
      "[Epoch 59/200] [Batch 110/938] loss_G: 3.018376, loss_D: 0.230898\n",
      "[Epoch 59/200] [Batch 120/938] loss_G: 2.313236, loss_D: 0.231329\n",
      "[Epoch 59/200] [Batch 130/938] loss_G: 2.881470, loss_D: 0.207592\n",
      "[Epoch 59/200] [Batch 140/938] loss_G: 2.683671, loss_D: 0.308434\n",
      "[Epoch 59/200] [Batch 150/938] loss_G: 2.556795, loss_D: 0.209481\n",
      "[Epoch 59/200] [Batch 160/938] loss_G: 2.292665, loss_D: 0.251861\n",
      "[Epoch 59/200] [Batch 170/938] loss_G: 2.665197, loss_D: 0.196760\n",
      "[Epoch 59/200] [Batch 180/938] loss_G: 2.387439, loss_D: 0.452327\n",
      "[Epoch 59/200] [Batch 190/938] loss_G: 2.853666, loss_D: 0.304771\n",
      "[Epoch 59/200] [Batch 200/938] loss_G: 2.176814, loss_D: 0.247459\n",
      "[Epoch 59/200] [Batch 210/938] loss_G: 2.645735, loss_D: 0.200691\n",
      "[Epoch 59/200] [Batch 220/938] loss_G: 2.489379, loss_D: 0.250964\n",
      "[Epoch 59/200] [Batch 230/938] loss_G: 2.789688, loss_D: 0.193541\n",
      "[Epoch 59/200] [Batch 240/938] loss_G: 2.439062, loss_D: 0.195740\n",
      "[Epoch 59/200] [Batch 250/938] loss_G: 2.875701, loss_D: 0.240762\n",
      "[Epoch 59/200] [Batch 260/938] loss_G: 2.364261, loss_D: 0.198253\n",
      "[Epoch 59/200] [Batch 270/938] loss_G: 2.793594, loss_D: 0.250626\n",
      "[Epoch 59/200] [Batch 280/938] loss_G: 2.206706, loss_D: 0.307362\n",
      "[Epoch 59/200] [Batch 290/938] loss_G: 2.845653, loss_D: 0.153849\n",
      "[Epoch 59/200] [Batch 300/938] loss_G: 2.849315, loss_D: 0.171833\n",
      "[Epoch 59/200] [Batch 310/938] loss_G: 2.710195, loss_D: 0.271421\n",
      "[Epoch 59/200] [Batch 320/938] loss_G: 2.669491, loss_D: 0.267919\n",
      "[Epoch 59/200] [Batch 330/938] loss_G: 2.498224, loss_D: 0.229159\n",
      "[Epoch 59/200] [Batch 340/938] loss_G: 2.676471, loss_D: 0.220166\n",
      "[Epoch 59/200] [Batch 350/938] loss_G: 2.721688, loss_D: 0.360976\n",
      "[Epoch 59/200] [Batch 360/938] loss_G: 2.916304, loss_D: 0.263817\n",
      "[Epoch 59/200] [Batch 370/938] loss_G: 2.425277, loss_D: 0.250862\n",
      "[Epoch 59/200] [Batch 380/938] loss_G: 2.491013, loss_D: 0.290520\n",
      "[Epoch 59/200] [Batch 390/938] loss_G: 2.528278, loss_D: 0.274567\n",
      "[Epoch 59/200] [Batch 400/938] loss_G: 2.615249, loss_D: 0.253378\n",
      "[Epoch 59/200] [Batch 410/938] loss_G: 2.335708, loss_D: 0.308758\n",
      "[Epoch 59/200] [Batch 420/938] loss_G: 2.424974, loss_D: 0.214101\n",
      "[Epoch 59/200] [Batch 430/938] loss_G: 2.326688, loss_D: 0.248399\n",
      "[Epoch 59/200] [Batch 440/938] loss_G: 2.651528, loss_D: 0.214057\n",
      "[Epoch 59/200] [Batch 450/938] loss_G: 2.811903, loss_D: 0.220104\n",
      "[Epoch 59/200] [Batch 460/938] loss_G: 2.112964, loss_D: 0.308178\n",
      "[Epoch 59/200] [Batch 470/938] loss_G: 2.603132, loss_D: 0.234449\n",
      "[Epoch 59/200] [Batch 480/938] loss_G: 2.382443, loss_D: 0.193547\n",
      "[Epoch 59/200] [Batch 490/938] loss_G: 2.447387, loss_D: 0.225190\n",
      "[Epoch 59/200] [Batch 500/938] loss_G: 2.518147, loss_D: 0.145014\n",
      "[Epoch 59/200] [Batch 510/938] loss_G: 2.642756, loss_D: 0.238625\n",
      "[Epoch 59/200] [Batch 520/938] loss_G: 2.313496, loss_D: 0.247690\n",
      "[Epoch 59/200] [Batch 530/938] loss_G: 2.449143, loss_D: 0.236768\n",
      "[Epoch 59/200] [Batch 540/938] loss_G: 2.088755, loss_D: 0.272915\n",
      "[Epoch 59/200] [Batch 550/938] loss_G: 2.735575, loss_D: 0.189101\n",
      "[Epoch 59/200] [Batch 560/938] loss_G: 2.643081, loss_D: 0.272725\n",
      "[Epoch 59/200] [Batch 570/938] loss_G: 2.681093, loss_D: 0.234011\n",
      "[Epoch 59/200] [Batch 580/938] loss_G: 2.644853, loss_D: 0.198734\n",
      "[Epoch 59/200] [Batch 590/938] loss_G: 2.558782, loss_D: 0.335295\n",
      "[Epoch 59/200] [Batch 600/938] loss_G: 2.379967, loss_D: 0.267069\n",
      "[Epoch 59/200] [Batch 610/938] loss_G: 2.502538, loss_D: 0.205202\n",
      "[Epoch 59/200] [Batch 620/938] loss_G: 2.989704, loss_D: 0.188342\n",
      "[Epoch 59/200] [Batch 630/938] loss_G: 2.755986, loss_D: 0.144849\n",
      "[Epoch 59/200] [Batch 640/938] loss_G: 2.583296, loss_D: 0.228695\n",
      "[Epoch 59/200] [Batch 650/938] loss_G: 2.115540, loss_D: 0.233643\n",
      "[Epoch 59/200] [Batch 660/938] loss_G: 2.515598, loss_D: 0.250283\n",
      "[Epoch 59/200] [Batch 670/938] loss_G: 2.522076, loss_D: 0.280621\n",
      "[Epoch 59/200] [Batch 680/938] loss_G: 2.571655, loss_D: 0.211308\n",
      "[Epoch 59/200] [Batch 690/938] loss_G: 2.676578, loss_D: 0.240527\n",
      "[Epoch 59/200] [Batch 700/938] loss_G: 2.651175, loss_D: 0.241822\n",
      "[Epoch 59/200] [Batch 710/938] loss_G: 2.473322, loss_D: 0.272071\n",
      "[Epoch 59/200] [Batch 720/938] loss_G: 2.343863, loss_D: 0.266469\n",
      "[Epoch 59/200] [Batch 730/938] loss_G: 2.534552, loss_D: 0.203967\n",
      "[Epoch 59/200] [Batch 740/938] loss_G: 2.651487, loss_D: 0.323700\n",
      "[Epoch 59/200] [Batch 750/938] loss_G: 2.240829, loss_D: 0.194285\n",
      "[Epoch 59/200] [Batch 760/938] loss_G: 2.287686, loss_D: 0.206384\n",
      "[Epoch 59/200] [Batch 770/938] loss_G: 2.838857, loss_D: 0.178283\n",
      "[Epoch 59/200] [Batch 780/938] loss_G: 3.254114, loss_D: 0.213335\n",
      "[Epoch 59/200] [Batch 790/938] loss_G: 2.835335, loss_D: 0.199646\n",
      "[Epoch 59/200] [Batch 800/938] loss_G: 2.576832, loss_D: 0.244665\n",
      "[Epoch 59/200] [Batch 810/938] loss_G: 2.678372, loss_D: 0.285279\n",
      "[Epoch 59/200] [Batch 820/938] loss_G: 2.765233, loss_D: 0.210584\n",
      "[Epoch 59/200] [Batch 830/938] loss_G: 2.411975, loss_D: 0.241862\n",
      "[Epoch 59/200] [Batch 840/938] loss_G: 3.017543, loss_D: 0.226823\n",
      "[Epoch 59/200] [Batch 850/938] loss_G: 2.219762, loss_D: 0.264292\n",
      "[Epoch 59/200] [Batch 860/938] loss_G: 2.553201, loss_D: 0.309796\n",
      "[Epoch 59/200] [Batch 870/938] loss_G: 2.429727, loss_D: 0.307288\n",
      "[Epoch 59/200] [Batch 880/938] loss_G: 2.403070, loss_D: 0.263433\n",
      "[Epoch 59/200] [Batch 890/938] loss_G: 2.687725, loss_D: 0.271704\n",
      "[Epoch 59/200] [Batch 900/938] loss_G: 2.387790, loss_D: 0.244319\n",
      "[Epoch 59/200] [Batch 910/938] loss_G: 2.595003, loss_D: 0.308938\n",
      "[Epoch 59/200] [Batch 920/938] loss_G: 2.471105, loss_D: 0.210590\n",
      "[Epoch 59/200] [Batch 930/938] loss_G: 2.640199, loss_D: 0.216028\n",
      "[Epoch 60/200] [Batch 0/938] loss_G: 2.743842, loss_D: 0.234583\n",
      "[Epoch 60/200] [Batch 10/938] loss_G: 2.711868, loss_D: 0.288565\n",
      "[Epoch 60/200] [Batch 20/938] loss_G: 2.559102, loss_D: 0.224867\n",
      "[Epoch 60/200] [Batch 30/938] loss_G: 2.542655, loss_D: 0.286182\n",
      "[Epoch 60/200] [Batch 40/938] loss_G: 2.393173, loss_D: 0.207772\n",
      "[Epoch 60/200] [Batch 50/938] loss_G: 2.434457, loss_D: 0.267970\n",
      "[Epoch 60/200] [Batch 60/938] loss_G: 2.784687, loss_D: 0.314338\n",
      "[Epoch 60/200] [Batch 70/938] loss_G: 2.344634, loss_D: 0.274329\n",
      "[Epoch 60/200] [Batch 80/938] loss_G: 2.490577, loss_D: 0.279529\n",
      "[Epoch 60/200] [Batch 90/938] loss_G: 2.766522, loss_D: 0.317656\n",
      "[Epoch 60/200] [Batch 100/938] loss_G: 2.608080, loss_D: 0.211301\n",
      "[Epoch 60/200] [Batch 110/938] loss_G: 2.364358, loss_D: 0.262925\n",
      "[Epoch 60/200] [Batch 120/938] loss_G: 2.478817, loss_D: 0.281394\n",
      "[Epoch 60/200] [Batch 130/938] loss_G: 2.426499, loss_D: 0.219549\n",
      "[Epoch 60/200] [Batch 140/938] loss_G: 2.763247, loss_D: 0.226282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 60/200] [Batch 150/938] loss_G: 2.642401, loss_D: 0.212547\n",
      "[Epoch 60/200] [Batch 160/938] loss_G: 2.906414, loss_D: 0.287983\n",
      "[Epoch 60/200] [Batch 170/938] loss_G: 2.483571, loss_D: 0.241589\n",
      "[Epoch 60/200] [Batch 180/938] loss_G: 2.949445, loss_D: 0.262612\n",
      "[Epoch 60/200] [Batch 190/938] loss_G: 2.762685, loss_D: 0.150378\n",
      "[Epoch 60/200] [Batch 200/938] loss_G: 2.794888, loss_D: 0.222000\n",
      "[Epoch 60/200] [Batch 210/938] loss_G: 2.539072, loss_D: 0.255797\n",
      "[Epoch 60/200] [Batch 220/938] loss_G: 2.744605, loss_D: 0.364377\n",
      "[Epoch 60/200] [Batch 230/938] loss_G: 2.692836, loss_D: 0.279599\n",
      "[Epoch 60/200] [Batch 240/938] loss_G: 2.913959, loss_D: 0.165585\n",
      "[Epoch 60/200] [Batch 250/938] loss_G: 2.949285, loss_D: 0.337175\n",
      "[Epoch 60/200] [Batch 260/938] loss_G: 2.499682, loss_D: 0.278398\n",
      "[Epoch 60/200] [Batch 270/938] loss_G: 2.876660, loss_D: 0.199625\n",
      "[Epoch 60/200] [Batch 280/938] loss_G: 2.732108, loss_D: 0.201009\n",
      "[Epoch 60/200] [Batch 290/938] loss_G: 2.831685, loss_D: 0.170983\n",
      "[Epoch 60/200] [Batch 300/938] loss_G: 2.841113, loss_D: 0.219388\n",
      "[Epoch 60/200] [Batch 310/938] loss_G: 2.343349, loss_D: 0.306141\n",
      "[Epoch 60/200] [Batch 320/938] loss_G: 2.830206, loss_D: 0.237552\n",
      "[Epoch 60/200] [Batch 330/938] loss_G: 2.783052, loss_D: 0.231148\n",
      "[Epoch 60/200] [Batch 340/938] loss_G: 2.567809, loss_D: 0.180365\n",
      "[Epoch 60/200] [Batch 350/938] loss_G: 2.389613, loss_D: 0.337264\n",
      "[Epoch 60/200] [Batch 360/938] loss_G: 2.946487, loss_D: 0.179664\n",
      "[Epoch 60/200] [Batch 370/938] loss_G: 2.848599, loss_D: 0.193299\n",
      "[Epoch 60/200] [Batch 380/938] loss_G: 2.640590, loss_D: 0.358196\n",
      "[Epoch 60/200] [Batch 390/938] loss_G: 2.771892, loss_D: 0.327052\n",
      "[Epoch 60/200] [Batch 400/938] loss_G: 2.437638, loss_D: 0.284582\n",
      "[Epoch 60/200] [Batch 410/938] loss_G: 2.409142, loss_D: 0.263452\n",
      "[Epoch 60/200] [Batch 420/938] loss_G: 2.533406, loss_D: 0.226045\n",
      "[Epoch 60/200] [Batch 430/938] loss_G: 2.641838, loss_D: 0.193367\n",
      "[Epoch 60/200] [Batch 440/938] loss_G: 2.673729, loss_D: 0.194843\n",
      "[Epoch 60/200] [Batch 450/938] loss_G: 2.793829, loss_D: 0.179459\n",
      "[Epoch 60/200] [Batch 460/938] loss_G: 2.740228, loss_D: 0.218233\n",
      "[Epoch 60/200] [Batch 470/938] loss_G: 2.775953, loss_D: 0.178865\n",
      "[Epoch 60/200] [Batch 480/938] loss_G: 2.226664, loss_D: 0.284904\n",
      "[Epoch 60/200] [Batch 490/938] loss_G: 2.463335, loss_D: 0.307407\n",
      "[Epoch 60/200] [Batch 500/938] loss_G: 2.483714, loss_D: 0.293239\n",
      "[Epoch 60/200] [Batch 510/938] loss_G: 2.430640, loss_D: 0.372589\n",
      "[Epoch 60/200] [Batch 520/938] loss_G: 2.232476, loss_D: 0.270602\n",
      "[Epoch 60/200] [Batch 530/938] loss_G: 3.010767, loss_D: 0.254836\n",
      "[Epoch 60/200] [Batch 540/938] loss_G: 2.422653, loss_D: 0.231807\n",
      "[Epoch 60/200] [Batch 550/938] loss_G: 2.409655, loss_D: 0.229691\n",
      "[Epoch 60/200] [Batch 560/938] loss_G: 2.563611, loss_D: 0.293764\n",
      "[Epoch 60/200] [Batch 570/938] loss_G: 2.321867, loss_D: 0.205339\n",
      "[Epoch 60/200] [Batch 580/938] loss_G: 2.528021, loss_D: 0.333771\n",
      "[Epoch 60/200] [Batch 590/938] loss_G: 2.525933, loss_D: 0.237384\n",
      "[Epoch 60/200] [Batch 600/938] loss_G: 2.963019, loss_D: 0.210507\n",
      "[Epoch 60/200] [Batch 610/938] loss_G: 2.419600, loss_D: 0.267707\n",
      "[Epoch 60/200] [Batch 620/938] loss_G: 3.337509, loss_D: 0.192458\n",
      "[Epoch 60/200] [Batch 630/938] loss_G: 2.535781, loss_D: 0.238311\n",
      "[Epoch 60/200] [Batch 640/938] loss_G: 2.701814, loss_D: 0.203270\n",
      "[Epoch 60/200] [Batch 650/938] loss_G: 2.643804, loss_D: 0.146053\n",
      "[Epoch 60/200] [Batch 660/938] loss_G: 2.912581, loss_D: 0.302758\n",
      "[Epoch 60/200] [Batch 670/938] loss_G: 2.138844, loss_D: 0.269086\n",
      "[Epoch 60/200] [Batch 680/938] loss_G: 2.591704, loss_D: 0.179813\n",
      "[Epoch 60/200] [Batch 690/938] loss_G: 2.591404, loss_D: 0.218120\n",
      "[Epoch 60/200] [Batch 700/938] loss_G: 2.642985, loss_D: 0.252262\n",
      "[Epoch 60/200] [Batch 710/938] loss_G: 2.289012, loss_D: 0.295317\n",
      "[Epoch 60/200] [Batch 720/938] loss_G: 2.438101, loss_D: 0.271674\n",
      "[Epoch 60/200] [Batch 730/938] loss_G: 2.370108, loss_D: 0.328233\n",
      "[Epoch 60/200] [Batch 740/938] loss_G: 2.492529, loss_D: 0.228954\n",
      "[Epoch 60/200] [Batch 750/938] loss_G: 2.453469, loss_D: 0.261977\n",
      "[Epoch 60/200] [Batch 760/938] loss_G: 2.385844, loss_D: 0.285493\n",
      "[Epoch 60/200] [Batch 770/938] loss_G: 2.553624, loss_D: 0.245791\n",
      "[Epoch 60/200] [Batch 780/938] loss_G: 2.806571, loss_D: 0.268251\n",
      "[Epoch 60/200] [Batch 790/938] loss_G: 2.620302, loss_D: 0.249480\n",
      "[Epoch 60/200] [Batch 800/938] loss_G: 2.327590, loss_D: 0.319037\n",
      "[Epoch 60/200] [Batch 810/938] loss_G: 2.622113, loss_D: 0.297018\n",
      "[Epoch 60/200] [Batch 820/938] loss_G: 2.547179, loss_D: 0.163141\n",
      "[Epoch 60/200] [Batch 830/938] loss_G: 2.608904, loss_D: 0.314149\n",
      "[Epoch 60/200] [Batch 840/938] loss_G: 2.452265, loss_D: 0.243284\n",
      "[Epoch 60/200] [Batch 850/938] loss_G: 2.299180, loss_D: 0.238493\n",
      "[Epoch 60/200] [Batch 860/938] loss_G: 2.596281, loss_D: 0.208486\n",
      "[Epoch 60/200] [Batch 870/938] loss_G: 2.220492, loss_D: 0.236420\n",
      "[Epoch 60/200] [Batch 880/938] loss_G: 2.175254, loss_D: 0.254497\n",
      "[Epoch 60/200] [Batch 890/938] loss_G: 2.845367, loss_D: 0.214166\n",
      "[Epoch 60/200] [Batch 900/938] loss_G: 2.276741, loss_D: 0.202009\n",
      "[Epoch 60/200] [Batch 910/938] loss_G: 2.562020, loss_D: 0.277482\n",
      "[Epoch 60/200] [Batch 920/938] loss_G: 2.461041, loss_D: 0.215095\n",
      "[Epoch 60/200] [Batch 930/938] loss_G: 2.670599, loss_D: 0.215107\n",
      "[Epoch 61/200] [Batch 0/938] loss_G: 2.590714, loss_D: 0.251615\n",
      "[Epoch 61/200] [Batch 10/938] loss_G: 2.430190, loss_D: 0.245428\n",
      "[Epoch 61/200] [Batch 20/938] loss_G: 2.781193, loss_D: 0.202155\n",
      "[Epoch 61/200] [Batch 30/938] loss_G: 2.377007, loss_D: 0.200170\n",
      "[Epoch 61/200] [Batch 40/938] loss_G: 2.252254, loss_D: 0.317659\n",
      "[Epoch 61/200] [Batch 50/938] loss_G: 2.395666, loss_D: 0.383924\n",
      "[Epoch 61/200] [Batch 60/938] loss_G: 2.604654, loss_D: 0.282792\n",
      "[Epoch 61/200] [Batch 70/938] loss_G: 2.650340, loss_D: 0.194233\n",
      "[Epoch 61/200] [Batch 80/938] loss_G: 2.531043, loss_D: 0.269838\n",
      "[Epoch 61/200] [Batch 90/938] loss_G: 2.196954, loss_D: 0.255560\n",
      "[Epoch 61/200] [Batch 100/938] loss_G: 2.736500, loss_D: 0.290501\n",
      "[Epoch 61/200] [Batch 110/938] loss_G: 2.728366, loss_D: 0.246446\n",
      "[Epoch 61/200] [Batch 120/938] loss_G: 2.410692, loss_D: 0.195073\n",
      "[Epoch 61/200] [Batch 130/938] loss_G: 2.571108, loss_D: 0.313827\n",
      "[Epoch 61/200] [Batch 140/938] loss_G: 2.689710, loss_D: 0.296665\n",
      "[Epoch 61/200] [Batch 150/938] loss_G: 2.543023, loss_D: 0.234045\n",
      "[Epoch 61/200] [Batch 160/938] loss_G: 2.429243, loss_D: 0.291330\n",
      "[Epoch 61/200] [Batch 170/938] loss_G: 2.575160, loss_D: 0.165266\n",
      "[Epoch 61/200] [Batch 180/938] loss_G: 2.300689, loss_D: 0.205106\n",
      "[Epoch 61/200] [Batch 190/938] loss_G: 2.836817, loss_D: 0.112465\n",
      "[Epoch 61/200] [Batch 200/938] loss_G: 3.016749, loss_D: 0.168030\n",
      "[Epoch 61/200] [Batch 210/938] loss_G: 2.762875, loss_D: 0.197934\n",
      "[Epoch 61/200] [Batch 220/938] loss_G: 2.618165, loss_D: 0.209876\n",
      "[Epoch 61/200] [Batch 230/938] loss_G: 2.635368, loss_D: 0.171770\n",
      "[Epoch 61/200] [Batch 240/938] loss_G: 2.597931, loss_D: 0.244273\n",
      "[Epoch 61/200] [Batch 250/938] loss_G: 2.435973, loss_D: 0.270952\n",
      "[Epoch 61/200] [Batch 260/938] loss_G: 2.401006, loss_D: 0.305391\n",
      "[Epoch 61/200] [Batch 270/938] loss_G: 2.942843, loss_D: 0.171939\n",
      "[Epoch 61/200] [Batch 280/938] loss_G: 2.984003, loss_D: 0.162127\n",
      "[Epoch 61/200] [Batch 290/938] loss_G: 2.350883, loss_D: 0.238103\n",
      "[Epoch 61/200] [Batch 300/938] loss_G: 2.930789, loss_D: 0.215588\n",
      "[Epoch 61/200] [Batch 310/938] loss_G: 2.652051, loss_D: 0.261146\n",
      "[Epoch 61/200] [Batch 320/938] loss_G: 2.808307, loss_D: 0.248239\n",
      "[Epoch 61/200] [Batch 330/938] loss_G: 2.652151, loss_D: 0.170421\n",
      "[Epoch 61/200] [Batch 340/938] loss_G: 3.108874, loss_D: 0.193663\n",
      "[Epoch 61/200] [Batch 350/938] loss_G: 2.729714, loss_D: 0.269932\n",
      "[Epoch 61/200] [Batch 360/938] loss_G: 2.747900, loss_D: 0.249044\n",
      "[Epoch 61/200] [Batch 370/938] loss_G: 2.731105, loss_D: 0.192121\n",
      "[Epoch 61/200] [Batch 380/938] loss_G: 2.585804, loss_D: 0.236556\n",
      "[Epoch 61/200] [Batch 390/938] loss_G: 2.791346, loss_D: 0.185934\n",
      "[Epoch 61/200] [Batch 400/938] loss_G: 2.832314, loss_D: 0.217888\n",
      "[Epoch 61/200] [Batch 410/938] loss_G: 2.588855, loss_D: 0.228074\n",
      "[Epoch 61/200] [Batch 420/938] loss_G: 2.466506, loss_D: 0.298987\n",
      "[Epoch 61/200] [Batch 430/938] loss_G: 2.601979, loss_D: 0.238804\n",
      "[Epoch 61/200] [Batch 440/938] loss_G: 2.645209, loss_D: 0.201478\n",
      "[Epoch 61/200] [Batch 450/938] loss_G: 2.551217, loss_D: 0.136113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 61/200] [Batch 460/938] loss_G: 2.578712, loss_D: 0.230738\n",
      "[Epoch 61/200] [Batch 470/938] loss_G: 2.472668, loss_D: 0.217663\n",
      "[Epoch 61/200] [Batch 480/938] loss_G: 2.505348, loss_D: 0.266691\n",
      "[Epoch 61/200] [Batch 490/938] loss_G: 2.360208, loss_D: 0.284899\n",
      "[Epoch 61/200] [Batch 500/938] loss_G: 2.511524, loss_D: 0.213054\n",
      "[Epoch 61/200] [Batch 510/938] loss_G: 2.365773, loss_D: 0.255514\n",
      "[Epoch 61/200] [Batch 520/938] loss_G: 2.749490, loss_D: 0.199446\n",
      "[Epoch 61/200] [Batch 530/938] loss_G: 2.221082, loss_D: 0.363722\n",
      "[Epoch 61/200] [Batch 540/938] loss_G: 2.607143, loss_D: 0.222651\n",
      "[Epoch 61/200] [Batch 550/938] loss_G: 3.069769, loss_D: 0.243185\n",
      "[Epoch 61/200] [Batch 560/938] loss_G: 2.674383, loss_D: 0.212032\n",
      "[Epoch 61/200] [Batch 570/938] loss_G: 2.295971, loss_D: 0.233367\n",
      "[Epoch 61/200] [Batch 580/938] loss_G: 2.495274, loss_D: 0.274130\n",
      "[Epoch 61/200] [Batch 590/938] loss_G: 2.191563, loss_D: 0.267825\n",
      "[Epoch 61/200] [Batch 600/938] loss_G: 2.511485, loss_D: 0.233828\n",
      "[Epoch 61/200] [Batch 610/938] loss_G: 2.515920, loss_D: 0.238809\n",
      "[Epoch 61/200] [Batch 620/938] loss_G: 2.691277, loss_D: 0.293205\n",
      "[Epoch 61/200] [Batch 630/938] loss_G: 2.431224, loss_D: 0.226706\n",
      "[Epoch 61/200] [Batch 640/938] loss_G: 2.446858, loss_D: 0.272805\n",
      "[Epoch 61/200] [Batch 650/938] loss_G: 2.581869, loss_D: 0.208081\n",
      "[Epoch 61/200] [Batch 660/938] loss_G: 2.480721, loss_D: 0.225266\n",
      "[Epoch 61/200] [Batch 670/938] loss_G: 2.440204, loss_D: 0.272989\n",
      "[Epoch 61/200] [Batch 680/938] loss_G: 2.999863, loss_D: 0.240950\n",
      "[Epoch 61/200] [Batch 690/938] loss_G: 2.482851, loss_D: 0.243927\n",
      "[Epoch 61/200] [Batch 700/938] loss_G: 2.712968, loss_D: 0.243836\n",
      "[Epoch 61/200] [Batch 710/938] loss_G: 2.283075, loss_D: 0.312836\n",
      "[Epoch 61/200] [Batch 720/938] loss_G: 2.840901, loss_D: 0.247415\n",
      "[Epoch 61/200] [Batch 730/938] loss_G: 2.417811, loss_D: 0.175544\n",
      "[Epoch 61/200] [Batch 740/938] loss_G: 2.876215, loss_D: 0.142809\n",
      "[Epoch 61/200] [Batch 750/938] loss_G: 2.680249, loss_D: 0.243062\n",
      "[Epoch 61/200] [Batch 760/938] loss_G: 2.451050, loss_D: 0.204118\n",
      "[Epoch 61/200] [Batch 770/938] loss_G: 2.369246, loss_D: 0.226545\n",
      "[Epoch 61/200] [Batch 780/938] loss_G: 2.415705, loss_D: 0.256056\n",
      "[Epoch 61/200] [Batch 790/938] loss_G: 2.529426, loss_D: 0.272800\n",
      "[Epoch 61/200] [Batch 800/938] loss_G: 2.380103, loss_D: 0.244739\n",
      "[Epoch 61/200] [Batch 810/938] loss_G: 2.679017, loss_D: 0.286828\n",
      "[Epoch 61/200] [Batch 820/938] loss_G: 2.429648, loss_D: 0.344508\n",
      "[Epoch 61/200] [Batch 830/938] loss_G: 2.712564, loss_D: 0.257453\n",
      "[Epoch 61/200] [Batch 840/938] loss_G: 2.866175, loss_D: 0.244750\n",
      "[Epoch 61/200] [Batch 850/938] loss_G: 2.647182, loss_D: 0.221108\n",
      "[Epoch 61/200] [Batch 860/938] loss_G: 2.524195, loss_D: 0.235183\n",
      "[Epoch 61/200] [Batch 870/938] loss_G: 2.999485, loss_D: 0.163520\n",
      "[Epoch 61/200] [Batch 880/938] loss_G: 2.834497, loss_D: 0.155111\n",
      "[Epoch 61/200] [Batch 890/938] loss_G: 3.270468, loss_D: 0.193992\n",
      "[Epoch 61/200] [Batch 900/938] loss_G: 2.622521, loss_D: 0.206162\n",
      "[Epoch 61/200] [Batch 910/938] loss_G: 2.645760, loss_D: 0.253350\n",
      "[Epoch 61/200] [Batch 920/938] loss_G: 2.669649, loss_D: 0.267459\n",
      "[Epoch 61/200] [Batch 930/938] loss_G: 3.080778, loss_D: 0.164726\n",
      "[Epoch 62/200] [Batch 0/938] loss_G: 2.653427, loss_D: 0.230298\n",
      "[Epoch 62/200] [Batch 10/938] loss_G: 3.048835, loss_D: 0.245212\n",
      "[Epoch 62/200] [Batch 20/938] loss_G: 2.721406, loss_D: 0.259948\n",
      "[Epoch 62/200] [Batch 30/938] loss_G: 2.587492, loss_D: 0.194544\n",
      "[Epoch 62/200] [Batch 40/938] loss_G: 2.838573, loss_D: 0.218184\n",
      "[Epoch 62/200] [Batch 50/938] loss_G: 2.627076, loss_D: 0.181302\n",
      "[Epoch 62/200] [Batch 60/938] loss_G: 2.901425, loss_D: 0.209738\n",
      "[Epoch 62/200] [Batch 70/938] loss_G: 2.348919, loss_D: 0.277547\n",
      "[Epoch 62/200] [Batch 80/938] loss_G: 2.784892, loss_D: 0.244056\n",
      "[Epoch 62/200] [Batch 90/938] loss_G: 2.444702, loss_D: 0.191837\n",
      "[Epoch 62/200] [Batch 100/938] loss_G: 2.746200, loss_D: 0.250099\n",
      "[Epoch 62/200] [Batch 110/938] loss_G: 2.441833, loss_D: 0.189263\n",
      "[Epoch 62/200] [Batch 120/938] loss_G: 2.417346, loss_D: 0.247062\n",
      "[Epoch 62/200] [Batch 130/938] loss_G: 2.466776, loss_D: 0.253242\n",
      "[Epoch 62/200] [Batch 140/938] loss_G: 2.502885, loss_D: 0.230493\n",
      "[Epoch 62/200] [Batch 150/938] loss_G: 2.748203, loss_D: 0.380505\n",
      "[Epoch 62/200] [Batch 160/938] loss_G: 2.268324, loss_D: 0.215286\n",
      "[Epoch 62/200] [Batch 170/938] loss_G: 2.741487, loss_D: 0.339086\n",
      "[Epoch 62/200] [Batch 180/938] loss_G: 3.015370, loss_D: 0.229665\n",
      "[Epoch 62/200] [Batch 190/938] loss_G: 2.389080, loss_D: 0.211848\n",
      "[Epoch 62/200] [Batch 200/938] loss_G: 3.049386, loss_D: 0.168628\n",
      "[Epoch 62/200] [Batch 210/938] loss_G: 2.450494, loss_D: 0.271911\n",
      "[Epoch 62/200] [Batch 220/938] loss_G: 2.596326, loss_D: 0.256592\n",
      "[Epoch 62/200] [Batch 230/938] loss_G: 2.630035, loss_D: 0.199785\n",
      "[Epoch 62/200] [Batch 240/938] loss_G: 2.801269, loss_D: 0.181762\n",
      "[Epoch 62/200] [Batch 250/938] loss_G: 2.555150, loss_D: 0.203294\n",
      "[Epoch 62/200] [Batch 260/938] loss_G: 2.733169, loss_D: 0.247073\n",
      "[Epoch 62/200] [Batch 270/938] loss_G: 2.952904, loss_D: 0.183832\n",
      "[Epoch 62/200] [Batch 280/938] loss_G: 2.362288, loss_D: 0.245817\n",
      "[Epoch 62/200] [Batch 290/938] loss_G: 2.826993, loss_D: 0.343265\n",
      "[Epoch 62/200] [Batch 300/938] loss_G: 2.484427, loss_D: 0.198272\n",
      "[Epoch 62/200] [Batch 310/938] loss_G: 2.589692, loss_D: 0.237652\n",
      "[Epoch 62/200] [Batch 320/938] loss_G: 2.678457, loss_D: 0.242924\n",
      "[Epoch 62/200] [Batch 330/938] loss_G: 2.254825, loss_D: 0.261314\n",
      "[Epoch 62/200] [Batch 340/938] loss_G: 2.631702, loss_D: 0.322114\n",
      "[Epoch 62/200] [Batch 350/938] loss_G: 2.685923, loss_D: 0.158430\n",
      "[Epoch 62/200] [Batch 360/938] loss_G: 2.848171, loss_D: 0.180121\n",
      "[Epoch 62/200] [Batch 370/938] loss_G: 2.775530, loss_D: 0.212042\n",
      "[Epoch 62/200] [Batch 380/938] loss_G: 2.470492, loss_D: 0.234289\n",
      "[Epoch 62/200] [Batch 390/938] loss_G: 2.848288, loss_D: 0.240237\n",
      "[Epoch 62/200] [Batch 400/938] loss_G: 2.407663, loss_D: 0.180751\n",
      "[Epoch 62/200] [Batch 410/938] loss_G: 2.612494, loss_D: 0.241424\n",
      "[Epoch 62/200] [Batch 420/938] loss_G: 2.663775, loss_D: 0.175407\n",
      "[Epoch 62/200] [Batch 430/938] loss_G: 2.591213, loss_D: 0.271546\n",
      "[Epoch 62/200] [Batch 440/938] loss_G: 2.447765, loss_D: 0.305535\n",
      "[Epoch 62/200] [Batch 450/938] loss_G: 2.397358, loss_D: 0.220490\n",
      "[Epoch 62/200] [Batch 460/938] loss_G: 2.391670, loss_D: 0.230006\n",
      "[Epoch 62/200] [Batch 470/938] loss_G: 2.960564, loss_D: 0.193811\n",
      "[Epoch 62/200] [Batch 480/938] loss_G: 2.552428, loss_D: 0.157710\n",
      "[Epoch 62/200] [Batch 490/938] loss_G: 2.621694, loss_D: 0.203013\n",
      "[Epoch 62/200] [Batch 500/938] loss_G: 2.529016, loss_D: 0.271370\n",
      "[Epoch 62/200] [Batch 510/938] loss_G: 3.050676, loss_D: 0.235822\n",
      "[Epoch 62/200] [Batch 520/938] loss_G: 2.926349, loss_D: 0.197261\n",
      "[Epoch 62/200] [Batch 530/938] loss_G: 2.555869, loss_D: 0.214644\n",
      "[Epoch 62/200] [Batch 540/938] loss_G: 2.941741, loss_D: 0.195409\n",
      "[Epoch 62/200] [Batch 550/938] loss_G: 2.408453, loss_D: 0.244764\n",
      "[Epoch 62/200] [Batch 560/938] loss_G: 2.438585, loss_D: 0.217735\n",
      "[Epoch 62/200] [Batch 570/938] loss_G: 2.528541, loss_D: 0.184618\n",
      "[Epoch 62/200] [Batch 580/938] loss_G: 2.536438, loss_D: 0.282890\n",
      "[Epoch 62/200] [Batch 590/938] loss_G: 2.753770, loss_D: 0.249185\n",
      "[Epoch 62/200] [Batch 600/938] loss_G: 2.760355, loss_D: 0.274890\n",
      "[Epoch 62/200] [Batch 610/938] loss_G: 2.805431, loss_D: 0.209143\n",
      "[Epoch 62/200] [Batch 620/938] loss_G: 2.532010, loss_D: 0.237979\n",
      "[Epoch 62/200] [Batch 630/938] loss_G: 2.682434, loss_D: 0.274321\n",
      "[Epoch 62/200] [Batch 640/938] loss_G: 2.976413, loss_D: 0.115310\n",
      "[Epoch 62/200] [Batch 650/938] loss_G: 2.934368, loss_D: 0.169179\n",
      "[Epoch 62/200] [Batch 660/938] loss_G: 3.199286, loss_D: 0.226790\n",
      "[Epoch 62/200] [Batch 670/938] loss_G: 2.434656, loss_D: 0.244883\n",
      "[Epoch 62/200] [Batch 680/938] loss_G: 2.589609, loss_D: 0.355145\n",
      "[Epoch 62/200] [Batch 690/938] loss_G: 3.033170, loss_D: 0.186781\n",
      "[Epoch 62/200] [Batch 700/938] loss_G: 2.648825, loss_D: 0.280274\n",
      "[Epoch 62/200] [Batch 710/938] loss_G: 2.820231, loss_D: 0.291299\n",
      "[Epoch 62/200] [Batch 720/938] loss_G: 2.436242, loss_D: 0.299719\n",
      "[Epoch 62/200] [Batch 730/938] loss_G: 2.812128, loss_D: 0.190607\n",
      "[Epoch 62/200] [Batch 740/938] loss_G: 3.012722, loss_D: 0.210665\n",
      "[Epoch 62/200] [Batch 750/938] loss_G: 2.438887, loss_D: 0.160125\n",
      "[Epoch 62/200] [Batch 760/938] loss_G: 2.575061, loss_D: 0.314515\n",
      "[Epoch 62/200] [Batch 770/938] loss_G: 2.160531, loss_D: 0.295514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 62/200] [Batch 780/938] loss_G: 2.709036, loss_D: 0.279799\n",
      "[Epoch 62/200] [Batch 790/938] loss_G: 2.580374, loss_D: 0.224160\n",
      "[Epoch 62/200] [Batch 800/938] loss_G: 2.894600, loss_D: 0.284371\n",
      "[Epoch 62/200] [Batch 810/938] loss_G: 2.683363, loss_D: 0.274882\n",
      "[Epoch 62/200] [Batch 820/938] loss_G: 2.715466, loss_D: 0.216055\n",
      "[Epoch 62/200] [Batch 830/938] loss_G: 2.612058, loss_D: 0.194420\n",
      "[Epoch 62/200] [Batch 840/938] loss_G: 2.378191, loss_D: 0.366488\n",
      "[Epoch 62/200] [Batch 850/938] loss_G: 2.793562, loss_D: 0.265655\n",
      "[Epoch 62/200] [Batch 860/938] loss_G: 2.511087, loss_D: 0.269065\n",
      "[Epoch 62/200] [Batch 870/938] loss_G: 2.634655, loss_D: 0.242677\n",
      "[Epoch 62/200] [Batch 880/938] loss_G: 2.679403, loss_D: 0.183024\n",
      "[Epoch 62/200] [Batch 890/938] loss_G: 2.663100, loss_D: 0.280005\n",
      "[Epoch 62/200] [Batch 900/938] loss_G: 2.766812, loss_D: 0.256420\n",
      "[Epoch 62/200] [Batch 910/938] loss_G: 2.805816, loss_D: 0.172729\n",
      "[Epoch 62/200] [Batch 920/938] loss_G: 2.973848, loss_D: 0.191258\n",
      "[Epoch 62/200] [Batch 930/938] loss_G: 2.927089, loss_D: 0.212199\n",
      "[Epoch 63/200] [Batch 0/938] loss_G: 2.636406, loss_D: 0.235955\n",
      "[Epoch 63/200] [Batch 10/938] loss_G: 2.585535, loss_D: 0.179988\n",
      "[Epoch 63/200] [Batch 20/938] loss_G: 2.638538, loss_D: 0.314718\n",
      "[Epoch 63/200] [Batch 30/938] loss_G: 2.478139, loss_D: 0.244264\n",
      "[Epoch 63/200] [Batch 40/938] loss_G: 2.455327, loss_D: 0.199591\n",
      "[Epoch 63/200] [Batch 50/938] loss_G: 2.688765, loss_D: 0.177658\n",
      "[Epoch 63/200] [Batch 60/938] loss_G: 2.925088, loss_D: 0.311699\n",
      "[Epoch 63/200] [Batch 70/938] loss_G: 2.833584, loss_D: 0.244236\n",
      "[Epoch 63/200] [Batch 80/938] loss_G: 2.543684, loss_D: 0.233676\n",
      "[Epoch 63/200] [Batch 90/938] loss_G: 2.720156, loss_D: 0.171275\n",
      "[Epoch 63/200] [Batch 100/938] loss_G: 2.719229, loss_D: 0.314743\n",
      "[Epoch 63/200] [Batch 110/938] loss_G: 2.615757, loss_D: 0.228497\n",
      "[Epoch 63/200] [Batch 120/938] loss_G: 2.544532, loss_D: 0.258884\n",
      "[Epoch 63/200] [Batch 130/938] loss_G: 2.760529, loss_D: 0.243940\n",
      "[Epoch 63/200] [Batch 140/938] loss_G: 2.807553, loss_D: 0.321793\n",
      "[Epoch 63/200] [Batch 150/938] loss_G: 2.570611, loss_D: 0.279624\n",
      "[Epoch 63/200] [Batch 160/938] loss_G: 3.016153, loss_D: 0.205479\n",
      "[Epoch 63/200] [Batch 170/938] loss_G: 2.307281, loss_D: 0.192236\n",
      "[Epoch 63/200] [Batch 180/938] loss_G: 2.463112, loss_D: 0.191125\n",
      "[Epoch 63/200] [Batch 190/938] loss_G: 2.832131, loss_D: 0.181445\n",
      "[Epoch 63/200] [Batch 200/938] loss_G: 2.699586, loss_D: 0.210124\n",
      "[Epoch 63/200] [Batch 210/938] loss_G: 2.394073, loss_D: 0.206751\n",
      "[Epoch 63/200] [Batch 220/938] loss_G: 2.744576, loss_D: 0.177881\n",
      "[Epoch 63/200] [Batch 230/938] loss_G: 2.698348, loss_D: 0.208073\n",
      "[Epoch 63/200] [Batch 240/938] loss_G: 2.618191, loss_D: 0.273301\n",
      "[Epoch 63/200] [Batch 250/938] loss_G: 2.331690, loss_D: 0.197558\n",
      "[Epoch 63/200] [Batch 260/938] loss_G: 2.580554, loss_D: 0.273547\n",
      "[Epoch 63/200] [Batch 270/938] loss_G: 2.682983, loss_D: 0.250197\n",
      "[Epoch 63/200] [Batch 280/938] loss_G: 2.487717, loss_D: 0.276613\n",
      "[Epoch 63/200] [Batch 290/938] loss_G: 2.905701, loss_D: 0.237030\n",
      "[Epoch 63/200] [Batch 300/938] loss_G: 2.583791, loss_D: 0.221358\n",
      "[Epoch 63/200] [Batch 310/938] loss_G: 3.088777, loss_D: 0.179717\n",
      "[Epoch 63/200] [Batch 320/938] loss_G: 2.859761, loss_D: 0.246442\n",
      "[Epoch 63/200] [Batch 330/938] loss_G: 2.627555, loss_D: 0.226423\n",
      "[Epoch 63/200] [Batch 340/938] loss_G: 2.623139, loss_D: 0.203584\n",
      "[Epoch 63/200] [Batch 350/938] loss_G: 2.532752, loss_D: 0.284876\n",
      "[Epoch 63/200] [Batch 360/938] loss_G: 2.789222, loss_D: 0.308309\n",
      "[Epoch 63/200] [Batch 370/938] loss_G: 2.490022, loss_D: 0.195353\n",
      "[Epoch 63/200] [Batch 380/938] loss_G: 2.742783, loss_D: 0.329509\n",
      "[Epoch 63/200] [Batch 390/938] loss_G: 2.597930, loss_D: 0.202040\n",
      "[Epoch 63/200] [Batch 400/938] loss_G: 2.788867, loss_D: 0.228050\n",
      "[Epoch 63/200] [Batch 410/938] loss_G: 2.832012, loss_D: 0.297989\n",
      "[Epoch 63/200] [Batch 420/938] loss_G: 2.736891, loss_D: 0.207685\n",
      "[Epoch 63/200] [Batch 430/938] loss_G: 2.739215, loss_D: 0.184926\n",
      "[Epoch 63/200] [Batch 440/938] loss_G: 2.695643, loss_D: 0.212037\n",
      "[Epoch 63/200] [Batch 450/938] loss_G: 2.679890, loss_D: 0.190395\n",
      "[Epoch 63/200] [Batch 460/938] loss_G: 2.636481, loss_D: 0.214594\n",
      "[Epoch 63/200] [Batch 470/938] loss_G: 2.716675, loss_D: 0.233830\n",
      "[Epoch 63/200] [Batch 480/938] loss_G: 2.590333, loss_D: 0.214746\n",
      "[Epoch 63/200] [Batch 490/938] loss_G: 2.562140, loss_D: 0.258763\n",
      "[Epoch 63/200] [Batch 500/938] loss_G: 2.608167, loss_D: 0.239226\n",
      "[Epoch 63/200] [Batch 510/938] loss_G: 2.545587, loss_D: 0.206841\n",
      "[Epoch 63/200] [Batch 520/938] loss_G: 2.707289, loss_D: 0.203768\n",
      "[Epoch 63/200] [Batch 530/938] loss_G: 2.460693, loss_D: 0.259670\n",
      "[Epoch 63/200] [Batch 540/938] loss_G: 2.531023, loss_D: 0.250950\n",
      "[Epoch 63/200] [Batch 550/938] loss_G: 2.628311, loss_D: 0.214361\n",
      "[Epoch 63/200] [Batch 560/938] loss_G: 2.703652, loss_D: 0.279350\n",
      "[Epoch 63/200] [Batch 570/938] loss_G: 2.517931, loss_D: 0.186225\n",
      "[Epoch 63/200] [Batch 580/938] loss_G: 2.510726, loss_D: 0.245764\n",
      "[Epoch 63/200] [Batch 590/938] loss_G: 2.419136, loss_D: 0.231033\n",
      "[Epoch 63/200] [Batch 600/938] loss_G: 2.709126, loss_D: 0.179924\n",
      "[Epoch 63/200] [Batch 610/938] loss_G: 2.774569, loss_D: 0.255133\n",
      "[Epoch 63/200] [Batch 620/938] loss_G: 2.803040, loss_D: 0.215337\n",
      "[Epoch 63/200] [Batch 630/938] loss_G: 2.596947, loss_D: 0.200939\n",
      "[Epoch 63/200] [Batch 640/938] loss_G: 2.788729, loss_D: 0.219744\n",
      "[Epoch 63/200] [Batch 650/938] loss_G: 2.432531, loss_D: 0.182868\n",
      "[Epoch 63/200] [Batch 660/938] loss_G: 2.795556, loss_D: 0.226710\n",
      "[Epoch 63/200] [Batch 670/938] loss_G: 2.531685, loss_D: 0.181431\n",
      "[Epoch 63/200] [Batch 680/938] loss_G: 2.362398, loss_D: 0.256825\n",
      "[Epoch 63/200] [Batch 690/938] loss_G: 2.707325, loss_D: 0.216615\n",
      "[Epoch 63/200] [Batch 700/938] loss_G: 2.851419, loss_D: 0.255307\n",
      "[Epoch 63/200] [Batch 710/938] loss_G: 2.628300, loss_D: 0.188325\n",
      "[Epoch 63/200] [Batch 720/938] loss_G: 2.751927, loss_D: 0.247720\n",
      "[Epoch 63/200] [Batch 730/938] loss_G: 2.794185, loss_D: 0.261103\n",
      "[Epoch 63/200] [Batch 740/938] loss_G: 2.699469, loss_D: 0.183476\n",
      "[Epoch 63/200] [Batch 750/938] loss_G: 2.234921, loss_D: 0.246769\n",
      "[Epoch 63/200] [Batch 760/938] loss_G: 2.711470, loss_D: 0.192670\n",
      "[Epoch 63/200] [Batch 770/938] loss_G: 2.692992, loss_D: 0.186709\n",
      "[Epoch 63/200] [Batch 780/938] loss_G: 3.137550, loss_D: 0.157510\n",
      "[Epoch 63/200] [Batch 790/938] loss_G: 2.792527, loss_D: 0.172636\n",
      "[Epoch 63/200] [Batch 800/938] loss_G: 2.928409, loss_D: 0.181243\n",
      "[Epoch 63/200] [Batch 810/938] loss_G: 2.657662, loss_D: 0.253272\n",
      "[Epoch 63/200] [Batch 820/938] loss_G: 2.769952, loss_D: 0.294667\n",
      "[Epoch 63/200] [Batch 830/938] loss_G: 2.867346, loss_D: 0.200681\n",
      "[Epoch 63/200] [Batch 840/938] loss_G: 2.640555, loss_D: 0.357146\n",
      "[Epoch 63/200] [Batch 850/938] loss_G: 3.093075, loss_D: 0.256461\n",
      "[Epoch 63/200] [Batch 860/938] loss_G: 2.605716, loss_D: 0.309407\n",
      "[Epoch 63/200] [Batch 870/938] loss_G: 2.278529, loss_D: 0.237720\n",
      "[Epoch 63/200] [Batch 880/938] loss_G: 2.623033, loss_D: 0.198279\n",
      "[Epoch 63/200] [Batch 890/938] loss_G: 2.504916, loss_D: 0.242590\n",
      "[Epoch 63/200] [Batch 900/938] loss_G: 2.814733, loss_D: 0.311700\n",
      "[Epoch 63/200] [Batch 910/938] loss_G: 2.990329, loss_D: 0.198196\n",
      "[Epoch 63/200] [Batch 920/938] loss_G: 3.066843, loss_D: 0.155800\n",
      "[Epoch 63/200] [Batch 930/938] loss_G: 2.728801, loss_D: 0.252119\n",
      "[Epoch 64/200] [Batch 0/938] loss_G: 2.747992, loss_D: 0.167722\n",
      "[Epoch 64/200] [Batch 10/938] loss_G: 2.851655, loss_D: 0.270158\n",
      "[Epoch 64/200] [Batch 20/938] loss_G: 2.569066, loss_D: 0.249332\n",
      "[Epoch 64/200] [Batch 30/938] loss_G: 2.807652, loss_D: 0.148566\n",
      "[Epoch 64/200] [Batch 40/938] loss_G: 2.861294, loss_D: 0.122584\n",
      "[Epoch 64/200] [Batch 50/938] loss_G: 2.686688, loss_D: 0.200759\n",
      "[Epoch 64/200] [Batch 60/938] loss_G: 2.512360, loss_D: 0.298328\n",
      "[Epoch 64/200] [Batch 70/938] loss_G: 2.901882, loss_D: 0.239836\n",
      "[Epoch 64/200] [Batch 80/938] loss_G: 2.571883, loss_D: 0.250733\n",
      "[Epoch 64/200] [Batch 90/938] loss_G: 2.998957, loss_D: 0.201151\n",
      "[Epoch 64/200] [Batch 100/938] loss_G: 2.241981, loss_D: 0.229519\n",
      "[Epoch 64/200] [Batch 110/938] loss_G: 2.743024, loss_D: 0.193367\n",
      "[Epoch 64/200] [Batch 120/938] loss_G: 2.537083, loss_D: 0.273568\n",
      "[Epoch 64/200] [Batch 130/938] loss_G: 3.018968, loss_D: 0.275033\n",
      "[Epoch 64/200] [Batch 140/938] loss_G: 2.652817, loss_D: 0.218809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 64/200] [Batch 150/938] loss_G: 3.049831, loss_D: 0.267615\n",
      "[Epoch 64/200] [Batch 160/938] loss_G: 2.712484, loss_D: 0.176130\n",
      "[Epoch 64/200] [Batch 170/938] loss_G: 3.081032, loss_D: 0.215013\n",
      "[Epoch 64/200] [Batch 180/938] loss_G: 2.438162, loss_D: 0.218182\n",
      "[Epoch 64/200] [Batch 190/938] loss_G: 2.787063, loss_D: 0.252737\n",
      "[Epoch 64/200] [Batch 200/938] loss_G: 2.724104, loss_D: 0.269266\n",
      "[Epoch 64/200] [Batch 210/938] loss_G: 2.801016, loss_D: 0.282507\n",
      "[Epoch 64/200] [Batch 220/938] loss_G: 3.035881, loss_D: 0.286996\n",
      "[Epoch 64/200] [Batch 230/938] loss_G: 2.642615, loss_D: 0.228968\n",
      "[Epoch 64/200] [Batch 240/938] loss_G: 2.835583, loss_D: 0.217581\n",
      "[Epoch 64/200] [Batch 250/938] loss_G: 2.452535, loss_D: 0.236528\n",
      "[Epoch 64/200] [Batch 260/938] loss_G: 2.655779, loss_D: 0.149438\n",
      "[Epoch 64/200] [Batch 270/938] loss_G: 2.576676, loss_D: 0.194796\n",
      "[Epoch 64/200] [Batch 280/938] loss_G: 2.524991, loss_D: 0.334133\n",
      "[Epoch 64/200] [Batch 290/938] loss_G: 2.596298, loss_D: 0.225627\n",
      "[Epoch 64/200] [Batch 300/938] loss_G: 2.459274, loss_D: 0.191512\n",
      "[Epoch 64/200] [Batch 310/938] loss_G: 2.327899, loss_D: 0.266002\n",
      "[Epoch 64/200] [Batch 320/938] loss_G: 2.466202, loss_D: 0.253793\n",
      "[Epoch 64/200] [Batch 330/938] loss_G: 2.596840, loss_D: 0.212306\n",
      "[Epoch 64/200] [Batch 340/938] loss_G: 2.915942, loss_D: 0.291930\n",
      "[Epoch 64/200] [Batch 350/938] loss_G: 2.684774, loss_D: 0.262403\n",
      "[Epoch 64/200] [Batch 360/938] loss_G: 2.981200, loss_D: 0.245360\n",
      "[Epoch 64/200] [Batch 370/938] loss_G: 2.817278, loss_D: 0.166694\n",
      "[Epoch 64/200] [Batch 380/938] loss_G: 2.562367, loss_D: 0.184852\n",
      "[Epoch 64/200] [Batch 390/938] loss_G: 2.426283, loss_D: 0.170102\n",
      "[Epoch 64/200] [Batch 400/938] loss_G: 2.903606, loss_D: 0.191096\n",
      "[Epoch 64/200] [Batch 410/938] loss_G: 2.895693, loss_D: 0.161422\n",
      "[Epoch 64/200] [Batch 420/938] loss_G: 2.907655, loss_D: 0.198459\n",
      "[Epoch 64/200] [Batch 430/938] loss_G: 2.519870, loss_D: 0.230441\n",
      "[Epoch 64/200] [Batch 440/938] loss_G: 2.834604, loss_D: 0.188636\n",
      "[Epoch 64/200] [Batch 450/938] loss_G: 2.668044, loss_D: 0.202020\n",
      "[Epoch 64/200] [Batch 460/938] loss_G: 3.184778, loss_D: 0.180279\n",
      "[Epoch 64/200] [Batch 470/938] loss_G: 2.406134, loss_D: 0.265834\n",
      "[Epoch 64/200] [Batch 480/938] loss_G: 2.636586, loss_D: 0.238429\n",
      "[Epoch 64/200] [Batch 490/938] loss_G: 2.940508, loss_D: 0.156017\n",
      "[Epoch 64/200] [Batch 500/938] loss_G: 2.941313, loss_D: 0.201003\n",
      "[Epoch 64/200] [Batch 510/938] loss_G: 2.514577, loss_D: 0.157191\n",
      "[Epoch 64/200] [Batch 520/938] loss_G: 2.982363, loss_D: 0.203580\n",
      "[Epoch 64/200] [Batch 530/938] loss_G: 2.675727, loss_D: 0.236879\n",
      "[Epoch 64/200] [Batch 540/938] loss_G: 2.515604, loss_D: 0.211683\n",
      "[Epoch 64/200] [Batch 550/938] loss_G: 2.826872, loss_D: 0.271183\n",
      "[Epoch 64/200] [Batch 560/938] loss_G: 2.097368, loss_D: 0.360341\n",
      "[Epoch 64/200] [Batch 570/938] loss_G: 2.770737, loss_D: 0.169270\n",
      "[Epoch 64/200] [Batch 580/938] loss_G: 2.509534, loss_D: 0.200911\n",
      "[Epoch 64/200] [Batch 590/938] loss_G: 2.829953, loss_D: 0.227524\n",
      "[Epoch 64/200] [Batch 600/938] loss_G: 2.495609, loss_D: 0.175779\n",
      "[Epoch 64/200] [Batch 610/938] loss_G: 2.606842, loss_D: 0.223763\n",
      "[Epoch 64/200] [Batch 620/938] loss_G: 2.488270, loss_D: 0.271757\n",
      "[Epoch 64/200] [Batch 630/938] loss_G: 2.737896, loss_D: 0.234708\n",
      "[Epoch 64/200] [Batch 640/938] loss_G: 3.156902, loss_D: 0.136195\n",
      "[Epoch 64/200] [Batch 650/938] loss_G: 3.373421, loss_D: 0.120880\n",
      "[Epoch 64/200] [Batch 660/938] loss_G: 2.790876, loss_D: 0.203350\n",
      "[Epoch 64/200] [Batch 670/938] loss_G: 2.570433, loss_D: 0.284825\n",
      "[Epoch 64/200] [Batch 680/938] loss_G: 2.757980, loss_D: 0.190082\n",
      "[Epoch 64/200] [Batch 690/938] loss_G: 2.764732, loss_D: 0.205884\n",
      "[Epoch 64/200] [Batch 700/938] loss_G: 2.510363, loss_D: 0.329190\n",
      "[Epoch 64/200] [Batch 710/938] loss_G: 3.045889, loss_D: 0.170174\n",
      "[Epoch 64/200] [Batch 720/938] loss_G: 2.662651, loss_D: 0.203907\n",
      "[Epoch 64/200] [Batch 730/938] loss_G: 3.000856, loss_D: 0.233553\n",
      "[Epoch 64/200] [Batch 740/938] loss_G: 2.414397, loss_D: 0.221095\n",
      "[Epoch 64/200] [Batch 750/938] loss_G: 2.541224, loss_D: 0.305449\n",
      "[Epoch 64/200] [Batch 760/938] loss_G: 2.902515, loss_D: 0.191148\n",
      "[Epoch 64/200] [Batch 770/938] loss_G: 2.390488, loss_D: 0.291473\n",
      "[Epoch 64/200] [Batch 780/938] loss_G: 2.191320, loss_D: 0.321388\n",
      "[Epoch 64/200] [Batch 790/938] loss_G: 3.191777, loss_D: 0.226461\n",
      "[Epoch 64/200] [Batch 800/938] loss_G: 3.063798, loss_D: 0.214681\n",
      "[Epoch 64/200] [Batch 810/938] loss_G: 2.811683, loss_D: 0.222060\n",
      "[Epoch 64/200] [Batch 820/938] loss_G: 3.079515, loss_D: 0.190212\n",
      "[Epoch 64/200] [Batch 830/938] loss_G: 2.372205, loss_D: 0.242968\n",
      "[Epoch 64/200] [Batch 840/938] loss_G: 2.367502, loss_D: 0.193809\n",
      "[Epoch 64/200] [Batch 850/938] loss_G: 2.486789, loss_D: 0.285699\n",
      "[Epoch 64/200] [Batch 860/938] loss_G: 2.736874, loss_D: 0.268450\n",
      "[Epoch 64/200] [Batch 870/938] loss_G: 3.046760, loss_D: 0.272881\n",
      "[Epoch 64/200] [Batch 880/938] loss_G: 2.639290, loss_D: 0.214931\n",
      "[Epoch 64/200] [Batch 890/938] loss_G: 2.228731, loss_D: 0.240435\n",
      "[Epoch 64/200] [Batch 900/938] loss_G: 2.733434, loss_D: 0.212218\n",
      "[Epoch 64/200] [Batch 910/938] loss_G: 2.479133, loss_D: 0.228012\n",
      "[Epoch 64/200] [Batch 920/938] loss_G: 2.776402, loss_D: 0.213754\n",
      "[Epoch 64/200] [Batch 930/938] loss_G: 2.712383, loss_D: 0.231505\n",
      "[Epoch 65/200] [Batch 0/938] loss_G: 2.453529, loss_D: 0.314091\n",
      "[Epoch 65/200] [Batch 10/938] loss_G: 2.814742, loss_D: 0.254095\n",
      "[Epoch 65/200] [Batch 20/938] loss_G: 2.612282, loss_D: 0.262099\n",
      "[Epoch 65/200] [Batch 30/938] loss_G: 2.900510, loss_D: 0.284152\n",
      "[Epoch 65/200] [Batch 40/938] loss_G: 2.763330, loss_D: 0.249308\n",
      "[Epoch 65/200] [Batch 50/938] loss_G: 2.064316, loss_D: 0.297884\n",
      "[Epoch 65/200] [Batch 60/938] loss_G: 2.851737, loss_D: 0.206243\n",
      "[Epoch 65/200] [Batch 70/938] loss_G: 2.669761, loss_D: 0.179722\n",
      "[Epoch 65/200] [Batch 80/938] loss_G: 2.651407, loss_D: 0.295462\n",
      "[Epoch 65/200] [Batch 90/938] loss_G: 3.004946, loss_D: 0.193919\n",
      "[Epoch 65/200] [Batch 100/938] loss_G: 2.630819, loss_D: 0.282196\n",
      "[Epoch 65/200] [Batch 110/938] loss_G: 2.720551, loss_D: 0.231598\n",
      "[Epoch 65/200] [Batch 120/938] loss_G: 2.728663, loss_D: 0.240988\n",
      "[Epoch 65/200] [Batch 130/938] loss_G: 2.841315, loss_D: 0.212070\n",
      "[Epoch 65/200] [Batch 140/938] loss_G: 2.819622, loss_D: 0.179506\n",
      "[Epoch 65/200] [Batch 150/938] loss_G: 2.958201, loss_D: 0.245835\n",
      "[Epoch 65/200] [Batch 160/938] loss_G: 2.640728, loss_D: 0.224566\n",
      "[Epoch 65/200] [Batch 170/938] loss_G: 2.598175, loss_D: 0.209403\n",
      "[Epoch 65/200] [Batch 180/938] loss_G: 2.439337, loss_D: 0.313438\n",
      "[Epoch 65/200] [Batch 190/938] loss_G: 2.891189, loss_D: 0.254483\n",
      "[Epoch 65/200] [Batch 200/938] loss_G: 2.561893, loss_D: 0.203368\n",
      "[Epoch 65/200] [Batch 210/938] loss_G: 2.634270, loss_D: 0.199970\n",
      "[Epoch 65/200] [Batch 220/938] loss_G: 3.407095, loss_D: 0.172724\n",
      "[Epoch 65/200] [Batch 230/938] loss_G: 2.320065, loss_D: 0.191461\n",
      "[Epoch 65/200] [Batch 240/938] loss_G: 2.716087, loss_D: 0.148356\n",
      "[Epoch 65/200] [Batch 250/938] loss_G: 2.805815, loss_D: 0.270166\n",
      "[Epoch 65/200] [Batch 260/938] loss_G: 2.666853, loss_D: 0.277708\n",
      "[Epoch 65/200] [Batch 270/938] loss_G: 2.490790, loss_D: 0.236389\n",
      "[Epoch 65/200] [Batch 280/938] loss_G: 2.976656, loss_D: 0.183733\n",
      "[Epoch 65/200] [Batch 290/938] loss_G: 2.646314, loss_D: 0.192742\n",
      "[Epoch 65/200] [Batch 300/938] loss_G: 2.600067, loss_D: 0.278135\n",
      "[Epoch 65/200] [Batch 310/938] loss_G: 2.646416, loss_D: 0.226948\n",
      "[Epoch 65/200] [Batch 320/938] loss_G: 2.729059, loss_D: 0.204787\n",
      "[Epoch 65/200] [Batch 330/938] loss_G: 2.836201, loss_D: 0.223544\n",
      "[Epoch 65/200] [Batch 340/938] loss_G: 2.767995, loss_D: 0.270398\n",
      "[Epoch 65/200] [Batch 350/938] loss_G: 2.651350, loss_D: 0.249650\n",
      "[Epoch 65/200] [Batch 360/938] loss_G: 2.826189, loss_D: 0.251108\n",
      "[Epoch 65/200] [Batch 370/938] loss_G: 2.523998, loss_D: 0.174395\n",
      "[Epoch 65/200] [Batch 380/938] loss_G: 2.837762, loss_D: 0.184380\n",
      "[Epoch 65/200] [Batch 390/938] loss_G: 2.473821, loss_D: 0.217443\n",
      "[Epoch 65/200] [Batch 400/938] loss_G: 2.693492, loss_D: 0.224891\n",
      "[Epoch 65/200] [Batch 410/938] loss_G: 2.833671, loss_D: 0.261696\n",
      "[Epoch 65/200] [Batch 420/938] loss_G: 2.621263, loss_D: 0.257368\n",
      "[Epoch 65/200] [Batch 430/938] loss_G: 2.957373, loss_D: 0.171176\n",
      "[Epoch 65/200] [Batch 440/938] loss_G: 2.969279, loss_D: 0.195654\n",
      "[Epoch 65/200] [Batch 450/938] loss_G: 2.810748, loss_D: 0.193475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 65/200] [Batch 460/938] loss_G: 2.694682, loss_D: 0.198862\n",
      "[Epoch 65/200] [Batch 470/938] loss_G: 2.785774, loss_D: 0.180527\n",
      "[Epoch 65/200] [Batch 480/938] loss_G: 2.787506, loss_D: 0.197484\n",
      "[Epoch 65/200] [Batch 490/938] loss_G: 2.799929, loss_D: 0.222413\n",
      "[Epoch 65/200] [Batch 500/938] loss_G: 2.891307, loss_D: 0.263296\n",
      "[Epoch 65/200] [Batch 510/938] loss_G: 3.078645, loss_D: 0.240962\n",
      "[Epoch 65/200] [Batch 520/938] loss_G: 2.848129, loss_D: 0.201193\n",
      "[Epoch 65/200] [Batch 530/938] loss_G: 3.144751, loss_D: 0.272321\n",
      "[Epoch 65/200] [Batch 540/938] loss_G: 2.602914, loss_D: 0.210339\n",
      "[Epoch 65/200] [Batch 550/938] loss_G: 2.761877, loss_D: 0.152518\n",
      "[Epoch 65/200] [Batch 560/938] loss_G: 2.916375, loss_D: 0.254228\n",
      "[Epoch 65/200] [Batch 570/938] loss_G: 2.409410, loss_D: 0.253144\n",
      "[Epoch 65/200] [Batch 580/938] loss_G: 2.918925, loss_D: 0.183677\n",
      "[Epoch 65/200] [Batch 590/938] loss_G: 2.454074, loss_D: 0.275141\n",
      "[Epoch 65/200] [Batch 600/938] loss_G: 2.842490, loss_D: 0.290263\n",
      "[Epoch 65/200] [Batch 610/938] loss_G: 2.798020, loss_D: 0.296964\n",
      "[Epoch 65/200] [Batch 620/938] loss_G: 2.775895, loss_D: 0.265110\n",
      "[Epoch 65/200] [Batch 630/938] loss_G: 2.849965, loss_D: 0.213954\n",
      "[Epoch 65/200] [Batch 640/938] loss_G: 2.482148, loss_D: 0.255586\n",
      "[Epoch 65/200] [Batch 650/938] loss_G: 2.998676, loss_D: 0.173901\n",
      "[Epoch 65/200] [Batch 660/938] loss_G: 2.535687, loss_D: 0.253016\n",
      "[Epoch 65/200] [Batch 670/938] loss_G: 3.167952, loss_D: 0.219988\n",
      "[Epoch 65/200] [Batch 680/938] loss_G: 2.976002, loss_D: 0.248460\n",
      "[Epoch 65/200] [Batch 690/938] loss_G: 2.869754, loss_D: 0.289517\n",
      "[Epoch 65/200] [Batch 700/938] loss_G: 2.679752, loss_D: 0.285301\n",
      "[Epoch 65/200] [Batch 710/938] loss_G: 2.314835, loss_D: 0.343015\n",
      "[Epoch 65/200] [Batch 720/938] loss_G: 2.552628, loss_D: 0.300847\n",
      "[Epoch 65/200] [Batch 730/938] loss_G: 2.810084, loss_D: 0.187598\n",
      "[Epoch 65/200] [Batch 740/938] loss_G: 2.437224, loss_D: 0.311116\n",
      "[Epoch 65/200] [Batch 750/938] loss_G: 2.583343, loss_D: 0.254086\n",
      "[Epoch 65/200] [Batch 760/938] loss_G: 2.449975, loss_D: 0.248267\n",
      "[Epoch 65/200] [Batch 770/938] loss_G: 2.591129, loss_D: 0.189967\n",
      "[Epoch 65/200] [Batch 780/938] loss_G: 2.464993, loss_D: 0.258594\n",
      "[Epoch 65/200] [Batch 790/938] loss_G: 3.140977, loss_D: 0.265556\n",
      "[Epoch 65/200] [Batch 800/938] loss_G: 2.824409, loss_D: 0.230296\n",
      "[Epoch 65/200] [Batch 810/938] loss_G: 2.729731, loss_D: 0.246340\n",
      "[Epoch 65/200] [Batch 820/938] loss_G: 2.801116, loss_D: 0.234676\n",
      "[Epoch 65/200] [Batch 830/938] loss_G: 2.786223, loss_D: 0.174321\n",
      "[Epoch 65/200] [Batch 840/938] loss_G: 2.973920, loss_D: 0.199207\n",
      "[Epoch 65/200] [Batch 850/938] loss_G: 2.494790, loss_D: 0.236630\n",
      "[Epoch 65/200] [Batch 860/938] loss_G: 2.565974, loss_D: 0.234120\n",
      "[Epoch 65/200] [Batch 870/938] loss_G: 2.387055, loss_D: 0.310808\n",
      "[Epoch 65/200] [Batch 880/938] loss_G: 2.532902, loss_D: 0.228520\n",
      "[Epoch 65/200] [Batch 890/938] loss_G: 2.834987, loss_D: 0.237348\n",
      "[Epoch 65/200] [Batch 900/938] loss_G: 2.654513, loss_D: 0.196051\n",
      "[Epoch 65/200] [Batch 910/938] loss_G: 2.878155, loss_D: 0.258355\n",
      "[Epoch 65/200] [Batch 920/938] loss_G: 2.432913, loss_D: 0.242006\n",
      "[Epoch 65/200] [Batch 930/938] loss_G: 2.492090, loss_D: 0.196291\n",
      "[Epoch 66/200] [Batch 0/938] loss_G: 2.707636, loss_D: 0.298863\n",
      "[Epoch 66/200] [Batch 10/938] loss_G: 2.669106, loss_D: 0.217878\n",
      "[Epoch 66/200] [Batch 20/938] loss_G: 2.640141, loss_D: 0.281214\n",
      "[Epoch 66/200] [Batch 30/938] loss_G: 2.453181, loss_D: 0.244885\n",
      "[Epoch 66/200] [Batch 40/938] loss_G: 2.691115, loss_D: 0.179599\n",
      "[Epoch 66/200] [Batch 50/938] loss_G: 2.971722, loss_D: 0.192296\n",
      "[Epoch 66/200] [Batch 60/938] loss_G: 2.620838, loss_D: 0.261733\n",
      "[Epoch 66/200] [Batch 70/938] loss_G: 2.797099, loss_D: 0.176518\n",
      "[Epoch 66/200] [Batch 80/938] loss_G: 2.535321, loss_D: 0.271125\n",
      "[Epoch 66/200] [Batch 90/938] loss_G: 2.793459, loss_D: 0.225378\n",
      "[Epoch 66/200] [Batch 100/938] loss_G: 2.790464, loss_D: 0.211895\n",
      "[Epoch 66/200] [Batch 110/938] loss_G: 2.935331, loss_D: 0.222933\n",
      "[Epoch 66/200] [Batch 120/938] loss_G: 2.438805, loss_D: 0.224572\n",
      "[Epoch 66/200] [Batch 130/938] loss_G: 2.636515, loss_D: 0.158218\n",
      "[Epoch 66/200] [Batch 140/938] loss_G: 2.850603, loss_D: 0.134091\n",
      "[Epoch 66/200] [Batch 150/938] loss_G: 2.843379, loss_D: 0.176739\n",
      "[Epoch 66/200] [Batch 160/938] loss_G: 2.472391, loss_D: 0.248622\n",
      "[Epoch 66/200] [Batch 170/938] loss_G: 2.828069, loss_D: 0.201615\n",
      "[Epoch 66/200] [Batch 180/938] loss_G: 2.539562, loss_D: 0.172882\n",
      "[Epoch 66/200] [Batch 190/938] loss_G: 2.656825, loss_D: 0.232161\n",
      "[Epoch 66/200] [Batch 200/938] loss_G: 3.098752, loss_D: 0.139310\n",
      "[Epoch 66/200] [Batch 210/938] loss_G: 2.675694, loss_D: 0.203508\n",
      "[Epoch 66/200] [Batch 220/938] loss_G: 2.757809, loss_D: 0.230808\n",
      "[Epoch 66/200] [Batch 230/938] loss_G: 3.156406, loss_D: 0.216009\n",
      "[Epoch 66/200] [Batch 240/938] loss_G: 2.963059, loss_D: 0.244997\n",
      "[Epoch 66/200] [Batch 250/938] loss_G: 2.941391, loss_D: 0.174302\n",
      "[Epoch 66/200] [Batch 260/938] loss_G: 2.442280, loss_D: 0.176468\n",
      "[Epoch 66/200] [Batch 270/938] loss_G: 3.031541, loss_D: 0.191249\n",
      "[Epoch 66/200] [Batch 280/938] loss_G: 2.853400, loss_D: 0.253919\n",
      "[Epoch 66/200] [Batch 290/938] loss_G: 2.898971, loss_D: 0.243475\n",
      "[Epoch 66/200] [Batch 300/938] loss_G: 2.581407, loss_D: 0.253404\n",
      "[Epoch 66/200] [Batch 310/938] loss_G: 3.093791, loss_D: 0.197052\n",
      "[Epoch 66/200] [Batch 320/938] loss_G: 2.882201, loss_D: 0.158166\n",
      "[Epoch 66/200] [Batch 330/938] loss_G: 2.989385, loss_D: 0.230095\n",
      "[Epoch 66/200] [Batch 340/938] loss_G: 2.520033, loss_D: 0.296920\n",
      "[Epoch 66/200] [Batch 350/938] loss_G: 2.620625, loss_D: 0.203211\n",
      "[Epoch 66/200] [Batch 360/938] loss_G: 2.330844, loss_D: 0.166018\n",
      "[Epoch 66/200] [Batch 370/938] loss_G: 3.176230, loss_D: 0.313704\n",
      "[Epoch 66/200] [Batch 380/938] loss_G: 2.399554, loss_D: 0.235115\n",
      "[Epoch 66/200] [Batch 390/938] loss_G: 2.623013, loss_D: 0.230487\n",
      "[Epoch 66/200] [Batch 400/938] loss_G: 2.852111, loss_D: 0.198332\n",
      "[Epoch 66/200] [Batch 410/938] loss_G: 2.785424, loss_D: 0.232021\n",
      "[Epoch 66/200] [Batch 420/938] loss_G: 2.511174, loss_D: 0.296050\n",
      "[Epoch 66/200] [Batch 430/938] loss_G: 2.516732, loss_D: 0.283165\n",
      "[Epoch 66/200] [Batch 440/938] loss_G: 2.411827, loss_D: 0.298398\n",
      "[Epoch 66/200] [Batch 450/938] loss_G: 2.721257, loss_D: 0.192557\n",
      "[Epoch 66/200] [Batch 460/938] loss_G: 2.315234, loss_D: 0.272653\n",
      "[Epoch 66/200] [Batch 470/938] loss_G: 3.085675, loss_D: 0.184646\n",
      "[Epoch 66/200] [Batch 480/938] loss_G: 2.703565, loss_D: 0.215965\n",
      "[Epoch 66/200] [Batch 490/938] loss_G: 3.042966, loss_D: 0.226002\n",
      "[Epoch 66/200] [Batch 500/938] loss_G: 2.564996, loss_D: 0.132592\n",
      "[Epoch 66/200] [Batch 510/938] loss_G: 2.985545, loss_D: 0.250540\n",
      "[Epoch 66/200] [Batch 520/938] loss_G: 2.566651, loss_D: 0.234508\n",
      "[Epoch 66/200] [Batch 530/938] loss_G: 2.780665, loss_D: 0.177883\n",
      "[Epoch 66/200] [Batch 540/938] loss_G: 2.761349, loss_D: 0.239989\n",
      "[Epoch 66/200] [Batch 550/938] loss_G: 2.703511, loss_D: 0.255564\n",
      "[Epoch 66/200] [Batch 560/938] loss_G: 2.832781, loss_D: 0.205693\n",
      "[Epoch 66/200] [Batch 570/938] loss_G: 2.903677, loss_D: 0.226501\n",
      "[Epoch 66/200] [Batch 580/938] loss_G: 2.508634, loss_D: 0.200497\n",
      "[Epoch 66/200] [Batch 590/938] loss_G: 3.135207, loss_D: 0.259328\n",
      "[Epoch 66/200] [Batch 600/938] loss_G: 2.697607, loss_D: 0.200186\n",
      "[Epoch 66/200] [Batch 610/938] loss_G: 3.060627, loss_D: 0.223190\n",
      "[Epoch 66/200] [Batch 620/938] loss_G: 2.717696, loss_D: 0.208974\n",
      "[Epoch 66/200] [Batch 630/938] loss_G: 3.223693, loss_D: 0.104006\n",
      "[Epoch 66/200] [Batch 640/938] loss_G: 3.163479, loss_D: 0.129515\n",
      "[Epoch 66/200] [Batch 650/938] loss_G: 3.228979, loss_D: 0.305500\n",
      "[Epoch 66/200] [Batch 660/938] loss_G: 3.099622, loss_D: 0.161754\n",
      "[Epoch 66/200] [Batch 670/938] loss_G: 3.263507, loss_D: 0.180453\n",
      "[Epoch 66/200] [Batch 680/938] loss_G: 2.671606, loss_D: 0.209537\n",
      "[Epoch 66/200] [Batch 690/938] loss_G: 3.141061, loss_D: 0.189647\n",
      "[Epoch 66/200] [Batch 700/938] loss_G: 2.949264, loss_D: 0.200044\n",
      "[Epoch 66/200] [Batch 710/938] loss_G: 2.829897, loss_D: 0.174482\n",
      "[Epoch 66/200] [Batch 720/938] loss_G: 2.836839, loss_D: 0.130864\n",
      "[Epoch 66/200] [Batch 730/938] loss_G: 2.819664, loss_D: 0.263857\n",
      "[Epoch 66/200] [Batch 740/938] loss_G: 2.605018, loss_D: 0.203801\n",
      "[Epoch 66/200] [Batch 750/938] loss_G: 3.078995, loss_D: 0.297608\n",
      "[Epoch 66/200] [Batch 760/938] loss_G: 2.548199, loss_D: 0.285225\n",
      "[Epoch 66/200] [Batch 770/938] loss_G: 2.989608, loss_D: 0.217568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 66/200] [Batch 780/938] loss_G: 2.592616, loss_D: 0.274965\n",
      "[Epoch 66/200] [Batch 790/938] loss_G: 2.697010, loss_D: 0.350137\n",
      "[Epoch 66/200] [Batch 800/938] loss_G: 2.763983, loss_D: 0.225228\n",
      "[Epoch 66/200] [Batch 810/938] loss_G: 3.060524, loss_D: 0.225298\n",
      "[Epoch 66/200] [Batch 820/938] loss_G: 2.661406, loss_D: 0.226678\n",
      "[Epoch 66/200] [Batch 830/938] loss_G: 2.704523, loss_D: 0.232638\n",
      "[Epoch 66/200] [Batch 840/938] loss_G: 2.885865, loss_D: 0.212853\n",
      "[Epoch 66/200] [Batch 850/938] loss_G: 2.588655, loss_D: 0.338271\n",
      "[Epoch 66/200] [Batch 860/938] loss_G: 2.489531, loss_D: 0.216246\n",
      "[Epoch 66/200] [Batch 870/938] loss_G: 2.850629, loss_D: 0.233878\n",
      "[Epoch 66/200] [Batch 880/938] loss_G: 2.794483, loss_D: 0.281907\n",
      "[Epoch 66/200] [Batch 890/938] loss_G: 2.641812, loss_D: 0.289064\n",
      "[Epoch 66/200] [Batch 900/938] loss_G: 2.606600, loss_D: 0.228258\n",
      "[Epoch 66/200] [Batch 910/938] loss_G: 2.672105, loss_D: 0.265953\n",
      "[Epoch 66/200] [Batch 920/938] loss_G: 2.696033, loss_D: 0.227392\n",
      "[Epoch 66/200] [Batch 930/938] loss_G: 3.000320, loss_D: 0.231926\n",
      "[Epoch 67/200] [Batch 0/938] loss_G: 3.052660, loss_D: 0.171700\n",
      "[Epoch 67/200] [Batch 10/938] loss_G: 2.807735, loss_D: 0.231509\n",
      "[Epoch 67/200] [Batch 20/938] loss_G: 2.629808, loss_D: 0.197688\n",
      "[Epoch 67/200] [Batch 30/938] loss_G: 2.705476, loss_D: 0.298032\n",
      "[Epoch 67/200] [Batch 40/938] loss_G: 2.652777, loss_D: 0.173420\n",
      "[Epoch 67/200] [Batch 50/938] loss_G: 2.832312, loss_D: 0.213649\n",
      "[Epoch 67/200] [Batch 60/938] loss_G: 2.704249, loss_D: 0.216242\n",
      "[Epoch 67/200] [Batch 70/938] loss_G: 2.661809, loss_D: 0.265547\n",
      "[Epoch 67/200] [Batch 80/938] loss_G: 3.103521, loss_D: 0.206731\n",
      "[Epoch 67/200] [Batch 90/938] loss_G: 2.736454, loss_D: 0.248808\n",
      "[Epoch 67/200] [Batch 100/938] loss_G: 2.677664, loss_D: 0.260025\n",
      "[Epoch 67/200] [Batch 110/938] loss_G: 2.944865, loss_D: 0.209323\n",
      "[Epoch 67/200] [Batch 120/938] loss_G: 2.672427, loss_D: 0.298708\n",
      "[Epoch 67/200] [Batch 130/938] loss_G: 2.445475, loss_D: 0.205070\n",
      "[Epoch 67/200] [Batch 140/938] loss_G: 2.597028, loss_D: 0.158704\n",
      "[Epoch 67/200] [Batch 150/938] loss_G: 2.639786, loss_D: 0.199820\n",
      "[Epoch 67/200] [Batch 160/938] loss_G: 2.404640, loss_D: 0.231024\n",
      "[Epoch 67/200] [Batch 170/938] loss_G: 2.784835, loss_D: 0.173653\n",
      "[Epoch 67/200] [Batch 180/938] loss_G: 2.566171, loss_D: 0.311642\n",
      "[Epoch 67/200] [Batch 190/938] loss_G: 2.919291, loss_D: 0.263742\n",
      "[Epoch 67/200] [Batch 200/938] loss_G: 2.993654, loss_D: 0.161899\n",
      "[Epoch 67/200] [Batch 210/938] loss_G: 2.573817, loss_D: 0.156654\n",
      "[Epoch 67/200] [Batch 220/938] loss_G: 2.646629, loss_D: 0.250444\n",
      "[Epoch 67/200] [Batch 230/938] loss_G: 2.859052, loss_D: 0.208951\n",
      "[Epoch 67/200] [Batch 240/938] loss_G: 2.628897, loss_D: 0.264901\n",
      "[Epoch 67/200] [Batch 250/938] loss_G: 3.020928, loss_D: 0.123533\n",
      "[Epoch 67/200] [Batch 260/938] loss_G: 2.665518, loss_D: 0.202953\n",
      "[Epoch 67/200] [Batch 270/938] loss_G: 2.695013, loss_D: 0.194483\n",
      "[Epoch 67/200] [Batch 280/938] loss_G: 2.594969, loss_D: 0.215864\n",
      "[Epoch 67/200] [Batch 290/938] loss_G: 2.951798, loss_D: 0.159218\n",
      "[Epoch 67/200] [Batch 300/938] loss_G: 2.813262, loss_D: 0.170419\n",
      "[Epoch 67/200] [Batch 310/938] loss_G: 2.405879, loss_D: 0.306209\n",
      "[Epoch 67/200] [Batch 320/938] loss_G: 2.824982, loss_D: 0.202385\n",
      "[Epoch 67/200] [Batch 330/938] loss_G: 2.882514, loss_D: 0.249787\n",
      "[Epoch 67/200] [Batch 340/938] loss_G: 3.111221, loss_D: 0.210703\n",
      "[Epoch 67/200] [Batch 350/938] loss_G: 2.829142, loss_D: 0.200297\n",
      "[Epoch 67/200] [Batch 360/938] loss_G: 2.968029, loss_D: 0.147983\n",
      "[Epoch 67/200] [Batch 370/938] loss_G: 3.113689, loss_D: 0.170632\n",
      "[Epoch 67/200] [Batch 380/938] loss_G: 2.928377, loss_D: 0.143547\n",
      "[Epoch 67/200] [Batch 390/938] loss_G: 2.748726, loss_D: 0.274197\n",
      "[Epoch 67/200] [Batch 400/938] loss_G: 2.789595, loss_D: 0.233380\n",
      "[Epoch 67/200] [Batch 410/938] loss_G: 2.679091, loss_D: 0.191590\n",
      "[Epoch 67/200] [Batch 420/938] loss_G: 2.766989, loss_D: 0.179050\n",
      "[Epoch 67/200] [Batch 430/938] loss_G: 2.546568, loss_D: 0.255538\n",
      "[Epoch 67/200] [Batch 440/938] loss_G: 2.800272, loss_D: 0.190066\n",
      "[Epoch 67/200] [Batch 450/938] loss_G: 2.738963, loss_D: 0.146558\n",
      "[Epoch 67/200] [Batch 460/938] loss_G: 2.668597, loss_D: 0.145338\n",
      "[Epoch 67/200] [Batch 470/938] loss_G: 3.017417, loss_D: 0.173897\n",
      "[Epoch 67/200] [Batch 480/938] loss_G: 2.759392, loss_D: 0.273157\n",
      "[Epoch 67/200] [Batch 490/938] loss_G: 2.976737, loss_D: 0.230475\n",
      "[Epoch 67/200] [Batch 500/938] loss_G: 2.636322, loss_D: 0.279538\n",
      "[Epoch 67/200] [Batch 510/938] loss_G: 3.000373, loss_D: 0.287440\n",
      "[Epoch 67/200] [Batch 520/938] loss_G: 3.100980, loss_D: 0.145134\n",
      "[Epoch 67/200] [Batch 530/938] loss_G: 2.796243, loss_D: 0.172893\n",
      "[Epoch 67/200] [Batch 540/938] loss_G: 2.630580, loss_D: 0.206276\n",
      "[Epoch 67/200] [Batch 550/938] loss_G: 2.794617, loss_D: 0.200691\n",
      "[Epoch 67/200] [Batch 560/938] loss_G: 2.965572, loss_D: 0.129202\n",
      "[Epoch 67/200] [Batch 570/938] loss_G: 2.494699, loss_D: 0.194624\n",
      "[Epoch 67/200] [Batch 580/938] loss_G: 2.736592, loss_D: 0.240404\n",
      "[Epoch 67/200] [Batch 590/938] loss_G: 3.089862, loss_D: 0.212185\n",
      "[Epoch 67/200] [Batch 600/938] loss_G: 2.703436, loss_D: 0.191060\n",
      "[Epoch 67/200] [Batch 610/938] loss_G: 2.948631, loss_D: 0.232486\n",
      "[Epoch 67/200] [Batch 620/938] loss_G: 2.314411, loss_D: 0.210234\n",
      "[Epoch 67/200] [Batch 630/938] loss_G: 3.033095, loss_D: 0.185039\n",
      "[Epoch 67/200] [Batch 640/938] loss_G: 2.634815, loss_D: 0.163974\n",
      "[Epoch 67/200] [Batch 650/938] loss_G: 2.671062, loss_D: 0.263166\n",
      "[Epoch 67/200] [Batch 660/938] loss_G: 2.578844, loss_D: 0.170528\n",
      "[Epoch 67/200] [Batch 670/938] loss_G: 2.715662, loss_D: 0.228836\n",
      "[Epoch 67/200] [Batch 680/938] loss_G: 2.772254, loss_D: 0.214928\n",
      "[Epoch 67/200] [Batch 690/938] loss_G: 2.628705, loss_D: 0.243448\n",
      "[Epoch 67/200] [Batch 700/938] loss_G: 2.594964, loss_D: 0.217460\n",
      "[Epoch 67/200] [Batch 710/938] loss_G: 2.381287, loss_D: 0.217717\n",
      "[Epoch 67/200] [Batch 720/938] loss_G: 3.140863, loss_D: 0.184764\n",
      "[Epoch 67/200] [Batch 730/938] loss_G: 2.687387, loss_D: 0.257557\n",
      "[Epoch 67/200] [Batch 740/938] loss_G: 2.829658, loss_D: 0.177227\n",
      "[Epoch 67/200] [Batch 750/938] loss_G: 2.528458, loss_D: 0.172283\n",
      "[Epoch 67/200] [Batch 760/938] loss_G: 2.530852, loss_D: 0.181225\n",
      "[Epoch 67/200] [Batch 770/938] loss_G: 2.756463, loss_D: 0.297352\n",
      "[Epoch 67/200] [Batch 780/938] loss_G: 2.936770, loss_D: 0.214780\n",
      "[Epoch 67/200] [Batch 790/938] loss_G: 2.625184, loss_D: 0.234420\n",
      "[Epoch 67/200] [Batch 800/938] loss_G: 2.762750, loss_D: 0.224906\n",
      "[Epoch 67/200] [Batch 810/938] loss_G: 2.509811, loss_D: 0.218895\n",
      "[Epoch 67/200] [Batch 820/938] loss_G: 2.701881, loss_D: 0.198974\n",
      "[Epoch 67/200] [Batch 830/938] loss_G: 2.620528, loss_D: 0.215776\n",
      "[Epoch 67/200] [Batch 840/938] loss_G: 3.060949, loss_D: 0.100680\n",
      "[Epoch 67/200] [Batch 850/938] loss_G: 2.524734, loss_D: 0.211102\n",
      "[Epoch 67/200] [Batch 860/938] loss_G: 2.715298, loss_D: 0.185571\n",
      "[Epoch 67/200] [Batch 870/938] loss_G: 2.780241, loss_D: 0.220380\n",
      "[Epoch 67/200] [Batch 880/938] loss_G: 2.948953, loss_D: 0.156601\n",
      "[Epoch 67/200] [Batch 890/938] loss_G: 2.511946, loss_D: 0.122026\n",
      "[Epoch 67/200] [Batch 900/938] loss_G: 2.881896, loss_D: 0.248910\n",
      "[Epoch 67/200] [Batch 910/938] loss_G: 2.345897, loss_D: 0.221174\n",
      "[Epoch 67/200] [Batch 920/938] loss_G: 2.770785, loss_D: 0.189202\n",
      "[Epoch 67/200] [Batch 930/938] loss_G: 3.143131, loss_D: 0.240219\n",
      "[Epoch 68/200] [Batch 0/938] loss_G: 2.352071, loss_D: 0.302607\n",
      "[Epoch 68/200] [Batch 10/938] loss_G: 2.809772, loss_D: 0.209358\n",
      "[Epoch 68/200] [Batch 20/938] loss_G: 2.589397, loss_D: 0.265689\n",
      "[Epoch 68/200] [Batch 30/938] loss_G: 2.674955, loss_D: 0.287930\n",
      "[Epoch 68/200] [Batch 40/938] loss_G: 2.575446, loss_D: 0.200590\n",
      "[Epoch 68/200] [Batch 50/938] loss_G: 2.842854, loss_D: 0.206070\n",
      "[Epoch 68/200] [Batch 60/938] loss_G: 2.428325, loss_D: 0.256176\n",
      "[Epoch 68/200] [Batch 70/938] loss_G: 2.672400, loss_D: 0.239260\n",
      "[Epoch 68/200] [Batch 80/938] loss_G: 2.952843, loss_D: 0.174568\n",
      "[Epoch 68/200] [Batch 90/938] loss_G: 2.995487, loss_D: 0.147038\n",
      "[Epoch 68/200] [Batch 100/938] loss_G: 2.792313, loss_D: 0.287785\n",
      "[Epoch 68/200] [Batch 110/938] loss_G: 2.867357, loss_D: 0.224765\n",
      "[Epoch 68/200] [Batch 120/938] loss_G: 2.682844, loss_D: 0.174202\n",
      "[Epoch 68/200] [Batch 130/938] loss_G: 3.119629, loss_D: 0.138286\n",
      "[Epoch 68/200] [Batch 140/938] loss_G: 2.966675, loss_D: 0.228427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 68/200] [Batch 150/938] loss_G: 2.801205, loss_D: 0.192293\n",
      "[Epoch 68/200] [Batch 160/938] loss_G: 2.918819, loss_D: 0.196571\n",
      "[Epoch 68/200] [Batch 170/938] loss_G: 2.601557, loss_D: 0.306222\n",
      "[Epoch 68/200] [Batch 180/938] loss_G: 2.805593, loss_D: 0.217305\n",
      "[Epoch 68/200] [Batch 190/938] loss_G: 2.766723, loss_D: 0.231067\n",
      "[Epoch 68/200] [Batch 200/938] loss_G: 2.609735, loss_D: 0.225796\n",
      "[Epoch 68/200] [Batch 210/938] loss_G: 3.044036, loss_D: 0.227131\n",
      "[Epoch 68/200] [Batch 220/938] loss_G: 2.701910, loss_D: 0.285482\n",
      "[Epoch 68/200] [Batch 230/938] loss_G: 2.954232, loss_D: 0.176520\n",
      "[Epoch 68/200] [Batch 240/938] loss_G: 3.134701, loss_D: 0.166247\n",
      "[Epoch 68/200] [Batch 250/938] loss_G: 2.952649, loss_D: 0.273377\n",
      "[Epoch 68/200] [Batch 260/938] loss_G: 2.814671, loss_D: 0.212173\n",
      "[Epoch 68/200] [Batch 270/938] loss_G: 2.373791, loss_D: 0.263121\n",
      "[Epoch 68/200] [Batch 280/938] loss_G: 2.568059, loss_D: 0.250517\n",
      "[Epoch 68/200] [Batch 290/938] loss_G: 3.085750, loss_D: 0.250628\n",
      "[Epoch 68/200] [Batch 300/938] loss_G: 2.525299, loss_D: 0.268898\n",
      "[Epoch 68/200] [Batch 310/938] loss_G: 3.011087, loss_D: 0.308438\n",
      "[Epoch 68/200] [Batch 320/938] loss_G: 2.548308, loss_D: 0.172140\n",
      "[Epoch 68/200] [Batch 330/938] loss_G: 2.929024, loss_D: 0.325845\n",
      "[Epoch 68/200] [Batch 340/938] loss_G: 2.814136, loss_D: 0.253335\n",
      "[Epoch 68/200] [Batch 350/938] loss_G: 2.842717, loss_D: 0.262552\n",
      "[Epoch 68/200] [Batch 360/938] loss_G: 2.336778, loss_D: 0.263104\n",
      "[Epoch 68/200] [Batch 370/938] loss_G: 3.197063, loss_D: 0.194681\n",
      "[Epoch 68/200] [Batch 380/938] loss_G: 2.318505, loss_D: 0.276225\n",
      "[Epoch 68/200] [Batch 390/938] loss_G: 2.859730, loss_D: 0.200992\n",
      "[Epoch 68/200] [Batch 400/938] loss_G: 2.476319, loss_D: 0.226632\n",
      "[Epoch 68/200] [Batch 410/938] loss_G: 3.567617, loss_D: 0.251357\n",
      "[Epoch 68/200] [Batch 420/938] loss_G: 2.795094, loss_D: 0.164311\n",
      "[Epoch 68/200] [Batch 430/938] loss_G: 2.471488, loss_D: 0.235071\n",
      "[Epoch 68/200] [Batch 440/938] loss_G: 2.809655, loss_D: 0.271381\n",
      "[Epoch 68/200] [Batch 450/938] loss_G: 2.729113, loss_D: 0.208342\n",
      "[Epoch 68/200] [Batch 460/938] loss_G: 2.593903, loss_D: 0.275668\n",
      "[Epoch 68/200] [Batch 470/938] loss_G: 3.057615, loss_D: 0.181566\n",
      "[Epoch 68/200] [Batch 480/938] loss_G: 2.742994, loss_D: 0.197401\n",
      "[Epoch 68/200] [Batch 490/938] loss_G: 2.756939, loss_D: 0.203853\n",
      "[Epoch 68/200] [Batch 500/938] loss_G: 2.509587, loss_D: 0.147341\n",
      "[Epoch 68/200] [Batch 510/938] loss_G: 2.659696, loss_D: 0.229556\n",
      "[Epoch 68/200] [Batch 520/938] loss_G: 3.045849, loss_D: 0.167452\n",
      "[Epoch 68/200] [Batch 530/938] loss_G: 2.650691, loss_D: 0.219805\n",
      "[Epoch 68/200] [Batch 540/938] loss_G: 3.108810, loss_D: 0.162995\n",
      "[Epoch 68/200] [Batch 550/938] loss_G: 3.422542, loss_D: 0.155968\n",
      "[Epoch 68/200] [Batch 560/938] loss_G: 2.698047, loss_D: 0.201113\n",
      "[Epoch 68/200] [Batch 570/938] loss_G: 3.072208, loss_D: 0.195882\n",
      "[Epoch 68/200] [Batch 580/938] loss_G: 2.613876, loss_D: 0.235726\n",
      "[Epoch 68/200] [Batch 590/938] loss_G: 3.065841, loss_D: 0.249274\n",
      "[Epoch 68/200] [Batch 600/938] loss_G: 2.637606, loss_D: 0.286449\n",
      "[Epoch 68/200] [Batch 610/938] loss_G: 3.019884, loss_D: 0.188173\n",
      "[Epoch 68/200] [Batch 620/938] loss_G: 3.423252, loss_D: 0.189056\n",
      "[Epoch 68/200] [Batch 630/938] loss_G: 3.194864, loss_D: 0.265614\n",
      "[Epoch 68/200] [Batch 640/938] loss_G: 2.790215, loss_D: 0.253842\n",
      "[Epoch 68/200] [Batch 650/938] loss_G: 2.870833, loss_D: 0.145900\n",
      "[Epoch 68/200] [Batch 660/938] loss_G: 2.430067, loss_D: 0.260257\n",
      "[Epoch 68/200] [Batch 670/938] loss_G: 2.781694, loss_D: 0.263016\n",
      "[Epoch 68/200] [Batch 680/938] loss_G: 2.669606, loss_D: 0.284808\n",
      "[Epoch 68/200] [Batch 690/938] loss_G: 3.176061, loss_D: 0.209776\n",
      "[Epoch 68/200] [Batch 700/938] loss_G: 2.884782, loss_D: 0.176839\n",
      "[Epoch 68/200] [Batch 710/938] loss_G: 2.722432, loss_D: 0.191044\n",
      "[Epoch 68/200] [Batch 720/938] loss_G: 2.889971, loss_D: 0.252531\n",
      "[Epoch 68/200] [Batch 730/938] loss_G: 2.795973, loss_D: 0.175072\n",
      "[Epoch 68/200] [Batch 740/938] loss_G: 2.569675, loss_D: 0.195682\n",
      "[Epoch 68/200] [Batch 750/938] loss_G: 2.514509, loss_D: 0.220075\n",
      "[Epoch 68/200] [Batch 760/938] loss_G: 2.917463, loss_D: 0.203010\n",
      "[Epoch 68/200] [Batch 770/938] loss_G: 2.619304, loss_D: 0.253856\n",
      "[Epoch 68/200] [Batch 780/938] loss_G: 2.711058, loss_D: 0.227348\n",
      "[Epoch 68/200] [Batch 790/938] loss_G: 2.711432, loss_D: 0.203164\n",
      "[Epoch 68/200] [Batch 800/938] loss_G: 2.578390, loss_D: 0.314493\n",
      "[Epoch 68/200] [Batch 810/938] loss_G: 2.705585, loss_D: 0.297552\n",
      "[Epoch 68/200] [Batch 820/938] loss_G: 2.919627, loss_D: 0.219670\n",
      "[Epoch 68/200] [Batch 830/938] loss_G: 2.388196, loss_D: 0.252767\n",
      "[Epoch 68/200] [Batch 840/938] loss_G: 2.482148, loss_D: 0.284439\n",
      "[Epoch 68/200] [Batch 850/938] loss_G: 2.670076, loss_D: 0.264957\n",
      "[Epoch 68/200] [Batch 860/938] loss_G: 2.831437, loss_D: 0.320238\n",
      "[Epoch 68/200] [Batch 870/938] loss_G: 2.732528, loss_D: 0.259265\n",
      "[Epoch 68/200] [Batch 880/938] loss_G: 2.704884, loss_D: 0.186316\n",
      "[Epoch 68/200] [Batch 890/938] loss_G: 2.518585, loss_D: 0.225334\n",
      "[Epoch 68/200] [Batch 900/938] loss_G: 2.389589, loss_D: 0.255099\n",
      "[Epoch 68/200] [Batch 910/938] loss_G: 2.690526, loss_D: 0.193595\n",
      "[Epoch 68/200] [Batch 920/938] loss_G: 2.396556, loss_D: 0.179844\n",
      "[Epoch 68/200] [Batch 930/938] loss_G: 2.783842, loss_D: 0.221858\n",
      "[Epoch 69/200] [Batch 0/938] loss_G: 2.809537, loss_D: 0.296144\n",
      "[Epoch 69/200] [Batch 10/938] loss_G: 2.543876, loss_D: 0.253807\n",
      "[Epoch 69/200] [Batch 20/938] loss_G: 2.575028, loss_D: 0.290812\n",
      "[Epoch 69/200] [Batch 30/938] loss_G: 2.815252, loss_D: 0.190026\n",
      "[Epoch 69/200] [Batch 40/938] loss_G: 2.967881, loss_D: 0.267925\n",
      "[Epoch 69/200] [Batch 50/938] loss_G: 2.661589, loss_D: 0.258677\n",
      "[Epoch 69/200] [Batch 60/938] loss_G: 3.104123, loss_D: 0.194263\n",
      "[Epoch 69/200] [Batch 70/938] loss_G: 2.882648, loss_D: 0.179934\n",
      "[Epoch 69/200] [Batch 80/938] loss_G: 2.803825, loss_D: 0.302561\n",
      "[Epoch 69/200] [Batch 90/938] loss_G: 2.601670, loss_D: 0.167728\n",
      "[Epoch 69/200] [Batch 100/938] loss_G: 2.618920, loss_D: 0.245657\n",
      "[Epoch 69/200] [Batch 110/938] loss_G: 2.958309, loss_D: 0.240618\n",
      "[Epoch 69/200] [Batch 120/938] loss_G: 2.565527, loss_D: 0.276758\n",
      "[Epoch 69/200] [Batch 130/938] loss_G: 2.838567, loss_D: 0.163940\n",
      "[Epoch 69/200] [Batch 140/938] loss_G: 2.657753, loss_D: 0.214462\n",
      "[Epoch 69/200] [Batch 150/938] loss_G: 3.088610, loss_D: 0.151015\n",
      "[Epoch 69/200] [Batch 160/938] loss_G: 2.512003, loss_D: 0.314320\n",
      "[Epoch 69/200] [Batch 170/938] loss_G: 2.970031, loss_D: 0.325991\n",
      "[Epoch 69/200] [Batch 180/938] loss_G: 2.460645, loss_D: 0.244083\n",
      "[Epoch 69/200] [Batch 190/938] loss_G: 3.113427, loss_D: 0.202798\n",
      "[Epoch 69/200] [Batch 200/938] loss_G: 2.513047, loss_D: 0.236496\n",
      "[Epoch 69/200] [Batch 210/938] loss_G: 2.703403, loss_D: 0.232423\n",
      "[Epoch 69/200] [Batch 220/938] loss_G: 2.661541, loss_D: 0.217728\n",
      "[Epoch 69/200] [Batch 230/938] loss_G: 2.736889, loss_D: 0.228407\n",
      "[Epoch 69/200] [Batch 240/938] loss_G: 2.766506, loss_D: 0.200570\n",
      "[Epoch 69/200] [Batch 250/938] loss_G: 2.553815, loss_D: 0.293599\n",
      "[Epoch 69/200] [Batch 260/938] loss_G: 2.970789, loss_D: 0.252276\n",
      "[Epoch 69/200] [Batch 270/938] loss_G: 2.977269, loss_D: 0.173426\n",
      "[Epoch 69/200] [Batch 280/938] loss_G: 2.772109, loss_D: 0.200859\n",
      "[Epoch 69/200] [Batch 290/938] loss_G: 3.363341, loss_D: 0.194597\n",
      "[Epoch 69/200] [Batch 300/938] loss_G: 2.674957, loss_D: 0.280527\n",
      "[Epoch 69/200] [Batch 310/938] loss_G: 2.576764, loss_D: 0.269758\n",
      "[Epoch 69/200] [Batch 320/938] loss_G: 2.605408, loss_D: 0.235830\n",
      "[Epoch 69/200] [Batch 330/938] loss_G: 2.938483, loss_D: 0.237285\n",
      "[Epoch 69/200] [Batch 340/938] loss_G: 2.773713, loss_D: 0.170860\n",
      "[Epoch 69/200] [Batch 350/938] loss_G: 2.865063, loss_D: 0.252013\n",
      "[Epoch 69/200] [Batch 360/938] loss_G: 2.700692, loss_D: 0.235641\n",
      "[Epoch 69/200] [Batch 370/938] loss_G: 2.710149, loss_D: 0.261935\n",
      "[Epoch 69/200] [Batch 380/938] loss_G: 2.759007, loss_D: 0.139056\n",
      "[Epoch 69/200] [Batch 390/938] loss_G: 3.034557, loss_D: 0.191500\n",
      "[Epoch 69/200] [Batch 400/938] loss_G: 2.727030, loss_D: 0.224948\n",
      "[Epoch 69/200] [Batch 410/938] loss_G: 2.578869, loss_D: 0.164742\n",
      "[Epoch 69/200] [Batch 420/938] loss_G: 2.868356, loss_D: 0.204689\n",
      "[Epoch 69/200] [Batch 430/938] loss_G: 3.133208, loss_D: 0.147639\n",
      "[Epoch 69/200] [Batch 440/938] loss_G: 2.505243, loss_D: 0.176634\n",
      "[Epoch 69/200] [Batch 450/938] loss_G: 2.584125, loss_D: 0.342789\n",
      "[Epoch 69/200] [Batch 460/938] loss_G: 2.662647, loss_D: 0.201350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 69/200] [Batch 470/938] loss_G: 2.863276, loss_D: 0.220931\n",
      "[Epoch 69/200] [Batch 480/938] loss_G: 2.587205, loss_D: 0.256137\n",
      "[Epoch 69/200] [Batch 490/938] loss_G: 2.996888, loss_D: 0.226247\n",
      "[Epoch 69/200] [Batch 500/938] loss_G: 2.635106, loss_D: 0.264553\n",
      "[Epoch 69/200] [Batch 510/938] loss_G: 2.667656, loss_D: 0.247495\n",
      "[Epoch 69/200] [Batch 520/938] loss_G: 2.945670, loss_D: 0.164638\n",
      "[Epoch 69/200] [Batch 530/938] loss_G: 2.720878, loss_D: 0.220523\n",
      "[Epoch 69/200] [Batch 540/938] loss_G: 2.740749, loss_D: 0.311763\n",
      "[Epoch 69/200] [Batch 550/938] loss_G: 2.506084, loss_D: 0.198785\n",
      "[Epoch 69/200] [Batch 560/938] loss_G: 2.764254, loss_D: 0.229953\n",
      "[Epoch 69/200] [Batch 570/938] loss_G: 2.831591, loss_D: 0.235372\n",
      "[Epoch 69/200] [Batch 580/938] loss_G: 2.561291, loss_D: 0.318274\n",
      "[Epoch 69/200] [Batch 590/938] loss_G: 2.707191, loss_D: 0.196614\n",
      "[Epoch 69/200] [Batch 600/938] loss_G: 2.666529, loss_D: 0.250826\n",
      "[Epoch 69/200] [Batch 610/938] loss_G: 2.414504, loss_D: 0.191107\n",
      "[Epoch 69/200] [Batch 620/938] loss_G: 2.625153, loss_D: 0.190765\n",
      "[Epoch 69/200] [Batch 630/938] loss_G: 2.612855, loss_D: 0.182584\n",
      "[Epoch 69/200] [Batch 640/938] loss_G: 2.607450, loss_D: 0.233950\n",
      "[Epoch 69/200] [Batch 650/938] loss_G: 2.533511, loss_D: 0.257274\n",
      "[Epoch 69/200] [Batch 660/938] loss_G: 2.473709, loss_D: 0.255064\n",
      "[Epoch 69/200] [Batch 670/938] loss_G: 2.475439, loss_D: 0.311410\n",
      "[Epoch 69/200] [Batch 680/938] loss_G: 2.658467, loss_D: 0.176419\n",
      "[Epoch 69/200] [Batch 690/938] loss_G: 3.056172, loss_D: 0.194291\n",
      "[Epoch 69/200] [Batch 700/938] loss_G: 2.685131, loss_D: 0.195667\n",
      "[Epoch 69/200] [Batch 710/938] loss_G: 2.887089, loss_D: 0.320779\n",
      "[Epoch 69/200] [Batch 720/938] loss_G: 2.985795, loss_D: 0.165267\n",
      "[Epoch 69/200] [Batch 730/938] loss_G: 2.643297, loss_D: 0.256590\n",
      "[Epoch 69/200] [Batch 740/938] loss_G: 2.358058, loss_D: 0.210290\n",
      "[Epoch 69/200] [Batch 750/938] loss_G: 2.980349, loss_D: 0.259735\n",
      "[Epoch 69/200] [Batch 760/938] loss_G: 2.818219, loss_D: 0.288909\n",
      "[Epoch 69/200] [Batch 770/938] loss_G: 2.689430, loss_D: 0.272199\n",
      "[Epoch 69/200] [Batch 780/938] loss_G: 2.704637, loss_D: 0.212912\n",
      "[Epoch 69/200] [Batch 790/938] loss_G: 2.849155, loss_D: 0.266226\n",
      "[Epoch 69/200] [Batch 800/938] loss_G: 3.070270, loss_D: 0.191619\n",
      "[Epoch 69/200] [Batch 810/938] loss_G: 2.803452, loss_D: 0.243619\n",
      "[Epoch 69/200] [Batch 820/938] loss_G: 2.722629, loss_D: 0.168110\n",
      "[Epoch 69/200] [Batch 830/938] loss_G: 2.756749, loss_D: 0.203475\n",
      "[Epoch 69/200] [Batch 840/938] loss_G: 2.821512, loss_D: 0.213831\n",
      "[Epoch 69/200] [Batch 850/938] loss_G: 3.000602, loss_D: 0.171365\n",
      "[Epoch 69/200] [Batch 860/938] loss_G: 2.648589, loss_D: 0.284819\n",
      "[Epoch 69/200] [Batch 870/938] loss_G: 2.798333, loss_D: 0.229584\n",
      "[Epoch 69/200] [Batch 880/938] loss_G: 2.619118, loss_D: 0.282198\n",
      "[Epoch 69/200] [Batch 890/938] loss_G: 2.345934, loss_D: 0.224938\n",
      "[Epoch 69/200] [Batch 900/938] loss_G: 3.043473, loss_D: 0.220110\n",
      "[Epoch 69/200] [Batch 910/938] loss_G: 2.271864, loss_D: 0.266110\n",
      "[Epoch 69/200] [Batch 920/938] loss_G: 2.861470, loss_D: 0.197334\n",
      "[Epoch 69/200] [Batch 930/938] loss_G: 2.807416, loss_D: 0.193328\n",
      "[Epoch 70/200] [Batch 0/938] loss_G: 2.948032, loss_D: 0.159156\n",
      "[Epoch 70/200] [Batch 10/938] loss_G: 2.853787, loss_D: 0.182654\n",
      "[Epoch 70/200] [Batch 20/938] loss_G: 2.947401, loss_D: 0.219272\n",
      "[Epoch 70/200] [Batch 30/938] loss_G: 2.518744, loss_D: 0.309842\n",
      "[Epoch 70/200] [Batch 40/938] loss_G: 2.897591, loss_D: 0.226462\n",
      "[Epoch 70/200] [Batch 50/938] loss_G: 2.556605, loss_D: 0.187032\n",
      "[Epoch 70/200] [Batch 60/938] loss_G: 2.899875, loss_D: 0.314895\n",
      "[Epoch 70/200] [Batch 70/938] loss_G: 2.370095, loss_D: 0.249771\n",
      "[Epoch 70/200] [Batch 80/938] loss_G: 3.028606, loss_D: 0.196896\n",
      "[Epoch 70/200] [Batch 90/938] loss_G: 2.910798, loss_D: 0.210095\n",
      "[Epoch 70/200] [Batch 100/938] loss_G: 2.963097, loss_D: 0.159715\n",
      "[Epoch 70/200] [Batch 110/938] loss_G: 2.722935, loss_D: 0.232186\n",
      "[Epoch 70/200] [Batch 120/938] loss_G: 3.014772, loss_D: 0.223211\n",
      "[Epoch 70/200] [Batch 130/938] loss_G: 2.588098, loss_D: 0.235935\n",
      "[Epoch 70/200] [Batch 140/938] loss_G: 2.756757, loss_D: 0.203181\n",
      "[Epoch 70/200] [Batch 150/938] loss_G: 2.826275, loss_D: 0.185378\n",
      "[Epoch 70/200] [Batch 160/938] loss_G: 2.655081, loss_D: 0.228040\n",
      "[Epoch 70/200] [Batch 170/938] loss_G: 3.019244, loss_D: 0.192741\n",
      "[Epoch 70/200] [Batch 180/938] loss_G: 2.895473, loss_D: 0.256528\n",
      "[Epoch 70/200] [Batch 190/938] loss_G: 2.889699, loss_D: 0.218926\n",
      "[Epoch 70/200] [Batch 200/938] loss_G: 2.692795, loss_D: 0.220560\n",
      "[Epoch 70/200] [Batch 210/938] loss_G: 2.747085, loss_D: 0.172251\n",
      "[Epoch 70/200] [Batch 220/938] loss_G: 2.471474, loss_D: 0.237740\n",
      "[Epoch 70/200] [Batch 230/938] loss_G: 3.181651, loss_D: 0.166434\n",
      "[Epoch 70/200] [Batch 240/938] loss_G: 2.549016, loss_D: 0.233640\n",
      "[Epoch 70/200] [Batch 250/938] loss_G: 2.773939, loss_D: 0.207081\n",
      "[Epoch 70/200] [Batch 260/938] loss_G: 2.417147, loss_D: 0.241085\n",
      "[Epoch 70/200] [Batch 270/938] loss_G: 2.927713, loss_D: 0.151444\n",
      "[Epoch 70/200] [Batch 280/938] loss_G: 2.820235, loss_D: 0.247883\n",
      "[Epoch 70/200] [Batch 290/938] loss_G: 2.678277, loss_D: 0.223594\n",
      "[Epoch 70/200] [Batch 300/938] loss_G: 3.121809, loss_D: 0.172389\n",
      "[Epoch 70/200] [Batch 310/938] loss_G: 2.740682, loss_D: 0.299492\n",
      "[Epoch 70/200] [Batch 320/938] loss_G: 2.738893, loss_D: 0.150401\n",
      "[Epoch 70/200] [Batch 330/938] loss_G: 3.050517, loss_D: 0.167274\n",
      "[Epoch 70/200] [Batch 340/938] loss_G: 2.711363, loss_D: 0.209128\n",
      "[Epoch 70/200] [Batch 350/938] loss_G: 2.865909, loss_D: 0.171457\n",
      "[Epoch 70/200] [Batch 360/938] loss_G: 2.525418, loss_D: 0.252321\n",
      "[Epoch 70/200] [Batch 370/938] loss_G: 2.780129, loss_D: 0.214587\n",
      "[Epoch 70/200] [Batch 380/938] loss_G: 3.025889, loss_D: 0.239520\n",
      "[Epoch 70/200] [Batch 390/938] loss_G: 2.987038, loss_D: 0.237055\n",
      "[Epoch 70/200] [Batch 400/938] loss_G: 2.931271, loss_D: 0.185368\n",
      "[Epoch 70/200] [Batch 410/938] loss_G: 2.994579, loss_D: 0.281275\n",
      "[Epoch 70/200] [Batch 420/938] loss_G: 2.384045, loss_D: 0.195251\n",
      "[Epoch 70/200] [Batch 430/938] loss_G: 2.710021, loss_D: 0.290445\n",
      "[Epoch 70/200] [Batch 440/938] loss_G: 2.541247, loss_D: 0.178868\n",
      "[Epoch 70/200] [Batch 450/938] loss_G: 2.608780, loss_D: 0.177145\n",
      "[Epoch 70/200] [Batch 460/938] loss_G: 2.776631, loss_D: 0.237617\n",
      "[Epoch 70/200] [Batch 470/938] loss_G: 2.956927, loss_D: 0.198075\n",
      "[Epoch 70/200] [Batch 480/938] loss_G: 3.139431, loss_D: 0.156976\n",
      "[Epoch 70/200] [Batch 490/938] loss_G: 2.892723, loss_D: 0.158169\n",
      "[Epoch 70/200] [Batch 500/938] loss_G: 3.072693, loss_D: 0.160230\n",
      "[Epoch 70/200] [Batch 510/938] loss_G: 2.702955, loss_D: 0.279671\n",
      "[Epoch 70/200] [Batch 520/938] loss_G: 2.720520, loss_D: 0.331404\n",
      "[Epoch 70/200] [Batch 530/938] loss_G: 2.826231, loss_D: 0.259075\n",
      "[Epoch 70/200] [Batch 540/938] loss_G: 3.026442, loss_D: 0.128530\n",
      "[Epoch 70/200] [Batch 550/938] loss_G: 2.749176, loss_D: 0.195606\n",
      "[Epoch 70/200] [Batch 560/938] loss_G: 2.429710, loss_D: 0.218981\n",
      "[Epoch 70/200] [Batch 570/938] loss_G: 2.751480, loss_D: 0.181150\n",
      "[Epoch 70/200] [Batch 580/938] loss_G: 2.777200, loss_D: 0.189649\n",
      "[Epoch 70/200] [Batch 590/938] loss_G: 2.916435, loss_D: 0.263991\n",
      "[Epoch 70/200] [Batch 600/938] loss_G: 2.422519, loss_D: 0.292469\n",
      "[Epoch 70/200] [Batch 610/938] loss_G: 2.583294, loss_D: 0.241858\n",
      "[Epoch 70/200] [Batch 620/938] loss_G: 2.804479, loss_D: 0.335234\n",
      "[Epoch 70/200] [Batch 630/938] loss_G: 3.097202, loss_D: 0.192174\n",
      "[Epoch 70/200] [Batch 640/938] loss_G: 2.965018, loss_D: 0.181785\n",
      "[Epoch 70/200] [Batch 650/938] loss_G: 2.666996, loss_D: 0.200131\n",
      "[Epoch 70/200] [Batch 660/938] loss_G: 2.849315, loss_D: 0.278459\n",
      "[Epoch 70/200] [Batch 670/938] loss_G: 2.452979, loss_D: 0.261904\n",
      "[Epoch 70/200] [Batch 680/938] loss_G: 2.798560, loss_D: 0.192267\n",
      "[Epoch 70/200] [Batch 690/938] loss_G: 2.699049, loss_D: 0.226907\n",
      "[Epoch 70/200] [Batch 700/938] loss_G: 2.192318, loss_D: 0.310723\n",
      "[Epoch 70/200] [Batch 710/938] loss_G: 3.028229, loss_D: 0.265833\n",
      "[Epoch 70/200] [Batch 720/938] loss_G: 2.850634, loss_D: 0.189982\n",
      "[Epoch 70/200] [Batch 730/938] loss_G: 2.965852, loss_D: 0.187465\n",
      "[Epoch 70/200] [Batch 740/938] loss_G: 2.966916, loss_D: 0.183054\n",
      "[Epoch 70/200] [Batch 750/938] loss_G: 2.502895, loss_D: 0.223656\n",
      "[Epoch 70/200] [Batch 760/938] loss_G: 3.011068, loss_D: 0.162536\n",
      "[Epoch 70/200] [Batch 770/938] loss_G: 2.440711, loss_D: 0.252362\n",
      "[Epoch 70/200] [Batch 780/938] loss_G: 2.920559, loss_D: 0.204532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 70/200] [Batch 790/938] loss_G: 2.638500, loss_D: 0.327255\n",
      "[Epoch 70/200] [Batch 800/938] loss_G: 2.726898, loss_D: 0.152132\n",
      "[Epoch 70/200] [Batch 810/938] loss_G: 2.931750, loss_D: 0.200412\n",
      "[Epoch 70/200] [Batch 820/938] loss_G: 2.575485, loss_D: 0.225917\n",
      "[Epoch 70/200] [Batch 830/938] loss_G: 2.663819, loss_D: 0.281023\n",
      "[Epoch 70/200] [Batch 840/938] loss_G: 3.028409, loss_D: 0.205077\n",
      "[Epoch 70/200] [Batch 850/938] loss_G: 2.872140, loss_D: 0.275060\n",
      "[Epoch 70/200] [Batch 860/938] loss_G: 2.605643, loss_D: 0.240355\n",
      "[Epoch 70/200] [Batch 870/938] loss_G: 2.916822, loss_D: 0.200745\n",
      "[Epoch 70/200] [Batch 880/938] loss_G: 2.832176, loss_D: 0.160253\n",
      "[Epoch 70/200] [Batch 890/938] loss_G: 2.639839, loss_D: 0.247799\n",
      "[Epoch 70/200] [Batch 900/938] loss_G: 2.739565, loss_D: 0.230320\n",
      "[Epoch 70/200] [Batch 910/938] loss_G: 2.908690, loss_D: 0.312957\n",
      "[Epoch 70/200] [Batch 920/938] loss_G: 2.701355, loss_D: 0.202715\n",
      "[Epoch 70/200] [Batch 930/938] loss_G: 2.686644, loss_D: 0.159245\n",
      "[Epoch 71/200] [Batch 0/938] loss_G: 2.537808, loss_D: 0.249709\n",
      "[Epoch 71/200] [Batch 10/938] loss_G: 2.531591, loss_D: 0.244572\n",
      "[Epoch 71/200] [Batch 20/938] loss_G: 2.880997, loss_D: 0.267381\n",
      "[Epoch 71/200] [Batch 30/938] loss_G: 2.442579, loss_D: 0.374699\n",
      "[Epoch 71/200] [Batch 40/938] loss_G: 2.621041, loss_D: 0.134062\n",
      "[Epoch 71/200] [Batch 50/938] loss_G: 2.715121, loss_D: 0.198620\n",
      "[Epoch 71/200] [Batch 60/938] loss_G: 2.831016, loss_D: 0.224641\n",
      "[Epoch 71/200] [Batch 70/938] loss_G: 2.703514, loss_D: 0.191312\n",
      "[Epoch 71/200] [Batch 80/938] loss_G: 2.866972, loss_D: 0.211828\n",
      "[Epoch 71/200] [Batch 90/938] loss_G: 3.075696, loss_D: 0.246007\n",
      "[Epoch 71/200] [Batch 100/938] loss_G: 3.091306, loss_D: 0.128250\n",
      "[Epoch 71/200] [Batch 110/938] loss_G: 2.806409, loss_D: 0.199751\n",
      "[Epoch 71/200] [Batch 120/938] loss_G: 2.886541, loss_D: 0.230646\n",
      "[Epoch 71/200] [Batch 130/938] loss_G: 2.631798, loss_D: 0.304004\n",
      "[Epoch 71/200] [Batch 140/938] loss_G: 2.943704, loss_D: 0.120937\n",
      "[Epoch 71/200] [Batch 150/938] loss_G: 2.839498, loss_D: 0.212652\n",
      "[Epoch 71/200] [Batch 160/938] loss_G: 2.694285, loss_D: 0.239571\n",
      "[Epoch 71/200] [Batch 170/938] loss_G: 3.100582, loss_D: 0.172838\n",
      "[Epoch 71/200] [Batch 180/938] loss_G: 2.822941, loss_D: 0.162319\n",
      "[Epoch 71/200] [Batch 190/938] loss_G: 2.581881, loss_D: 0.182969\n",
      "[Epoch 71/200] [Batch 200/938] loss_G: 2.812772, loss_D: 0.184629\n",
      "[Epoch 71/200] [Batch 210/938] loss_G: 2.756875, loss_D: 0.280603\n",
      "[Epoch 71/200] [Batch 220/938] loss_G: 2.558797, loss_D: 0.259315\n",
      "[Epoch 71/200] [Batch 230/938] loss_G: 2.660589, loss_D: 0.164236\n",
      "[Epoch 71/200] [Batch 240/938] loss_G: 2.954573, loss_D: 0.197276\n",
      "[Epoch 71/200] [Batch 250/938] loss_G: 2.598339, loss_D: 0.235884\n",
      "[Epoch 71/200] [Batch 260/938] loss_G: 2.851339, loss_D: 0.328871\n",
      "[Epoch 71/200] [Batch 270/938] loss_G: 2.650460, loss_D: 0.261193\n",
      "[Epoch 71/200] [Batch 280/938] loss_G: 2.857134, loss_D: 0.205410\n",
      "[Epoch 71/200] [Batch 290/938] loss_G: 2.661675, loss_D: 0.239807\n",
      "[Epoch 71/200] [Batch 300/938] loss_G: 2.797134, loss_D: 0.273927\n",
      "[Epoch 71/200] [Batch 310/938] loss_G: 2.517637, loss_D: 0.321402\n",
      "[Epoch 71/200] [Batch 320/938] loss_G: 2.713384, loss_D: 0.196181\n",
      "[Epoch 71/200] [Batch 330/938] loss_G: 3.106081, loss_D: 0.164471\n",
      "[Epoch 71/200] [Batch 340/938] loss_G: 3.025866, loss_D: 0.306748\n",
      "[Epoch 71/200] [Batch 350/938] loss_G: 2.874092, loss_D: 0.211107\n",
      "[Epoch 71/200] [Batch 360/938] loss_G: 2.734473, loss_D: 0.230427\n",
      "[Epoch 71/200] [Batch 370/938] loss_G: 2.450657, loss_D: 0.225715\n",
      "[Epoch 71/200] [Batch 380/938] loss_G: 2.777581, loss_D: 0.204969\n",
      "[Epoch 71/200] [Batch 390/938] loss_G: 2.757851, loss_D: 0.223532\n",
      "[Epoch 71/200] [Batch 400/938] loss_G: 2.881050, loss_D: 0.206456\n",
      "[Epoch 71/200] [Batch 410/938] loss_G: 2.540880, loss_D: 0.276015\n",
      "[Epoch 71/200] [Batch 420/938] loss_G: 2.824703, loss_D: 0.318943\n",
      "[Epoch 71/200] [Batch 430/938] loss_G: 2.596478, loss_D: 0.249966\n",
      "[Epoch 71/200] [Batch 440/938] loss_G: 2.651158, loss_D: 0.198987\n",
      "[Epoch 71/200] [Batch 450/938] loss_G: 3.178568, loss_D: 0.293866\n",
      "[Epoch 71/200] [Batch 460/938] loss_G: 2.852742, loss_D: 0.235581\n",
      "[Epoch 71/200] [Batch 470/938] loss_G: 2.664664, loss_D: 0.278172\n",
      "[Epoch 71/200] [Batch 480/938] loss_G: 2.749283, loss_D: 0.244109\n",
      "[Epoch 71/200] [Batch 490/938] loss_G: 2.855274, loss_D: 0.231795\n",
      "[Epoch 71/200] [Batch 500/938] loss_G: 2.807564, loss_D: 0.184958\n",
      "[Epoch 71/200] [Batch 510/938] loss_G: 2.529963, loss_D: 0.189276\n",
      "[Epoch 71/200] [Batch 520/938] loss_G: 3.255577, loss_D: 0.138090\n",
      "[Epoch 71/200] [Batch 530/938] loss_G: 2.575789, loss_D: 0.164864\n",
      "[Epoch 71/200] [Batch 540/938] loss_G: 2.840289, loss_D: 0.188160\n",
      "[Epoch 71/200] [Batch 550/938] loss_G: 2.767584, loss_D: 0.231788\n",
      "[Epoch 71/200] [Batch 560/938] loss_G: 3.046566, loss_D: 0.142319\n",
      "[Epoch 71/200] [Batch 570/938] loss_G: 2.809848, loss_D: 0.277821\n",
      "[Epoch 71/200] [Batch 580/938] loss_G: 3.175499, loss_D: 0.153519\n",
      "[Epoch 71/200] [Batch 590/938] loss_G: 3.143382, loss_D: 0.179541\n",
      "[Epoch 71/200] [Batch 600/938] loss_G: 2.719206, loss_D: 0.185527\n",
      "[Epoch 71/200] [Batch 610/938] loss_G: 2.922213, loss_D: 0.145897\n",
      "[Epoch 71/200] [Batch 620/938] loss_G: 2.782055, loss_D: 0.205474\n",
      "[Epoch 71/200] [Batch 630/938] loss_G: 3.011328, loss_D: 0.137274\n",
      "[Epoch 71/200] [Batch 640/938] loss_G: 3.131737, loss_D: 0.205376\n",
      "[Epoch 71/200] [Batch 650/938] loss_G: 2.894683, loss_D: 0.190316\n",
      "[Epoch 71/200] [Batch 660/938] loss_G: 2.938510, loss_D: 0.269934\n",
      "[Epoch 71/200] [Batch 670/938] loss_G: 3.325749, loss_D: 0.123155\n",
      "[Epoch 71/200] [Batch 680/938] loss_G: 2.881164, loss_D: 0.236715\n",
      "[Epoch 71/200] [Batch 690/938] loss_G: 2.920920, loss_D: 0.257484\n",
      "[Epoch 71/200] [Batch 700/938] loss_G: 2.786423, loss_D: 0.235806\n",
      "[Epoch 71/200] [Batch 710/938] loss_G: 2.528445, loss_D: 0.261203\n",
      "[Epoch 71/200] [Batch 720/938] loss_G: 2.960392, loss_D: 0.288870\n",
      "[Epoch 71/200] [Batch 730/938] loss_G: 2.710315, loss_D: 0.243426\n",
      "[Epoch 71/200] [Batch 740/938] loss_G: 3.105971, loss_D: 0.241776\n",
      "[Epoch 71/200] [Batch 750/938] loss_G: 3.014949, loss_D: 0.196275\n",
      "[Epoch 71/200] [Batch 760/938] loss_G: 2.938655, loss_D: 0.355464\n",
      "[Epoch 71/200] [Batch 770/938] loss_G: 2.851614, loss_D: 0.181304\n",
      "[Epoch 71/200] [Batch 780/938] loss_G: 2.654834, loss_D: 0.268852\n",
      "[Epoch 71/200] [Batch 790/938] loss_G: 2.921173, loss_D: 0.208029\n",
      "[Epoch 71/200] [Batch 800/938] loss_G: 2.991168, loss_D: 0.272767\n",
      "[Epoch 71/200] [Batch 810/938] loss_G: 2.594428, loss_D: 0.190775\n",
      "[Epoch 71/200] [Batch 820/938] loss_G: 2.749880, loss_D: 0.193426\n",
      "[Epoch 71/200] [Batch 830/938] loss_G: 2.628907, loss_D: 0.272941\n",
      "[Epoch 71/200] [Batch 840/938] loss_G: 2.268617, loss_D: 0.314191\n",
      "[Epoch 71/200] [Batch 850/938] loss_G: 2.657030, loss_D: 0.310656\n",
      "[Epoch 71/200] [Batch 860/938] loss_G: 2.423708, loss_D: 0.263602\n",
      "[Epoch 71/200] [Batch 870/938] loss_G: 3.015374, loss_D: 0.177702\n",
      "[Epoch 71/200] [Batch 880/938] loss_G: 2.561730, loss_D: 0.240861\n",
      "[Epoch 71/200] [Batch 890/938] loss_G: 2.602676, loss_D: 0.226291\n",
      "[Epoch 71/200] [Batch 900/938] loss_G: 2.572041, loss_D: 0.249553\n",
      "[Epoch 71/200] [Batch 910/938] loss_G: 2.723409, loss_D: 0.277946\n",
      "[Epoch 71/200] [Batch 920/938] loss_G: 3.017021, loss_D: 0.216237\n",
      "[Epoch 71/200] [Batch 930/938] loss_G: 2.688280, loss_D: 0.348900\n",
      "[Epoch 72/200] [Batch 0/938] loss_G: 2.343996, loss_D: 0.162791\n",
      "[Epoch 72/200] [Batch 10/938] loss_G: 2.734453, loss_D: 0.118955\n",
      "[Epoch 72/200] [Batch 20/938] loss_G: 2.872679, loss_D: 0.322221\n",
      "[Epoch 72/200] [Batch 30/938] loss_G: 2.862564, loss_D: 0.192556\n",
      "[Epoch 72/200] [Batch 40/938] loss_G: 2.666338, loss_D: 0.253124\n",
      "[Epoch 72/200] [Batch 50/938] loss_G: 3.077924, loss_D: 0.152916\n",
      "[Epoch 72/200] [Batch 60/938] loss_G: 3.108432, loss_D: 0.102564\n",
      "[Epoch 72/200] [Batch 70/938] loss_G: 2.538122, loss_D: 0.178813\n",
      "[Epoch 72/200] [Batch 80/938] loss_G: 2.864233, loss_D: 0.225109\n",
      "[Epoch 72/200] [Batch 90/938] loss_G: 2.698813, loss_D: 0.218687\n",
      "[Epoch 72/200] [Batch 100/938] loss_G: 2.668019, loss_D: 0.200513\n",
      "[Epoch 72/200] [Batch 110/938] loss_G: 3.014651, loss_D: 0.184803\n",
      "[Epoch 72/200] [Batch 120/938] loss_G: 2.988014, loss_D: 0.140138\n",
      "[Epoch 72/200] [Batch 130/938] loss_G: 2.903145, loss_D: 0.239806\n",
      "[Epoch 72/200] [Batch 140/938] loss_G: 2.640489, loss_D: 0.243701\n",
      "[Epoch 72/200] [Batch 150/938] loss_G: 2.910287, loss_D: 0.228581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 72/200] [Batch 160/938] loss_G: 2.645051, loss_D: 0.204959\n",
      "[Epoch 72/200] [Batch 170/938] loss_G: 3.015798, loss_D: 0.210081\n",
      "[Epoch 72/200] [Batch 180/938] loss_G: 2.583440, loss_D: 0.222143\n",
      "[Epoch 72/200] [Batch 190/938] loss_G: 2.543036, loss_D: 0.229215\n",
      "[Epoch 72/200] [Batch 200/938] loss_G: 2.747738, loss_D: 0.258866\n",
      "[Epoch 72/200] [Batch 210/938] loss_G: 2.347328, loss_D: 0.247796\n",
      "[Epoch 72/200] [Batch 220/938] loss_G: 3.074006, loss_D: 0.282850\n",
      "[Epoch 72/200] [Batch 230/938] loss_G: 2.331147, loss_D: 0.263767\n",
      "[Epoch 72/200] [Batch 240/938] loss_G: 2.877677, loss_D: 0.288945\n",
      "[Epoch 72/200] [Batch 250/938] loss_G: 2.926921, loss_D: 0.201612\n",
      "[Epoch 72/200] [Batch 260/938] loss_G: 2.768790, loss_D: 0.139625\n",
      "[Epoch 72/200] [Batch 270/938] loss_G: 2.757419, loss_D: 0.250120\n",
      "[Epoch 72/200] [Batch 280/938] loss_G: 2.184783, loss_D: 0.233945\n",
      "[Epoch 72/200] [Batch 290/938] loss_G: 3.335922, loss_D: 0.191836\n",
      "[Epoch 72/200] [Batch 300/938] loss_G: 2.328933, loss_D: 0.248576\n",
      "[Epoch 72/200] [Batch 310/938] loss_G: 2.759831, loss_D: 0.221900\n",
      "[Epoch 72/200] [Batch 320/938] loss_G: 2.813278, loss_D: 0.202100\n",
      "[Epoch 72/200] [Batch 330/938] loss_G: 2.747437, loss_D: 0.172261\n",
      "[Epoch 72/200] [Batch 340/938] loss_G: 2.457476, loss_D: 0.238209\n",
      "[Epoch 72/200] [Batch 350/938] loss_G: 2.349514, loss_D: 0.308551\n",
      "[Epoch 72/200] [Batch 360/938] loss_G: 2.661786, loss_D: 0.221412\n",
      "[Epoch 72/200] [Batch 370/938] loss_G: 2.567644, loss_D: 0.250026\n",
      "[Epoch 72/200] [Batch 380/938] loss_G: 2.860520, loss_D: 0.201462\n",
      "[Epoch 72/200] [Batch 390/938] loss_G: 2.703138, loss_D: 0.141008\n",
      "[Epoch 72/200] [Batch 400/938] loss_G: 2.859407, loss_D: 0.232187\n",
      "[Epoch 72/200] [Batch 410/938] loss_G: 2.826433, loss_D: 0.215488\n",
      "[Epoch 72/200] [Batch 420/938] loss_G: 2.833271, loss_D: 0.199957\n",
      "[Epoch 72/200] [Batch 430/938] loss_G: 2.371009, loss_D: 0.216141\n",
      "[Epoch 72/200] [Batch 440/938] loss_G: 2.998267, loss_D: 0.157490\n",
      "[Epoch 72/200] [Batch 450/938] loss_G: 2.785657, loss_D: 0.215910\n",
      "[Epoch 72/200] [Batch 460/938] loss_G: 2.509233, loss_D: 0.322495\n",
      "[Epoch 72/200] [Batch 470/938] loss_G: 3.048873, loss_D: 0.139468\n",
      "[Epoch 72/200] [Batch 480/938] loss_G: 2.926189, loss_D: 0.215908\n",
      "[Epoch 72/200] [Batch 490/938] loss_G: 2.893184, loss_D: 0.215877\n",
      "[Epoch 72/200] [Batch 500/938] loss_G: 3.098552, loss_D: 0.207837\n",
      "[Epoch 72/200] [Batch 510/938] loss_G: 2.873701, loss_D: 0.192835\n",
      "[Epoch 72/200] [Batch 520/938] loss_G: 3.165583, loss_D: 0.251412\n",
      "[Epoch 72/200] [Batch 530/938] loss_G: 2.339795, loss_D: 0.219119\n",
      "[Epoch 72/200] [Batch 540/938] loss_G: 2.887990, loss_D: 0.208586\n",
      "[Epoch 72/200] [Batch 550/938] loss_G: 3.065174, loss_D: 0.165839\n",
      "[Epoch 72/200] [Batch 560/938] loss_G: 2.639810, loss_D: 0.261565\n",
      "[Epoch 72/200] [Batch 570/938] loss_G: 2.816319, loss_D: 0.167373\n",
      "[Epoch 72/200] [Batch 580/938] loss_G: 2.966071, loss_D: 0.107004\n",
      "[Epoch 72/200] [Batch 590/938] loss_G: 2.878826, loss_D: 0.185671\n",
      "[Epoch 72/200] [Batch 600/938] loss_G: 2.733721, loss_D: 0.223017\n",
      "[Epoch 72/200] [Batch 610/938] loss_G: 2.903593, loss_D: 0.245386\n",
      "[Epoch 72/200] [Batch 620/938] loss_G: 2.768405, loss_D: 0.231198\n",
      "[Epoch 72/200] [Batch 630/938] loss_G: 2.766515, loss_D: 0.189061\n",
      "[Epoch 72/200] [Batch 640/938] loss_G: 2.581123, loss_D: 0.259483\n",
      "[Epoch 72/200] [Batch 650/938] loss_G: 2.894302, loss_D: 0.220341\n",
      "[Epoch 72/200] [Batch 660/938] loss_G: 2.315382, loss_D: 0.270004\n",
      "[Epoch 72/200] [Batch 670/938] loss_G: 2.706109, loss_D: 0.303465\n",
      "[Epoch 72/200] [Batch 680/938] loss_G: 2.919791, loss_D: 0.197052\n",
      "[Epoch 72/200] [Batch 690/938] loss_G: 2.789065, loss_D: 0.156302\n",
      "[Epoch 72/200] [Batch 700/938] loss_G: 3.121356, loss_D: 0.215928\n",
      "[Epoch 72/200] [Batch 710/938] loss_G: 2.960322, loss_D: 0.204571\n",
      "[Epoch 72/200] [Batch 720/938] loss_G: 2.519428, loss_D: 0.202218\n",
      "[Epoch 72/200] [Batch 730/938] loss_G: 2.726902, loss_D: 0.240587\n",
      "[Epoch 72/200] [Batch 740/938] loss_G: 2.674737, loss_D: 0.226740\n",
      "[Epoch 72/200] [Batch 750/938] loss_G: 2.780975, loss_D: 0.204082\n",
      "[Epoch 72/200] [Batch 760/938] loss_G: 3.083768, loss_D: 0.210414\n",
      "[Epoch 72/200] [Batch 770/938] loss_G: 2.787448, loss_D: 0.204566\n",
      "[Epoch 72/200] [Batch 780/938] loss_G: 2.535306, loss_D: 0.176417\n",
      "[Epoch 72/200] [Batch 790/938] loss_G: 2.876745, loss_D: 0.214104\n",
      "[Epoch 72/200] [Batch 800/938] loss_G: 2.515643, loss_D: 0.208385\n",
      "[Epoch 72/200] [Batch 810/938] loss_G: 2.516459, loss_D: 0.213044\n",
      "[Epoch 72/200] [Batch 820/938] loss_G: 2.707114, loss_D: 0.236434\n",
      "[Epoch 72/200] [Batch 830/938] loss_G: 2.625747, loss_D: 0.223485\n",
      "[Epoch 72/200] [Batch 840/938] loss_G: 2.662436, loss_D: 0.260496\n",
      "[Epoch 72/200] [Batch 850/938] loss_G: 2.752775, loss_D: 0.220337\n",
      "[Epoch 72/200] [Batch 860/938] loss_G: 3.033947, loss_D: 0.209777\n",
      "[Epoch 72/200] [Batch 870/938] loss_G: 2.830186, loss_D: 0.254542\n",
      "[Epoch 72/200] [Batch 880/938] loss_G: 2.837325, loss_D: 0.197325\n",
      "[Epoch 72/200] [Batch 890/938] loss_G: 3.187098, loss_D: 0.170850\n",
      "[Epoch 72/200] [Batch 900/938] loss_G: 2.852337, loss_D: 0.234667\n",
      "[Epoch 72/200] [Batch 910/938] loss_G: 2.981471, loss_D: 0.220231\n",
      "[Epoch 72/200] [Batch 920/938] loss_G: 2.799050, loss_D: 0.231822\n",
      "[Epoch 72/200] [Batch 930/938] loss_G: 2.857079, loss_D: 0.240274\n",
      "[Epoch 73/200] [Batch 0/938] loss_G: 2.517286, loss_D: 0.314226\n",
      "[Epoch 73/200] [Batch 10/938] loss_G: 2.776052, loss_D: 0.266185\n",
      "[Epoch 73/200] [Batch 20/938] loss_G: 2.759525, loss_D: 0.191251\n",
      "[Epoch 73/200] [Batch 30/938] loss_G: 2.896129, loss_D: 0.192878\n",
      "[Epoch 73/200] [Batch 40/938] loss_G: 2.633678, loss_D: 0.240285\n",
      "[Epoch 73/200] [Batch 50/938] loss_G: 3.202090, loss_D: 0.140877\n",
      "[Epoch 73/200] [Batch 60/938] loss_G: 3.119735, loss_D: 0.190738\n",
      "[Epoch 73/200] [Batch 70/938] loss_G: 2.455539, loss_D: 0.201472\n",
      "[Epoch 73/200] [Batch 80/938] loss_G: 2.791052, loss_D: 0.235663\n",
      "[Epoch 73/200] [Batch 90/938] loss_G: 2.664505, loss_D: 0.288370\n",
      "[Epoch 73/200] [Batch 100/938] loss_G: 2.709581, loss_D: 0.177937\n",
      "[Epoch 73/200] [Batch 110/938] loss_G: 2.655421, loss_D: 0.231648\n",
      "[Epoch 73/200] [Batch 120/938] loss_G: 2.937632, loss_D: 0.192946\n",
      "[Epoch 73/200] [Batch 130/938] loss_G: 2.794042, loss_D: 0.255369\n",
      "[Epoch 73/200] [Batch 140/938] loss_G: 2.688082, loss_D: 0.223965\n",
      "[Epoch 73/200] [Batch 150/938] loss_G: 2.682948, loss_D: 0.199813\n",
      "[Epoch 73/200] [Batch 160/938] loss_G: 2.819560, loss_D: 0.230622\n",
      "[Epoch 73/200] [Batch 170/938] loss_G: 2.721128, loss_D: 0.183678\n",
      "[Epoch 73/200] [Batch 180/938] loss_G: 2.983589, loss_D: 0.223955\n",
      "[Epoch 73/200] [Batch 190/938] loss_G: 2.717072, loss_D: 0.203568\n",
      "[Epoch 73/200] [Batch 200/938] loss_G: 2.782258, loss_D: 0.162660\n",
      "[Epoch 73/200] [Batch 210/938] loss_G: 2.800629, loss_D: 0.209387\n",
      "[Epoch 73/200] [Batch 220/938] loss_G: 2.842663, loss_D: 0.221058\n",
      "[Epoch 73/200] [Batch 230/938] loss_G: 2.971459, loss_D: 0.116657\n",
      "[Epoch 73/200] [Batch 240/938] loss_G: 2.801785, loss_D: 0.207425\n",
      "[Epoch 73/200] [Batch 250/938] loss_G: 2.742259, loss_D: 0.237218\n",
      "[Epoch 73/200] [Batch 260/938] loss_G: 3.265030, loss_D: 0.169215\n",
      "[Epoch 73/200] [Batch 270/938] loss_G: 2.757880, loss_D: 0.264619\n",
      "[Epoch 73/200] [Batch 280/938] loss_G: 3.032207, loss_D: 0.245148\n",
      "[Epoch 73/200] [Batch 290/938] loss_G: 2.565665, loss_D: 0.239190\n",
      "[Epoch 73/200] [Batch 300/938] loss_G: 2.679600, loss_D: 0.252824\n",
      "[Epoch 73/200] [Batch 310/938] loss_G: 2.730014, loss_D: 0.176452\n",
      "[Epoch 73/200] [Batch 320/938] loss_G: 2.546164, loss_D: 0.223208\n",
      "[Epoch 73/200] [Batch 330/938] loss_G: 2.477690, loss_D: 0.228228\n",
      "[Epoch 73/200] [Batch 340/938] loss_G: 2.908377, loss_D: 0.140242\n",
      "[Epoch 73/200] [Batch 350/938] loss_G: 2.834501, loss_D: 0.252919\n",
      "[Epoch 73/200] [Batch 360/938] loss_G: 2.779317, loss_D: 0.230388\n",
      "[Epoch 73/200] [Batch 370/938] loss_G: 2.598401, loss_D: 0.262300\n",
      "[Epoch 73/200] [Batch 380/938] loss_G: 2.729888, loss_D: 0.235864\n",
      "[Epoch 73/200] [Batch 390/938] loss_G: 3.015964, loss_D: 0.150260\n",
      "[Epoch 73/200] [Batch 400/938] loss_G: 2.718939, loss_D: 0.209397\n",
      "[Epoch 73/200] [Batch 410/938] loss_G: 2.878246, loss_D: 0.169406\n",
      "[Epoch 73/200] [Batch 420/938] loss_G: 3.051385, loss_D: 0.206478\n",
      "[Epoch 73/200] [Batch 430/938] loss_G: 2.847226, loss_D: 0.119117\n",
      "[Epoch 73/200] [Batch 440/938] loss_G: 2.613798, loss_D: 0.190123\n",
      "[Epoch 73/200] [Batch 450/938] loss_G: 2.680255, loss_D: 0.264421\n",
      "[Epoch 73/200] [Batch 460/938] loss_G: 2.550331, loss_D: 0.311933\n",
      "[Epoch 73/200] [Batch 470/938] loss_G: 2.840186, loss_D: 0.181928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 73/200] [Batch 480/938] loss_G: 2.949302, loss_D: 0.205930\n",
      "[Epoch 73/200] [Batch 490/938] loss_G: 2.867786, loss_D: 0.305943\n",
      "[Epoch 73/200] [Batch 500/938] loss_G: 2.563479, loss_D: 0.264264\n",
      "[Epoch 73/200] [Batch 510/938] loss_G: 3.148979, loss_D: 0.229718\n",
      "[Epoch 73/200] [Batch 520/938] loss_G: 2.956062, loss_D: 0.258343\n",
      "[Epoch 73/200] [Batch 530/938] loss_G: 2.909790, loss_D: 0.236693\n",
      "[Epoch 73/200] [Batch 540/938] loss_G: 2.747850, loss_D: 0.229640\n",
      "[Epoch 73/200] [Batch 550/938] loss_G: 2.447257, loss_D: 0.273435\n",
      "[Epoch 73/200] [Batch 560/938] loss_G: 3.014320, loss_D: 0.338889\n",
      "[Epoch 73/200] [Batch 570/938] loss_G: 2.832012, loss_D: 0.169877\n",
      "[Epoch 73/200] [Batch 580/938] loss_G: 3.037781, loss_D: 0.190180\n",
      "[Epoch 73/200] [Batch 590/938] loss_G: 2.831699, loss_D: 0.166900\n",
      "[Epoch 73/200] [Batch 600/938] loss_G: 2.891735, loss_D: 0.204420\n",
      "[Epoch 73/200] [Batch 610/938] loss_G: 2.495492, loss_D: 0.261405\n",
      "[Epoch 73/200] [Batch 620/938] loss_G: 3.234239, loss_D: 0.218372\n",
      "[Epoch 73/200] [Batch 630/938] loss_G: 2.803063, loss_D: 0.269840\n",
      "[Epoch 73/200] [Batch 640/938] loss_G: 2.864019, loss_D: 0.233035\n",
      "[Epoch 73/200] [Batch 650/938] loss_G: 2.951226, loss_D: 0.229307\n",
      "[Epoch 73/200] [Batch 660/938] loss_G: 2.685434, loss_D: 0.251211\n",
      "[Epoch 73/200] [Batch 670/938] loss_G: 2.807364, loss_D: 0.270707\n",
      "[Epoch 73/200] [Batch 680/938] loss_G: 2.712434, loss_D: 0.179540\n",
      "[Epoch 73/200] [Batch 690/938] loss_G: 2.724864, loss_D: 0.228337\n",
      "[Epoch 73/200] [Batch 700/938] loss_G: 3.090929, loss_D: 0.237131\n",
      "[Epoch 73/200] [Batch 710/938] loss_G: 2.649106, loss_D: 0.190270\n",
      "[Epoch 73/200] [Batch 720/938] loss_G: 2.895683, loss_D: 0.243050\n",
      "[Epoch 73/200] [Batch 730/938] loss_G: 2.712637, loss_D: 0.206716\n",
      "[Epoch 73/200] [Batch 740/938] loss_G: 3.059365, loss_D: 0.227237\n",
      "[Epoch 73/200] [Batch 750/938] loss_G: 2.667235, loss_D: 0.346397\n",
      "[Epoch 73/200] [Batch 760/938] loss_G: 2.767469, loss_D: 0.179085\n",
      "[Epoch 73/200] [Batch 770/938] loss_G: 3.128959, loss_D: 0.151765\n",
      "[Epoch 73/200] [Batch 780/938] loss_G: 3.306985, loss_D: 0.157461\n",
      "[Epoch 73/200] [Batch 790/938] loss_G: 3.195087, loss_D: 0.262583\n",
      "[Epoch 73/200] [Batch 800/938] loss_G: 2.800929, loss_D: 0.284588\n",
      "[Epoch 73/200] [Batch 810/938] loss_G: 2.771323, loss_D: 0.230324\n",
      "[Epoch 73/200] [Batch 820/938] loss_G: 2.983327, loss_D: 0.168555\n",
      "[Epoch 73/200] [Batch 830/938] loss_G: 2.664822, loss_D: 0.237914\n",
      "[Epoch 73/200] [Batch 840/938] loss_G: 2.892106, loss_D: 0.226352\n",
      "[Epoch 73/200] [Batch 850/938] loss_G: 2.893754, loss_D: 0.258451\n",
      "[Epoch 73/200] [Batch 860/938] loss_G: 2.830242, loss_D: 0.176053\n",
      "[Epoch 73/200] [Batch 870/938] loss_G: 2.614208, loss_D: 0.292957\n",
      "[Epoch 73/200] [Batch 880/938] loss_G: 2.908502, loss_D: 0.226510\n",
      "[Epoch 73/200] [Batch 890/938] loss_G: 2.903650, loss_D: 0.186575\n",
      "[Epoch 73/200] [Batch 900/938] loss_G: 2.990084, loss_D: 0.187596\n",
      "[Epoch 73/200] [Batch 910/938] loss_G: 3.154366, loss_D: 0.230373\n",
      "[Epoch 73/200] [Batch 920/938] loss_G: 2.602802, loss_D: 0.198581\n",
      "[Epoch 73/200] [Batch 930/938] loss_G: 2.760694, loss_D: 0.163600\n",
      "[Epoch 74/200] [Batch 0/938] loss_G: 2.792081, loss_D: 0.207925\n",
      "[Epoch 74/200] [Batch 10/938] loss_G: 2.764340, loss_D: 0.209671\n",
      "[Epoch 74/200] [Batch 20/938] loss_G: 2.709169, loss_D: 0.163702\n",
      "[Epoch 74/200] [Batch 30/938] loss_G: 3.229061, loss_D: 0.221907\n",
      "[Epoch 74/200] [Batch 40/938] loss_G: 2.511420, loss_D: 0.248225\n",
      "[Epoch 74/200] [Batch 50/938] loss_G: 2.767760, loss_D: 0.264996\n",
      "[Epoch 74/200] [Batch 60/938] loss_G: 2.827419, loss_D: 0.249518\n",
      "[Epoch 74/200] [Batch 70/938] loss_G: 2.353061, loss_D: 0.211055\n",
      "[Epoch 74/200] [Batch 80/938] loss_G: 2.986918, loss_D: 0.232614\n",
      "[Epoch 74/200] [Batch 90/938] loss_G: 2.552043, loss_D: 0.197661\n",
      "[Epoch 74/200] [Batch 100/938] loss_G: 2.800804, loss_D: 0.274456\n",
      "[Epoch 74/200] [Batch 110/938] loss_G: 2.726789, loss_D: 0.157513\n",
      "[Epoch 74/200] [Batch 120/938] loss_G: 3.059594, loss_D: 0.273411\n",
      "[Epoch 74/200] [Batch 130/938] loss_G: 2.693859, loss_D: 0.180797\n",
      "[Epoch 74/200] [Batch 140/938] loss_G: 2.754137, loss_D: 0.215716\n",
      "[Epoch 74/200] [Batch 150/938] loss_G: 2.654998, loss_D: 0.186545\n",
      "[Epoch 74/200] [Batch 160/938] loss_G: 2.823520, loss_D: 0.208903\n",
      "[Epoch 74/200] [Batch 170/938] loss_G: 2.750103, loss_D: 0.256019\n",
      "[Epoch 74/200] [Batch 180/938] loss_G: 3.275651, loss_D: 0.186235\n",
      "[Epoch 74/200] [Batch 190/938] loss_G: 2.530610, loss_D: 0.180205\n",
      "[Epoch 74/200] [Batch 200/938] loss_G: 2.632854, loss_D: 0.262828\n",
      "[Epoch 74/200] [Batch 210/938] loss_G: 2.472907, loss_D: 0.206961\n",
      "[Epoch 74/200] [Batch 220/938] loss_G: 2.858977, loss_D: 0.209531\n",
      "[Epoch 74/200] [Batch 230/938] loss_G: 2.957878, loss_D: 0.162643\n",
      "[Epoch 74/200] [Batch 240/938] loss_G: 2.988285, loss_D: 0.196422\n",
      "[Epoch 74/200] [Batch 250/938] loss_G: 2.538397, loss_D: 0.218624\n",
      "[Epoch 74/200] [Batch 260/938] loss_G: 2.936457, loss_D: 0.237019\n",
      "[Epoch 74/200] [Batch 270/938] loss_G: 2.771583, loss_D: 0.167265\n",
      "[Epoch 74/200] [Batch 280/938] loss_G: 2.689742, loss_D: 0.253792\n",
      "[Epoch 74/200] [Batch 290/938] loss_G: 2.967975, loss_D: 0.259688\n",
      "[Epoch 74/200] [Batch 300/938] loss_G: 2.839421, loss_D: 0.167182\n",
      "[Epoch 74/200] [Batch 310/938] loss_G: 3.086692, loss_D: 0.220802\n",
      "[Epoch 74/200] [Batch 320/938] loss_G: 2.921246, loss_D: 0.181367\n",
      "[Epoch 74/200] [Batch 330/938] loss_G: 2.698978, loss_D: 0.278444\n",
      "[Epoch 74/200] [Batch 340/938] loss_G: 2.824895, loss_D: 0.248997\n",
      "[Epoch 74/200] [Batch 350/938] loss_G: 3.084419, loss_D: 0.170809\n",
      "[Epoch 74/200] [Batch 360/938] loss_G: 2.489652, loss_D: 0.256744\n",
      "[Epoch 74/200] [Batch 370/938] loss_G: 2.565023, loss_D: 0.226908\n",
      "[Epoch 74/200] [Batch 380/938] loss_G: 2.882394, loss_D: 0.329658\n",
      "[Epoch 74/200] [Batch 390/938] loss_G: 2.617810, loss_D: 0.229575\n",
      "[Epoch 74/200] [Batch 400/938] loss_G: 2.909522, loss_D: 0.197848\n",
      "[Epoch 74/200] [Batch 410/938] loss_G: 2.721893, loss_D: 0.184239\n",
      "[Epoch 74/200] [Batch 420/938] loss_G: 2.846259, loss_D: 0.270015\n",
      "[Epoch 74/200] [Batch 430/938] loss_G: 2.749476, loss_D: 0.182601\n",
      "[Epoch 74/200] [Batch 440/938] loss_G: 3.175873, loss_D: 0.191601\n",
      "[Epoch 74/200] [Batch 450/938] loss_G: 3.048956, loss_D: 0.261254\n",
      "[Epoch 74/200] [Batch 460/938] loss_G: 3.276103, loss_D: 0.196273\n",
      "[Epoch 74/200] [Batch 470/938] loss_G: 2.589653, loss_D: 0.155548\n",
      "[Epoch 74/200] [Batch 480/938] loss_G: 3.226974, loss_D: 0.230117\n",
      "[Epoch 74/200] [Batch 490/938] loss_G: 2.795258, loss_D: 0.258752\n",
      "[Epoch 74/200] [Batch 500/938] loss_G: 2.850370, loss_D: 0.264662\n",
      "[Epoch 74/200] [Batch 510/938] loss_G: 2.785570, loss_D: 0.248899\n",
      "[Epoch 74/200] [Batch 520/938] loss_G: 2.814569, loss_D: 0.270514\n",
      "[Epoch 74/200] [Batch 530/938] loss_G: 2.710515, loss_D: 0.227625\n",
      "[Epoch 74/200] [Batch 540/938] loss_G: 2.794213, loss_D: 0.283148\n",
      "[Epoch 74/200] [Batch 550/938] loss_G: 2.814972, loss_D: 0.145267\n",
      "[Epoch 74/200] [Batch 560/938] loss_G: 2.741690, loss_D: 0.219385\n",
      "[Epoch 74/200] [Batch 570/938] loss_G: 2.611748, loss_D: 0.280245\n",
      "[Epoch 74/200] [Batch 580/938] loss_G: 3.101185, loss_D: 0.180785\n",
      "[Epoch 74/200] [Batch 590/938] loss_G: 3.114003, loss_D: 0.257490\n",
      "[Epoch 74/200] [Batch 600/938] loss_G: 3.091162, loss_D: 0.276682\n",
      "[Epoch 74/200] [Batch 610/938] loss_G: 2.564677, loss_D: 0.178614\n",
      "[Epoch 74/200] [Batch 620/938] loss_G: 2.562398, loss_D: 0.207202\n",
      "[Epoch 74/200] [Batch 630/938] loss_G: 2.861280, loss_D: 0.184450\n",
      "[Epoch 74/200] [Batch 640/938] loss_G: 2.759053, loss_D: 0.217863\n",
      "[Epoch 74/200] [Batch 650/938] loss_G: 2.970539, loss_D: 0.188501\n",
      "[Epoch 74/200] [Batch 660/938] loss_G: 2.835798, loss_D: 0.255532\n",
      "[Epoch 74/200] [Batch 670/938] loss_G: 3.382110, loss_D: 0.269531\n",
      "[Epoch 74/200] [Batch 680/938] loss_G: 2.674309, loss_D: 0.221332\n",
      "[Epoch 74/200] [Batch 690/938] loss_G: 2.836312, loss_D: 0.263494\n",
      "[Epoch 74/200] [Batch 700/938] loss_G: 2.814076, loss_D: 0.163894\n",
      "[Epoch 74/200] [Batch 710/938] loss_G: 2.866851, loss_D: 0.247257\n",
      "[Epoch 74/200] [Batch 720/938] loss_G: 2.974578, loss_D: 0.277295\n",
      "[Epoch 74/200] [Batch 730/938] loss_G: 2.406657, loss_D: 0.211265\n",
      "[Epoch 74/200] [Batch 740/938] loss_G: 2.427259, loss_D: 0.245174\n",
      "[Epoch 74/200] [Batch 750/938] loss_G: 2.655172, loss_D: 0.189580\n",
      "[Epoch 74/200] [Batch 760/938] loss_G: 3.060719, loss_D: 0.193260\n",
      "[Epoch 74/200] [Batch 770/938] loss_G: 2.752967, loss_D: 0.249111\n",
      "[Epoch 74/200] [Batch 780/938] loss_G: 2.631474, loss_D: 0.221020\n",
      "[Epoch 74/200] [Batch 790/938] loss_G: 2.966118, loss_D: 0.234037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 74/200] [Batch 800/938] loss_G: 2.460332, loss_D: 0.229575\n",
      "[Epoch 74/200] [Batch 810/938] loss_G: 2.421393, loss_D: 0.267894\n",
      "[Epoch 74/200] [Batch 820/938] loss_G: 2.793099, loss_D: 0.244575\n",
      "[Epoch 74/200] [Batch 830/938] loss_G: 2.981244, loss_D: 0.270014\n",
      "[Epoch 74/200] [Batch 840/938] loss_G: 3.124688, loss_D: 0.180444\n",
      "[Epoch 74/200] [Batch 850/938] loss_G: 2.906263, loss_D: 0.199636\n",
      "[Epoch 74/200] [Batch 860/938] loss_G: 3.029012, loss_D: 0.170343\n",
      "[Epoch 74/200] [Batch 870/938] loss_G: 3.020028, loss_D: 0.235522\n",
      "[Epoch 74/200] [Batch 880/938] loss_G: 3.030380, loss_D: 0.333721\n",
      "[Epoch 74/200] [Batch 890/938] loss_G: 2.638200, loss_D: 0.197319\n",
      "[Epoch 74/200] [Batch 900/938] loss_G: 2.957030, loss_D: 0.273253\n",
      "[Epoch 74/200] [Batch 910/938] loss_G: 2.636762, loss_D: 0.236970\n",
      "[Epoch 74/200] [Batch 920/938] loss_G: 2.923916, loss_D: 0.168738\n",
      "[Epoch 74/200] [Batch 930/938] loss_G: 2.753166, loss_D: 0.185817\n",
      "[Epoch 75/200] [Batch 0/938] loss_G: 2.543319, loss_D: 0.270515\n",
      "[Epoch 75/200] [Batch 10/938] loss_G: 2.887498, loss_D: 0.248125\n",
      "[Epoch 75/200] [Batch 20/938] loss_G: 2.836861, loss_D: 0.242248\n",
      "[Epoch 75/200] [Batch 30/938] loss_G: 2.994648, loss_D: 0.168622\n",
      "[Epoch 75/200] [Batch 40/938] loss_G: 2.944615, loss_D: 0.188533\n",
      "[Epoch 75/200] [Batch 50/938] loss_G: 2.738778, loss_D: 0.212664\n",
      "[Epoch 75/200] [Batch 60/938] loss_G: 3.148494, loss_D: 0.290730\n",
      "[Epoch 75/200] [Batch 70/938] loss_G: 2.577761, loss_D: 0.253820\n",
      "[Epoch 75/200] [Batch 80/938] loss_G: 2.956576, loss_D: 0.246943\n",
      "[Epoch 75/200] [Batch 90/938] loss_G: 3.185315, loss_D: 0.220558\n",
      "[Epoch 75/200] [Batch 100/938] loss_G: 2.840300, loss_D: 0.292760\n",
      "[Epoch 75/200] [Batch 110/938] loss_G: 2.441531, loss_D: 0.199170\n",
      "[Epoch 75/200] [Batch 120/938] loss_G: 2.799103, loss_D: 0.224726\n",
      "[Epoch 75/200] [Batch 130/938] loss_G: 2.569209, loss_D: 0.283475\n",
      "[Epoch 75/200] [Batch 140/938] loss_G: 2.563773, loss_D: 0.255511\n",
      "[Epoch 75/200] [Batch 150/938] loss_G: 3.173457, loss_D: 0.241755\n",
      "[Epoch 75/200] [Batch 160/938] loss_G: 2.727600, loss_D: 0.233961\n",
      "[Epoch 75/200] [Batch 170/938] loss_G: 2.495885, loss_D: 0.256501\n",
      "[Epoch 75/200] [Batch 180/938] loss_G: 3.010983, loss_D: 0.203635\n",
      "[Epoch 75/200] [Batch 190/938] loss_G: 2.734975, loss_D: 0.335364\n",
      "[Epoch 75/200] [Batch 200/938] loss_G: 3.105981, loss_D: 0.157556\n",
      "[Epoch 75/200] [Batch 210/938] loss_G: 3.059907, loss_D: 0.238192\n",
      "[Epoch 75/200] [Batch 220/938] loss_G: 3.032292, loss_D: 0.292639\n",
      "[Epoch 75/200] [Batch 230/938] loss_G: 2.762174, loss_D: 0.239909\n",
      "[Epoch 75/200] [Batch 240/938] loss_G: 2.898619, loss_D: 0.220039\n",
      "[Epoch 75/200] [Batch 250/938] loss_G: 2.982942, loss_D: 0.197028\n",
      "[Epoch 75/200] [Batch 260/938] loss_G: 2.564685, loss_D: 0.148420\n",
      "[Epoch 75/200] [Batch 270/938] loss_G: 2.887159, loss_D: 0.228203\n",
      "[Epoch 75/200] [Batch 280/938] loss_G: 2.786310, loss_D: 0.114887\n",
      "[Epoch 75/200] [Batch 290/938] loss_G: 2.967002, loss_D: 0.162935\n",
      "[Epoch 75/200] [Batch 300/938] loss_G: 2.414394, loss_D: 0.195800\n",
      "[Epoch 75/200] [Batch 310/938] loss_G: 2.907588, loss_D: 0.224594\n",
      "[Epoch 75/200] [Batch 320/938] loss_G: 3.093719, loss_D: 0.200616\n",
      "[Epoch 75/200] [Batch 330/938] loss_G: 2.688339, loss_D: 0.212594\n",
      "[Epoch 75/200] [Batch 340/938] loss_G: 2.977941, loss_D: 0.182810\n",
      "[Epoch 75/200] [Batch 350/938] loss_G: 2.663280, loss_D: 0.311261\n",
      "[Epoch 75/200] [Batch 360/938] loss_G: 2.927619, loss_D: 0.177902\n",
      "[Epoch 75/200] [Batch 370/938] loss_G: 3.126828, loss_D: 0.248529\n",
      "[Epoch 75/200] [Batch 380/938] loss_G: 2.871749, loss_D: 0.135414\n",
      "[Epoch 75/200] [Batch 390/938] loss_G: 2.837184, loss_D: 0.171255\n",
      "[Epoch 75/200] [Batch 400/938] loss_G: 2.850344, loss_D: 0.198228\n",
      "[Epoch 75/200] [Batch 410/938] loss_G: 2.777182, loss_D: 0.152512\n",
      "[Epoch 75/200] [Batch 420/938] loss_G: 2.849038, loss_D: 0.202439\n",
      "[Epoch 75/200] [Batch 430/938] loss_G: 3.189451, loss_D: 0.204898\n",
      "[Epoch 75/200] [Batch 440/938] loss_G: 3.134696, loss_D: 0.171954\n",
      "[Epoch 75/200] [Batch 450/938] loss_G: 3.072132, loss_D: 0.274971\n",
      "[Epoch 75/200] [Batch 460/938] loss_G: 2.869721, loss_D: 0.149094\n",
      "[Epoch 75/200] [Batch 470/938] loss_G: 3.050824, loss_D: 0.195310\n",
      "[Epoch 75/200] [Batch 480/938] loss_G: 2.861725, loss_D: 0.210412\n",
      "[Epoch 75/200] [Batch 490/938] loss_G: 2.615380, loss_D: 0.233898\n",
      "[Epoch 75/200] [Batch 500/938] loss_G: 2.977622, loss_D: 0.229237\n",
      "[Epoch 75/200] [Batch 510/938] loss_G: 2.821109, loss_D: 0.342106\n",
      "[Epoch 75/200] [Batch 520/938] loss_G: 2.919954, loss_D: 0.350580\n",
      "[Epoch 75/200] [Batch 530/938] loss_G: 2.652343, loss_D: 0.258019\n",
      "[Epoch 75/200] [Batch 540/938] loss_G: 2.793891, loss_D: 0.213528\n",
      "[Epoch 75/200] [Batch 550/938] loss_G: 2.897282, loss_D: 0.135270\n",
      "[Epoch 75/200] [Batch 560/938] loss_G: 2.779704, loss_D: 0.289443\n",
      "[Epoch 75/200] [Batch 570/938] loss_G: 2.569365, loss_D: 0.194120\n",
      "[Epoch 75/200] [Batch 580/938] loss_G: 3.074365, loss_D: 0.198983\n",
      "[Epoch 75/200] [Batch 590/938] loss_G: 2.845978, loss_D: 0.189999\n",
      "[Epoch 75/200] [Batch 600/938] loss_G: 2.853466, loss_D: 0.264161\n",
      "[Epoch 75/200] [Batch 610/938] loss_G: 2.474873, loss_D: 0.205293\n",
      "[Epoch 75/200] [Batch 620/938] loss_G: 2.749668, loss_D: 0.184240\n",
      "[Epoch 75/200] [Batch 630/938] loss_G: 2.776017, loss_D: 0.211180\n",
      "[Epoch 75/200] [Batch 640/938] loss_G: 3.151641, loss_D: 0.163277\n",
      "[Epoch 75/200] [Batch 650/938] loss_G: 2.782639, loss_D: 0.222348\n",
      "[Epoch 75/200] [Batch 660/938] loss_G: 2.929524, loss_D: 0.231043\n",
      "[Epoch 75/200] [Batch 670/938] loss_G: 2.997858, loss_D: 0.154994\n",
      "[Epoch 75/200] [Batch 680/938] loss_G: 2.381340, loss_D: 0.184389\n",
      "[Epoch 75/200] [Batch 690/938] loss_G: 2.711814, loss_D: 0.232365\n",
      "[Epoch 75/200] [Batch 700/938] loss_G: 2.920178, loss_D: 0.199465\n",
      "[Epoch 75/200] [Batch 710/938] loss_G: 2.649918, loss_D: 0.181589\n",
      "[Epoch 75/200] [Batch 720/938] loss_G: 3.301770, loss_D: 0.191665\n",
      "[Epoch 75/200] [Batch 730/938] loss_G: 2.818017, loss_D: 0.187655\n",
      "[Epoch 75/200] [Batch 740/938] loss_G: 3.137497, loss_D: 0.259458\n",
      "[Epoch 75/200] [Batch 750/938] loss_G: 2.441695, loss_D: 0.348212\n",
      "[Epoch 75/200] [Batch 760/938] loss_G: 3.035977, loss_D: 0.135210\n",
      "[Epoch 75/200] [Batch 770/938] loss_G: 3.005520, loss_D: 0.211831\n",
      "[Epoch 75/200] [Batch 780/938] loss_G: 2.577468, loss_D: 0.190686\n",
      "[Epoch 75/200] [Batch 790/938] loss_G: 2.803545, loss_D: 0.223905\n",
      "[Epoch 75/200] [Batch 800/938] loss_G: 2.724804, loss_D: 0.263889\n",
      "[Epoch 75/200] [Batch 810/938] loss_G: 3.105908, loss_D: 0.123876\n",
      "[Epoch 75/200] [Batch 820/938] loss_G: 2.920173, loss_D: 0.216627\n",
      "[Epoch 75/200] [Batch 830/938] loss_G: 3.004771, loss_D: 0.194732\n",
      "[Epoch 75/200] [Batch 840/938] loss_G: 2.957231, loss_D: 0.200782\n",
      "[Epoch 75/200] [Batch 850/938] loss_G: 2.781975, loss_D: 0.207880\n",
      "[Epoch 75/200] [Batch 860/938] loss_G: 2.662160, loss_D: 0.209933\n",
      "[Epoch 75/200] [Batch 870/938] loss_G: 2.921339, loss_D: 0.186729\n",
      "[Epoch 75/200] [Batch 880/938] loss_G: 2.569659, loss_D: 0.165372\n",
      "[Epoch 75/200] [Batch 890/938] loss_G: 3.089477, loss_D: 0.334730\n",
      "[Epoch 75/200] [Batch 900/938] loss_G: 2.710260, loss_D: 0.257552\n",
      "[Epoch 75/200] [Batch 910/938] loss_G: 2.971444, loss_D: 0.163769\n",
      "[Epoch 75/200] [Batch 920/938] loss_G: 2.858121, loss_D: 0.205765\n",
      "[Epoch 75/200] [Batch 930/938] loss_G: 2.965768, loss_D: 0.225920\n",
      "[Epoch 76/200] [Batch 0/938] loss_G: 2.845020, loss_D: 0.244981\n",
      "[Epoch 76/200] [Batch 10/938] loss_G: 2.679652, loss_D: 0.208292\n",
      "[Epoch 76/200] [Batch 20/938] loss_G: 2.798867, loss_D: 0.246492\n",
      "[Epoch 76/200] [Batch 30/938] loss_G: 3.203717, loss_D: 0.130052\n",
      "[Epoch 76/200] [Batch 40/938] loss_G: 2.784983, loss_D: 0.169627\n",
      "[Epoch 76/200] [Batch 50/938] loss_G: 2.934887, loss_D: 0.259042\n",
      "[Epoch 76/200] [Batch 60/938] loss_G: 2.772087, loss_D: 0.198028\n",
      "[Epoch 76/200] [Batch 70/938] loss_G: 2.684732, loss_D: 0.238915\n",
      "[Epoch 76/200] [Batch 80/938] loss_G: 2.989688, loss_D: 0.230240\n",
      "[Epoch 76/200] [Batch 90/938] loss_G: 2.768748, loss_D: 0.196005\n",
      "[Epoch 76/200] [Batch 100/938] loss_G: 3.276584, loss_D: 0.194675\n",
      "[Epoch 76/200] [Batch 110/938] loss_G: 2.930235, loss_D: 0.169589\n",
      "[Epoch 76/200] [Batch 120/938] loss_G: 3.106893, loss_D: 0.153833\n",
      "[Epoch 76/200] [Batch 130/938] loss_G: 2.563762, loss_D: 0.236731\n",
      "[Epoch 76/200] [Batch 140/938] loss_G: 3.044769, loss_D: 0.174000\n",
      "[Epoch 76/200] [Batch 150/938] loss_G: 3.076407, loss_D: 0.183781\n",
      "[Epoch 76/200] [Batch 160/938] loss_G: 2.884434, loss_D: 0.245885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 76/200] [Batch 170/938] loss_G: 2.735490, loss_D: 0.187933\n",
      "[Epoch 76/200] [Batch 180/938] loss_G: 2.980931, loss_D: 0.179288\n",
      "[Epoch 76/200] [Batch 190/938] loss_G: 2.809320, loss_D: 0.188178\n",
      "[Epoch 76/200] [Batch 200/938] loss_G: 2.406498, loss_D: 0.301885\n",
      "[Epoch 76/200] [Batch 210/938] loss_G: 3.264049, loss_D: 0.155728\n",
      "[Epoch 76/200] [Batch 220/938] loss_G: 2.924148, loss_D: 0.185928\n",
      "[Epoch 76/200] [Batch 230/938] loss_G: 2.862964, loss_D: 0.220058\n",
      "[Epoch 76/200] [Batch 240/938] loss_G: 3.283824, loss_D: 0.210481\n",
      "[Epoch 76/200] [Batch 250/938] loss_G: 2.606236, loss_D: 0.190353\n",
      "[Epoch 76/200] [Batch 260/938] loss_G: 2.894191, loss_D: 0.208096\n",
      "[Epoch 76/200] [Batch 270/938] loss_G: 2.866228, loss_D: 0.162742\n",
      "[Epoch 76/200] [Batch 280/938] loss_G: 2.396479, loss_D: 0.313710\n",
      "[Epoch 76/200] [Batch 290/938] loss_G: 2.937345, loss_D: 0.178189\n",
      "[Epoch 76/200] [Batch 300/938] loss_G: 2.450500, loss_D: 0.206843\n",
      "[Epoch 76/200] [Batch 310/938] loss_G: 2.759748, loss_D: 0.196577\n",
      "[Epoch 76/200] [Batch 320/938] loss_G: 2.673341, loss_D: 0.257901\n",
      "[Epoch 76/200] [Batch 330/938] loss_G: 2.822169, loss_D: 0.219627\n",
      "[Epoch 76/200] [Batch 340/938] loss_G: 3.051889, loss_D: 0.258470\n",
      "[Epoch 76/200] [Batch 350/938] loss_G: 2.435805, loss_D: 0.148974\n",
      "[Epoch 76/200] [Batch 360/938] loss_G: 2.803553, loss_D: 0.185151\n",
      "[Epoch 76/200] [Batch 370/938] loss_G: 2.794407, loss_D: 0.159320\n",
      "[Epoch 76/200] [Batch 380/938] loss_G: 3.094254, loss_D: 0.187168\n",
      "[Epoch 76/200] [Batch 390/938] loss_G: 2.654979, loss_D: 0.174007\n",
      "[Epoch 76/200] [Batch 400/938] loss_G: 3.104438, loss_D: 0.148199\n",
      "[Epoch 76/200] [Batch 410/938] loss_G: 3.060566, loss_D: 0.177664\n",
      "[Epoch 76/200] [Batch 420/938] loss_G: 3.166689, loss_D: 0.227700\n",
      "[Epoch 76/200] [Batch 430/938] loss_G: 2.660351, loss_D: 0.278040\n",
      "[Epoch 76/200] [Batch 440/938] loss_G: 3.065811, loss_D: 0.244045\n",
      "[Epoch 76/200] [Batch 450/938] loss_G: 2.552015, loss_D: 0.275761\n",
      "[Epoch 76/200] [Batch 460/938] loss_G: 2.954836, loss_D: 0.292967\n",
      "[Epoch 76/200] [Batch 470/938] loss_G: 2.883466, loss_D: 0.185669\n",
      "[Epoch 76/200] [Batch 480/938] loss_G: 2.868317, loss_D: 0.303834\n",
      "[Epoch 76/200] [Batch 490/938] loss_G: 2.936653, loss_D: 0.168928\n",
      "[Epoch 76/200] [Batch 500/938] loss_G: 2.783536, loss_D: 0.281122\n",
      "[Epoch 76/200] [Batch 510/938] loss_G: 2.810629, loss_D: 0.259707\n",
      "[Epoch 76/200] [Batch 520/938] loss_G: 3.067366, loss_D: 0.142810\n",
      "[Epoch 76/200] [Batch 530/938] loss_G: 2.516046, loss_D: 0.189153\n",
      "[Epoch 76/200] [Batch 540/938] loss_G: 2.903212, loss_D: 0.208243\n",
      "[Epoch 76/200] [Batch 550/938] loss_G: 2.728636, loss_D: 0.169335\n",
      "[Epoch 76/200] [Batch 560/938] loss_G: 2.751775, loss_D: 0.232268\n",
      "[Epoch 76/200] [Batch 570/938] loss_G: 2.717413, loss_D: 0.229621\n",
      "[Epoch 76/200] [Batch 580/938] loss_G: 3.003589, loss_D: 0.218484\n",
      "[Epoch 76/200] [Batch 590/938] loss_G: 3.106545, loss_D: 0.237948\n",
      "[Epoch 76/200] [Batch 600/938] loss_G: 2.836459, loss_D: 0.160597\n",
      "[Epoch 76/200] [Batch 610/938] loss_G: 3.383675, loss_D: 0.230481\n",
      "[Epoch 76/200] [Batch 620/938] loss_G: 3.167704, loss_D: 0.299009\n",
      "[Epoch 76/200] [Batch 630/938] loss_G: 2.826882, loss_D: 0.181785\n",
      "[Epoch 76/200] [Batch 640/938] loss_G: 2.941400, loss_D: 0.245365\n",
      "[Epoch 76/200] [Batch 650/938] loss_G: 2.913912, loss_D: 0.314490\n",
      "[Epoch 76/200] [Batch 660/938] loss_G: 2.864549, loss_D: 0.202673\n",
      "[Epoch 76/200] [Batch 670/938] loss_G: 2.705372, loss_D: 0.243081\n",
      "[Epoch 76/200] [Batch 680/938] loss_G: 3.178854, loss_D: 0.266721\n",
      "[Epoch 76/200] [Batch 690/938] loss_G: 2.652794, loss_D: 0.209449\n",
      "[Epoch 76/200] [Batch 700/938] loss_G: 2.985085, loss_D: 0.202917\n",
      "[Epoch 76/200] [Batch 710/938] loss_G: 3.310587, loss_D: 0.206345\n",
      "[Epoch 76/200] [Batch 720/938] loss_G: 2.899016, loss_D: 0.211805\n",
      "[Epoch 76/200] [Batch 730/938] loss_G: 2.936687, loss_D: 0.173609\n",
      "[Epoch 76/200] [Batch 740/938] loss_G: 3.056559, loss_D: 0.158188\n",
      "[Epoch 76/200] [Batch 750/938] loss_G: 2.819732, loss_D: 0.141050\n",
      "[Epoch 76/200] [Batch 760/938] loss_G: 2.831632, loss_D: 0.305040\n",
      "[Epoch 76/200] [Batch 770/938] loss_G: 3.197902, loss_D: 0.143464\n",
      "[Epoch 76/200] [Batch 780/938] loss_G: 3.011867, loss_D: 0.192640\n",
      "[Epoch 76/200] [Batch 790/938] loss_G: 3.548278, loss_D: 0.147718\n",
      "[Epoch 76/200] [Batch 800/938] loss_G: 2.894295, loss_D: 0.281288\n",
      "[Epoch 76/200] [Batch 810/938] loss_G: 2.926679, loss_D: 0.163921\n",
      "[Epoch 76/200] [Batch 820/938] loss_G: 2.791606, loss_D: 0.224667\n",
      "[Epoch 76/200] [Batch 830/938] loss_G: 3.289052, loss_D: 0.171866\n",
      "[Epoch 76/200] [Batch 840/938] loss_G: 3.008059, loss_D: 0.185481\n",
      "[Epoch 76/200] [Batch 850/938] loss_G: 2.814994, loss_D: 0.158972\n",
      "[Epoch 76/200] [Batch 860/938] loss_G: 2.767593, loss_D: 0.248636\n",
      "[Epoch 76/200] [Batch 870/938] loss_G: 2.810643, loss_D: 0.192948\n",
      "[Epoch 76/200] [Batch 880/938] loss_G: 2.745139, loss_D: 0.165912\n",
      "[Epoch 76/200] [Batch 890/938] loss_G: 3.094308, loss_D: 0.180663\n",
      "[Epoch 76/200] [Batch 900/938] loss_G: 2.684441, loss_D: 0.202622\n",
      "[Epoch 76/200] [Batch 910/938] loss_G: 2.667653, loss_D: 0.210736\n",
      "[Epoch 76/200] [Batch 920/938] loss_G: 2.867573, loss_D: 0.274567\n",
      "[Epoch 76/200] [Batch 930/938] loss_G: 2.748211, loss_D: 0.260023\n",
      "[Epoch 77/200] [Batch 0/938] loss_G: 3.134645, loss_D: 0.201995\n",
      "[Epoch 77/200] [Batch 10/938] loss_G: 2.793225, loss_D: 0.240383\n",
      "[Epoch 77/200] [Batch 20/938] loss_G: 2.577476, loss_D: 0.273538\n",
      "[Epoch 77/200] [Batch 30/938] loss_G: 2.878210, loss_D: 0.228716\n",
      "[Epoch 77/200] [Batch 40/938] loss_G: 3.092693, loss_D: 0.220465\n",
      "[Epoch 77/200] [Batch 50/938] loss_G: 3.018791, loss_D: 0.170616\n",
      "[Epoch 77/200] [Batch 60/938] loss_G: 2.964702, loss_D: 0.152037\n",
      "[Epoch 77/200] [Batch 70/938] loss_G: 3.016840, loss_D: 0.154152\n",
      "[Epoch 77/200] [Batch 80/938] loss_G: 2.818652, loss_D: 0.166974\n",
      "[Epoch 77/200] [Batch 90/938] loss_G: 3.124099, loss_D: 0.201212\n",
      "[Epoch 77/200] [Batch 100/938] loss_G: 3.338817, loss_D: 0.256857\n",
      "[Epoch 77/200] [Batch 110/938] loss_G: 2.707034, loss_D: 0.206109\n",
      "[Epoch 77/200] [Batch 120/938] loss_G: 2.736761, loss_D: 0.218176\n",
      "[Epoch 77/200] [Batch 130/938] loss_G: 3.019902, loss_D: 0.204799\n",
      "[Epoch 77/200] [Batch 140/938] loss_G: 2.753056, loss_D: 0.153105\n",
      "[Epoch 77/200] [Batch 150/938] loss_G: 3.010610, loss_D: 0.222834\n",
      "[Epoch 77/200] [Batch 160/938] loss_G: 2.681012, loss_D: 0.264205\n",
      "[Epoch 77/200] [Batch 170/938] loss_G: 3.127227, loss_D: 0.237673\n",
      "[Epoch 77/200] [Batch 180/938] loss_G: 2.459390, loss_D: 0.257341\n",
      "[Epoch 77/200] [Batch 190/938] loss_G: 3.290614, loss_D: 0.209376\n",
      "[Epoch 77/200] [Batch 200/938] loss_G: 2.820983, loss_D: 0.179475\n",
      "[Epoch 77/200] [Batch 210/938] loss_G: 2.985761, loss_D: 0.307125\n",
      "[Epoch 77/200] [Batch 220/938] loss_G: 2.719105, loss_D: 0.213576\n",
      "[Epoch 77/200] [Batch 230/938] loss_G: 3.118793, loss_D: 0.217087\n",
      "[Epoch 77/200] [Batch 240/938] loss_G: 2.686730, loss_D: 0.187276\n",
      "[Epoch 77/200] [Batch 250/938] loss_G: 3.081440, loss_D: 0.214958\n",
      "[Epoch 77/200] [Batch 260/938] loss_G: 2.703372, loss_D: 0.205958\n",
      "[Epoch 77/200] [Batch 270/938] loss_G: 2.402280, loss_D: 0.198274\n",
      "[Epoch 77/200] [Batch 280/938] loss_G: 3.057185, loss_D: 0.206301\n",
      "[Epoch 77/200] [Batch 290/938] loss_G: 2.919197, loss_D: 0.287964\n",
      "[Epoch 77/200] [Batch 300/938] loss_G: 2.685585, loss_D: 0.252001\n",
      "[Epoch 77/200] [Batch 310/938] loss_G: 2.944264, loss_D: 0.192899\n",
      "[Epoch 77/200] [Batch 320/938] loss_G: 3.167205, loss_D: 0.123846\n",
      "[Epoch 77/200] [Batch 330/938] loss_G: 2.738523, loss_D: 0.164111\n",
      "[Epoch 77/200] [Batch 340/938] loss_G: 2.986506, loss_D: 0.188727\n",
      "[Epoch 77/200] [Batch 350/938] loss_G: 3.229459, loss_D: 0.110713\n",
      "[Epoch 77/200] [Batch 360/938] loss_G: 2.581224, loss_D: 0.206231\n",
      "[Epoch 77/200] [Batch 370/938] loss_G: 3.108012, loss_D: 0.211805\n",
      "[Epoch 77/200] [Batch 380/938] loss_G: 2.757131, loss_D: 0.215331\n",
      "[Epoch 77/200] [Batch 390/938] loss_G: 2.857427, loss_D: 0.201760\n",
      "[Epoch 77/200] [Batch 400/938] loss_G: 2.580699, loss_D: 0.291305\n",
      "[Epoch 77/200] [Batch 410/938] loss_G: 3.070089, loss_D: 0.228577\n",
      "[Epoch 77/200] [Batch 420/938] loss_G: 3.002043, loss_D: 0.110422\n",
      "[Epoch 77/200] [Batch 430/938] loss_G: 3.262352, loss_D: 0.156898\n",
      "[Epoch 77/200] [Batch 440/938] loss_G: 2.626683, loss_D: 0.302313\n",
      "[Epoch 77/200] [Batch 450/938] loss_G: 3.068766, loss_D: 0.169863\n",
      "[Epoch 77/200] [Batch 460/938] loss_G: 2.710416, loss_D: 0.212452\n",
      "[Epoch 77/200] [Batch 470/938] loss_G: 3.291722, loss_D: 0.130448\n",
      "[Epoch 77/200] [Batch 480/938] loss_G: 2.871033, loss_D: 0.211240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 77/200] [Batch 490/938] loss_G: 2.757868, loss_D: 0.208613\n",
      "[Epoch 77/200] [Batch 500/938] loss_G: 2.657631, loss_D: 0.235971\n",
      "[Epoch 77/200] [Batch 510/938] loss_G: 3.276339, loss_D: 0.149915\n",
      "[Epoch 77/200] [Batch 520/938] loss_G: 2.824499, loss_D: 0.294049\n",
      "[Epoch 77/200] [Batch 530/938] loss_G: 2.808218, loss_D: 0.191221\n",
      "[Epoch 77/200] [Batch 540/938] loss_G: 2.785410, loss_D: 0.207300\n",
      "[Epoch 77/200] [Batch 550/938] loss_G: 2.897405, loss_D: 0.206250\n",
      "[Epoch 77/200] [Batch 560/938] loss_G: 2.745190, loss_D: 0.244060\n",
      "[Epoch 77/200] [Batch 570/938] loss_G: 3.155878, loss_D: 0.176514\n",
      "[Epoch 77/200] [Batch 580/938] loss_G: 3.063144, loss_D: 0.206937\n",
      "[Epoch 77/200] [Batch 590/938] loss_G: 3.095725, loss_D: 0.184853\n",
      "[Epoch 77/200] [Batch 600/938] loss_G: 3.099429, loss_D: 0.183933\n",
      "[Epoch 77/200] [Batch 610/938] loss_G: 2.822738, loss_D: 0.221238\n",
      "[Epoch 77/200] [Batch 620/938] loss_G: 2.855827, loss_D: 0.272788\n",
      "[Epoch 77/200] [Batch 630/938] loss_G: 2.986329, loss_D: 0.219875\n",
      "[Epoch 77/200] [Batch 640/938] loss_G: 2.907472, loss_D: 0.245133\n",
      "[Epoch 77/200] [Batch 650/938] loss_G: 2.452346, loss_D: 0.214089\n",
      "[Epoch 77/200] [Batch 660/938] loss_G: 2.723310, loss_D: 0.232191\n",
      "[Epoch 77/200] [Batch 670/938] loss_G: 2.952546, loss_D: 0.264424\n",
      "[Epoch 77/200] [Batch 680/938] loss_G: 2.564819, loss_D: 0.158210\n",
      "[Epoch 77/200] [Batch 690/938] loss_G: 3.181512, loss_D: 0.202028\n",
      "[Epoch 77/200] [Batch 700/938] loss_G: 2.869462, loss_D: 0.230055\n",
      "[Epoch 77/200] [Batch 710/938] loss_G: 3.254340, loss_D: 0.125555\n",
      "[Epoch 77/200] [Batch 720/938] loss_G: 2.954372, loss_D: 0.211736\n",
      "[Epoch 77/200] [Batch 730/938] loss_G: 2.907145, loss_D: 0.188484\n",
      "[Epoch 77/200] [Batch 740/938] loss_G: 2.865993, loss_D: 0.167133\n",
      "[Epoch 77/200] [Batch 750/938] loss_G: 2.903791, loss_D: 0.246732\n",
      "[Epoch 77/200] [Batch 760/938] loss_G: 2.651965, loss_D: 0.209110\n",
      "[Epoch 77/200] [Batch 770/938] loss_G: 2.971659, loss_D: 0.266558\n",
      "[Epoch 77/200] [Batch 780/938] loss_G: 3.301218, loss_D: 0.198648\n",
      "[Epoch 77/200] [Batch 790/938] loss_G: 2.890665, loss_D: 0.216580\n",
      "[Epoch 77/200] [Batch 800/938] loss_G: 2.954223, loss_D: 0.245740\n",
      "[Epoch 77/200] [Batch 810/938] loss_G: 2.884949, loss_D: 0.258729\n",
      "[Epoch 77/200] [Batch 820/938] loss_G: 3.315001, loss_D: 0.189574\n",
      "[Epoch 77/200] [Batch 830/938] loss_G: 2.737965, loss_D: 0.264067\n",
      "[Epoch 77/200] [Batch 840/938] loss_G: 3.001872, loss_D: 0.271507\n",
      "[Epoch 77/200] [Batch 850/938] loss_G: 3.176260, loss_D: 0.218657\n",
      "[Epoch 77/200] [Batch 860/938] loss_G: 2.752679, loss_D: 0.204407\n",
      "[Epoch 77/200] [Batch 870/938] loss_G: 2.783776, loss_D: 0.200776\n",
      "[Epoch 77/200] [Batch 880/938] loss_G: 3.353336, loss_D: 0.275922\n",
      "[Epoch 77/200] [Batch 890/938] loss_G: 3.060814, loss_D: 0.304725\n",
      "[Epoch 77/200] [Batch 900/938] loss_G: 2.698812, loss_D: 0.191331\n",
      "[Epoch 77/200] [Batch 910/938] loss_G: 3.177520, loss_D: 0.232463\n",
      "[Epoch 77/200] [Batch 920/938] loss_G: 2.630249, loss_D: 0.294656\n",
      "[Epoch 77/200] [Batch 930/938] loss_G: 2.710772, loss_D: 0.184237\n",
      "[Epoch 78/200] [Batch 0/938] loss_G: 3.042125, loss_D: 0.237765\n",
      "[Epoch 78/200] [Batch 10/938] loss_G: 3.159027, loss_D: 0.248768\n",
      "[Epoch 78/200] [Batch 20/938] loss_G: 2.936068, loss_D: 0.174375\n",
      "[Epoch 78/200] [Batch 30/938] loss_G: 2.839107, loss_D: 0.223941\n",
      "[Epoch 78/200] [Batch 40/938] loss_G: 2.667590, loss_D: 0.279150\n",
      "[Epoch 78/200] [Batch 50/938] loss_G: 2.842746, loss_D: 0.225196\n",
      "[Epoch 78/200] [Batch 60/938] loss_G: 2.733901, loss_D: 0.298697\n",
      "[Epoch 78/200] [Batch 70/938] loss_G: 3.193272, loss_D: 0.132913\n",
      "[Epoch 78/200] [Batch 80/938] loss_G: 2.838094, loss_D: 0.174057\n",
      "[Epoch 78/200] [Batch 90/938] loss_G: 2.542983, loss_D: 0.241261\n",
      "[Epoch 78/200] [Batch 100/938] loss_G: 2.708959, loss_D: 0.224974\n",
      "[Epoch 78/200] [Batch 110/938] loss_G: 2.564865, loss_D: 0.265632\n",
      "[Epoch 78/200] [Batch 120/938] loss_G: 2.897855, loss_D: 0.237622\n",
      "[Epoch 78/200] [Batch 130/938] loss_G: 2.915290, loss_D: 0.209451\n",
      "[Epoch 78/200] [Batch 140/938] loss_G: 3.009899, loss_D: 0.159014\n",
      "[Epoch 78/200] [Batch 150/938] loss_G: 2.902596, loss_D: 0.242413\n",
      "[Epoch 78/200] [Batch 160/938] loss_G: 2.874739, loss_D: 0.186829\n",
      "[Epoch 78/200] [Batch 170/938] loss_G: 2.660619, loss_D: 0.217658\n",
      "[Epoch 78/200] [Batch 180/938] loss_G: 2.981355, loss_D: 0.172050\n",
      "[Epoch 78/200] [Batch 190/938] loss_G: 3.162980, loss_D: 0.163501\n",
      "[Epoch 78/200] [Batch 200/938] loss_G: 3.255725, loss_D: 0.204752\n",
      "[Epoch 78/200] [Batch 210/938] loss_G: 2.802424, loss_D: 0.207483\n",
      "[Epoch 78/200] [Batch 220/938] loss_G: 2.911269, loss_D: 0.201998\n",
      "[Epoch 78/200] [Batch 230/938] loss_G: 2.845167, loss_D: 0.269724\n",
      "[Epoch 78/200] [Batch 240/938] loss_G: 2.721276, loss_D: 0.162934\n",
      "[Epoch 78/200] [Batch 250/938] loss_G: 2.694128, loss_D: 0.158593\n",
      "[Epoch 78/200] [Batch 260/938] loss_G: 2.854306, loss_D: 0.171088\n",
      "[Epoch 78/200] [Batch 270/938] loss_G: 3.113142, loss_D: 0.181456\n",
      "[Epoch 78/200] [Batch 280/938] loss_G: 2.944816, loss_D: 0.238483\n",
      "[Epoch 78/200] [Batch 290/938] loss_G: 2.603103, loss_D: 0.168042\n",
      "[Epoch 78/200] [Batch 300/938] loss_G: 2.853534, loss_D: 0.170957\n",
      "[Epoch 78/200] [Batch 310/938] loss_G: 3.061267, loss_D: 0.138637\n",
      "[Epoch 78/200] [Batch 320/938] loss_G: 3.073122, loss_D: 0.208990\n",
      "[Epoch 78/200] [Batch 330/938] loss_G: 2.950270, loss_D: 0.144004\n",
      "[Epoch 78/200] [Batch 340/938] loss_G: 2.982039, loss_D: 0.175510\n",
      "[Epoch 78/200] [Batch 350/938] loss_G: 3.072249, loss_D: 0.163322\n",
      "[Epoch 78/200] [Batch 360/938] loss_G: 3.389387, loss_D: 0.178218\n",
      "[Epoch 78/200] [Batch 370/938] loss_G: 2.781758, loss_D: 0.195002\n",
      "[Epoch 78/200] [Batch 380/938] loss_G: 3.065665, loss_D: 0.227836\n",
      "[Epoch 78/200] [Batch 390/938] loss_G: 2.554947, loss_D: 0.212674\n",
      "[Epoch 78/200] [Batch 400/938] loss_G: 2.728852, loss_D: 0.253758\n",
      "[Epoch 78/200] [Batch 410/938] loss_G: 2.624752, loss_D: 0.211919\n",
      "[Epoch 78/200] [Batch 420/938] loss_G: 2.888865, loss_D: 0.260120\n",
      "[Epoch 78/200] [Batch 430/938] loss_G: 2.996283, loss_D: 0.161860\n",
      "[Epoch 78/200] [Batch 440/938] loss_G: 2.671479, loss_D: 0.133066\n",
      "[Epoch 78/200] [Batch 450/938] loss_G: 3.012104, loss_D: 0.175034\n",
      "[Epoch 78/200] [Batch 460/938] loss_G: 2.605836, loss_D: 0.220059\n",
      "[Epoch 78/200] [Batch 470/938] loss_G: 3.023293, loss_D: 0.129188\n",
      "[Epoch 78/200] [Batch 480/938] loss_G: 2.838822, loss_D: 0.151028\n",
      "[Epoch 78/200] [Batch 490/938] loss_G: 2.629768, loss_D: 0.284972\n",
      "[Epoch 78/200] [Batch 500/938] loss_G: 2.378928, loss_D: 0.220372\n",
      "[Epoch 78/200] [Batch 510/938] loss_G: 2.736675, loss_D: 0.189963\n",
      "[Epoch 78/200] [Batch 520/938] loss_G: 2.894751, loss_D: 0.209371\n",
      "[Epoch 78/200] [Batch 530/938] loss_G: 2.495406, loss_D: 0.294941\n",
      "[Epoch 78/200] [Batch 540/938] loss_G: 2.915159, loss_D: 0.203942\n",
      "[Epoch 78/200] [Batch 550/938] loss_G: 2.544757, loss_D: 0.209779\n",
      "[Epoch 78/200] [Batch 560/938] loss_G: 2.846117, loss_D: 0.271036\n",
      "[Epoch 78/200] [Batch 570/938] loss_G: 3.179312, loss_D: 0.210485\n",
      "[Epoch 78/200] [Batch 580/938] loss_G: 2.548399, loss_D: 0.239005\n",
      "[Epoch 78/200] [Batch 590/938] loss_G: 3.173913, loss_D: 0.210084\n",
      "[Epoch 78/200] [Batch 600/938] loss_G: 2.802963, loss_D: 0.180889\n",
      "[Epoch 78/200] [Batch 610/938] loss_G: 2.984701, loss_D: 0.251797\n",
      "[Epoch 78/200] [Batch 620/938] loss_G: 2.442525, loss_D: 0.153050\n",
      "[Epoch 78/200] [Batch 630/938] loss_G: 2.608801, loss_D: 0.311334\n",
      "[Epoch 78/200] [Batch 640/938] loss_G: 2.828964, loss_D: 0.229105\n",
      "[Epoch 78/200] [Batch 650/938] loss_G: 2.567288, loss_D: 0.333842\n",
      "[Epoch 78/200] [Batch 660/938] loss_G: 3.134198, loss_D: 0.241931\n",
      "[Epoch 78/200] [Batch 670/938] loss_G: 2.970031, loss_D: 0.264157\n",
      "[Epoch 78/200] [Batch 680/938] loss_G: 2.738302, loss_D: 0.189422\n",
      "[Epoch 78/200] [Batch 690/938] loss_G: 3.336968, loss_D: 0.170090\n",
      "[Epoch 78/200] [Batch 700/938] loss_G: 2.794236, loss_D: 0.230225\n",
      "[Epoch 78/200] [Batch 710/938] loss_G: 2.909070, loss_D: 0.224640\n",
      "[Epoch 78/200] [Batch 720/938] loss_G: 2.840081, loss_D: 0.174263\n",
      "[Epoch 78/200] [Batch 730/938] loss_G: 2.991301, loss_D: 0.207601\n",
      "[Epoch 78/200] [Batch 740/938] loss_G: 2.667389, loss_D: 0.172567\n",
      "[Epoch 78/200] [Batch 750/938] loss_G: 2.969483, loss_D: 0.185934\n",
      "[Epoch 78/200] [Batch 760/938] loss_G: 2.746878, loss_D: 0.212503\n",
      "[Epoch 78/200] [Batch 770/938] loss_G: 2.820315, loss_D: 0.210987\n",
      "[Epoch 78/200] [Batch 780/938] loss_G: 2.863363, loss_D: 0.247007\n",
      "[Epoch 78/200] [Batch 790/938] loss_G: 2.677556, loss_D: 0.207310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 78/200] [Batch 800/938] loss_G: 2.580377, loss_D: 0.248908\n",
      "[Epoch 78/200] [Batch 810/938] loss_G: 2.985677, loss_D: 0.145226\n",
      "[Epoch 78/200] [Batch 820/938] loss_G: 3.037477, loss_D: 0.210810\n",
      "[Epoch 78/200] [Batch 830/938] loss_G: 2.944768, loss_D: 0.148060\n",
      "[Epoch 78/200] [Batch 840/938] loss_G: 2.903936, loss_D: 0.207266\n",
      "[Epoch 78/200] [Batch 850/938] loss_G: 2.721928, loss_D: 0.238900\n",
      "[Epoch 78/200] [Batch 860/938] loss_G: 3.036577, loss_D: 0.180824\n",
      "[Epoch 78/200] [Batch 870/938] loss_G: 2.975245, loss_D: 0.254442\n",
      "[Epoch 78/200] [Batch 880/938] loss_G: 2.840625, loss_D: 0.172678\n",
      "[Epoch 78/200] [Batch 890/938] loss_G: 2.725080, loss_D: 0.240449\n",
      "[Epoch 78/200] [Batch 900/938] loss_G: 2.984309, loss_D: 0.182567\n",
      "[Epoch 78/200] [Batch 910/938] loss_G: 2.621243, loss_D: 0.201265\n",
      "[Epoch 78/200] [Batch 920/938] loss_G: 2.840601, loss_D: 0.241895\n",
      "[Epoch 78/200] [Batch 930/938] loss_G: 2.838094, loss_D: 0.232636\n",
      "[Epoch 79/200] [Batch 0/938] loss_G: 3.106115, loss_D: 0.217861\n",
      "[Epoch 79/200] [Batch 10/938] loss_G: 2.847879, loss_D: 0.134221\n",
      "[Epoch 79/200] [Batch 20/938] loss_G: 3.066618, loss_D: 0.258126\n",
      "[Epoch 79/200] [Batch 30/938] loss_G: 3.133513, loss_D: 0.287471\n",
      "[Epoch 79/200] [Batch 40/938] loss_G: 2.924151, loss_D: 0.189046\n",
      "[Epoch 79/200] [Batch 50/938] loss_G: 2.889299, loss_D: 0.175145\n",
      "[Epoch 79/200] [Batch 60/938] loss_G: 3.214975, loss_D: 0.197959\n",
      "[Epoch 79/200] [Batch 70/938] loss_G: 3.075609, loss_D: 0.288673\n",
      "[Epoch 79/200] [Batch 80/938] loss_G: 2.763023, loss_D: 0.226260\n",
      "[Epoch 79/200] [Batch 90/938] loss_G: 2.961360, loss_D: 0.197495\n",
      "[Epoch 79/200] [Batch 100/938] loss_G: 3.031995, loss_D: 0.208621\n",
      "[Epoch 79/200] [Batch 110/938] loss_G: 2.955526, loss_D: 0.216903\n",
      "[Epoch 79/200] [Batch 120/938] loss_G: 2.759672, loss_D: 0.197699\n",
      "[Epoch 79/200] [Batch 130/938] loss_G: 2.770653, loss_D: 0.235712\n",
      "[Epoch 79/200] [Batch 140/938] loss_G: 2.791118, loss_D: 0.183506\n",
      "[Epoch 79/200] [Batch 150/938] loss_G: 2.675786, loss_D: 0.212193\n",
      "[Epoch 79/200] [Batch 160/938] loss_G: 2.534005, loss_D: 0.234533\n",
      "[Epoch 79/200] [Batch 170/938] loss_G: 2.871658, loss_D: 0.231841\n",
      "[Epoch 79/200] [Batch 180/938] loss_G: 2.944051, loss_D: 0.194390\n",
      "[Epoch 79/200] [Batch 190/938] loss_G: 2.807749, loss_D: 0.176907\n",
      "[Epoch 79/200] [Batch 200/938] loss_G: 2.952052, loss_D: 0.255926\n",
      "[Epoch 79/200] [Batch 210/938] loss_G: 2.758733, loss_D: 0.260771\n",
      "[Epoch 79/200] [Batch 220/938] loss_G: 3.429099, loss_D: 0.231881\n",
      "[Epoch 79/200] [Batch 230/938] loss_G: 2.715971, loss_D: 0.250165\n",
      "[Epoch 79/200] [Batch 240/938] loss_G: 2.919471, loss_D: 0.262348\n",
      "[Epoch 79/200] [Batch 250/938] loss_G: 3.128791, loss_D: 0.131552\n",
      "[Epoch 79/200] [Batch 260/938] loss_G: 2.889046, loss_D: 0.236770\n",
      "[Epoch 79/200] [Batch 270/938] loss_G: 3.011371, loss_D: 0.201801\n",
      "[Epoch 79/200] [Batch 280/938] loss_G: 2.996545, loss_D: 0.306168\n",
      "[Epoch 79/200] [Batch 290/938] loss_G: 2.969644, loss_D: 0.321270\n",
      "[Epoch 79/200] [Batch 300/938] loss_G: 3.014353, loss_D: 0.208422\n",
      "[Epoch 79/200] [Batch 310/938] loss_G: 2.899828, loss_D: 0.155629\n",
      "[Epoch 79/200] [Batch 320/938] loss_G: 3.153914, loss_D: 0.246606\n",
      "[Epoch 79/200] [Batch 330/938] loss_G: 2.787755, loss_D: 0.251352\n",
      "[Epoch 79/200] [Batch 340/938] loss_G: 2.703691, loss_D: 0.232208\n",
      "[Epoch 79/200] [Batch 350/938] loss_G: 3.099120, loss_D: 0.222359\n",
      "[Epoch 79/200] [Batch 360/938] loss_G: 2.571071, loss_D: 0.165613\n",
      "[Epoch 79/200] [Batch 370/938] loss_G: 2.978125, loss_D: 0.204428\n",
      "[Epoch 79/200] [Batch 380/938] loss_G: 2.740443, loss_D: 0.243386\n",
      "[Epoch 79/200] [Batch 390/938] loss_G: 2.678727, loss_D: 0.326269\n",
      "[Epoch 79/200] [Batch 400/938] loss_G: 2.977783, loss_D: 0.189898\n",
      "[Epoch 79/200] [Batch 410/938] loss_G: 2.968283, loss_D: 0.190302\n",
      "[Epoch 79/200] [Batch 420/938] loss_G: 2.985445, loss_D: 0.222282\n",
      "[Epoch 79/200] [Batch 430/938] loss_G: 2.818359, loss_D: 0.227688\n",
      "[Epoch 79/200] [Batch 440/938] loss_G: 2.803110, loss_D: 0.335435\n",
      "[Epoch 79/200] [Batch 450/938] loss_G: 3.086480, loss_D: 0.179536\n",
      "[Epoch 79/200] [Batch 460/938] loss_G: 3.002854, loss_D: 0.169719\n",
      "[Epoch 79/200] [Batch 470/938] loss_G: 2.895818, loss_D: 0.186436\n",
      "[Epoch 79/200] [Batch 480/938] loss_G: 2.754657, loss_D: 0.203257\n",
      "[Epoch 79/200] [Batch 490/938] loss_G: 2.503520, loss_D: 0.198919\n",
      "[Epoch 79/200] [Batch 500/938] loss_G: 3.103648, loss_D: 0.147862\n",
      "[Epoch 79/200] [Batch 510/938] loss_G: 2.904796, loss_D: 0.239849\n",
      "[Epoch 79/200] [Batch 520/938] loss_G: 2.957237, loss_D: 0.236757\n",
      "[Epoch 79/200] [Batch 530/938] loss_G: 3.154707, loss_D: 0.239301\n",
      "[Epoch 79/200] [Batch 540/938] loss_G: 2.586682, loss_D: 0.189437\n",
      "[Epoch 79/200] [Batch 550/938] loss_G: 2.882133, loss_D: 0.219965\n",
      "[Epoch 79/200] [Batch 560/938] loss_G: 2.822263, loss_D: 0.244377\n",
      "[Epoch 79/200] [Batch 570/938] loss_G: 3.034956, loss_D: 0.199921\n",
      "[Epoch 79/200] [Batch 580/938] loss_G: 2.849634, loss_D: 0.270896\n",
      "[Epoch 79/200] [Batch 590/938] loss_G: 2.797885, loss_D: 0.214580\n",
      "[Epoch 79/200] [Batch 600/938] loss_G: 2.890766, loss_D: 0.218468\n",
      "[Epoch 79/200] [Batch 610/938] loss_G: 2.870717, loss_D: 0.153358\n",
      "[Epoch 79/200] [Batch 620/938] loss_G: 2.921022, loss_D: 0.235465\n",
      "[Epoch 79/200] [Batch 630/938] loss_G: 2.577312, loss_D: 0.208228\n",
      "[Epoch 79/200] [Batch 640/938] loss_G: 2.621035, loss_D: 0.230759\n",
      "[Epoch 79/200] [Batch 650/938] loss_G: 2.780526, loss_D: 0.183576\n",
      "[Epoch 79/200] [Batch 660/938] loss_G: 2.976527, loss_D: 0.208756\n",
      "[Epoch 79/200] [Batch 670/938] loss_G: 2.954977, loss_D: 0.234389\n",
      "[Epoch 79/200] [Batch 680/938] loss_G: 3.199110, loss_D: 0.168512\n",
      "[Epoch 79/200] [Batch 690/938] loss_G: 2.790669, loss_D: 0.153003\n",
      "[Epoch 79/200] [Batch 700/938] loss_G: 2.666763, loss_D: 0.265998\n",
      "[Epoch 79/200] [Batch 710/938] loss_G: 2.816995, loss_D: 0.157124\n",
      "[Epoch 79/200] [Batch 720/938] loss_G: 2.911523, loss_D: 0.229098\n",
      "[Epoch 79/200] [Batch 730/938] loss_G: 2.945845, loss_D: 0.174832\n",
      "[Epoch 79/200] [Batch 740/938] loss_G: 3.034730, loss_D: 0.246341\n",
      "[Epoch 79/200] [Batch 750/938] loss_G: 2.880840, loss_D: 0.185312\n",
      "[Epoch 79/200] [Batch 760/938] loss_G: 3.077142, loss_D: 0.341061\n",
      "[Epoch 79/200] [Batch 770/938] loss_G: 2.986161, loss_D: 0.229995\n",
      "[Epoch 79/200] [Batch 780/938] loss_G: 2.663368, loss_D: 0.214933\n",
      "[Epoch 79/200] [Batch 790/938] loss_G: 2.690177, loss_D: 0.317565\n",
      "[Epoch 79/200] [Batch 800/938] loss_G: 2.565474, loss_D: 0.236007\n",
      "[Epoch 79/200] [Batch 810/938] loss_G: 2.510796, loss_D: 0.249109\n",
      "[Epoch 79/200] [Batch 820/938] loss_G: 2.784383, loss_D: 0.171651\n",
      "[Epoch 79/200] [Batch 830/938] loss_G: 3.032977, loss_D: 0.162503\n",
      "[Epoch 79/200] [Batch 840/938] loss_G: 2.953482, loss_D: 0.240496\n",
      "[Epoch 79/200] [Batch 850/938] loss_G: 2.730461, loss_D: 0.201400\n",
      "[Epoch 79/200] [Batch 860/938] loss_G: 2.908533, loss_D: 0.228187\n",
      "[Epoch 79/200] [Batch 870/938] loss_G: 2.854827, loss_D: 0.182164\n",
      "[Epoch 79/200] [Batch 880/938] loss_G: 2.490448, loss_D: 0.221571\n",
      "[Epoch 79/200] [Batch 890/938] loss_G: 2.778049, loss_D: 0.187150\n",
      "[Epoch 79/200] [Batch 900/938] loss_G: 2.635277, loss_D: 0.198660\n",
      "[Epoch 79/200] [Batch 910/938] loss_G: 3.021369, loss_D: 0.252998\n",
      "[Epoch 79/200] [Batch 920/938] loss_G: 2.942835, loss_D: 0.198004\n",
      "[Epoch 79/200] [Batch 930/938] loss_G: 2.712917, loss_D: 0.166751\n",
      "[Epoch 80/200] [Batch 0/938] loss_G: 2.789593, loss_D: 0.191154\n",
      "[Epoch 80/200] [Batch 10/938] loss_G: 2.868348, loss_D: 0.205367\n",
      "[Epoch 80/200] [Batch 20/938] loss_G: 2.734522, loss_D: 0.239064\n",
      "[Epoch 80/200] [Batch 30/938] loss_G: 2.713510, loss_D: 0.181549\n",
      "[Epoch 80/200] [Batch 40/938] loss_G: 2.654469, loss_D: 0.226772\n",
      "[Epoch 80/200] [Batch 50/938] loss_G: 2.670835, loss_D: 0.230526\n",
      "[Epoch 80/200] [Batch 60/938] loss_G: 2.763693, loss_D: 0.188517\n",
      "[Epoch 80/200] [Batch 70/938] loss_G: 2.652896, loss_D: 0.235506\n",
      "[Epoch 80/200] [Batch 80/938] loss_G: 2.759336, loss_D: 0.133926\n",
      "[Epoch 80/200] [Batch 90/938] loss_G: 2.836743, loss_D: 0.182913\n",
      "[Epoch 80/200] [Batch 100/938] loss_G: 2.736490, loss_D: 0.218580\n",
      "[Epoch 80/200] [Batch 110/938] loss_G: 2.831177, loss_D: 0.224678\n",
      "[Epoch 80/200] [Batch 120/938] loss_G: 2.629459, loss_D: 0.229654\n",
      "[Epoch 80/200] [Batch 130/938] loss_G: 2.767524, loss_D: 0.182712\n",
      "[Epoch 80/200] [Batch 140/938] loss_G: 3.010898, loss_D: 0.135531\n",
      "[Epoch 80/200] [Batch 150/938] loss_G: 2.959748, loss_D: 0.231156\n",
      "[Epoch 80/200] [Batch 160/938] loss_G: 2.356171, loss_D: 0.247199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 80/200] [Batch 170/938] loss_G: 2.944288, loss_D: 0.258518\n",
      "[Epoch 80/200] [Batch 180/938] loss_G: 2.885399, loss_D: 0.166862\n",
      "[Epoch 80/200] [Batch 190/938] loss_G: 2.564599, loss_D: 0.263591\n",
      "[Epoch 80/200] [Batch 200/938] loss_G: 2.905758, loss_D: 0.268351\n",
      "[Epoch 80/200] [Batch 210/938] loss_G: 2.912283, loss_D: 0.230060\n",
      "[Epoch 80/200] [Batch 220/938] loss_G: 2.807710, loss_D: 0.234437\n",
      "[Epoch 80/200] [Batch 230/938] loss_G: 3.119192, loss_D: 0.187460\n",
      "[Epoch 80/200] [Batch 240/938] loss_G: 2.630072, loss_D: 0.277826\n",
      "[Epoch 80/200] [Batch 250/938] loss_G: 2.632379, loss_D: 0.210946\n",
      "[Epoch 80/200] [Batch 260/938] loss_G: 2.836498, loss_D: 0.268518\n",
      "[Epoch 80/200] [Batch 270/938] loss_G: 2.778296, loss_D: 0.171423\n",
      "[Epoch 80/200] [Batch 280/938] loss_G: 3.039693, loss_D: 0.205241\n",
      "[Epoch 80/200] [Batch 290/938] loss_G: 2.890301, loss_D: 0.217827\n",
      "[Epoch 80/200] [Batch 300/938] loss_G: 3.137768, loss_D: 0.185936\n",
      "[Epoch 80/200] [Batch 310/938] loss_G: 2.979447, loss_D: 0.213136\n",
      "[Epoch 80/200] [Batch 320/938] loss_G: 2.416695, loss_D: 0.228699\n",
      "[Epoch 80/200] [Batch 330/938] loss_G: 2.869219, loss_D: 0.171941\n",
      "[Epoch 80/200] [Batch 340/938] loss_G: 2.985094, loss_D: 0.187992\n",
      "[Epoch 80/200] [Batch 350/938] loss_G: 2.894523, loss_D: 0.164744\n",
      "[Epoch 80/200] [Batch 360/938] loss_G: 3.191163, loss_D: 0.188218\n",
      "[Epoch 80/200] [Batch 370/938] loss_G: 2.798449, loss_D: 0.143414\n",
      "[Epoch 80/200] [Batch 380/938] loss_G: 2.718859, loss_D: 0.238367\n",
      "[Epoch 80/200] [Batch 390/938] loss_G: 3.107180, loss_D: 0.198089\n",
      "[Epoch 80/200] [Batch 400/938] loss_G: 2.821054, loss_D: 0.201061\n",
      "[Epoch 80/200] [Batch 410/938] loss_G: 2.978432, loss_D: 0.251610\n",
      "[Epoch 80/200] [Batch 420/938] loss_G: 2.771262, loss_D: 0.373287\n",
      "[Epoch 80/200] [Batch 430/938] loss_G: 3.080436, loss_D: 0.175423\n",
      "[Epoch 80/200] [Batch 440/938] loss_G: 3.404207, loss_D: 0.207528\n",
      "[Epoch 80/200] [Batch 450/938] loss_G: 2.702998, loss_D: 0.268821\n",
      "[Epoch 80/200] [Batch 460/938] loss_G: 2.789380, loss_D: 0.244819\n",
      "[Epoch 80/200] [Batch 470/938] loss_G: 2.663083, loss_D: 0.221456\n",
      "[Epoch 80/200] [Batch 480/938] loss_G: 2.879187, loss_D: 0.325557\n",
      "[Epoch 80/200] [Batch 490/938] loss_G: 2.727892, loss_D: 0.265472\n",
      "[Epoch 80/200] [Batch 500/938] loss_G: 2.873143, loss_D: 0.256430\n",
      "[Epoch 80/200] [Batch 510/938] loss_G: 2.820954, loss_D: 0.202711\n",
      "[Epoch 80/200] [Batch 520/938] loss_G: 2.785130, loss_D: 0.253460\n",
      "[Epoch 80/200] [Batch 530/938] loss_G: 2.926573, loss_D: 0.265747\n",
      "[Epoch 80/200] [Batch 540/938] loss_G: 2.511055, loss_D: 0.200300\n",
      "[Epoch 80/200] [Batch 550/938] loss_G: 2.579745, loss_D: 0.191522\n",
      "[Epoch 80/200] [Batch 560/938] loss_G: 2.574440, loss_D: 0.286713\n",
      "[Epoch 80/200] [Batch 570/938] loss_G: 3.464808, loss_D: 0.235140\n",
      "[Epoch 80/200] [Batch 580/938] loss_G: 2.829292, loss_D: 0.217788\n",
      "[Epoch 80/200] [Batch 590/938] loss_G: 2.807168, loss_D: 0.184130\n",
      "[Epoch 80/200] [Batch 600/938] loss_G: 2.482240, loss_D: 0.235804\n",
      "[Epoch 80/200] [Batch 610/938] loss_G: 3.032668, loss_D: 0.279988\n",
      "[Epoch 80/200] [Batch 620/938] loss_G: 3.173122, loss_D: 0.208657\n",
      "[Epoch 80/200] [Batch 630/938] loss_G: 2.874036, loss_D: 0.277287\n",
      "[Epoch 80/200] [Batch 640/938] loss_G: 3.106575, loss_D: 0.208926\n",
      "[Epoch 80/200] [Batch 650/938] loss_G: 2.824642, loss_D: 0.209614\n",
      "[Epoch 80/200] [Batch 660/938] loss_G: 2.809162, loss_D: 0.168193\n",
      "[Epoch 80/200] [Batch 670/938] loss_G: 2.790012, loss_D: 0.288586\n",
      "[Epoch 80/200] [Batch 680/938] loss_G: 2.732959, loss_D: 0.308009\n",
      "[Epoch 80/200] [Batch 690/938] loss_G: 2.673811, loss_D: 0.228338\n",
      "[Epoch 80/200] [Batch 700/938] loss_G: 2.715168, loss_D: 0.256347\n",
      "[Epoch 80/200] [Batch 710/938] loss_G: 2.932018, loss_D: 0.262026\n",
      "[Epoch 80/200] [Batch 720/938] loss_G: 2.818177, loss_D: 0.254321\n",
      "[Epoch 80/200] [Batch 730/938] loss_G: 2.903798, loss_D: 0.214727\n",
      "[Epoch 80/200] [Batch 740/938] loss_G: 2.947861, loss_D: 0.305625\n",
      "[Epoch 80/200] [Batch 750/938] loss_G: 2.807161, loss_D: 0.167099\n",
      "[Epoch 80/200] [Batch 760/938] loss_G: 2.699870, loss_D: 0.254779\n",
      "[Epoch 80/200] [Batch 770/938] loss_G: 2.923157, loss_D: 0.299562\n",
      "[Epoch 80/200] [Batch 780/938] loss_G: 3.299924, loss_D: 0.186388\n",
      "[Epoch 80/200] [Batch 790/938] loss_G: 3.358652, loss_D: 0.174084\n",
      "[Epoch 80/200] [Batch 800/938] loss_G: 2.622656, loss_D: 0.192538\n",
      "[Epoch 80/200] [Batch 810/938] loss_G: 2.643260, loss_D: 0.192109\n",
      "[Epoch 80/200] [Batch 820/938] loss_G: 2.831288, loss_D: 0.184288\n",
      "[Epoch 80/200] [Batch 830/938] loss_G: 2.918744, loss_D: 0.221754\n",
      "[Epoch 80/200] [Batch 840/938] loss_G: 2.796217, loss_D: 0.214215\n",
      "[Epoch 80/200] [Batch 850/938] loss_G: 3.489166, loss_D: 0.166337\n",
      "[Epoch 80/200] [Batch 860/938] loss_G: 2.897739, loss_D: 0.264749\n",
      "[Epoch 80/200] [Batch 870/938] loss_G: 2.730510, loss_D: 0.163817\n",
      "[Epoch 80/200] [Batch 880/938] loss_G: 2.934978, loss_D: 0.224287\n",
      "[Epoch 80/200] [Batch 890/938] loss_G: 2.793154, loss_D: 0.233983\n",
      "[Epoch 80/200] [Batch 900/938] loss_G: 2.549530, loss_D: 0.170786\n",
      "[Epoch 80/200] [Batch 910/938] loss_G: 2.577554, loss_D: 0.337912\n",
      "[Epoch 80/200] [Batch 920/938] loss_G: 2.960071, loss_D: 0.289049\n",
      "[Epoch 80/200] [Batch 930/938] loss_G: 3.008854, loss_D: 0.205113\n",
      "[Epoch 81/200] [Batch 0/938] loss_G: 3.138901, loss_D: 0.195798\n",
      "[Epoch 81/200] [Batch 10/938] loss_G: 2.651470, loss_D: 0.100988\n",
      "[Epoch 81/200] [Batch 20/938] loss_G: 2.983767, loss_D: 0.293117\n",
      "[Epoch 81/200] [Batch 30/938] loss_G: 2.816038, loss_D: 0.167920\n",
      "[Epoch 81/200] [Batch 40/938] loss_G: 2.876551, loss_D: 0.207704\n",
      "[Epoch 81/200] [Batch 50/938] loss_G: 2.716072, loss_D: 0.157931\n",
      "[Epoch 81/200] [Batch 60/938] loss_G: 3.055869, loss_D: 0.191366\n",
      "[Epoch 81/200] [Batch 70/938] loss_G: 2.848235, loss_D: 0.297365\n",
      "[Epoch 81/200] [Batch 80/938] loss_G: 2.918636, loss_D: 0.215957\n",
      "[Epoch 81/200] [Batch 90/938] loss_G: 2.850615, loss_D: 0.152095\n",
      "[Epoch 81/200] [Batch 100/938] loss_G: 2.812046, loss_D: 0.171796\n",
      "[Epoch 81/200] [Batch 110/938] loss_G: 2.981690, loss_D: 0.233499\n",
      "[Epoch 81/200] [Batch 120/938] loss_G: 2.736399, loss_D: 0.117086\n",
      "[Epoch 81/200] [Batch 130/938] loss_G: 2.587850, loss_D: 0.216135\n",
      "[Epoch 81/200] [Batch 140/938] loss_G: 2.784958, loss_D: 0.180665\n",
      "[Epoch 81/200] [Batch 150/938] loss_G: 2.741148, loss_D: 0.158615\n",
      "[Epoch 81/200] [Batch 160/938] loss_G: 2.772686, loss_D: 0.131732\n",
      "[Epoch 81/200] [Batch 170/938] loss_G: 2.881840, loss_D: 0.216474\n",
      "[Epoch 81/200] [Batch 180/938] loss_G: 3.253807, loss_D: 0.162113\n",
      "[Epoch 81/200] [Batch 190/938] loss_G: 2.637473, loss_D: 0.197966\n",
      "[Epoch 81/200] [Batch 200/938] loss_G: 3.012219, loss_D: 0.150336\n",
      "[Epoch 81/200] [Batch 210/938] loss_G: 2.908340, loss_D: 0.238941\n",
      "[Epoch 81/200] [Batch 220/938] loss_G: 2.935026, loss_D: 0.176843\n",
      "[Epoch 81/200] [Batch 230/938] loss_G: 3.069892, loss_D: 0.293627\n",
      "[Epoch 81/200] [Batch 240/938] loss_G: 2.613474, loss_D: 0.212013\n",
      "[Epoch 81/200] [Batch 250/938] loss_G: 2.748975, loss_D: 0.160678\n",
      "[Epoch 81/200] [Batch 260/938] loss_G: 3.185648, loss_D: 0.174714\n",
      "[Epoch 81/200] [Batch 270/938] loss_G: 2.858941, loss_D: 0.202838\n",
      "[Epoch 81/200] [Batch 280/938] loss_G: 2.828267, loss_D: 0.200190\n",
      "[Epoch 81/200] [Batch 290/938] loss_G: 2.783994, loss_D: 0.144280\n",
      "[Epoch 81/200] [Batch 300/938] loss_G: 2.871550, loss_D: 0.181521\n",
      "[Epoch 81/200] [Batch 310/938] loss_G: 3.095334, loss_D: 0.183454\n",
      "[Epoch 81/200] [Batch 320/938] loss_G: 2.732198, loss_D: 0.179992\n",
      "[Epoch 81/200] [Batch 330/938] loss_G: 2.581966, loss_D: 0.275481\n",
      "[Epoch 81/200] [Batch 340/938] loss_G: 3.147021, loss_D: 0.284213\n",
      "[Epoch 81/200] [Batch 350/938] loss_G: 2.844579, loss_D: 0.246879\n",
      "[Epoch 81/200] [Batch 360/938] loss_G: 2.905812, loss_D: 0.178424\n",
      "[Epoch 81/200] [Batch 370/938] loss_G: 3.019238, loss_D: 0.162622\n",
      "[Epoch 81/200] [Batch 380/938] loss_G: 2.709105, loss_D: 0.172290\n",
      "[Epoch 81/200] [Batch 390/938] loss_G: 3.039319, loss_D: 0.237505\n",
      "[Epoch 81/200] [Batch 400/938] loss_G: 3.134611, loss_D: 0.181715\n",
      "[Epoch 81/200] [Batch 410/938] loss_G: 2.746809, loss_D: 0.153524\n",
      "[Epoch 81/200] [Batch 420/938] loss_G: 3.029994, loss_D: 0.247137\n",
      "[Epoch 81/200] [Batch 430/938] loss_G: 2.821644, loss_D: 0.255880\n",
      "[Epoch 81/200] [Batch 440/938] loss_G: 2.649873, loss_D: 0.228717\n",
      "[Epoch 81/200] [Batch 450/938] loss_G: 2.901225, loss_D: 0.257014\n",
      "[Epoch 81/200] [Batch 460/938] loss_G: 3.040344, loss_D: 0.139694\n",
      "[Epoch 81/200] [Batch 470/938] loss_G: 3.257666, loss_D: 0.175234\n",
      "[Epoch 81/200] [Batch 480/938] loss_G: 2.834949, loss_D: 0.175413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 81/200] [Batch 490/938] loss_G: 2.913993, loss_D: 0.314489\n",
      "[Epoch 81/200] [Batch 500/938] loss_G: 2.757477, loss_D: 0.181321\n",
      "[Epoch 81/200] [Batch 510/938] loss_G: 2.857866, loss_D: 0.193366\n",
      "[Epoch 81/200] [Batch 520/938] loss_G: 2.741998, loss_D: 0.227305\n",
      "[Epoch 81/200] [Batch 530/938] loss_G: 3.169709, loss_D: 0.196539\n",
      "[Epoch 81/200] [Batch 540/938] loss_G: 2.887855, loss_D: 0.263351\n",
      "[Epoch 81/200] [Batch 550/938] loss_G: 3.079391, loss_D: 0.141680\n",
      "[Epoch 81/200] [Batch 560/938] loss_G: 3.367676, loss_D: 0.202234\n",
      "[Epoch 81/200] [Batch 570/938] loss_G: 2.839847, loss_D: 0.121253\n",
      "[Epoch 81/200] [Batch 580/938] loss_G: 2.890530, loss_D: 0.165096\n",
      "[Epoch 81/200] [Batch 590/938] loss_G: 3.132334, loss_D: 0.246262\n",
      "[Epoch 81/200] [Batch 600/938] loss_G: 2.772604, loss_D: 0.213984\n",
      "[Epoch 81/200] [Batch 610/938] loss_G: 2.811746, loss_D: 0.221835\n",
      "[Epoch 81/200] [Batch 620/938] loss_G: 2.826314, loss_D: 0.238147\n",
      "[Epoch 81/200] [Batch 630/938] loss_G: 2.494370, loss_D: 0.157970\n",
      "[Epoch 81/200] [Batch 640/938] loss_G: 2.972157, loss_D: 0.245931\n",
      "[Epoch 81/200] [Batch 650/938] loss_G: 2.630119, loss_D: 0.231522\n",
      "[Epoch 81/200] [Batch 660/938] loss_G: 2.952480, loss_D: 0.192446\n",
      "[Epoch 81/200] [Batch 670/938] loss_G: 3.041931, loss_D: 0.226881\n",
      "[Epoch 81/200] [Batch 680/938] loss_G: 2.837768, loss_D: 0.276449\n",
      "[Epoch 81/200] [Batch 690/938] loss_G: 2.788610, loss_D: 0.239551\n",
      "[Epoch 81/200] [Batch 700/938] loss_G: 3.194344, loss_D: 0.263089\n",
      "[Epoch 81/200] [Batch 710/938] loss_G: 2.952080, loss_D: 0.178741\n",
      "[Epoch 81/200] [Batch 720/938] loss_G: 3.218040, loss_D: 0.233996\n",
      "[Epoch 81/200] [Batch 730/938] loss_G: 2.923532, loss_D: 0.199000\n",
      "[Epoch 81/200] [Batch 740/938] loss_G: 2.784542, loss_D: 0.199455\n",
      "[Epoch 81/200] [Batch 750/938] loss_G: 2.808555, loss_D: 0.372124\n",
      "[Epoch 81/200] [Batch 760/938] loss_G: 2.685308, loss_D: 0.278677\n",
      "[Epoch 81/200] [Batch 770/938] loss_G: 2.649493, loss_D: 0.305589\n",
      "[Epoch 81/200] [Batch 780/938] loss_G: 2.853534, loss_D: 0.329340\n",
      "[Epoch 81/200] [Batch 790/938] loss_G: 2.631611, loss_D: 0.266393\n",
      "[Epoch 81/200] [Batch 800/938] loss_G: 3.089757, loss_D: 0.101136\n",
      "[Epoch 81/200] [Batch 810/938] loss_G: 2.927061, loss_D: 0.224400\n",
      "[Epoch 81/200] [Batch 820/938] loss_G: 2.967936, loss_D: 0.252505\n",
      "[Epoch 81/200] [Batch 830/938] loss_G: 3.058427, loss_D: 0.160921\n",
      "[Epoch 81/200] [Batch 840/938] loss_G: 2.949593, loss_D: 0.216902\n",
      "[Epoch 81/200] [Batch 850/938] loss_G: 2.995247, loss_D: 0.141240\n",
      "[Epoch 81/200] [Batch 860/938] loss_G: 2.949836, loss_D: 0.211368\n",
      "[Epoch 81/200] [Batch 870/938] loss_G: 2.383098, loss_D: 0.238212\n",
      "[Epoch 81/200] [Batch 880/938] loss_G: 2.744487, loss_D: 0.321622\n",
      "[Epoch 81/200] [Batch 890/938] loss_G: 2.926826, loss_D: 0.135450\n",
      "[Epoch 81/200] [Batch 900/938] loss_G: 3.142567, loss_D: 0.226738\n",
      "[Epoch 81/200] [Batch 910/938] loss_G: 2.971937, loss_D: 0.226523\n",
      "[Epoch 81/200] [Batch 920/938] loss_G: 3.054294, loss_D: 0.212248\n",
      "[Epoch 81/200] [Batch 930/938] loss_G: 2.874118, loss_D: 0.145229\n",
      "[Epoch 82/200] [Batch 0/938] loss_G: 2.656709, loss_D: 0.199916\n",
      "[Epoch 82/200] [Batch 10/938] loss_G: 2.648468, loss_D: 0.186093\n",
      "[Epoch 82/200] [Batch 20/938] loss_G: 2.606241, loss_D: 0.399450\n",
      "[Epoch 82/200] [Batch 30/938] loss_G: 2.796677, loss_D: 0.202213\n",
      "[Epoch 82/200] [Batch 40/938] loss_G: 3.123716, loss_D: 0.207630\n",
      "[Epoch 82/200] [Batch 50/938] loss_G: 2.548727, loss_D: 0.207745\n",
      "[Epoch 82/200] [Batch 60/938] loss_G: 3.008923, loss_D: 0.219816\n",
      "[Epoch 82/200] [Batch 70/938] loss_G: 2.945619, loss_D: 0.198528\n",
      "[Epoch 82/200] [Batch 80/938] loss_G: 2.874060, loss_D: 0.202966\n",
      "[Epoch 82/200] [Batch 90/938] loss_G: 2.842057, loss_D: 0.169489\n",
      "[Epoch 82/200] [Batch 100/938] loss_G: 2.804294, loss_D: 0.248065\n",
      "[Epoch 82/200] [Batch 110/938] loss_G: 2.905792, loss_D: 0.165446\n",
      "[Epoch 82/200] [Batch 120/938] loss_G: 3.424443, loss_D: 0.228307\n",
      "[Epoch 82/200] [Batch 130/938] loss_G: 2.634569, loss_D: 0.155203\n",
      "[Epoch 82/200] [Batch 140/938] loss_G: 3.198059, loss_D: 0.231946\n",
      "[Epoch 82/200] [Batch 150/938] loss_G: 2.637386, loss_D: 0.224145\n",
      "[Epoch 82/200] [Batch 160/938] loss_G: 2.586543, loss_D: 0.332791\n",
      "[Epoch 82/200] [Batch 170/938] loss_G: 3.379105, loss_D: 0.168343\n",
      "[Epoch 82/200] [Batch 180/938] loss_G: 2.531538, loss_D: 0.193190\n",
      "[Epoch 82/200] [Batch 190/938] loss_G: 3.110071, loss_D: 0.278400\n",
      "[Epoch 82/200] [Batch 200/938] loss_G: 2.937832, loss_D: 0.233999\n",
      "[Epoch 82/200] [Batch 210/938] loss_G: 2.933139, loss_D: 0.196532\n",
      "[Epoch 82/200] [Batch 220/938] loss_G: 2.421723, loss_D: 0.308064\n",
      "[Epoch 82/200] [Batch 230/938] loss_G: 2.583067, loss_D: 0.318561\n",
      "[Epoch 82/200] [Batch 240/938] loss_G: 2.725165, loss_D: 0.195370\n",
      "[Epoch 82/200] [Batch 250/938] loss_G: 3.084673, loss_D: 0.242458\n",
      "[Epoch 82/200] [Batch 260/938] loss_G: 2.856524, loss_D: 0.199385\n",
      "[Epoch 82/200] [Batch 270/938] loss_G: 3.307928, loss_D: 0.246026\n",
      "[Epoch 82/200] [Batch 280/938] loss_G: 3.158285, loss_D: 0.283707\n",
      "[Epoch 82/200] [Batch 290/938] loss_G: 2.766141, loss_D: 0.256349\n",
      "[Epoch 82/200] [Batch 300/938] loss_G: 2.797847, loss_D: 0.188237\n",
      "[Epoch 82/200] [Batch 310/938] loss_G: 3.116106, loss_D: 0.156062\n",
      "[Epoch 82/200] [Batch 320/938] loss_G: 2.804502, loss_D: 0.183806\n",
      "[Epoch 82/200] [Batch 330/938] loss_G: 3.260600, loss_D: 0.239764\n",
      "[Epoch 82/200] [Batch 340/938] loss_G: 2.854837, loss_D: 0.233415\n",
      "[Epoch 82/200] [Batch 350/938] loss_G: 3.005555, loss_D: 0.214102\n",
      "[Epoch 82/200] [Batch 360/938] loss_G: 2.848798, loss_D: 0.237205\n",
      "[Epoch 82/200] [Batch 370/938] loss_G: 2.954461, loss_D: 0.237703\n",
      "[Epoch 82/200] [Batch 380/938] loss_G: 2.782073, loss_D: 0.202908\n",
      "[Epoch 82/200] [Batch 390/938] loss_G: 2.784658, loss_D: 0.264886\n",
      "[Epoch 82/200] [Batch 400/938] loss_G: 2.965351, loss_D: 0.229376\n",
      "[Epoch 82/200] [Batch 410/938] loss_G: 2.979672, loss_D: 0.276112\n",
      "[Epoch 82/200] [Batch 420/938] loss_G: 2.961112, loss_D: 0.260712\n",
      "[Epoch 82/200] [Batch 430/938] loss_G: 2.630156, loss_D: 0.206521\n",
      "[Epoch 82/200] [Batch 440/938] loss_G: 2.908983, loss_D: 0.161737\n",
      "[Epoch 82/200] [Batch 450/938] loss_G: 3.260550, loss_D: 0.268934\n",
      "[Epoch 82/200] [Batch 460/938] loss_G: 2.908834, loss_D: 0.247644\n",
      "[Epoch 82/200] [Batch 470/938] loss_G: 3.413026, loss_D: 0.206406\n",
      "[Epoch 82/200] [Batch 480/938] loss_G: 2.718621, loss_D: 0.229412\n",
      "[Epoch 82/200] [Batch 490/938] loss_G: 2.958307, loss_D: 0.172937\n",
      "[Epoch 82/200] [Batch 500/938] loss_G: 2.709350, loss_D: 0.154621\n",
      "[Epoch 82/200] [Batch 510/938] loss_G: 2.832076, loss_D: 0.334548\n",
      "[Epoch 82/200] [Batch 520/938] loss_G: 3.167490, loss_D: 0.191489\n",
      "[Epoch 82/200] [Batch 530/938] loss_G: 3.066748, loss_D: 0.287549\n",
      "[Epoch 82/200] [Batch 540/938] loss_G: 2.426723, loss_D: 0.158180\n",
      "[Epoch 82/200] [Batch 550/938] loss_G: 2.674418, loss_D: 0.164256\n",
      "[Epoch 82/200] [Batch 560/938] loss_G: 3.008136, loss_D: 0.142186\n",
      "[Epoch 82/200] [Batch 570/938] loss_G: 3.001532, loss_D: 0.161041\n",
      "[Epoch 82/200] [Batch 580/938] loss_G: 2.856340, loss_D: 0.192116\n",
      "[Epoch 82/200] [Batch 590/938] loss_G: 2.624689, loss_D: 0.229693\n",
      "[Epoch 82/200] [Batch 600/938] loss_G: 3.261671, loss_D: 0.183747\n",
      "[Epoch 82/200] [Batch 610/938] loss_G: 2.561408, loss_D: 0.311129\n",
      "[Epoch 82/200] [Batch 620/938] loss_G: 2.849248, loss_D: 0.177850\n",
      "[Epoch 82/200] [Batch 630/938] loss_G: 3.100106, loss_D: 0.229105\n",
      "[Epoch 82/200] [Batch 640/938] loss_G: 2.773618, loss_D: 0.184669\n",
      "[Epoch 82/200] [Batch 650/938] loss_G: 3.028908, loss_D: 0.228866\n",
      "[Epoch 82/200] [Batch 660/938] loss_G: 2.634581, loss_D: 0.226690\n",
      "[Epoch 82/200] [Batch 670/938] loss_G: 3.106878, loss_D: 0.288546\n",
      "[Epoch 82/200] [Batch 680/938] loss_G: 2.660169, loss_D: 0.238788\n",
      "[Epoch 82/200] [Batch 690/938] loss_G: 2.763666, loss_D: 0.249817\n",
      "[Epoch 82/200] [Batch 700/938] loss_G: 2.978555, loss_D: 0.232112\n",
      "[Epoch 82/200] [Batch 710/938] loss_G: 2.971196, loss_D: 0.162514\n",
      "[Epoch 82/200] [Batch 720/938] loss_G: 2.910872, loss_D: 0.284442\n",
      "[Epoch 82/200] [Batch 730/938] loss_G: 2.738105, loss_D: 0.168346\n",
      "[Epoch 82/200] [Batch 740/938] loss_G: 2.757650, loss_D: 0.252307\n",
      "[Epoch 82/200] [Batch 750/938] loss_G: 2.885542, loss_D: 0.268375\n",
      "[Epoch 82/200] [Batch 760/938] loss_G: 3.105513, loss_D: 0.177483\n",
      "[Epoch 82/200] [Batch 770/938] loss_G: 2.794434, loss_D: 0.163610\n",
      "[Epoch 82/200] [Batch 780/938] loss_G: 2.499634, loss_D: 0.205841\n",
      "[Epoch 82/200] [Batch 790/938] loss_G: 3.168692, loss_D: 0.177765\n",
      "[Epoch 82/200] [Batch 800/938] loss_G: 2.734365, loss_D: 0.274183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 82/200] [Batch 810/938] loss_G: 2.813612, loss_D: 0.182930\n",
      "[Epoch 82/200] [Batch 820/938] loss_G: 3.107347, loss_D: 0.201424\n",
      "[Epoch 82/200] [Batch 830/938] loss_G: 2.700869, loss_D: 0.268268\n",
      "[Epoch 82/200] [Batch 840/938] loss_G: 2.899705, loss_D: 0.215464\n",
      "[Epoch 82/200] [Batch 850/938] loss_G: 3.001254, loss_D: 0.213486\n",
      "[Epoch 82/200] [Batch 860/938] loss_G: 2.997710, loss_D: 0.258541\n",
      "[Epoch 82/200] [Batch 870/938] loss_G: 2.860678, loss_D: 0.168285\n",
      "[Epoch 82/200] [Batch 880/938] loss_G: 3.142917, loss_D: 0.258665\n",
      "[Epoch 82/200] [Batch 890/938] loss_G: 2.876882, loss_D: 0.260064\n",
      "[Epoch 82/200] [Batch 900/938] loss_G: 3.022232, loss_D: 0.231344\n",
      "[Epoch 82/200] [Batch 910/938] loss_G: 2.679807, loss_D: 0.164581\n",
      "[Epoch 82/200] [Batch 920/938] loss_G: 2.810668, loss_D: 0.193950\n",
      "[Epoch 82/200] [Batch 930/938] loss_G: 2.501438, loss_D: 0.240840\n",
      "[Epoch 83/200] [Batch 0/938] loss_G: 3.230611, loss_D: 0.223850\n",
      "[Epoch 83/200] [Batch 10/938] loss_G: 2.871049, loss_D: 0.245772\n",
      "[Epoch 83/200] [Batch 20/938] loss_G: 3.053297, loss_D: 0.179977\n",
      "[Epoch 83/200] [Batch 30/938] loss_G: 3.190449, loss_D: 0.181966\n",
      "[Epoch 83/200] [Batch 40/938] loss_G: 2.999489, loss_D: 0.312086\n",
      "[Epoch 83/200] [Batch 50/938] loss_G: 2.812784, loss_D: 0.216830\n",
      "[Epoch 83/200] [Batch 60/938] loss_G: 3.477697, loss_D: 0.173196\n",
      "[Epoch 83/200] [Batch 70/938] loss_G: 2.653214, loss_D: 0.288000\n",
      "[Epoch 83/200] [Batch 80/938] loss_G: 2.839543, loss_D: 0.186983\n",
      "[Epoch 83/200] [Batch 90/938] loss_G: 2.892443, loss_D: 0.182827\n",
      "[Epoch 83/200] [Batch 100/938] loss_G: 2.477110, loss_D: 0.281776\n",
      "[Epoch 83/200] [Batch 110/938] loss_G: 3.435666, loss_D: 0.195544\n",
      "[Epoch 83/200] [Batch 120/938] loss_G: 2.613843, loss_D: 0.180057\n",
      "[Epoch 83/200] [Batch 130/938] loss_G: 3.162680, loss_D: 0.273316\n",
      "[Epoch 83/200] [Batch 140/938] loss_G: 2.806820, loss_D: 0.204134\n",
      "[Epoch 83/200] [Batch 150/938] loss_G: 2.670340, loss_D: 0.227589\n",
      "[Epoch 83/200] [Batch 160/938] loss_G: 2.903421, loss_D: 0.204529\n",
      "[Epoch 83/200] [Batch 170/938] loss_G: 3.312589, loss_D: 0.209201\n",
      "[Epoch 83/200] [Batch 180/938] loss_G: 3.149950, loss_D: 0.176290\n",
      "[Epoch 83/200] [Batch 190/938] loss_G: 2.822641, loss_D: 0.207287\n",
      "[Epoch 83/200] [Batch 200/938] loss_G: 2.808011, loss_D: 0.200351\n",
      "[Epoch 83/200] [Batch 210/938] loss_G: 3.037761, loss_D: 0.154248\n",
      "[Epoch 83/200] [Batch 220/938] loss_G: 3.013884, loss_D: 0.181765\n",
      "[Epoch 83/200] [Batch 230/938] loss_G: 3.043663, loss_D: 0.173470\n",
      "[Epoch 83/200] [Batch 240/938] loss_G: 2.498518, loss_D: 0.300388\n",
      "[Epoch 83/200] [Batch 250/938] loss_G: 2.933518, loss_D: 0.162736\n",
      "[Epoch 83/200] [Batch 260/938] loss_G: 2.420576, loss_D: 0.297989\n",
      "[Epoch 83/200] [Batch 270/938] loss_G: 2.877386, loss_D: 0.205471\n",
      "[Epoch 83/200] [Batch 280/938] loss_G: 2.812918, loss_D: 0.281499\n",
      "[Epoch 83/200] [Batch 290/938] loss_G: 3.035282, loss_D: 0.207444\n",
      "[Epoch 83/200] [Batch 300/938] loss_G: 3.019689, loss_D: 0.120038\n",
      "[Epoch 83/200] [Batch 310/938] loss_G: 3.326702, loss_D: 0.197650\n",
      "[Epoch 83/200] [Batch 320/938] loss_G: 2.607744, loss_D: 0.200765\n",
      "[Epoch 83/200] [Batch 330/938] loss_G: 3.121881, loss_D: 0.268831\n",
      "[Epoch 83/200] [Batch 340/938] loss_G: 2.618384, loss_D: 0.191256\n",
      "[Epoch 83/200] [Batch 350/938] loss_G: 2.936850, loss_D: 0.176068\n",
      "[Epoch 83/200] [Batch 360/938] loss_G: 3.420794, loss_D: 0.136512\n",
      "[Epoch 83/200] [Batch 370/938] loss_G: 2.748266, loss_D: 0.188772\n",
      "[Epoch 83/200] [Batch 380/938] loss_G: 3.298813, loss_D: 0.119695\n",
      "[Epoch 83/200] [Batch 390/938] loss_G: 2.497546, loss_D: 0.281714\n",
      "[Epoch 83/200] [Batch 400/938] loss_G: 2.996968, loss_D: 0.241075\n",
      "[Epoch 83/200] [Batch 410/938] loss_G: 2.587626, loss_D: 0.265331\n",
      "[Epoch 83/200] [Batch 420/938] loss_G: 3.137160, loss_D: 0.180086\n",
      "[Epoch 83/200] [Batch 430/938] loss_G: 2.766959, loss_D: 0.195124\n",
      "[Epoch 83/200] [Batch 440/938] loss_G: 3.022356, loss_D: 0.195498\n",
      "[Epoch 83/200] [Batch 450/938] loss_G: 2.887328, loss_D: 0.172055\n",
      "[Epoch 83/200] [Batch 460/938] loss_G: 2.742339, loss_D: 0.174767\n",
      "[Epoch 83/200] [Batch 470/938] loss_G: 2.512229, loss_D: 0.289967\n",
      "[Epoch 83/200] [Batch 480/938] loss_G: 2.726693, loss_D: 0.264462\n",
      "[Epoch 83/200] [Batch 490/938] loss_G: 2.638472, loss_D: 0.169094\n",
      "[Epoch 83/200] [Batch 500/938] loss_G: 2.751467, loss_D: 0.163865\n",
      "[Epoch 83/200] [Batch 510/938] loss_G: 2.809986, loss_D: 0.168185\n",
      "[Epoch 83/200] [Batch 520/938] loss_G: 2.913241, loss_D: 0.277402\n",
      "[Epoch 83/200] [Batch 530/938] loss_G: 2.881893, loss_D: 0.225102\n",
      "[Epoch 83/200] [Batch 540/938] loss_G: 2.949986, loss_D: 0.199255\n",
      "[Epoch 83/200] [Batch 550/938] loss_G: 2.642257, loss_D: 0.254210\n",
      "[Epoch 83/200] [Batch 560/938] loss_G: 3.077064, loss_D: 0.169079\n",
      "[Epoch 83/200] [Batch 570/938] loss_G: 2.954097, loss_D: 0.203651\n",
      "[Epoch 83/200] [Batch 580/938] loss_G: 3.258791, loss_D: 0.231487\n",
      "[Epoch 83/200] [Batch 590/938] loss_G: 3.110554, loss_D: 0.167648\n",
      "[Epoch 83/200] [Batch 600/938] loss_G: 3.071186, loss_D: 0.211489\n",
      "[Epoch 83/200] [Batch 610/938] loss_G: 3.231527, loss_D: 0.252389\n",
      "[Epoch 83/200] [Batch 620/938] loss_G: 2.995657, loss_D: 0.234123\n",
      "[Epoch 83/200] [Batch 630/938] loss_G: 3.103183, loss_D: 0.257640\n",
      "[Epoch 83/200] [Batch 640/938] loss_G: 3.409730, loss_D: 0.208625\n",
      "[Epoch 83/200] [Batch 650/938] loss_G: 2.818587, loss_D: 0.222115\n",
      "[Epoch 83/200] [Batch 660/938] loss_G: 2.838305, loss_D: 0.235212\n",
      "[Epoch 83/200] [Batch 670/938] loss_G: 2.685647, loss_D: 0.256991\n",
      "[Epoch 83/200] [Batch 680/938] loss_G: 2.882662, loss_D: 0.210548\n",
      "[Epoch 83/200] [Batch 690/938] loss_G: 2.942793, loss_D: 0.219923\n",
      "[Epoch 83/200] [Batch 700/938] loss_G: 3.267452, loss_D: 0.202427\n",
      "[Epoch 83/200] [Batch 710/938] loss_G: 2.679608, loss_D: 0.161994\n",
      "[Epoch 83/200] [Batch 720/938] loss_G: 3.383885, loss_D: 0.249243\n",
      "[Epoch 83/200] [Batch 730/938] loss_G: 2.845085, loss_D: 0.234403\n",
      "[Epoch 83/200] [Batch 740/938] loss_G: 3.158749, loss_D: 0.227771\n",
      "[Epoch 83/200] [Batch 750/938] loss_G: 2.877253, loss_D: 0.218056\n",
      "[Epoch 83/200] [Batch 760/938] loss_G: 2.590238, loss_D: 0.222832\n",
      "[Epoch 83/200] [Batch 770/938] loss_G: 3.599253, loss_D: 0.213429\n",
      "[Epoch 83/200] [Batch 780/938] loss_G: 2.508197, loss_D: 0.181214\n",
      "[Epoch 83/200] [Batch 790/938] loss_G: 2.611751, loss_D: 0.347127\n",
      "[Epoch 83/200] [Batch 800/938] loss_G: 2.866493, loss_D: 0.213717\n",
      "[Epoch 83/200] [Batch 810/938] loss_G: 2.906128, loss_D: 0.266876\n",
      "[Epoch 83/200] [Batch 820/938] loss_G: 2.594042, loss_D: 0.214868\n",
      "[Epoch 83/200] [Batch 830/938] loss_G: 2.624428, loss_D: 0.227615\n",
      "[Epoch 83/200] [Batch 840/938] loss_G: 2.953943, loss_D: 0.289446\n",
      "[Epoch 83/200] [Batch 850/938] loss_G: 2.873993, loss_D: 0.211639\n",
      "[Epoch 83/200] [Batch 860/938] loss_G: 3.527267, loss_D: 0.181854\n",
      "[Epoch 83/200] [Batch 870/938] loss_G: 2.593400, loss_D: 0.247781\n",
      "[Epoch 83/200] [Batch 880/938] loss_G: 2.844588, loss_D: 0.193561\n",
      "[Epoch 83/200] [Batch 890/938] loss_G: 2.720099, loss_D: 0.194719\n",
      "[Epoch 83/200] [Batch 900/938] loss_G: 2.766376, loss_D: 0.277024\n",
      "[Epoch 83/200] [Batch 910/938] loss_G: 2.797752, loss_D: 0.294089\n",
      "[Epoch 83/200] [Batch 920/938] loss_G: 3.484722, loss_D: 0.227021\n",
      "[Epoch 83/200] [Batch 930/938] loss_G: 2.894650, loss_D: 0.216733\n",
      "[Epoch 84/200] [Batch 0/938] loss_G: 2.729814, loss_D: 0.231233\n",
      "[Epoch 84/200] [Batch 10/938] loss_G: 3.164989, loss_D: 0.204878\n",
      "[Epoch 84/200] [Batch 20/938] loss_G: 3.056236, loss_D: 0.221264\n",
      "[Epoch 84/200] [Batch 30/938] loss_G: 3.144330, loss_D: 0.124872\n",
      "[Epoch 84/200] [Batch 40/938] loss_G: 2.653406, loss_D: 0.196367\n",
      "[Epoch 84/200] [Batch 50/938] loss_G: 2.783943, loss_D: 0.194152\n",
      "[Epoch 84/200] [Batch 60/938] loss_G: 2.523365, loss_D: 0.254286\n",
      "[Epoch 84/200] [Batch 70/938] loss_G: 3.019765, loss_D: 0.194313\n",
      "[Epoch 84/200] [Batch 80/938] loss_G: 2.803601, loss_D: 0.193773\n",
      "[Epoch 84/200] [Batch 90/938] loss_G: 3.044830, loss_D: 0.283567\n",
      "[Epoch 84/200] [Batch 100/938] loss_G: 2.626029, loss_D: 0.226310\n",
      "[Epoch 84/200] [Batch 110/938] loss_G: 3.058578, loss_D: 0.286564\n",
      "[Epoch 84/200] [Batch 120/938] loss_G: 2.697433, loss_D: 0.228979\n",
      "[Epoch 84/200] [Batch 130/938] loss_G: 2.667860, loss_D: 0.310151\n",
      "[Epoch 84/200] [Batch 140/938] loss_G: 2.940696, loss_D: 0.190039\n",
      "[Epoch 84/200] [Batch 150/938] loss_G: 2.909497, loss_D: 0.228849\n",
      "[Epoch 84/200] [Batch 160/938] loss_G: 2.868614, loss_D: 0.218221\n",
      "[Epoch 84/200] [Batch 170/938] loss_G: 3.126370, loss_D: 0.216427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 84/200] [Batch 180/938] loss_G: 2.854759, loss_D: 0.245364\n",
      "[Epoch 84/200] [Batch 190/938] loss_G: 2.962093, loss_D: 0.295252\n",
      "[Epoch 84/200] [Batch 200/938] loss_G: 3.065142, loss_D: 0.260683\n",
      "[Epoch 84/200] [Batch 210/938] loss_G: 3.247742, loss_D: 0.220913\n",
      "[Epoch 84/200] [Batch 220/938] loss_G: 2.733052, loss_D: 0.223516\n",
      "[Epoch 84/200] [Batch 230/938] loss_G: 3.088260, loss_D: 0.186533\n",
      "[Epoch 84/200] [Batch 240/938] loss_G: 2.937649, loss_D: 0.320382\n",
      "[Epoch 84/200] [Batch 250/938] loss_G: 2.908765, loss_D: 0.170114\n",
      "[Epoch 84/200] [Batch 260/938] loss_G: 2.843573, loss_D: 0.234856\n",
      "[Epoch 84/200] [Batch 270/938] loss_G: 3.072217, loss_D: 0.178319\n",
      "[Epoch 84/200] [Batch 280/938] loss_G: 2.982550, loss_D: 0.226488\n",
      "[Epoch 84/200] [Batch 290/938] loss_G: 3.211159, loss_D: 0.193221\n",
      "[Epoch 84/200] [Batch 300/938] loss_G: 2.716370, loss_D: 0.161716\n",
      "[Epoch 84/200] [Batch 310/938] loss_G: 3.026856, loss_D: 0.189728\n",
      "[Epoch 84/200] [Batch 320/938] loss_G: 3.056197, loss_D: 0.237524\n",
      "[Epoch 84/200] [Batch 330/938] loss_G: 2.929921, loss_D: 0.171187\n",
      "[Epoch 84/200] [Batch 340/938] loss_G: 2.805713, loss_D: 0.257280\n",
      "[Epoch 84/200] [Batch 350/938] loss_G: 2.906261, loss_D: 0.159131\n",
      "[Epoch 84/200] [Batch 360/938] loss_G: 2.699481, loss_D: 0.242518\n",
      "[Epoch 84/200] [Batch 370/938] loss_G: 3.052834, loss_D: 0.223657\n",
      "[Epoch 84/200] [Batch 380/938] loss_G: 2.986208, loss_D: 0.198156\n",
      "[Epoch 84/200] [Batch 390/938] loss_G: 2.601949, loss_D: 0.235220\n",
      "[Epoch 84/200] [Batch 400/938] loss_G: 2.946882, loss_D: 0.185650\n",
      "[Epoch 84/200] [Batch 410/938] loss_G: 2.960288, loss_D: 0.214566\n",
      "[Epoch 84/200] [Batch 420/938] loss_G: 2.527046, loss_D: 0.170767\n",
      "[Epoch 84/200] [Batch 430/938] loss_G: 3.150761, loss_D: 0.138163\n",
      "[Epoch 84/200] [Batch 440/938] loss_G: 2.697092, loss_D: 0.279354\n",
      "[Epoch 84/200] [Batch 450/938] loss_G: 3.352609, loss_D: 0.163951\n",
      "[Epoch 84/200] [Batch 460/938] loss_G: 2.938977, loss_D: 0.228579\n",
      "[Epoch 84/200] [Batch 470/938] loss_G: 3.175801, loss_D: 0.154448\n",
      "[Epoch 84/200] [Batch 480/938] loss_G: 2.735934, loss_D: 0.192412\n",
      "[Epoch 84/200] [Batch 490/938] loss_G: 3.167302, loss_D: 0.130830\n",
      "[Epoch 84/200] [Batch 500/938] loss_G: 3.038318, loss_D: 0.149163\n",
      "[Epoch 84/200] [Batch 510/938] loss_G: 2.919508, loss_D: 0.301357\n",
      "[Epoch 84/200] [Batch 520/938] loss_G: 2.875128, loss_D: 0.230462\n",
      "[Epoch 84/200] [Batch 530/938] loss_G: 2.637392, loss_D: 0.228912\n",
      "[Epoch 84/200] [Batch 540/938] loss_G: 3.002693, loss_D: 0.178080\n",
      "[Epoch 84/200] [Batch 550/938] loss_G: 2.852025, loss_D: 0.228331\n",
      "[Epoch 84/200] [Batch 560/938] loss_G: 2.856892, loss_D: 0.183444\n",
      "[Epoch 84/200] [Batch 570/938] loss_G: 3.006340, loss_D: 0.243606\n",
      "[Epoch 84/200] [Batch 580/938] loss_G: 2.803767, loss_D: 0.218544\n",
      "[Epoch 84/200] [Batch 590/938] loss_G: 2.803891, loss_D: 0.217857\n",
      "[Epoch 84/200] [Batch 600/938] loss_G: 2.871850, loss_D: 0.208623\n",
      "[Epoch 84/200] [Batch 610/938] loss_G: 2.405852, loss_D: 0.212618\n",
      "[Epoch 84/200] [Batch 620/938] loss_G: 3.093045, loss_D: 0.193253\n",
      "[Epoch 84/200] [Batch 630/938] loss_G: 2.819049, loss_D: 0.207632\n",
      "[Epoch 84/200] [Batch 640/938] loss_G: 2.783264, loss_D: 0.282514\n",
      "[Epoch 84/200] [Batch 650/938] loss_G: 3.018892, loss_D: 0.188417\n",
      "[Epoch 84/200] [Batch 660/938] loss_G: 3.146691, loss_D: 0.208042\n",
      "[Epoch 84/200] [Batch 670/938] loss_G: 2.708446, loss_D: 0.284468\n",
      "[Epoch 84/200] [Batch 680/938] loss_G: 2.932357, loss_D: 0.248585\n",
      "[Epoch 84/200] [Batch 690/938] loss_G: 2.676370, loss_D: 0.125006\n",
      "[Epoch 84/200] [Batch 700/938] loss_G: 2.846093, loss_D: 0.257376\n",
      "[Epoch 84/200] [Batch 710/938] loss_G: 2.708265, loss_D: 0.168164\n",
      "[Epoch 84/200] [Batch 720/938] loss_G: 3.254579, loss_D: 0.147688\n",
      "[Epoch 84/200] [Batch 730/938] loss_G: 2.810924, loss_D: 0.282428\n",
      "[Epoch 84/200] [Batch 740/938] loss_G: 3.151617, loss_D: 0.175699\n",
      "[Epoch 84/200] [Batch 750/938] loss_G: 2.928102, loss_D: 0.334570\n",
      "[Epoch 84/200] [Batch 760/938] loss_G: 2.821687, loss_D: 0.194496\n",
      "[Epoch 84/200] [Batch 770/938] loss_G: 2.912070, loss_D: 0.290867\n",
      "[Epoch 84/200] [Batch 780/938] loss_G: 2.993430, loss_D: 0.251540\n",
      "[Epoch 84/200] [Batch 790/938] loss_G: 3.016589, loss_D: 0.187786\n",
      "[Epoch 84/200] [Batch 800/938] loss_G: 3.351485, loss_D: 0.197496\n",
      "[Epoch 84/200] [Batch 810/938] loss_G: 2.824836, loss_D: 0.244199\n",
      "[Epoch 84/200] [Batch 820/938] loss_G: 3.097581, loss_D: 0.165109\n",
      "[Epoch 84/200] [Batch 830/938] loss_G: 3.229204, loss_D: 0.148940\n",
      "[Epoch 84/200] [Batch 840/938] loss_G: 2.816901, loss_D: 0.280675\n",
      "[Epoch 84/200] [Batch 850/938] loss_G: 2.553104, loss_D: 0.301550\n",
      "[Epoch 84/200] [Batch 860/938] loss_G: 3.047910, loss_D: 0.148161\n",
      "[Epoch 84/200] [Batch 870/938] loss_G: 2.952529, loss_D: 0.170172\n",
      "[Epoch 84/200] [Batch 880/938] loss_G: 2.748797, loss_D: 0.346796\n",
      "[Epoch 84/200] [Batch 890/938] loss_G: 2.577431, loss_D: 0.205112\n",
      "[Epoch 84/200] [Batch 900/938] loss_G: 2.973182, loss_D: 0.272685\n",
      "[Epoch 84/200] [Batch 910/938] loss_G: 2.564204, loss_D: 0.269560\n",
      "[Epoch 84/200] [Batch 920/938] loss_G: 3.115920, loss_D: 0.220022\n",
      "[Epoch 84/200] [Batch 930/938] loss_G: 2.722412, loss_D: 0.332784\n",
      "[Epoch 85/200] [Batch 0/938] loss_G: 2.959092, loss_D: 0.179553\n",
      "[Epoch 85/200] [Batch 10/938] loss_G: 2.849900, loss_D: 0.288796\n",
      "[Epoch 85/200] [Batch 20/938] loss_G: 2.939310, loss_D: 0.277776\n",
      "[Epoch 85/200] [Batch 30/938] loss_G: 2.668047, loss_D: 0.258113\n",
      "[Epoch 85/200] [Batch 40/938] loss_G: 3.417151, loss_D: 0.121212\n",
      "[Epoch 85/200] [Batch 50/938] loss_G: 2.845266, loss_D: 0.169952\n",
      "[Epoch 85/200] [Batch 60/938] loss_G: 3.121342, loss_D: 0.180293\n",
      "[Epoch 85/200] [Batch 70/938] loss_G: 3.064826, loss_D: 0.171824\n",
      "[Epoch 85/200] [Batch 80/938] loss_G: 2.959677, loss_D: 0.184250\n",
      "[Epoch 85/200] [Batch 90/938] loss_G: 3.218941, loss_D: 0.241947\n",
      "[Epoch 85/200] [Batch 100/938] loss_G: 3.122399, loss_D: 0.141549\n",
      "[Epoch 85/200] [Batch 110/938] loss_G: 2.787586, loss_D: 0.294113\n",
      "[Epoch 85/200] [Batch 120/938] loss_G: 2.847538, loss_D: 0.227709\n",
      "[Epoch 85/200] [Batch 130/938] loss_G: 2.736398, loss_D: 0.193483\n",
      "[Epoch 85/200] [Batch 140/938] loss_G: 2.789942, loss_D: 0.172238\n",
      "[Epoch 85/200] [Batch 150/938] loss_G: 3.369386, loss_D: 0.175233\n",
      "[Epoch 85/200] [Batch 160/938] loss_G: 2.802835, loss_D: 0.189190\n",
      "[Epoch 85/200] [Batch 170/938] loss_G: 3.130378, loss_D: 0.131774\n",
      "[Epoch 85/200] [Batch 180/938] loss_G: 3.054292, loss_D: 0.284447\n",
      "[Epoch 85/200] [Batch 190/938] loss_G: 2.734356, loss_D: 0.344331\n",
      "[Epoch 85/200] [Batch 200/938] loss_G: 3.142422, loss_D: 0.272693\n",
      "[Epoch 85/200] [Batch 210/938] loss_G: 2.650948, loss_D: 0.244021\n",
      "[Epoch 85/200] [Batch 220/938] loss_G: 3.263176, loss_D: 0.192878\n",
      "[Epoch 85/200] [Batch 230/938] loss_G: 2.899217, loss_D: 0.222889\n",
      "[Epoch 85/200] [Batch 240/938] loss_G: 2.764909, loss_D: 0.292924\n",
      "[Epoch 85/200] [Batch 250/938] loss_G: 3.051957, loss_D: 0.206962\n",
      "[Epoch 85/200] [Batch 260/938] loss_G: 2.260876, loss_D: 0.287554\n",
      "[Epoch 85/200] [Batch 270/938] loss_G: 3.336714, loss_D: 0.263822\n",
      "[Epoch 85/200] [Batch 280/938] loss_G: 2.455485, loss_D: 0.219761\n",
      "[Epoch 85/200] [Batch 290/938] loss_G: 3.154389, loss_D: 0.253001\n",
      "[Epoch 85/200] [Batch 300/938] loss_G: 3.052985, loss_D: 0.253417\n",
      "[Epoch 85/200] [Batch 310/938] loss_G: 2.781187, loss_D: 0.149026\n",
      "[Epoch 85/200] [Batch 320/938] loss_G: 3.284817, loss_D: 0.274751\n",
      "[Epoch 85/200] [Batch 330/938] loss_G: 2.690707, loss_D: 0.172489\n",
      "[Epoch 85/200] [Batch 340/938] loss_G: 3.221374, loss_D: 0.259593\n",
      "[Epoch 85/200] [Batch 350/938] loss_G: 2.863982, loss_D: 0.244211\n",
      "[Epoch 85/200] [Batch 360/938] loss_G: 2.951063, loss_D: 0.273463\n",
      "[Epoch 85/200] [Batch 370/938] loss_G: 2.831086, loss_D: 0.174601\n",
      "[Epoch 85/200] [Batch 380/938] loss_G: 2.538768, loss_D: 0.342227\n",
      "[Epoch 85/200] [Batch 390/938] loss_G: 2.943891, loss_D: 0.204149\n",
      "[Epoch 85/200] [Batch 400/938] loss_G: 2.863806, loss_D: 0.200231\n",
      "[Epoch 85/200] [Batch 410/938] loss_G: 2.860897, loss_D: 0.185008\n",
      "[Epoch 85/200] [Batch 420/938] loss_G: 2.628232, loss_D: 0.193913\n",
      "[Epoch 85/200] [Batch 430/938] loss_G: 2.699242, loss_D: 0.304805\n",
      "[Epoch 85/200] [Batch 440/938] loss_G: 2.645767, loss_D: 0.281939\n",
      "[Epoch 85/200] [Batch 450/938] loss_G: 2.755095, loss_D: 0.129949\n",
      "[Epoch 85/200] [Batch 460/938] loss_G: 2.835577, loss_D: 0.249711\n",
      "[Epoch 85/200] [Batch 470/938] loss_G: 2.910849, loss_D: 0.141607\n",
      "[Epoch 85/200] [Batch 480/938] loss_G: 2.837644, loss_D: 0.268015\n",
      "[Epoch 85/200] [Batch 490/938] loss_G: 3.197480, loss_D: 0.244886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 85/200] [Batch 500/938] loss_G: 3.137565, loss_D: 0.179452\n",
      "[Epoch 85/200] [Batch 510/938] loss_G: 2.618768, loss_D: 0.170944\n",
      "[Epoch 85/200] [Batch 520/938] loss_G: 2.955677, loss_D: 0.144080\n",
      "[Epoch 85/200] [Batch 530/938] loss_G: 2.628517, loss_D: 0.223991\n",
      "[Epoch 85/200] [Batch 540/938] loss_G: 2.659757, loss_D: 0.112602\n",
      "[Epoch 85/200] [Batch 550/938] loss_G: 2.975496, loss_D: 0.192896\n",
      "[Epoch 85/200] [Batch 560/938] loss_G: 3.045838, loss_D: 0.287089\n",
      "[Epoch 85/200] [Batch 570/938] loss_G: 2.990276, loss_D: 0.163567\n",
      "[Epoch 85/200] [Batch 580/938] loss_G: 2.835227, loss_D: 0.204044\n",
      "[Epoch 85/200] [Batch 590/938] loss_G: 3.268529, loss_D: 0.163487\n",
      "[Epoch 85/200] [Batch 600/938] loss_G: 2.856131, loss_D: 0.186017\n",
      "[Epoch 85/200] [Batch 610/938] loss_G: 2.831374, loss_D: 0.306391\n",
      "[Epoch 85/200] [Batch 620/938] loss_G: 2.959482, loss_D: 0.207710\n",
      "[Epoch 85/200] [Batch 630/938] loss_G: 2.772305, loss_D: 0.184549\n",
      "[Epoch 85/200] [Batch 640/938] loss_G: 2.756680, loss_D: 0.239479\n",
      "[Epoch 85/200] [Batch 650/938] loss_G: 2.790436, loss_D: 0.214025\n",
      "[Epoch 85/200] [Batch 660/938] loss_G: 2.807413, loss_D: 0.224952\n",
      "[Epoch 85/200] [Batch 670/938] loss_G: 2.719261, loss_D: 0.271604\n",
      "[Epoch 85/200] [Batch 680/938] loss_G: 2.544120, loss_D: 0.291440\n",
      "[Epoch 85/200] [Batch 690/938] loss_G: 2.873934, loss_D: 0.231839\n",
      "[Epoch 85/200] [Batch 700/938] loss_G: 2.539144, loss_D: 0.261265\n",
      "[Epoch 85/200] [Batch 710/938] loss_G: 2.911974, loss_D: 0.223925\n",
      "[Epoch 85/200] [Batch 720/938] loss_G: 2.824815, loss_D: 0.206705\n",
      "[Epoch 85/200] [Batch 730/938] loss_G: 2.947144, loss_D: 0.207388\n",
      "[Epoch 85/200] [Batch 740/938] loss_G: 2.892634, loss_D: 0.193821\n",
      "[Epoch 85/200] [Batch 750/938] loss_G: 2.910367, loss_D: 0.176118\n",
      "[Epoch 85/200] [Batch 760/938] loss_G: 2.828359, loss_D: 0.155536\n",
      "[Epoch 85/200] [Batch 770/938] loss_G: 2.998725, loss_D: 0.208214\n",
      "[Epoch 85/200] [Batch 780/938] loss_G: 2.784719, loss_D: 0.196915\n",
      "[Epoch 85/200] [Batch 790/938] loss_G: 3.072932, loss_D: 0.164359\n",
      "[Epoch 85/200] [Batch 800/938] loss_G: 2.970568, loss_D: 0.195706\n",
      "[Epoch 85/200] [Batch 810/938] loss_G: 2.713137, loss_D: 0.246621\n",
      "[Epoch 85/200] [Batch 820/938] loss_G: 2.749898, loss_D: 0.260151\n",
      "[Epoch 85/200] [Batch 830/938] loss_G: 2.609031, loss_D: 0.181221\n",
      "[Epoch 85/200] [Batch 840/938] loss_G: 2.943516, loss_D: 0.266120\n",
      "[Epoch 85/200] [Batch 850/938] loss_G: 2.858554, loss_D: 0.176995\n",
      "[Epoch 85/200] [Batch 860/938] loss_G: 2.903424, loss_D: 0.368014\n",
      "[Epoch 85/200] [Batch 870/938] loss_G: 2.547158, loss_D: 0.208480\n",
      "[Epoch 85/200] [Batch 880/938] loss_G: 3.389669, loss_D: 0.159965\n",
      "[Epoch 85/200] [Batch 890/938] loss_G: 2.979665, loss_D: 0.164552\n",
      "[Epoch 85/200] [Batch 900/938] loss_G: 2.886561, loss_D: 0.204021\n",
      "[Epoch 85/200] [Batch 910/938] loss_G: 3.079746, loss_D: 0.151653\n",
      "[Epoch 85/200] [Batch 920/938] loss_G: 2.948962, loss_D: 0.190288\n",
      "[Epoch 85/200] [Batch 930/938] loss_G: 2.716816, loss_D: 0.210343\n",
      "[Epoch 86/200] [Batch 0/938] loss_G: 2.588066, loss_D: 0.252097\n",
      "[Epoch 86/200] [Batch 10/938] loss_G: 2.853440, loss_D: 0.221537\n",
      "[Epoch 86/200] [Batch 20/938] loss_G: 2.812029, loss_D: 0.243490\n",
      "[Epoch 86/200] [Batch 30/938] loss_G: 2.726262, loss_D: 0.203584\n",
      "[Epoch 86/200] [Batch 40/938] loss_G: 2.983517, loss_D: 0.215352\n",
      "[Epoch 86/200] [Batch 50/938] loss_G: 2.732479, loss_D: 0.236500\n",
      "[Epoch 86/200] [Batch 60/938] loss_G: 3.084936, loss_D: 0.265037\n",
      "[Epoch 86/200] [Batch 70/938] loss_G: 2.589932, loss_D: 0.213821\n",
      "[Epoch 86/200] [Batch 80/938] loss_G: 2.389281, loss_D: 0.193569\n",
      "[Epoch 86/200] [Batch 90/938] loss_G: 2.845842, loss_D: 0.202657\n",
      "[Epoch 86/200] [Batch 100/938] loss_G: 2.898119, loss_D: 0.191473\n",
      "[Epoch 86/200] [Batch 110/938] loss_G: 2.764849, loss_D: 0.212877\n",
      "[Epoch 86/200] [Batch 120/938] loss_G: 2.758333, loss_D: 0.177889\n",
      "[Epoch 86/200] [Batch 130/938] loss_G: 2.831216, loss_D: 0.189900\n",
      "[Epoch 86/200] [Batch 140/938] loss_G: 2.849626, loss_D: 0.227964\n",
      "[Epoch 86/200] [Batch 150/938] loss_G: 2.488229, loss_D: 0.338070\n",
      "[Epoch 86/200] [Batch 160/938] loss_G: 3.086649, loss_D: 0.261958\n",
      "[Epoch 86/200] [Batch 170/938] loss_G: 2.953184, loss_D: 0.192364\n",
      "[Epoch 86/200] [Batch 180/938] loss_G: 2.977910, loss_D: 0.208907\n",
      "[Epoch 86/200] [Batch 190/938] loss_G: 2.754766, loss_D: 0.204172\n",
      "[Epoch 86/200] [Batch 200/938] loss_G: 2.433522, loss_D: 0.285926\n",
      "[Epoch 86/200] [Batch 210/938] loss_G: 2.918881, loss_D: 0.199855\n",
      "[Epoch 86/200] [Batch 220/938] loss_G: 3.279789, loss_D: 0.164268\n",
      "[Epoch 86/200] [Batch 230/938] loss_G: 2.652802, loss_D: 0.188577\n",
      "[Epoch 86/200] [Batch 240/938] loss_G: 2.964882, loss_D: 0.234780\n",
      "[Epoch 86/200] [Batch 250/938] loss_G: 2.872355, loss_D: 0.197523\n",
      "[Epoch 86/200] [Batch 260/938] loss_G: 3.068251, loss_D: 0.205126\n",
      "[Epoch 86/200] [Batch 270/938] loss_G: 2.907731, loss_D: 0.227485\n",
      "[Epoch 86/200] [Batch 280/938] loss_G: 3.055593, loss_D: 0.175131\n",
      "[Epoch 86/200] [Batch 290/938] loss_G: 2.915493, loss_D: 0.223445\n",
      "[Epoch 86/200] [Batch 300/938] loss_G: 3.112209, loss_D: 0.168177\n",
      "[Epoch 86/200] [Batch 310/938] loss_G: 3.019765, loss_D: 0.236161\n",
      "[Epoch 86/200] [Batch 320/938] loss_G: 2.952649, loss_D: 0.204464\n",
      "[Epoch 86/200] [Batch 330/938] loss_G: 3.150205, loss_D: 0.152274\n",
      "[Epoch 86/200] [Batch 340/938] loss_G: 2.838158, loss_D: 0.173111\n",
      "[Epoch 86/200] [Batch 350/938] loss_G: 3.162154, loss_D: 0.162039\n",
      "[Epoch 86/200] [Batch 360/938] loss_G: 2.813026, loss_D: 0.300276\n",
      "[Epoch 86/200] [Batch 370/938] loss_G: 3.108233, loss_D: 0.154636\n",
      "[Epoch 86/200] [Batch 380/938] loss_G: 2.759547, loss_D: 0.232993\n",
      "[Epoch 86/200] [Batch 390/938] loss_G: 3.008823, loss_D: 0.158651\n",
      "[Epoch 86/200] [Batch 400/938] loss_G: 2.878884, loss_D: 0.214060\n",
      "[Epoch 86/200] [Batch 410/938] loss_G: 2.891494, loss_D: 0.206477\n",
      "[Epoch 86/200] [Batch 420/938] loss_G: 3.062904, loss_D: 0.174918\n",
      "[Epoch 86/200] [Batch 430/938] loss_G: 2.806471, loss_D: 0.216177\n",
      "[Epoch 86/200] [Batch 440/938] loss_G: 2.852133, loss_D: 0.174279\n",
      "[Epoch 86/200] [Batch 450/938] loss_G: 3.016578, loss_D: 0.209647\n",
      "[Epoch 86/200] [Batch 460/938] loss_G: 3.103272, loss_D: 0.197918\n",
      "[Epoch 86/200] [Batch 470/938] loss_G: 2.687836, loss_D: 0.257621\n",
      "[Epoch 86/200] [Batch 480/938] loss_G: 2.909869, loss_D: 0.319878\n",
      "[Epoch 86/200] [Batch 490/938] loss_G: 2.643056, loss_D: 0.274322\n",
      "[Epoch 86/200] [Batch 500/938] loss_G: 2.770951, loss_D: 0.213681\n",
      "[Epoch 86/200] [Batch 510/938] loss_G: 2.773715, loss_D: 0.235324\n",
      "[Epoch 86/200] [Batch 520/938] loss_G: 2.504586, loss_D: 0.180423\n",
      "[Epoch 86/200] [Batch 530/938] loss_G: 2.976332, loss_D: 0.230654\n",
      "[Epoch 86/200] [Batch 540/938] loss_G: 2.599173, loss_D: 0.245664\n",
      "[Epoch 86/200] [Batch 550/938] loss_G: 2.957828, loss_D: 0.180170\n",
      "[Epoch 86/200] [Batch 560/938] loss_G: 2.985128, loss_D: 0.171517\n",
      "[Epoch 86/200] [Batch 570/938] loss_G: 2.701442, loss_D: 0.260087\n",
      "[Epoch 86/200] [Batch 580/938] loss_G: 2.866028, loss_D: 0.164010\n",
      "[Epoch 86/200] [Batch 590/938] loss_G: 2.546584, loss_D: 0.281025\n",
      "[Epoch 86/200] [Batch 600/938] loss_G: 2.867959, loss_D: 0.213693\n",
      "[Epoch 86/200] [Batch 610/938] loss_G: 3.426002, loss_D: 0.149596\n",
      "[Epoch 86/200] [Batch 620/938] loss_G: 2.506304, loss_D: 0.211217\n",
      "[Epoch 86/200] [Batch 630/938] loss_G: 3.127729, loss_D: 0.216467\n",
      "[Epoch 86/200] [Batch 640/938] loss_G: 2.703541, loss_D: 0.264346\n",
      "[Epoch 86/200] [Batch 650/938] loss_G: 2.725822, loss_D: 0.157999\n",
      "[Epoch 86/200] [Batch 660/938] loss_G: 3.110981, loss_D: 0.204769\n",
      "[Epoch 86/200] [Batch 670/938] loss_G: 2.810884, loss_D: 0.234642\n",
      "[Epoch 86/200] [Batch 680/938] loss_G: 2.887099, loss_D: 0.166014\n",
      "[Epoch 86/200] [Batch 690/938] loss_G: 3.012396, loss_D: 0.154294\n",
      "[Epoch 86/200] [Batch 700/938] loss_G: 2.965813, loss_D: 0.221128\n",
      "[Epoch 86/200] [Batch 710/938] loss_G: 2.936077, loss_D: 0.162291\n",
      "[Epoch 86/200] [Batch 720/938] loss_G: 3.277710, loss_D: 0.258923\n",
      "[Epoch 86/200] [Batch 730/938] loss_G: 2.789602, loss_D: 0.192806\n",
      "[Epoch 86/200] [Batch 740/938] loss_G: 3.065214, loss_D: 0.216542\n",
      "[Epoch 86/200] [Batch 750/938] loss_G: 2.703914, loss_D: 0.155731\n",
      "[Epoch 86/200] [Batch 760/938] loss_G: 2.776978, loss_D: 0.167193\n",
      "[Epoch 86/200] [Batch 770/938] loss_G: 2.780491, loss_D: 0.192147\n",
      "[Epoch 86/200] [Batch 780/938] loss_G: 2.827375, loss_D: 0.225328\n",
      "[Epoch 86/200] [Batch 790/938] loss_G: 2.829177, loss_D: 0.244759\n",
      "[Epoch 86/200] [Batch 800/938] loss_G: 2.138874, loss_D: 0.267488\n",
      "[Epoch 86/200] [Batch 810/938] loss_G: 3.073992, loss_D: 0.268136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 86/200] [Batch 820/938] loss_G: 2.623957, loss_D: 0.219695\n",
      "[Epoch 86/200] [Batch 830/938] loss_G: 2.893079, loss_D: 0.252512\n",
      "[Epoch 86/200] [Batch 840/938] loss_G: 3.204060, loss_D: 0.148673\n",
      "[Epoch 86/200] [Batch 850/938] loss_G: 2.824267, loss_D: 0.177875\n",
      "[Epoch 86/200] [Batch 860/938] loss_G: 2.968848, loss_D: 0.286510\n",
      "[Epoch 86/200] [Batch 870/938] loss_G: 2.390181, loss_D: 0.277657\n",
      "[Epoch 86/200] [Batch 880/938] loss_G: 3.143329, loss_D: 0.270242\n",
      "[Epoch 86/200] [Batch 890/938] loss_G: 2.635594, loss_D: 0.272628\n",
      "[Epoch 86/200] [Batch 900/938] loss_G: 2.915945, loss_D: 0.227004\n",
      "[Epoch 86/200] [Batch 910/938] loss_G: 2.474751, loss_D: 0.251281\n",
      "[Epoch 86/200] [Batch 920/938] loss_G: 3.261711, loss_D: 0.333527\n",
      "[Epoch 86/200] [Batch 930/938] loss_G: 2.832692, loss_D: 0.218924\n",
      "[Epoch 87/200] [Batch 0/938] loss_G: 2.837734, loss_D: 0.174959\n",
      "[Epoch 87/200] [Batch 10/938] loss_G: 2.831841, loss_D: 0.161577\n",
      "[Epoch 87/200] [Batch 20/938] loss_G: 3.041009, loss_D: 0.186252\n",
      "[Epoch 87/200] [Batch 30/938] loss_G: 2.925256, loss_D: 0.228772\n",
      "[Epoch 87/200] [Batch 40/938] loss_G: 2.734540, loss_D: 0.179823\n",
      "[Epoch 87/200] [Batch 50/938] loss_G: 2.822289, loss_D: 0.213628\n",
      "[Epoch 87/200] [Batch 60/938] loss_G: 2.811034, loss_D: 0.195810\n",
      "[Epoch 87/200] [Batch 70/938] loss_G: 2.893562, loss_D: 0.213686\n",
      "[Epoch 87/200] [Batch 80/938] loss_G: 3.005700, loss_D: 0.203356\n",
      "[Epoch 87/200] [Batch 90/938] loss_G: 3.146519, loss_D: 0.176268\n",
      "[Epoch 87/200] [Batch 100/938] loss_G: 2.957215, loss_D: 0.283695\n",
      "[Epoch 87/200] [Batch 110/938] loss_G: 2.896319, loss_D: 0.240874\n",
      "[Epoch 87/200] [Batch 120/938] loss_G: 2.799853, loss_D: 0.193492\n",
      "[Epoch 87/200] [Batch 130/938] loss_G: 2.620610, loss_D: 0.237957\n",
      "[Epoch 87/200] [Batch 140/938] loss_G: 3.083561, loss_D: 0.177358\n",
      "[Epoch 87/200] [Batch 150/938] loss_G: 2.799196, loss_D: 0.209614\n",
      "[Epoch 87/200] [Batch 160/938] loss_G: 2.486525, loss_D: 0.212751\n",
      "[Epoch 87/200] [Batch 170/938] loss_G: 2.736166, loss_D: 0.227645\n",
      "[Epoch 87/200] [Batch 180/938] loss_G: 3.091297, loss_D: 0.153082\n",
      "[Epoch 87/200] [Batch 190/938] loss_G: 2.231715, loss_D: 0.229554\n",
      "[Epoch 87/200] [Batch 200/938] loss_G: 2.792026, loss_D: 0.330460\n",
      "[Epoch 87/200] [Batch 210/938] loss_G: 3.194745, loss_D: 0.209149\n",
      "[Epoch 87/200] [Batch 220/938] loss_G: 2.959308, loss_D: 0.148732\n",
      "[Epoch 87/200] [Batch 230/938] loss_G: 3.092791, loss_D: 0.184740\n",
      "[Epoch 87/200] [Batch 240/938] loss_G: 2.892672, loss_D: 0.166708\n",
      "[Epoch 87/200] [Batch 250/938] loss_G: 3.134335, loss_D: 0.263687\n",
      "[Epoch 87/200] [Batch 260/938] loss_G: 2.961464, loss_D: 0.261002\n",
      "[Epoch 87/200] [Batch 270/938] loss_G: 3.292639, loss_D: 0.185758\n",
      "[Epoch 87/200] [Batch 280/938] loss_G: 3.023220, loss_D: 0.194466\n",
      "[Epoch 87/200] [Batch 290/938] loss_G: 2.611163, loss_D: 0.221887\n",
      "[Epoch 87/200] [Batch 300/938] loss_G: 3.185552, loss_D: 0.226035\n",
      "[Epoch 87/200] [Batch 310/938] loss_G: 2.730710, loss_D: 0.214783\n",
      "[Epoch 87/200] [Batch 320/938] loss_G: 2.582823, loss_D: 0.226841\n",
      "[Epoch 87/200] [Batch 330/938] loss_G: 3.360095, loss_D: 0.180831\n",
      "[Epoch 87/200] [Batch 340/938] loss_G: 2.822578, loss_D: 0.223793\n",
      "[Epoch 87/200] [Batch 350/938] loss_G: 2.802711, loss_D: 0.212971\n",
      "[Epoch 87/200] [Batch 360/938] loss_G: 2.533877, loss_D: 0.244649\n",
      "[Epoch 87/200] [Batch 370/938] loss_G: 3.012149, loss_D: 0.185428\n",
      "[Epoch 87/200] [Batch 380/938] loss_G: 2.939337, loss_D: 0.251478\n",
      "[Epoch 87/200] [Batch 390/938] loss_G: 3.005036, loss_D: 0.198211\n",
      "[Epoch 87/200] [Batch 400/938] loss_G: 2.857857, loss_D: 0.262015\n",
      "[Epoch 87/200] [Batch 410/938] loss_G: 2.856157, loss_D: 0.268122\n",
      "[Epoch 87/200] [Batch 420/938] loss_G: 2.971133, loss_D: 0.235823\n",
      "[Epoch 87/200] [Batch 430/938] loss_G: 2.637481, loss_D: 0.207919\n",
      "[Epoch 87/200] [Batch 440/938] loss_G: 2.646634, loss_D: 0.254362\n",
      "[Epoch 87/200] [Batch 450/938] loss_G: 2.856053, loss_D: 0.212059\n",
      "[Epoch 87/200] [Batch 460/938] loss_G: 2.799917, loss_D: 0.282581\n",
      "[Epoch 87/200] [Batch 470/938] loss_G: 3.327056, loss_D: 0.186163\n",
      "[Epoch 87/200] [Batch 480/938] loss_G: 2.763643, loss_D: 0.225700\n",
      "[Epoch 87/200] [Batch 490/938] loss_G: 3.141535, loss_D: 0.211119\n",
      "[Epoch 87/200] [Batch 500/938] loss_G: 2.545325, loss_D: 0.318769\n",
      "[Epoch 87/200] [Batch 510/938] loss_G: 3.204232, loss_D: 0.188977\n",
      "[Epoch 87/200] [Batch 520/938] loss_G: 2.732783, loss_D: 0.325391\n",
      "[Epoch 87/200] [Batch 530/938] loss_G: 3.252273, loss_D: 0.196992\n",
      "[Epoch 87/200] [Batch 540/938] loss_G: 3.015478, loss_D: 0.152105\n",
      "[Epoch 87/200] [Batch 550/938] loss_G: 3.125870, loss_D: 0.206531\n",
      "[Epoch 87/200] [Batch 560/938] loss_G: 3.082077, loss_D: 0.229957\n",
      "[Epoch 87/200] [Batch 570/938] loss_G: 2.396151, loss_D: 0.260613\n",
      "[Epoch 87/200] [Batch 580/938] loss_G: 3.067707, loss_D: 0.158973\n",
      "[Epoch 87/200] [Batch 590/938] loss_G: 2.760086, loss_D: 0.293878\n",
      "[Epoch 87/200] [Batch 600/938] loss_G: 2.865045, loss_D: 0.298571\n",
      "[Epoch 87/200] [Batch 610/938] loss_G: 2.790586, loss_D: 0.224856\n",
      "[Epoch 87/200] [Batch 620/938] loss_G: 2.869462, loss_D: 0.212270\n",
      "[Epoch 87/200] [Batch 630/938] loss_G: 2.941586, loss_D: 0.105877\n",
      "[Epoch 87/200] [Batch 640/938] loss_G: 2.839230, loss_D: 0.206860\n",
      "[Epoch 87/200] [Batch 650/938] loss_G: 2.843434, loss_D: 0.164628\n",
      "[Epoch 87/200] [Batch 660/938] loss_G: 2.963387, loss_D: 0.255152\n",
      "[Epoch 87/200] [Batch 670/938] loss_G: 2.847569, loss_D: 0.153260\n",
      "[Epoch 87/200] [Batch 680/938] loss_G: 3.132278, loss_D: 0.243386\n",
      "[Epoch 87/200] [Batch 690/938] loss_G: 2.477970, loss_D: 0.293730\n",
      "[Epoch 87/200] [Batch 700/938] loss_G: 3.069417, loss_D: 0.147064\n",
      "[Epoch 87/200] [Batch 710/938] loss_G: 2.947109, loss_D: 0.195862\n",
      "[Epoch 87/200] [Batch 720/938] loss_G: 2.883578, loss_D: 0.222642\n",
      "[Epoch 87/200] [Batch 730/938] loss_G: 2.823699, loss_D: 0.207774\n",
      "[Epoch 87/200] [Batch 740/938] loss_G: 3.182432, loss_D: 0.246997\n",
      "[Epoch 87/200] [Batch 750/938] loss_G: 2.726883, loss_D: 0.225646\n",
      "[Epoch 87/200] [Batch 760/938] loss_G: 2.939250, loss_D: 0.187370\n",
      "[Epoch 87/200] [Batch 770/938] loss_G: 3.010864, loss_D: 0.182649\n",
      "[Epoch 87/200] [Batch 780/938] loss_G: 2.930138, loss_D: 0.219485\n",
      "[Epoch 87/200] [Batch 790/938] loss_G: 3.353816, loss_D: 0.194906\n",
      "[Epoch 87/200] [Batch 800/938] loss_G: 2.706255, loss_D: 0.179044\n",
      "[Epoch 87/200] [Batch 810/938] loss_G: 3.156775, loss_D: 0.181020\n",
      "[Epoch 87/200] [Batch 820/938] loss_G: 2.433410, loss_D: 0.200921\n",
      "[Epoch 87/200] [Batch 830/938] loss_G: 3.053970, loss_D: 0.190774\n",
      "[Epoch 87/200] [Batch 840/938] loss_G: 2.766377, loss_D: 0.196873\n",
      "[Epoch 87/200] [Batch 850/938] loss_G: 2.879356, loss_D: 0.111990\n",
      "[Epoch 87/200] [Batch 860/938] loss_G: 2.815378, loss_D: 0.176295\n",
      "[Epoch 87/200] [Batch 870/938] loss_G: 2.986593, loss_D: 0.143218\n",
      "[Epoch 87/200] [Batch 880/938] loss_G: 2.745789, loss_D: 0.233696\n",
      "[Epoch 87/200] [Batch 890/938] loss_G: 2.867971, loss_D: 0.278545\n",
      "[Epoch 87/200] [Batch 900/938] loss_G: 2.707541, loss_D: 0.204325\n",
      "[Epoch 87/200] [Batch 910/938] loss_G: 2.997164, loss_D: 0.159891\n",
      "[Epoch 87/200] [Batch 920/938] loss_G: 2.944858, loss_D: 0.217521\n",
      "[Epoch 87/200] [Batch 930/938] loss_G: 2.673012, loss_D: 0.185271\n",
      "[Epoch 88/200] [Batch 0/938] loss_G: 2.828810, loss_D: 0.303243\n",
      "[Epoch 88/200] [Batch 10/938] loss_G: 2.551129, loss_D: 0.285067\n",
      "[Epoch 88/200] [Batch 20/938] loss_G: 3.397965, loss_D: 0.190827\n",
      "[Epoch 88/200] [Batch 30/938] loss_G: 3.251679, loss_D: 0.147638\n",
      "[Epoch 88/200] [Batch 40/938] loss_G: 2.920232, loss_D: 0.150956\n",
      "[Epoch 88/200] [Batch 50/938] loss_G: 3.193218, loss_D: 0.140801\n",
      "[Epoch 88/200] [Batch 60/938] loss_G: 3.040390, loss_D: 0.233326\n",
      "[Epoch 88/200] [Batch 70/938] loss_G: 2.680108, loss_D: 0.160941\n",
      "[Epoch 88/200] [Batch 80/938] loss_G: 3.277316, loss_D: 0.218206\n",
      "[Epoch 88/200] [Batch 90/938] loss_G: 2.717803, loss_D: 0.309707\n",
      "[Epoch 88/200] [Batch 100/938] loss_G: 2.882052, loss_D: 0.261222\n",
      "[Epoch 88/200] [Batch 110/938] loss_G: 2.986485, loss_D: 0.169732\n",
      "[Epoch 88/200] [Batch 120/938] loss_G: 3.122285, loss_D: 0.207674\n",
      "[Epoch 88/200] [Batch 130/938] loss_G: 2.785976, loss_D: 0.227234\n",
      "[Epoch 88/200] [Batch 140/938] loss_G: 3.111885, loss_D: 0.159986\n",
      "[Epoch 88/200] [Batch 150/938] loss_G: 3.196835, loss_D: 0.186940\n",
      "[Epoch 88/200] [Batch 160/938] loss_G: 3.183911, loss_D: 0.141550\n",
      "[Epoch 88/200] [Batch 170/938] loss_G: 2.711189, loss_D: 0.272437\n",
      "[Epoch 88/200] [Batch 180/938] loss_G: 2.932715, loss_D: 0.190955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 88/200] [Batch 190/938] loss_G: 2.473041, loss_D: 0.252281\n",
      "[Epoch 88/200] [Batch 200/938] loss_G: 2.891183, loss_D: 0.226456\n",
      "[Epoch 88/200] [Batch 210/938] loss_G: 3.262960, loss_D: 0.168687\n",
      "[Epoch 88/200] [Batch 220/938] loss_G: 3.215930, loss_D: 0.233041\n",
      "[Epoch 88/200] [Batch 230/938] loss_G: 3.188822, loss_D: 0.187718\n",
      "[Epoch 88/200] [Batch 240/938] loss_G: 3.031446, loss_D: 0.210896\n",
      "[Epoch 88/200] [Batch 250/938] loss_G: 2.949263, loss_D: 0.193148\n",
      "[Epoch 88/200] [Batch 260/938] loss_G: 2.833358, loss_D: 0.190266\n",
      "[Epoch 88/200] [Batch 270/938] loss_G: 2.787791, loss_D: 0.140517\n",
      "[Epoch 88/200] [Batch 280/938] loss_G: 2.567755, loss_D: 0.244425\n",
      "[Epoch 88/200] [Batch 290/938] loss_G: 3.294226, loss_D: 0.295091\n",
      "[Epoch 88/200] [Batch 300/938] loss_G: 2.718552, loss_D: 0.225379\n",
      "[Epoch 88/200] [Batch 310/938] loss_G: 2.844797, loss_D: 0.229360\n",
      "[Epoch 88/200] [Batch 320/938] loss_G: 3.284482, loss_D: 0.252796\n",
      "[Epoch 88/200] [Batch 330/938] loss_G: 2.626312, loss_D: 0.276633\n",
      "[Epoch 88/200] [Batch 340/938] loss_G: 2.561072, loss_D: 0.187755\n",
      "[Epoch 88/200] [Batch 350/938] loss_G: 2.799988, loss_D: 0.246919\n",
      "[Epoch 88/200] [Batch 360/938] loss_G: 3.152391, loss_D: 0.203258\n",
      "[Epoch 88/200] [Batch 370/938] loss_G: 3.098772, loss_D: 0.129432\n",
      "[Epoch 88/200] [Batch 380/938] loss_G: 2.956846, loss_D: 0.234535\n",
      "[Epoch 88/200] [Batch 390/938] loss_G: 2.970659, loss_D: 0.189171\n",
      "[Epoch 88/200] [Batch 400/938] loss_G: 3.262967, loss_D: 0.152924\n",
      "[Epoch 88/200] [Batch 410/938] loss_G: 3.114786, loss_D: 0.268660\n",
      "[Epoch 88/200] [Batch 420/938] loss_G: 3.139048, loss_D: 0.257258\n",
      "[Epoch 88/200] [Batch 430/938] loss_G: 3.290772, loss_D: 0.177309\n",
      "[Epoch 88/200] [Batch 440/938] loss_G: 2.640385, loss_D: 0.228153\n",
      "[Epoch 88/200] [Batch 450/938] loss_G: 3.423275, loss_D: 0.263253\n",
      "[Epoch 88/200] [Batch 460/938] loss_G: 3.075895, loss_D: 0.214775\n",
      "[Epoch 88/200] [Batch 470/938] loss_G: 3.035703, loss_D: 0.226730\n",
      "[Epoch 88/200] [Batch 480/938] loss_G: 2.651547, loss_D: 0.131895\n",
      "[Epoch 88/200] [Batch 490/938] loss_G: 3.103682, loss_D: 0.145778\n",
      "[Epoch 88/200] [Batch 500/938] loss_G: 3.144303, loss_D: 0.218501\n",
      "[Epoch 88/200] [Batch 510/938] loss_G: 2.529177, loss_D: 0.162043\n",
      "[Epoch 88/200] [Batch 520/938] loss_G: 3.368155, loss_D: 0.174366\n",
      "[Epoch 88/200] [Batch 530/938] loss_G: 2.908191, loss_D: 0.182643\n",
      "[Epoch 88/200] [Batch 540/938] loss_G: 3.072905, loss_D: 0.233231\n",
      "[Epoch 88/200] [Batch 550/938] loss_G: 2.927519, loss_D: 0.201887\n",
      "[Epoch 88/200] [Batch 560/938] loss_G: 3.085230, loss_D: 0.224752\n",
      "[Epoch 88/200] [Batch 570/938] loss_G: 2.809724, loss_D: 0.190355\n",
      "[Epoch 88/200] [Batch 580/938] loss_G: 2.905315, loss_D: 0.212593\n",
      "[Epoch 88/200] [Batch 590/938] loss_G: 3.278786, loss_D: 0.216926\n",
      "[Epoch 88/200] [Batch 600/938] loss_G: 2.528643, loss_D: 0.339074\n",
      "[Epoch 88/200] [Batch 610/938] loss_G: 3.106866, loss_D: 0.178694\n",
      "[Epoch 88/200] [Batch 620/938] loss_G: 2.708881, loss_D: 0.226740\n",
      "[Epoch 88/200] [Batch 630/938] loss_G: 3.197174, loss_D: 0.208215\n",
      "[Epoch 88/200] [Batch 640/938] loss_G: 3.044588, loss_D: 0.152038\n",
      "[Epoch 88/200] [Batch 650/938] loss_G: 2.895656, loss_D: 0.240563\n",
      "[Epoch 88/200] [Batch 660/938] loss_G: 3.381621, loss_D: 0.148537\n",
      "[Epoch 88/200] [Batch 670/938] loss_G: 2.635778, loss_D: 0.241582\n",
      "[Epoch 88/200] [Batch 680/938] loss_G: 2.945942, loss_D: 0.200855\n",
      "[Epoch 88/200] [Batch 690/938] loss_G: 3.084558, loss_D: 0.258916\n",
      "[Epoch 88/200] [Batch 700/938] loss_G: 2.648283, loss_D: 0.228168\n",
      "[Epoch 88/200] [Batch 710/938] loss_G: 3.074077, loss_D: 0.209457\n",
      "[Epoch 88/200] [Batch 720/938] loss_G: 2.993527, loss_D: 0.150492\n",
      "[Epoch 88/200] [Batch 730/938] loss_G: 2.846760, loss_D: 0.200833\n",
      "[Epoch 88/200] [Batch 740/938] loss_G: 2.599566, loss_D: 0.181676\n",
      "[Epoch 88/200] [Batch 750/938] loss_G: 3.100190, loss_D: 0.272700\n",
      "[Epoch 88/200] [Batch 760/938] loss_G: 3.029278, loss_D: 0.176226\n",
      "[Epoch 88/200] [Batch 770/938] loss_G: 2.994833, loss_D: 0.199954\n",
      "[Epoch 88/200] [Batch 780/938] loss_G: 2.969958, loss_D: 0.206781\n",
      "[Epoch 88/200] [Batch 790/938] loss_G: 3.109480, loss_D: 0.203617\n",
      "[Epoch 88/200] [Batch 800/938] loss_G: 3.148097, loss_D: 0.154583\n",
      "[Epoch 88/200] [Batch 810/938] loss_G: 3.130512, loss_D: 0.185737\n",
      "[Epoch 88/200] [Batch 820/938] loss_G: 3.102449, loss_D: 0.179390\n",
      "[Epoch 88/200] [Batch 830/938] loss_G: 3.287872, loss_D: 0.293305\n",
      "[Epoch 88/200] [Batch 840/938] loss_G: 2.753059, loss_D: 0.219429\n",
      "[Epoch 88/200] [Batch 850/938] loss_G: 3.244703, loss_D: 0.298199\n",
      "[Epoch 88/200] [Batch 860/938] loss_G: 3.180427, loss_D: 0.196995\n",
      "[Epoch 88/200] [Batch 870/938] loss_G: 2.887184, loss_D: 0.227149\n",
      "[Epoch 88/200] [Batch 880/938] loss_G: 3.202433, loss_D: 0.203900\n",
      "[Epoch 88/200] [Batch 890/938] loss_G: 2.925601, loss_D: 0.267304\n",
      "[Epoch 88/200] [Batch 900/938] loss_G: 2.349287, loss_D: 0.244683\n",
      "[Epoch 88/200] [Batch 910/938] loss_G: 3.260775, loss_D: 0.155484\n",
      "[Epoch 88/200] [Batch 920/938] loss_G: 2.715648, loss_D: 0.153441\n",
      "[Epoch 88/200] [Batch 930/938] loss_G: 2.930520, loss_D: 0.217879\n",
      "[Epoch 89/200] [Batch 0/938] loss_G: 2.390861, loss_D: 0.235823\n",
      "[Epoch 89/200] [Batch 10/938] loss_G: 2.717820, loss_D: 0.276621\n",
      "[Epoch 89/200] [Batch 20/938] loss_G: 2.999997, loss_D: 0.228792\n",
      "[Epoch 89/200] [Batch 30/938] loss_G: 2.815719, loss_D: 0.264061\n",
      "[Epoch 89/200] [Batch 40/938] loss_G: 2.801366, loss_D: 0.168182\n",
      "[Epoch 89/200] [Batch 50/938] loss_G: 3.001855, loss_D: 0.195271\n",
      "[Epoch 89/200] [Batch 60/938] loss_G: 2.854556, loss_D: 0.199249\n",
      "[Epoch 89/200] [Batch 70/938] loss_G: 3.047036, loss_D: 0.223860\n",
      "[Epoch 89/200] [Batch 80/938] loss_G: 2.989070, loss_D: 0.236750\n",
      "[Epoch 89/200] [Batch 90/938] loss_G: 2.594137, loss_D: 0.188017\n",
      "[Epoch 89/200] [Batch 100/938] loss_G: 3.115783, loss_D: 0.199298\n",
      "[Epoch 89/200] [Batch 110/938] loss_G: 2.677655, loss_D: 0.232007\n",
      "[Epoch 89/200] [Batch 120/938] loss_G: 2.813109, loss_D: 0.227731\n",
      "[Epoch 89/200] [Batch 130/938] loss_G: 3.323537, loss_D: 0.104164\n",
      "[Epoch 89/200] [Batch 140/938] loss_G: 3.230162, loss_D: 0.176852\n",
      "[Epoch 89/200] [Batch 150/938] loss_G: 3.201097, loss_D: 0.171575\n",
      "[Epoch 89/200] [Batch 160/938] loss_G: 3.063508, loss_D: 0.234006\n",
      "[Epoch 89/200] [Batch 170/938] loss_G: 3.089961, loss_D: 0.253748\n",
      "[Epoch 89/200] [Batch 180/938] loss_G: 3.010126, loss_D: 0.188746\n",
      "[Epoch 89/200] [Batch 190/938] loss_G: 3.125655, loss_D: 0.211192\n",
      "[Epoch 89/200] [Batch 200/938] loss_G: 3.027641, loss_D: 0.272015\n",
      "[Epoch 89/200] [Batch 210/938] loss_G: 3.087472, loss_D: 0.198950\n",
      "[Epoch 89/200] [Batch 220/938] loss_G: 2.867204, loss_D: 0.304767\n",
      "[Epoch 89/200] [Batch 230/938] loss_G: 3.170295, loss_D: 0.271645\n",
      "[Epoch 89/200] [Batch 240/938] loss_G: 3.150697, loss_D: 0.246842\n",
      "[Epoch 89/200] [Batch 250/938] loss_G: 2.917425, loss_D: 0.168190\n",
      "[Epoch 89/200] [Batch 260/938] loss_G: 2.988310, loss_D: 0.178942\n",
      "[Epoch 89/200] [Batch 270/938] loss_G: 3.145635, loss_D: 0.282407\n",
      "[Epoch 89/200] [Batch 280/938] loss_G: 2.931254, loss_D: 0.157678\n",
      "[Epoch 89/200] [Batch 290/938] loss_G: 3.109279, loss_D: 0.174952\n",
      "[Epoch 89/200] [Batch 300/938] loss_G: 3.055815, loss_D: 0.206835\n",
      "[Epoch 89/200] [Batch 310/938] loss_G: 2.802790, loss_D: 0.162361\n",
      "[Epoch 89/200] [Batch 320/938] loss_G: 2.901863, loss_D: 0.190656\n",
      "[Epoch 89/200] [Batch 330/938] loss_G: 3.005222, loss_D: 0.169297\n",
      "[Epoch 89/200] [Batch 340/938] loss_G: 2.917665, loss_D: 0.180000\n",
      "[Epoch 89/200] [Batch 350/938] loss_G: 2.602595, loss_D: 0.204700\n",
      "[Epoch 89/200] [Batch 360/938] loss_G: 3.542934, loss_D: 0.178701\n",
      "[Epoch 89/200] [Batch 370/938] loss_G: 3.132726, loss_D: 0.181080\n",
      "[Epoch 89/200] [Batch 380/938] loss_G: 3.250438, loss_D: 0.195593\n",
      "[Epoch 89/200] [Batch 390/938] loss_G: 2.917266, loss_D: 0.239924\n",
      "[Epoch 89/200] [Batch 400/938] loss_G: 2.648223, loss_D: 0.225143\n",
      "[Epoch 89/200] [Batch 410/938] loss_G: 3.077842, loss_D: 0.208831\n",
      "[Epoch 89/200] [Batch 420/938] loss_G: 3.043759, loss_D: 0.285300\n",
      "[Epoch 89/200] [Batch 430/938] loss_G: 2.793221, loss_D: 0.196210\n",
      "[Epoch 89/200] [Batch 440/938] loss_G: 3.033953, loss_D: 0.150156\n",
      "[Epoch 89/200] [Batch 450/938] loss_G: 3.107005, loss_D: 0.233940\n",
      "[Epoch 89/200] [Batch 460/938] loss_G: 3.090557, loss_D: 0.211048\n",
      "[Epoch 89/200] [Batch 470/938] loss_G: 3.114732, loss_D: 0.173381\n",
      "[Epoch 89/200] [Batch 480/938] loss_G: 2.935567, loss_D: 0.207343\n",
      "[Epoch 89/200] [Batch 490/938] loss_G: 2.482693, loss_D: 0.141309\n",
      "[Epoch 89/200] [Batch 500/938] loss_G: 2.866750, loss_D: 0.160193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 89/200] [Batch 510/938] loss_G: 3.159594, loss_D: 0.144314\n",
      "[Epoch 89/200] [Batch 520/938] loss_G: 3.116515, loss_D: 0.217078\n",
      "[Epoch 89/200] [Batch 530/938] loss_G: 2.651113, loss_D: 0.257639\n",
      "[Epoch 89/200] [Batch 540/938] loss_G: 2.948714, loss_D: 0.196363\n",
      "[Epoch 89/200] [Batch 550/938] loss_G: 3.085700, loss_D: 0.152325\n",
      "[Epoch 89/200] [Batch 560/938] loss_G: 3.288813, loss_D: 0.140192\n",
      "[Epoch 89/200] [Batch 570/938] loss_G: 2.481616, loss_D: 0.291311\n",
      "[Epoch 89/200] [Batch 580/938] loss_G: 3.284526, loss_D: 0.204842\n",
      "[Epoch 89/200] [Batch 590/938] loss_G: 2.714511, loss_D: 0.205094\n",
      "[Epoch 89/200] [Batch 600/938] loss_G: 3.020295, loss_D: 0.243633\n",
      "[Epoch 89/200] [Batch 610/938] loss_G: 2.628867, loss_D: 0.252793\n",
      "[Epoch 89/200] [Batch 620/938] loss_G: 3.160389, loss_D: 0.158117\n",
      "[Epoch 89/200] [Batch 630/938] loss_G: 2.919843, loss_D: 0.262001\n",
      "[Epoch 89/200] [Batch 640/938] loss_G: 3.095681, loss_D: 0.210010\n",
      "[Epoch 89/200] [Batch 650/938] loss_G: 2.997589, loss_D: 0.193957\n",
      "[Epoch 89/200] [Batch 660/938] loss_G: 2.771462, loss_D: 0.249487\n",
      "[Epoch 89/200] [Batch 670/938] loss_G: 2.895612, loss_D: 0.195740\n",
      "[Epoch 89/200] [Batch 680/938] loss_G: 3.178711, loss_D: 0.257199\n",
      "[Epoch 89/200] [Batch 690/938] loss_G: 2.877883, loss_D: 0.218100\n",
      "[Epoch 89/200] [Batch 700/938] loss_G: 3.053129, loss_D: 0.207801\n",
      "[Epoch 89/200] [Batch 710/938] loss_G: 3.128190, loss_D: 0.201307\n",
      "[Epoch 89/200] [Batch 720/938] loss_G: 2.693662, loss_D: 0.225868\n",
      "[Epoch 89/200] [Batch 730/938] loss_G: 3.137217, loss_D: 0.159506\n",
      "[Epoch 89/200] [Batch 740/938] loss_G: 2.839846, loss_D: 0.222397\n",
      "[Epoch 89/200] [Batch 750/938] loss_G: 2.957866, loss_D: 0.215704\n",
      "[Epoch 89/200] [Batch 760/938] loss_G: 3.091628, loss_D: 0.250092\n",
      "[Epoch 89/200] [Batch 770/938] loss_G: 2.869012, loss_D: 0.203918\n",
      "[Epoch 89/200] [Batch 780/938] loss_G: 3.246846, loss_D: 0.221855\n",
      "[Epoch 89/200] [Batch 790/938] loss_G: 2.796277, loss_D: 0.181723\n",
      "[Epoch 89/200] [Batch 800/938] loss_G: 3.003995, loss_D: 0.201445\n",
      "[Epoch 89/200] [Batch 810/938] loss_G: 3.012116, loss_D: 0.224078\n",
      "[Epoch 89/200] [Batch 820/938] loss_G: 3.015579, loss_D: 0.204538\n",
      "[Epoch 89/200] [Batch 830/938] loss_G: 3.208149, loss_D: 0.188481\n",
      "[Epoch 89/200] [Batch 840/938] loss_G: 3.060116, loss_D: 0.190576\n",
      "[Epoch 89/200] [Batch 850/938] loss_G: 2.828718, loss_D: 0.175051\n",
      "[Epoch 89/200] [Batch 860/938] loss_G: 3.058185, loss_D: 0.175774\n",
      "[Epoch 89/200] [Batch 870/938] loss_G: 2.709428, loss_D: 0.207365\n",
      "[Epoch 89/200] [Batch 880/938] loss_G: 3.337092, loss_D: 0.140612\n",
      "[Epoch 89/200] [Batch 890/938] loss_G: 2.650389, loss_D: 0.195364\n",
      "[Epoch 89/200] [Batch 900/938] loss_G: 3.198361, loss_D: 0.175637\n",
      "[Epoch 89/200] [Batch 910/938] loss_G: 2.995106, loss_D: 0.224875\n",
      "[Epoch 89/200] [Batch 920/938] loss_G: 3.058965, loss_D: 0.208767\n",
      "[Epoch 89/200] [Batch 930/938] loss_G: 3.035300, loss_D: 0.200125\n",
      "[Epoch 90/200] [Batch 0/938] loss_G: 3.537123, loss_D: 0.184644\n",
      "[Epoch 90/200] [Batch 10/938] loss_G: 3.493431, loss_D: 0.161713\n",
      "[Epoch 90/200] [Batch 20/938] loss_G: 3.098728, loss_D: 0.263002\n",
      "[Epoch 90/200] [Batch 30/938] loss_G: 2.961771, loss_D: 0.140551\n",
      "[Epoch 90/200] [Batch 40/938] loss_G: 3.161192, loss_D: 0.215309\n",
      "[Epoch 90/200] [Batch 50/938] loss_G: 3.059593, loss_D: 0.197305\n",
      "[Epoch 90/200] [Batch 60/938] loss_G: 2.722836, loss_D: 0.165945\n",
      "[Epoch 90/200] [Batch 70/938] loss_G: 3.073226, loss_D: 0.194927\n",
      "[Epoch 90/200] [Batch 80/938] loss_G: 2.882379, loss_D: 0.210492\n",
      "[Epoch 90/200] [Batch 90/938] loss_G: 3.219385, loss_D: 0.185482\n",
      "[Epoch 90/200] [Batch 100/938] loss_G: 2.875465, loss_D: 0.157987\n",
      "[Epoch 90/200] [Batch 110/938] loss_G: 3.049224, loss_D: 0.167533\n",
      "[Epoch 90/200] [Batch 120/938] loss_G: 3.049500, loss_D: 0.249267\n",
      "[Epoch 90/200] [Batch 130/938] loss_G: 3.023205, loss_D: 0.262814\n",
      "[Epoch 90/200] [Batch 140/938] loss_G: 2.843194, loss_D: 0.275655\n",
      "[Epoch 90/200] [Batch 150/938] loss_G: 3.211656, loss_D: 0.215181\n",
      "[Epoch 90/200] [Batch 160/938] loss_G: 3.285841, loss_D: 0.166544\n",
      "[Epoch 90/200] [Batch 170/938] loss_G: 3.071959, loss_D: 0.228852\n",
      "[Epoch 90/200] [Batch 180/938] loss_G: 3.020310, loss_D: 0.218389\n",
      "[Epoch 90/200] [Batch 190/938] loss_G: 3.122980, loss_D: 0.193010\n",
      "[Epoch 90/200] [Batch 200/938] loss_G: 2.904727, loss_D: 0.243583\n",
      "[Epoch 90/200] [Batch 210/938] loss_G: 2.957434, loss_D: 0.156490\n",
      "[Epoch 90/200] [Batch 220/938] loss_G: 3.326559, loss_D: 0.181262\n",
      "[Epoch 90/200] [Batch 230/938] loss_G: 2.901814, loss_D: 0.191968\n",
      "[Epoch 90/200] [Batch 240/938] loss_G: 2.685718, loss_D: 0.214600\n",
      "[Epoch 90/200] [Batch 250/938] loss_G: 2.879072, loss_D: 0.169697\n",
      "[Epoch 90/200] [Batch 260/938] loss_G: 2.908154, loss_D: 0.220448\n",
      "[Epoch 90/200] [Batch 270/938] loss_G: 2.815959, loss_D: 0.246837\n",
      "[Epoch 90/200] [Batch 280/938] loss_G: 2.824682, loss_D: 0.176247\n",
      "[Epoch 90/200] [Batch 290/938] loss_G: 2.965679, loss_D: 0.195101\n",
      "[Epoch 90/200] [Batch 300/938] loss_G: 3.249126, loss_D: 0.139359\n",
      "[Epoch 90/200] [Batch 310/938] loss_G: 2.855632, loss_D: 0.194502\n",
      "[Epoch 90/200] [Batch 320/938] loss_G: 3.021873, loss_D: 0.111686\n",
      "[Epoch 90/200] [Batch 330/938] loss_G: 2.508963, loss_D: 0.211705\n",
      "[Epoch 90/200] [Batch 340/938] loss_G: 2.960596, loss_D: 0.117889\n",
      "[Epoch 90/200] [Batch 350/938] loss_G: 2.743002, loss_D: 0.184732\n",
      "[Epoch 90/200] [Batch 360/938] loss_G: 3.016852, loss_D: 0.181082\n",
      "[Epoch 90/200] [Batch 370/938] loss_G: 3.140051, loss_D: 0.229842\n",
      "[Epoch 90/200] [Batch 380/938] loss_G: 2.995538, loss_D: 0.216837\n",
      "[Epoch 90/200] [Batch 390/938] loss_G: 3.095821, loss_D: 0.178699\n",
      "[Epoch 90/200] [Batch 400/938] loss_G: 2.766937, loss_D: 0.222571\n",
      "[Epoch 90/200] [Batch 410/938] loss_G: 3.250761, loss_D: 0.186551\n",
      "[Epoch 90/200] [Batch 420/938] loss_G: 2.956331, loss_D: 0.180353\n",
      "[Epoch 90/200] [Batch 430/938] loss_G: 2.825023, loss_D: 0.257721\n",
      "[Epoch 90/200] [Batch 440/938] loss_G: 2.939243, loss_D: 0.198543\n",
      "[Epoch 90/200] [Batch 450/938] loss_G: 2.913281, loss_D: 0.265849\n",
      "[Epoch 90/200] [Batch 460/938] loss_G: 2.961066, loss_D: 0.179288\n",
      "[Epoch 90/200] [Batch 470/938] loss_G: 2.986391, loss_D: 0.233745\n",
      "[Epoch 90/200] [Batch 480/938] loss_G: 2.997439, loss_D: 0.130437\n",
      "[Epoch 90/200] [Batch 490/938] loss_G: 3.029989, loss_D: 0.176778\n",
      "[Epoch 90/200] [Batch 500/938] loss_G: 3.221285, loss_D: 0.218580\n",
      "[Epoch 90/200] [Batch 510/938] loss_G: 3.208964, loss_D: 0.172920\n",
      "[Epoch 90/200] [Batch 520/938] loss_G: 3.153152, loss_D: 0.144417\n",
      "[Epoch 90/200] [Batch 530/938] loss_G: 2.839174, loss_D: 0.189761\n",
      "[Epoch 90/200] [Batch 540/938] loss_G: 3.290157, loss_D: 0.249716\n",
      "[Epoch 90/200] [Batch 550/938] loss_G: 3.121514, loss_D: 0.180489\n",
      "[Epoch 90/200] [Batch 560/938] loss_G: 2.648192, loss_D: 0.152409\n",
      "[Epoch 90/200] [Batch 570/938] loss_G: 3.092750, loss_D: 0.256088\n",
      "[Epoch 90/200] [Batch 580/938] loss_G: 3.020977, loss_D: 0.161670\n",
      "[Epoch 90/200] [Batch 590/938] loss_G: 3.272617, loss_D: 0.139555\n",
      "[Epoch 90/200] [Batch 600/938] loss_G: 3.352698, loss_D: 0.262078\n",
      "[Epoch 90/200] [Batch 610/938] loss_G: 2.959714, loss_D: 0.198000\n",
      "[Epoch 90/200] [Batch 620/938] loss_G: 3.116188, loss_D: 0.265221\n",
      "[Epoch 90/200] [Batch 630/938] loss_G: 2.930196, loss_D: 0.247677\n",
      "[Epoch 90/200] [Batch 640/938] loss_G: 3.147608, loss_D: 0.189791\n",
      "[Epoch 90/200] [Batch 650/938] loss_G: 2.764105, loss_D: 0.256391\n",
      "[Epoch 90/200] [Batch 660/938] loss_G: 2.588679, loss_D: 0.150098\n",
      "[Epoch 90/200] [Batch 670/938] loss_G: 3.130240, loss_D: 0.169514\n",
      "[Epoch 90/200] [Batch 680/938] loss_G: 3.030610, loss_D: 0.222776\n",
      "[Epoch 90/200] [Batch 690/938] loss_G: 3.043386, loss_D: 0.251272\n",
      "[Epoch 90/200] [Batch 700/938] loss_G: 2.773341, loss_D: 0.254773\n",
      "[Epoch 90/200] [Batch 710/938] loss_G: 3.615211, loss_D: 0.178887\n",
      "[Epoch 90/200] [Batch 720/938] loss_G: 2.953107, loss_D: 0.211557\n",
      "[Epoch 90/200] [Batch 730/938] loss_G: 3.257385, loss_D: 0.226401\n",
      "[Epoch 90/200] [Batch 740/938] loss_G: 3.060528, loss_D: 0.125464\n",
      "[Epoch 90/200] [Batch 750/938] loss_G: 2.827459, loss_D: 0.181424\n",
      "[Epoch 90/200] [Batch 760/938] loss_G: 3.073692, loss_D: 0.190440\n",
      "[Epoch 90/200] [Batch 770/938] loss_G: 3.109782, loss_D: 0.111333\n",
      "[Epoch 90/200] [Batch 780/938] loss_G: 2.998747, loss_D: 0.226435\n",
      "[Epoch 90/200] [Batch 790/938] loss_G: 3.007477, loss_D: 0.184786\n",
      "[Epoch 90/200] [Batch 800/938] loss_G: 3.183060, loss_D: 0.181604\n",
      "[Epoch 90/200] [Batch 810/938] loss_G: 2.814275, loss_D: 0.204550\n",
      "[Epoch 90/200] [Batch 820/938] loss_G: 2.977088, loss_D: 0.241234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 90/200] [Batch 830/938] loss_G: 3.303122, loss_D: 0.190908\n",
      "[Epoch 90/200] [Batch 840/938] loss_G: 3.051940, loss_D: 0.180458\n",
      "[Epoch 90/200] [Batch 850/938] loss_G: 2.863283, loss_D: 0.142697\n",
      "[Epoch 90/200] [Batch 860/938] loss_G: 2.775934, loss_D: 0.268129\n",
      "[Epoch 90/200] [Batch 870/938] loss_G: 3.227094, loss_D: 0.224650\n",
      "[Epoch 90/200] [Batch 880/938] loss_G: 2.432418, loss_D: 0.296094\n",
      "[Epoch 90/200] [Batch 890/938] loss_G: 3.041400, loss_D: 0.203289\n",
      "[Epoch 90/200] [Batch 900/938] loss_G: 3.145751, loss_D: 0.214716\n",
      "[Epoch 90/200] [Batch 910/938] loss_G: 3.163735, loss_D: 0.206696\n",
      "[Epoch 90/200] [Batch 920/938] loss_G: 2.856092, loss_D: 0.233285\n",
      "[Epoch 90/200] [Batch 930/938] loss_G: 2.604983, loss_D: 0.354392\n",
      "[Epoch 91/200] [Batch 0/938] loss_G: 2.795851, loss_D: 0.266227\n",
      "[Epoch 91/200] [Batch 10/938] loss_G: 2.968780, loss_D: 0.213131\n",
      "[Epoch 91/200] [Batch 20/938] loss_G: 2.749504, loss_D: 0.173050\n",
      "[Epoch 91/200] [Batch 30/938] loss_G: 2.866540, loss_D: 0.213688\n",
      "[Epoch 91/200] [Batch 40/938] loss_G: 2.606383, loss_D: 0.277814\n",
      "[Epoch 91/200] [Batch 50/938] loss_G: 3.466219, loss_D: 0.126461\n",
      "[Epoch 91/200] [Batch 60/938] loss_G: 3.163979, loss_D: 0.197346\n",
      "[Epoch 91/200] [Batch 70/938] loss_G: 2.815808, loss_D: 0.173898\n",
      "[Epoch 91/200] [Batch 80/938] loss_G: 3.103657, loss_D: 0.175646\n",
      "[Epoch 91/200] [Batch 90/938] loss_G: 3.176034, loss_D: 0.109319\n",
      "[Epoch 91/200] [Batch 100/938] loss_G: 2.803402, loss_D: 0.200264\n",
      "[Epoch 91/200] [Batch 110/938] loss_G: 2.598766, loss_D: 0.205090\n",
      "[Epoch 91/200] [Batch 120/938] loss_G: 2.527171, loss_D: 0.319229\n",
      "[Epoch 91/200] [Batch 130/938] loss_G: 2.828808, loss_D: 0.216376\n",
      "[Epoch 91/200] [Batch 140/938] loss_G: 3.012870, loss_D: 0.187510\n",
      "[Epoch 91/200] [Batch 150/938] loss_G: 2.819451, loss_D: 0.237069\n",
      "[Epoch 91/200] [Batch 160/938] loss_G: 3.073781, loss_D: 0.144693\n",
      "[Epoch 91/200] [Batch 170/938] loss_G: 3.205952, loss_D: 0.128083\n",
      "[Epoch 91/200] [Batch 180/938] loss_G: 2.955671, loss_D: 0.284588\n",
      "[Epoch 91/200] [Batch 190/938] loss_G: 3.068748, loss_D: 0.145287\n",
      "[Epoch 91/200] [Batch 200/938] loss_G: 3.253414, loss_D: 0.214451\n",
      "[Epoch 91/200] [Batch 210/938] loss_G: 2.929021, loss_D: 0.138048\n",
      "[Epoch 91/200] [Batch 220/938] loss_G: 3.124263, loss_D: 0.094441\n",
      "[Epoch 91/200] [Batch 230/938] loss_G: 3.034031, loss_D: 0.230923\n",
      "[Epoch 91/200] [Batch 240/938] loss_G: 2.920146, loss_D: 0.185140\n",
      "[Epoch 91/200] [Batch 250/938] loss_G: 3.313468, loss_D: 0.197621\n",
      "[Epoch 91/200] [Batch 260/938] loss_G: 3.214048, loss_D: 0.241981\n",
      "[Epoch 91/200] [Batch 270/938] loss_G: 3.027628, loss_D: 0.161818\n",
      "[Epoch 91/200] [Batch 280/938] loss_G: 2.982995, loss_D: 0.199496\n",
      "[Epoch 91/200] [Batch 290/938] loss_G: 3.284413, loss_D: 0.217092\n",
      "[Epoch 91/200] [Batch 300/938] loss_G: 2.904836, loss_D: 0.126240\n",
      "[Epoch 91/200] [Batch 310/938] loss_G: 2.865619, loss_D: 0.233338\n",
      "[Epoch 91/200] [Batch 320/938] loss_G: 2.782948, loss_D: 0.165940\n",
      "[Epoch 91/200] [Batch 330/938] loss_G: 3.004807, loss_D: 0.287358\n",
      "[Epoch 91/200] [Batch 340/938] loss_G: 2.908413, loss_D: 0.273284\n",
      "[Epoch 91/200] [Batch 350/938] loss_G: 3.585347, loss_D: 0.191230\n",
      "[Epoch 91/200] [Batch 360/938] loss_G: 3.162996, loss_D: 0.188087\n",
      "[Epoch 91/200] [Batch 370/938] loss_G: 3.080796, loss_D: 0.209758\n",
      "[Epoch 91/200] [Batch 380/938] loss_G: 3.061886, loss_D: 0.190895\n",
      "[Epoch 91/200] [Batch 390/938] loss_G: 2.850150, loss_D: 0.256853\n",
      "[Epoch 91/200] [Batch 400/938] loss_G: 2.835603, loss_D: 0.202020\n",
      "[Epoch 91/200] [Batch 410/938] loss_G: 2.779597, loss_D: 0.234149\n",
      "[Epoch 91/200] [Batch 420/938] loss_G: 3.172438, loss_D: 0.238735\n",
      "[Epoch 91/200] [Batch 430/938] loss_G: 2.870056, loss_D: 0.172591\n",
      "[Epoch 91/200] [Batch 440/938] loss_G: 2.521489, loss_D: 0.347327\n",
      "[Epoch 91/200] [Batch 450/938] loss_G: 2.937950, loss_D: 0.272549\n",
      "[Epoch 91/200] [Batch 460/938] loss_G: 2.904795, loss_D: 0.306059\n",
      "[Epoch 91/200] [Batch 470/938] loss_G: 2.765019, loss_D: 0.303182\n",
      "[Epoch 91/200] [Batch 480/938] loss_G: 2.743401, loss_D: 0.136109\n",
      "[Epoch 91/200] [Batch 490/938] loss_G: 3.290870, loss_D: 0.159249\n",
      "[Epoch 91/200] [Batch 500/938] loss_G: 2.862378, loss_D: 0.215462\n",
      "[Epoch 91/200] [Batch 510/938] loss_G: 2.979524, loss_D: 0.116785\n",
      "[Epoch 91/200] [Batch 520/938] loss_G: 2.730426, loss_D: 0.138143\n",
      "[Epoch 91/200] [Batch 530/938] loss_G: 3.179747, loss_D: 0.075693\n",
      "[Epoch 91/200] [Batch 540/938] loss_G: 3.245318, loss_D: 0.178028\n",
      "[Epoch 91/200] [Batch 550/938] loss_G: 3.003358, loss_D: 0.153561\n",
      "[Epoch 91/200] [Batch 560/938] loss_G: 2.915111, loss_D: 0.203699\n",
      "[Epoch 91/200] [Batch 570/938] loss_G: 2.946890, loss_D: 0.205999\n",
      "[Epoch 91/200] [Batch 580/938] loss_G: 3.439437, loss_D: 0.180677\n",
      "[Epoch 91/200] [Batch 590/938] loss_G: 3.268694, loss_D: 0.220268\n",
      "[Epoch 91/200] [Batch 600/938] loss_G: 3.044942, loss_D: 0.149551\n",
      "[Epoch 91/200] [Batch 610/938] loss_G: 3.004011, loss_D: 0.167813\n",
      "[Epoch 91/200] [Batch 620/938] loss_G: 3.634550, loss_D: 0.232437\n",
      "[Epoch 91/200] [Batch 630/938] loss_G: 2.935483, loss_D: 0.218680\n",
      "[Epoch 91/200] [Batch 640/938] loss_G: 2.926417, loss_D: 0.262453\n",
      "[Epoch 91/200] [Batch 650/938] loss_G: 3.011293, loss_D: 0.203579\n",
      "[Epoch 91/200] [Batch 660/938] loss_G: 3.025091, loss_D: 0.219822\n",
      "[Epoch 91/200] [Batch 670/938] loss_G: 2.898273, loss_D: 0.262487\n",
      "[Epoch 91/200] [Batch 680/938] loss_G: 2.614834, loss_D: 0.192802\n",
      "[Epoch 91/200] [Batch 690/938] loss_G: 3.198988, loss_D: 0.183863\n",
      "[Epoch 91/200] [Batch 700/938] loss_G: 3.254023, loss_D: 0.176444\n",
      "[Epoch 91/200] [Batch 710/938] loss_G: 2.857094, loss_D: 0.164713\n",
      "[Epoch 91/200] [Batch 720/938] loss_G: 2.823541, loss_D: 0.223928\n",
      "[Epoch 91/200] [Batch 730/938] loss_G: 2.621133, loss_D: 0.264974\n",
      "[Epoch 91/200] [Batch 740/938] loss_G: 3.458735, loss_D: 0.195454\n",
      "[Epoch 91/200] [Batch 750/938] loss_G: 2.788946, loss_D: 0.239156\n",
      "[Epoch 91/200] [Batch 760/938] loss_G: 3.073710, loss_D: 0.261724\n",
      "[Epoch 91/200] [Batch 770/938] loss_G: 3.076597, loss_D: 0.278107\n",
      "[Epoch 91/200] [Batch 780/938] loss_G: 3.174745, loss_D: 0.191094\n",
      "[Epoch 91/200] [Batch 790/938] loss_G: 2.810976, loss_D: 0.227556\n",
      "[Epoch 91/200] [Batch 800/938] loss_G: 3.104366, loss_D: 0.210477\n",
      "[Epoch 91/200] [Batch 810/938] loss_G: 3.255886, loss_D: 0.199296\n",
      "[Epoch 91/200] [Batch 820/938] loss_G: 3.410348, loss_D: 0.101755\n",
      "[Epoch 91/200] [Batch 830/938] loss_G: 2.989715, loss_D: 0.176892\n",
      "[Epoch 91/200] [Batch 840/938] loss_G: 3.032911, loss_D: 0.230639\n",
      "[Epoch 91/200] [Batch 850/938] loss_G: 2.879073, loss_D: 0.234823\n",
      "[Epoch 91/200] [Batch 860/938] loss_G: 2.685414, loss_D: 0.241766\n",
      "[Epoch 91/200] [Batch 870/938] loss_G: 2.899206, loss_D: 0.195617\n",
      "[Epoch 91/200] [Batch 880/938] loss_G: 3.014164, loss_D: 0.137665\n",
      "[Epoch 91/200] [Batch 890/938] loss_G: 3.003079, loss_D: 0.235667\n",
      "[Epoch 91/200] [Batch 900/938] loss_G: 3.264774, loss_D: 0.232628\n",
      "[Epoch 91/200] [Batch 910/938] loss_G: 3.139632, loss_D: 0.217020\n",
      "[Epoch 91/200] [Batch 920/938] loss_G: 2.695748, loss_D: 0.156246\n",
      "[Epoch 91/200] [Batch 930/938] loss_G: 2.617065, loss_D: 0.190493\n",
      "[Epoch 92/200] [Batch 0/938] loss_G: 2.880494, loss_D: 0.238154\n",
      "[Epoch 92/200] [Batch 10/938] loss_G: 3.250849, loss_D: 0.193308\n",
      "[Epoch 92/200] [Batch 20/938] loss_G: 3.281486, loss_D: 0.151444\n",
      "[Epoch 92/200] [Batch 30/938] loss_G: 3.056426, loss_D: 0.207049\n",
      "[Epoch 92/200] [Batch 40/938] loss_G: 2.784683, loss_D: 0.175747\n",
      "[Epoch 92/200] [Batch 50/938] loss_G: 3.056126, loss_D: 0.192250\n",
      "[Epoch 92/200] [Batch 60/938] loss_G: 2.881255, loss_D: 0.194867\n",
      "[Epoch 92/200] [Batch 70/938] loss_G: 3.043703, loss_D: 0.130167\n",
      "[Epoch 92/200] [Batch 80/938] loss_G: 3.002858, loss_D: 0.315975\n",
      "[Epoch 92/200] [Batch 90/938] loss_G: 3.056915, loss_D: 0.245028\n",
      "[Epoch 92/200] [Batch 100/938] loss_G: 3.233661, loss_D: 0.154808\n",
      "[Epoch 92/200] [Batch 110/938] loss_G: 3.250173, loss_D: 0.306062\n",
      "[Epoch 92/200] [Batch 120/938] loss_G: 3.067512, loss_D: 0.147812\n",
      "[Epoch 92/200] [Batch 130/938] loss_G: 2.853717, loss_D: 0.200723\n",
      "[Epoch 92/200] [Batch 140/938] loss_G: 3.224288, loss_D: 0.211481\n",
      "[Epoch 92/200] [Batch 150/938] loss_G: 3.279488, loss_D: 0.173927\n",
      "[Epoch 92/200] [Batch 160/938] loss_G: 2.980474, loss_D: 0.176570\n",
      "[Epoch 92/200] [Batch 170/938] loss_G: 3.063207, loss_D: 0.183004\n",
      "[Epoch 92/200] [Batch 180/938] loss_G: 2.609251, loss_D: 0.266006\n",
      "[Epoch 92/200] [Batch 190/938] loss_G: 3.150916, loss_D: 0.297993\n",
      "[Epoch 92/200] [Batch 200/938] loss_G: 3.123417, loss_D: 0.212846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 92/200] [Batch 210/938] loss_G: 2.809400, loss_D: 0.226328\n",
      "[Epoch 92/200] [Batch 220/938] loss_G: 2.768430, loss_D: 0.210379\n",
      "[Epoch 92/200] [Batch 230/938] loss_G: 3.363856, loss_D: 0.222601\n",
      "[Epoch 92/200] [Batch 240/938] loss_G: 2.912302, loss_D: 0.146302\n",
      "[Epoch 92/200] [Batch 250/938] loss_G: 2.955130, loss_D: 0.142362\n",
      "[Epoch 92/200] [Batch 260/938] loss_G: 3.176902, loss_D: 0.224355\n",
      "[Epoch 92/200] [Batch 270/938] loss_G: 3.057083, loss_D: 0.184956\n",
      "[Epoch 92/200] [Batch 280/938] loss_G: 2.739184, loss_D: 0.188892\n",
      "[Epoch 92/200] [Batch 290/938] loss_G: 3.126488, loss_D: 0.079722\n",
      "[Epoch 92/200] [Batch 300/938] loss_G: 2.603962, loss_D: 0.283983\n",
      "[Epoch 92/200] [Batch 310/938] loss_G: 3.546422, loss_D: 0.275336\n",
      "[Epoch 92/200] [Batch 320/938] loss_G: 3.291173, loss_D: 0.192340\n",
      "[Epoch 92/200] [Batch 330/938] loss_G: 2.977086, loss_D: 0.221104\n",
      "[Epoch 92/200] [Batch 340/938] loss_G: 3.180079, loss_D: 0.170964\n",
      "[Epoch 92/200] [Batch 350/938] loss_G: 2.722034, loss_D: 0.187678\n",
      "[Epoch 92/200] [Batch 360/938] loss_G: 2.826732, loss_D: 0.260942\n",
      "[Epoch 92/200] [Batch 370/938] loss_G: 3.303702, loss_D: 0.120731\n",
      "[Epoch 92/200] [Batch 380/938] loss_G: 2.909518, loss_D: 0.222330\n",
      "[Epoch 92/200] [Batch 390/938] loss_G: 2.670200, loss_D: 0.141063\n",
      "[Epoch 92/200] [Batch 400/938] loss_G: 2.949882, loss_D: 0.166386\n",
      "[Epoch 92/200] [Batch 410/938] loss_G: 3.152300, loss_D: 0.180307\n",
      "[Epoch 92/200] [Batch 420/938] loss_G: 3.006535, loss_D: 0.172190\n",
      "[Epoch 92/200] [Batch 430/938] loss_G: 3.075228, loss_D: 0.235822\n",
      "[Epoch 92/200] [Batch 440/938] loss_G: 2.946164, loss_D: 0.210636\n",
      "[Epoch 92/200] [Batch 450/938] loss_G: 2.607237, loss_D: 0.212060\n",
      "[Epoch 92/200] [Batch 460/938] loss_G: 2.640808, loss_D: 0.230901\n",
      "[Epoch 92/200] [Batch 470/938] loss_G: 2.906595, loss_D: 0.236452\n",
      "[Epoch 92/200] [Batch 480/938] loss_G: 3.030089, loss_D: 0.164092\n",
      "[Epoch 92/200] [Batch 490/938] loss_G: 3.012068, loss_D: 0.250912\n",
      "[Epoch 92/200] [Batch 500/938] loss_G: 2.848104, loss_D: 0.243535\n",
      "[Epoch 92/200] [Batch 510/938] loss_G: 3.197443, loss_D: 0.248836\n",
      "[Epoch 92/200] [Batch 520/938] loss_G: 3.261739, loss_D: 0.108282\n",
      "[Epoch 92/200] [Batch 530/938] loss_G: 2.934828, loss_D: 0.227729\n",
      "[Epoch 92/200] [Batch 540/938] loss_G: 2.796841, loss_D: 0.199870\n",
      "[Epoch 92/200] [Batch 550/938] loss_G: 3.238696, loss_D: 0.178489\n",
      "[Epoch 92/200] [Batch 560/938] loss_G: 3.066945, loss_D: 0.171998\n",
      "[Epoch 92/200] [Batch 570/938] loss_G: 3.377517, loss_D: 0.220085\n",
      "[Epoch 92/200] [Batch 580/938] loss_G: 3.098154, loss_D: 0.194845\n",
      "[Epoch 92/200] [Batch 590/938] loss_G: 2.869220, loss_D: 0.221748\n",
      "[Epoch 92/200] [Batch 600/938] loss_G: 2.828296, loss_D: 0.146811\n",
      "[Epoch 92/200] [Batch 610/938] loss_G: 3.372081, loss_D: 0.191243\n",
      "[Epoch 92/200] [Batch 620/938] loss_G: 2.457024, loss_D: 0.287913\n",
      "[Epoch 92/200] [Batch 630/938] loss_G: 3.260764, loss_D: 0.289745\n",
      "[Epoch 92/200] [Batch 640/938] loss_G: 2.798714, loss_D: 0.155825\n",
      "[Epoch 92/200] [Batch 650/938] loss_G: 2.715036, loss_D: 0.239464\n",
      "[Epoch 92/200] [Batch 660/938] loss_G: 3.293621, loss_D: 0.270156\n",
      "[Epoch 92/200] [Batch 670/938] loss_G: 2.736331, loss_D: 0.259436\n",
      "[Epoch 92/200] [Batch 680/938] loss_G: 2.860382, loss_D: 0.252675\n",
      "[Epoch 92/200] [Batch 690/938] loss_G: 2.894560, loss_D: 0.162666\n",
      "[Epoch 92/200] [Batch 700/938] loss_G: 3.377313, loss_D: 0.184176\n",
      "[Epoch 92/200] [Batch 710/938] loss_G: 2.841708, loss_D: 0.169478\n",
      "[Epoch 92/200] [Batch 720/938] loss_G: 2.839580, loss_D: 0.278994\n",
      "[Epoch 92/200] [Batch 730/938] loss_G: 2.704201, loss_D: 0.218600\n",
      "[Epoch 92/200] [Batch 740/938] loss_G: 2.965990, loss_D: 0.216056\n",
      "[Epoch 92/200] [Batch 750/938] loss_G: 3.004371, loss_D: 0.223694\n",
      "[Epoch 92/200] [Batch 760/938] loss_G: 2.890515, loss_D: 0.264445\n",
      "[Epoch 92/200] [Batch 770/938] loss_G: 3.251359, loss_D: 0.263228\n",
      "[Epoch 92/200] [Batch 780/938] loss_G: 3.157686, loss_D: 0.167797\n",
      "[Epoch 92/200] [Batch 790/938] loss_G: 3.042252, loss_D: 0.178060\n",
      "[Epoch 92/200] [Batch 800/938] loss_G: 3.245578, loss_D: 0.176425\n",
      "[Epoch 92/200] [Batch 810/938] loss_G: 3.111894, loss_D: 0.217860\n",
      "[Epoch 92/200] [Batch 820/938] loss_G: 3.127413, loss_D: 0.234139\n",
      "[Epoch 92/200] [Batch 830/938] loss_G: 2.699786, loss_D: 0.232430\n",
      "[Epoch 92/200] [Batch 840/938] loss_G: 3.244225, loss_D: 0.276109\n",
      "[Epoch 92/200] [Batch 850/938] loss_G: 3.060900, loss_D: 0.235644\n",
      "[Epoch 92/200] [Batch 860/938] loss_G: 2.984999, loss_D: 0.196048\n",
      "[Epoch 92/200] [Batch 870/938] loss_G: 2.986266, loss_D: 0.142288\n",
      "[Epoch 92/200] [Batch 880/938] loss_G: 2.990621, loss_D: 0.189591\n",
      "[Epoch 92/200] [Batch 890/938] loss_G: 2.741367, loss_D: 0.145190\n",
      "[Epoch 92/200] [Batch 900/938] loss_G: 3.264345, loss_D: 0.152873\n",
      "[Epoch 92/200] [Batch 910/938] loss_G: 2.803096, loss_D: 0.227994\n",
      "[Epoch 92/200] [Batch 920/938] loss_G: 3.330467, loss_D: 0.173494\n",
      "[Epoch 92/200] [Batch 930/938] loss_G: 2.887193, loss_D: 0.213673\n",
      "[Epoch 93/200] [Batch 0/938] loss_G: 3.365144, loss_D: 0.269417\n",
      "[Epoch 93/200] [Batch 10/938] loss_G: 2.626461, loss_D: 0.244981\n",
      "[Epoch 93/200] [Batch 20/938] loss_G: 3.161474, loss_D: 0.189389\n",
      "[Epoch 93/200] [Batch 30/938] loss_G: 2.958021, loss_D: 0.178494\n",
      "[Epoch 93/200] [Batch 40/938] loss_G: 3.023471, loss_D: 0.214276\n",
      "[Epoch 93/200] [Batch 50/938] loss_G: 2.785801, loss_D: 0.190424\n",
      "[Epoch 93/200] [Batch 60/938] loss_G: 3.188243, loss_D: 0.223044\n",
      "[Epoch 93/200] [Batch 70/938] loss_G: 3.050985, loss_D: 0.218926\n",
      "[Epoch 93/200] [Batch 80/938] loss_G: 3.303216, loss_D: 0.189143\n",
      "[Epoch 93/200] [Batch 90/938] loss_G: 3.372637, loss_D: 0.159703\n",
      "[Epoch 93/200] [Batch 100/938] loss_G: 2.992389, loss_D: 0.222323\n",
      "[Epoch 93/200] [Batch 110/938] loss_G: 3.245190, loss_D: 0.267398\n",
      "[Epoch 93/200] [Batch 120/938] loss_G: 2.849232, loss_D: 0.242929\n",
      "[Epoch 93/200] [Batch 130/938] loss_G: 3.145764, loss_D: 0.241610\n",
      "[Epoch 93/200] [Batch 140/938] loss_G: 3.018408, loss_D: 0.236415\n",
      "[Epoch 93/200] [Batch 150/938] loss_G: 3.433726, loss_D: 0.303239\n",
      "[Epoch 93/200] [Batch 160/938] loss_G: 3.001928, loss_D: 0.152282\n",
      "[Epoch 93/200] [Batch 170/938] loss_G: 3.255894, loss_D: 0.194800\n",
      "[Epoch 93/200] [Batch 180/938] loss_G: 3.390849, loss_D: 0.159876\n",
      "[Epoch 93/200] [Batch 190/938] loss_G: 2.805674, loss_D: 0.172716\n",
      "[Epoch 93/200] [Batch 200/938] loss_G: 3.420576, loss_D: 0.143659\n",
      "[Epoch 93/200] [Batch 210/938] loss_G: 2.905934, loss_D: 0.209154\n",
      "[Epoch 93/200] [Batch 220/938] loss_G: 2.942820, loss_D: 0.189093\n",
      "[Epoch 93/200] [Batch 230/938] loss_G: 2.665113, loss_D: 0.289059\n",
      "[Epoch 93/200] [Batch 240/938] loss_G: 2.932736, loss_D: 0.167977\n",
      "[Epoch 93/200] [Batch 250/938] loss_G: 3.002496, loss_D: 0.183765\n",
      "[Epoch 93/200] [Batch 260/938] loss_G: 2.814563, loss_D: 0.216315\n",
      "[Epoch 93/200] [Batch 270/938] loss_G: 3.077882, loss_D: 0.188171\n",
      "[Epoch 93/200] [Batch 280/938] loss_G: 3.214145, loss_D: 0.236231\n",
      "[Epoch 93/200] [Batch 290/938] loss_G: 2.875195, loss_D: 0.182282\n",
      "[Epoch 93/200] [Batch 300/938] loss_G: 2.934370, loss_D: 0.274859\n",
      "[Epoch 93/200] [Batch 310/938] loss_G: 3.337518, loss_D: 0.223070\n",
      "[Epoch 93/200] [Batch 320/938] loss_G: 2.878690, loss_D: 0.210966\n",
      "[Epoch 93/200] [Batch 330/938] loss_G: 3.129410, loss_D: 0.184599\n",
      "[Epoch 93/200] [Batch 340/938] loss_G: 3.218874, loss_D: 0.195646\n",
      "[Epoch 93/200] [Batch 350/938] loss_G: 3.150373, loss_D: 0.238935\n",
      "[Epoch 93/200] [Batch 360/938] loss_G: 3.240458, loss_D: 0.204192\n",
      "[Epoch 93/200] [Batch 370/938] loss_G: 3.159327, loss_D: 0.218278\n",
      "[Epoch 93/200] [Batch 380/938] loss_G: 3.295954, loss_D: 0.216059\n",
      "[Epoch 93/200] [Batch 390/938] loss_G: 3.222969, loss_D: 0.129592\n",
      "[Epoch 93/200] [Batch 400/938] loss_G: 3.015037, loss_D: 0.186207\n",
      "[Epoch 93/200] [Batch 410/938] loss_G: 3.218548, loss_D: 0.234643\n",
      "[Epoch 93/200] [Batch 420/938] loss_G: 2.861667, loss_D: 0.213805\n",
      "[Epoch 93/200] [Batch 430/938] loss_G: 2.694506, loss_D: 0.187988\n",
      "[Epoch 93/200] [Batch 440/938] loss_G: 3.517110, loss_D: 0.279333\n",
      "[Epoch 93/200] [Batch 450/938] loss_G: 2.758438, loss_D: 0.156287\n",
      "[Epoch 93/200] [Batch 460/938] loss_G: 3.051713, loss_D: 0.171009\n",
      "[Epoch 93/200] [Batch 470/938] loss_G: 2.879337, loss_D: 0.264433\n",
      "[Epoch 93/200] [Batch 480/938] loss_G: 3.328946, loss_D: 0.175773\n",
      "[Epoch 93/200] [Batch 490/938] loss_G: 2.804779, loss_D: 0.225071\n",
      "[Epoch 93/200] [Batch 500/938] loss_G: 2.887273, loss_D: 0.160565\n",
      "[Epoch 93/200] [Batch 510/938] loss_G: 3.087329, loss_D: 0.221825\n",
      "[Epoch 93/200] [Batch 520/938] loss_G: 3.178266, loss_D: 0.179885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 93/200] [Batch 530/938] loss_G: 2.719338, loss_D: 0.237070\n",
      "[Epoch 93/200] [Batch 540/938] loss_G: 3.056721, loss_D: 0.231968\n",
      "[Epoch 93/200] [Batch 550/938] loss_G: 2.970997, loss_D: 0.217862\n",
      "[Epoch 93/200] [Batch 560/938] loss_G: 2.817216, loss_D: 0.188721\n",
      "[Epoch 93/200] [Batch 570/938] loss_G: 2.585111, loss_D: 0.181041\n",
      "[Epoch 93/200] [Batch 580/938] loss_G: 3.098554, loss_D: 0.163783\n",
      "[Epoch 93/200] [Batch 590/938] loss_G: 2.988272, loss_D: 0.236045\n",
      "[Epoch 93/200] [Batch 600/938] loss_G: 2.659600, loss_D: 0.214576\n",
      "[Epoch 93/200] [Batch 610/938] loss_G: 2.961609, loss_D: 0.213748\n",
      "[Epoch 93/200] [Batch 620/938] loss_G: 3.118910, loss_D: 0.204884\n",
      "[Epoch 93/200] [Batch 630/938] loss_G: 3.248003, loss_D: 0.126396\n",
      "[Epoch 93/200] [Batch 640/938] loss_G: 2.751146, loss_D: 0.321376\n",
      "[Epoch 93/200] [Batch 650/938] loss_G: 2.945452, loss_D: 0.180124\n",
      "[Epoch 93/200] [Batch 660/938] loss_G: 2.840890, loss_D: 0.215103\n",
      "[Epoch 93/200] [Batch 670/938] loss_G: 2.754349, loss_D: 0.165523\n",
      "[Epoch 93/200] [Batch 680/938] loss_G: 2.981782, loss_D: 0.225124\n",
      "[Epoch 93/200] [Batch 690/938] loss_G: 3.113658, loss_D: 0.143500\n",
      "[Epoch 93/200] [Batch 700/938] loss_G: 2.887269, loss_D: 0.198796\n",
      "[Epoch 93/200] [Batch 710/938] loss_G: 2.830538, loss_D: 0.183859\n",
      "[Epoch 93/200] [Batch 720/938] loss_G: 2.962756, loss_D: 0.183666\n",
      "[Epoch 93/200] [Batch 730/938] loss_G: 3.466614, loss_D: 0.108618\n",
      "[Epoch 93/200] [Batch 740/938] loss_G: 3.341102, loss_D: 0.230023\n",
      "[Epoch 93/200] [Batch 750/938] loss_G: 3.250788, loss_D: 0.202321\n",
      "[Epoch 93/200] [Batch 760/938] loss_G: 3.107236, loss_D: 0.246453\n",
      "[Epoch 93/200] [Batch 770/938] loss_G: 3.043933, loss_D: 0.150003\n",
      "[Epoch 93/200] [Batch 780/938] loss_G: 2.868906, loss_D: 0.134007\n",
      "[Epoch 93/200] [Batch 790/938] loss_G: 2.892653, loss_D: 0.160498\n",
      "[Epoch 93/200] [Batch 800/938] loss_G: 3.559315, loss_D: 0.204800\n",
      "[Epoch 93/200] [Batch 810/938] loss_G: 3.173953, loss_D: 0.168456\n",
      "[Epoch 93/200] [Batch 820/938] loss_G: 3.378428, loss_D: 0.227267\n",
      "[Epoch 93/200] [Batch 830/938] loss_G: 2.801984, loss_D: 0.258097\n",
      "[Epoch 93/200] [Batch 840/938] loss_G: 2.953778, loss_D: 0.177267\n",
      "[Epoch 93/200] [Batch 850/938] loss_G: 3.178034, loss_D: 0.264861\n",
      "[Epoch 93/200] [Batch 860/938] loss_G: 2.973702, loss_D: 0.173482\n",
      "[Epoch 93/200] [Batch 870/938] loss_G: 2.739692, loss_D: 0.148565\n",
      "[Epoch 93/200] [Batch 880/938] loss_G: 3.100262, loss_D: 0.219074\n",
      "[Epoch 93/200] [Batch 890/938] loss_G: 3.114003, loss_D: 0.184843\n",
      "[Epoch 93/200] [Batch 900/938] loss_G: 3.057946, loss_D: 0.219429\n",
      "[Epoch 93/200] [Batch 910/938] loss_G: 2.833793, loss_D: 0.177685\n",
      "[Epoch 93/200] [Batch 920/938] loss_G: 2.954811, loss_D: 0.221550\n",
      "[Epoch 93/200] [Batch 930/938] loss_G: 3.062587, loss_D: 0.213727\n",
      "[Epoch 94/200] [Batch 0/938] loss_G: 2.955675, loss_D: 0.198906\n",
      "[Epoch 94/200] [Batch 10/938] loss_G: 2.885343, loss_D: 0.208903\n",
      "[Epoch 94/200] [Batch 20/938] loss_G: 2.741480, loss_D: 0.226321\n",
      "[Epoch 94/200] [Batch 30/938] loss_G: 3.326930, loss_D: 0.211053\n",
      "[Epoch 94/200] [Batch 40/938] loss_G: 2.655069, loss_D: 0.267806\n",
      "[Epoch 94/200] [Batch 50/938] loss_G: 3.462757, loss_D: 0.174891\n",
      "[Epoch 94/200] [Batch 60/938] loss_G: 2.982705, loss_D: 0.185260\n",
      "[Epoch 94/200] [Batch 70/938] loss_G: 2.758746, loss_D: 0.221264\n",
      "[Epoch 94/200] [Batch 80/938] loss_G: 3.049573, loss_D: 0.197927\n",
      "[Epoch 94/200] [Batch 90/938] loss_G: 3.255739, loss_D: 0.176916\n",
      "[Epoch 94/200] [Batch 100/938] loss_G: 2.790522, loss_D: 0.180009\n",
      "[Epoch 94/200] [Batch 110/938] loss_G: 2.652577, loss_D: 0.388563\n",
      "[Epoch 94/200] [Batch 120/938] loss_G: 2.992238, loss_D: 0.211125\n",
      "[Epoch 94/200] [Batch 130/938] loss_G: 2.752405, loss_D: 0.239728\n",
      "[Epoch 94/200] [Batch 140/938] loss_G: 2.811484, loss_D: 0.246331\n",
      "[Epoch 94/200] [Batch 150/938] loss_G: 3.103395, loss_D: 0.276629\n",
      "[Epoch 94/200] [Batch 160/938] loss_G: 3.221243, loss_D: 0.181475\n",
      "[Epoch 94/200] [Batch 170/938] loss_G: 3.005816, loss_D: 0.162799\n",
      "[Epoch 94/200] [Batch 180/938] loss_G: 3.201025, loss_D: 0.141534\n",
      "[Epoch 94/200] [Batch 190/938] loss_G: 2.904389, loss_D: 0.170337\n",
      "[Epoch 94/200] [Batch 200/938] loss_G: 3.167541, loss_D: 0.216999\n",
      "[Epoch 94/200] [Batch 210/938] loss_G: 3.180830, loss_D: 0.144183\n",
      "[Epoch 94/200] [Batch 220/938] loss_G: 3.253162, loss_D: 0.124543\n",
      "[Epoch 94/200] [Batch 230/938] loss_G: 2.867576, loss_D: 0.108054\n",
      "[Epoch 94/200] [Batch 240/938] loss_G: 3.202093, loss_D: 0.229358\n",
      "[Epoch 94/200] [Batch 250/938] loss_G: 2.562077, loss_D: 0.147946\n",
      "[Epoch 94/200] [Batch 260/938] loss_G: 3.108970, loss_D: 0.176985\n",
      "[Epoch 94/200] [Batch 270/938] loss_G: 2.821548, loss_D: 0.145807\n",
      "[Epoch 94/200] [Batch 280/938] loss_G: 3.121943, loss_D: 0.180825\n",
      "[Epoch 94/200] [Batch 290/938] loss_G: 3.062413, loss_D: 0.173386\n",
      "[Epoch 94/200] [Batch 300/938] loss_G: 2.760200, loss_D: 0.217143\n",
      "[Epoch 94/200] [Batch 310/938] loss_G: 2.913808, loss_D: 0.203427\n",
      "[Epoch 94/200] [Batch 320/938] loss_G: 2.885440, loss_D: 0.191767\n",
      "[Epoch 94/200] [Batch 330/938] loss_G: 2.455145, loss_D: 0.179101\n",
      "[Epoch 94/200] [Batch 340/938] loss_G: 3.189438, loss_D: 0.159134\n",
      "[Epoch 94/200] [Batch 350/938] loss_G: 3.050166, loss_D: 0.202674\n",
      "[Epoch 94/200] [Batch 360/938] loss_G: 2.810804, loss_D: 0.257874\n",
      "[Epoch 94/200] [Batch 370/938] loss_G: 3.210760, loss_D: 0.177169\n",
      "[Epoch 94/200] [Batch 380/938] loss_G: 3.124304, loss_D: 0.221419\n",
      "[Epoch 94/200] [Batch 390/938] loss_G: 2.771171, loss_D: 0.152725\n",
      "[Epoch 94/200] [Batch 400/938] loss_G: 3.329932, loss_D: 0.159796\n",
      "[Epoch 94/200] [Batch 410/938] loss_G: 2.861541, loss_D: 0.266961\n",
      "[Epoch 94/200] [Batch 420/938] loss_G: 3.103328, loss_D: 0.201059\n",
      "[Epoch 94/200] [Batch 430/938] loss_G: 3.395564, loss_D: 0.154640\n",
      "[Epoch 94/200] [Batch 440/938] loss_G: 3.171180, loss_D: 0.216962\n",
      "[Epoch 94/200] [Batch 450/938] loss_G: 3.246218, loss_D: 0.225576\n",
      "[Epoch 94/200] [Batch 460/938] loss_G: 3.234976, loss_D: 0.219050\n",
      "[Epoch 94/200] [Batch 470/938] loss_G: 3.059753, loss_D: 0.153906\n",
      "[Epoch 94/200] [Batch 480/938] loss_G: 2.938379, loss_D: 0.198204\n",
      "[Epoch 94/200] [Batch 490/938] loss_G: 3.201266, loss_D: 0.159177\n",
      "[Epoch 94/200] [Batch 500/938] loss_G: 2.923986, loss_D: 0.225893\n",
      "[Epoch 94/200] [Batch 510/938] loss_G: 2.928424, loss_D: 0.150726\n",
      "[Epoch 94/200] [Batch 520/938] loss_G: 3.132860, loss_D: 0.254377\n",
      "[Epoch 94/200] [Batch 530/938] loss_G: 2.847036, loss_D: 0.153503\n",
      "[Epoch 94/200] [Batch 540/938] loss_G: 3.132477, loss_D: 0.171411\n",
      "[Epoch 94/200] [Batch 550/938] loss_G: 3.205988, loss_D: 0.211749\n",
      "[Epoch 94/200] [Batch 560/938] loss_G: 2.678966, loss_D: 0.230042\n",
      "[Epoch 94/200] [Batch 570/938] loss_G: 2.983210, loss_D: 0.130489\n",
      "[Epoch 94/200] [Batch 580/938] loss_G: 2.888699, loss_D: 0.226456\n",
      "[Epoch 94/200] [Batch 590/938] loss_G: 3.238079, loss_D: 0.176684\n",
      "[Epoch 94/200] [Batch 600/938] loss_G: 3.082462, loss_D: 0.173136\n",
      "[Epoch 94/200] [Batch 610/938] loss_G: 2.813581, loss_D: 0.180748\n",
      "[Epoch 94/200] [Batch 620/938] loss_G: 3.045465, loss_D: 0.270014\n",
      "[Epoch 94/200] [Batch 630/938] loss_G: 3.096589, loss_D: 0.166748\n",
      "[Epoch 94/200] [Batch 640/938] loss_G: 3.204321, loss_D: 0.275512\n",
      "[Epoch 94/200] [Batch 650/938] loss_G: 3.092024, loss_D: 0.141861\n",
      "[Epoch 94/200] [Batch 660/938] loss_G: 3.180710, loss_D: 0.231432\n",
      "[Epoch 94/200] [Batch 670/938] loss_G: 2.722042, loss_D: 0.186572\n",
      "[Epoch 94/200] [Batch 680/938] loss_G: 2.388520, loss_D: 0.277859\n",
      "[Epoch 94/200] [Batch 690/938] loss_G: 3.399377, loss_D: 0.095849\n",
      "[Epoch 94/200] [Batch 700/938] loss_G: 2.991588, loss_D: 0.231596\n",
      "[Epoch 94/200] [Batch 710/938] loss_G: 2.794265, loss_D: 0.240779\n",
      "[Epoch 94/200] [Batch 720/938] loss_G: 3.273125, loss_D: 0.281151\n",
      "[Epoch 94/200] [Batch 730/938] loss_G: 3.189733, loss_D: 0.137059\n",
      "[Epoch 94/200] [Batch 740/938] loss_G: 3.268878, loss_D: 0.145075\n",
      "[Epoch 94/200] [Batch 750/938] loss_G: 2.971673, loss_D: 0.261476\n",
      "[Epoch 94/200] [Batch 760/938] loss_G: 3.002213, loss_D: 0.269874\n",
      "[Epoch 94/200] [Batch 770/938] loss_G: 2.959778, loss_D: 0.222869\n",
      "[Epoch 94/200] [Batch 780/938] loss_G: 2.947537, loss_D: 0.228590\n",
      "[Epoch 94/200] [Batch 790/938] loss_G: 3.250613, loss_D: 0.201220\n",
      "[Epoch 94/200] [Batch 800/938] loss_G: 3.385155, loss_D: 0.125164\n",
      "[Epoch 94/200] [Batch 810/938] loss_G: 2.749605, loss_D: 0.187079\n",
      "[Epoch 94/200] [Batch 820/938] loss_G: 3.025943, loss_D: 0.174909\n",
      "[Epoch 94/200] [Batch 830/938] loss_G: 2.881650, loss_D: 0.229326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 94/200] [Batch 840/938] loss_G: 2.834533, loss_D: 0.255277\n",
      "[Epoch 94/200] [Batch 850/938] loss_G: 2.811610, loss_D: 0.237093\n",
      "[Epoch 94/200] [Batch 860/938] loss_G: 2.550638, loss_D: 0.209144\n",
      "[Epoch 94/200] [Batch 870/938] loss_G: 2.777277, loss_D: 0.263071\n",
      "[Epoch 94/200] [Batch 880/938] loss_G: 3.012308, loss_D: 0.280340\n",
      "[Epoch 94/200] [Batch 890/938] loss_G: 2.994385, loss_D: 0.202531\n",
      "[Epoch 94/200] [Batch 900/938] loss_G: 2.529657, loss_D: 0.331403\n",
      "[Epoch 94/200] [Batch 910/938] loss_G: 3.182694, loss_D: 0.200961\n",
      "[Epoch 94/200] [Batch 920/938] loss_G: 2.801300, loss_D: 0.125239\n",
      "[Epoch 94/200] [Batch 930/938] loss_G: 3.119235, loss_D: 0.173805\n",
      "[Epoch 95/200] [Batch 0/938] loss_G: 3.019890, loss_D: 0.142963\n",
      "[Epoch 95/200] [Batch 10/938] loss_G: 2.689601, loss_D: 0.189003\n",
      "[Epoch 95/200] [Batch 20/938] loss_G: 3.221209, loss_D: 0.173567\n",
      "[Epoch 95/200] [Batch 30/938] loss_G: 2.687695, loss_D: 0.171377\n",
      "[Epoch 95/200] [Batch 40/938] loss_G: 3.021359, loss_D: 0.201000\n",
      "[Epoch 95/200] [Batch 50/938] loss_G: 2.786144, loss_D: 0.198191\n",
      "[Epoch 95/200] [Batch 60/938] loss_G: 2.652199, loss_D: 0.225706\n",
      "[Epoch 95/200] [Batch 70/938] loss_G: 3.130435, loss_D: 0.161327\n",
      "[Epoch 95/200] [Batch 80/938] loss_G: 3.121515, loss_D: 0.233525\n",
      "[Epoch 95/200] [Batch 90/938] loss_G: 2.907201, loss_D: 0.177459\n",
      "[Epoch 95/200] [Batch 100/938] loss_G: 2.905555, loss_D: 0.357686\n",
      "[Epoch 95/200] [Batch 110/938] loss_G: 3.138670, loss_D: 0.177507\n",
      "[Epoch 95/200] [Batch 120/938] loss_G: 2.908236, loss_D: 0.228079\n",
      "[Epoch 95/200] [Batch 130/938] loss_G: 2.431005, loss_D: 0.255866\n",
      "[Epoch 95/200] [Batch 140/938] loss_G: 3.256793, loss_D: 0.146328\n",
      "[Epoch 95/200] [Batch 150/938] loss_G: 2.969138, loss_D: 0.174330\n",
      "[Epoch 95/200] [Batch 160/938] loss_G: 3.361761, loss_D: 0.192563\n",
      "[Epoch 95/200] [Batch 170/938] loss_G: 3.178499, loss_D: 0.227367\n",
      "[Epoch 95/200] [Batch 180/938] loss_G: 2.946782, loss_D: 0.160959\n",
      "[Epoch 95/200] [Batch 190/938] loss_G: 3.119294, loss_D: 0.245920\n",
      "[Epoch 95/200] [Batch 200/938] loss_G: 2.945901, loss_D: 0.172348\n",
      "[Epoch 95/200] [Batch 210/938] loss_G: 2.977463, loss_D: 0.240311\n",
      "[Epoch 95/200] [Batch 220/938] loss_G: 2.893122, loss_D: 0.204650\n",
      "[Epoch 95/200] [Batch 230/938] loss_G: 2.943756, loss_D: 0.244589\n",
      "[Epoch 95/200] [Batch 240/938] loss_G: 3.122794, loss_D: 0.176659\n",
      "[Epoch 95/200] [Batch 250/938] loss_G: 2.978840, loss_D: 0.221058\n",
      "[Epoch 95/200] [Batch 260/938] loss_G: 2.639605, loss_D: 0.180907\n",
      "[Epoch 95/200] [Batch 270/938] loss_G: 2.813252, loss_D: 0.186213\n",
      "[Epoch 95/200] [Batch 280/938] loss_G: 3.259540, loss_D: 0.195178\n",
      "[Epoch 95/200] [Batch 290/938] loss_G: 3.079089, loss_D: 0.248737\n",
      "[Epoch 95/200] [Batch 300/938] loss_G: 2.937099, loss_D: 0.286651\n",
      "[Epoch 95/200] [Batch 310/938] loss_G: 3.005889, loss_D: 0.264677\n",
      "[Epoch 95/200] [Batch 320/938] loss_G: 3.156303, loss_D: 0.148456\n",
      "[Epoch 95/200] [Batch 330/938] loss_G: 2.956706, loss_D: 0.217957\n",
      "[Epoch 95/200] [Batch 340/938] loss_G: 2.960276, loss_D: 0.220856\n",
      "[Epoch 95/200] [Batch 350/938] loss_G: 2.904963, loss_D: 0.152449\n",
      "[Epoch 95/200] [Batch 360/938] loss_G: 2.985271, loss_D: 0.315341\n",
      "[Epoch 95/200] [Batch 370/938] loss_G: 3.212250, loss_D: 0.230552\n",
      "[Epoch 95/200] [Batch 380/938] loss_G: 2.964504, loss_D: 0.197309\n",
      "[Epoch 95/200] [Batch 390/938] loss_G: 3.244436, loss_D: 0.187808\n",
      "[Epoch 95/200] [Batch 400/938] loss_G: 2.835032, loss_D: 0.211053\n",
      "[Epoch 95/200] [Batch 410/938] loss_G: 2.894763, loss_D: 0.186054\n",
      "[Epoch 95/200] [Batch 420/938] loss_G: 3.154066, loss_D: 0.152010\n",
      "[Epoch 95/200] [Batch 430/938] loss_G: 3.150080, loss_D: 0.183220\n",
      "[Epoch 95/200] [Batch 440/938] loss_G: 2.908569, loss_D: 0.277695\n",
      "[Epoch 95/200] [Batch 450/938] loss_G: 2.973362, loss_D: 0.295248\n",
      "[Epoch 95/200] [Batch 460/938] loss_G: 3.074070, loss_D: 0.234699\n",
      "[Epoch 95/200] [Batch 470/938] loss_G: 3.305739, loss_D: 0.158705\n",
      "[Epoch 95/200] [Batch 480/938] loss_G: 3.057467, loss_D: 0.218153\n",
      "[Epoch 95/200] [Batch 490/938] loss_G: 3.333033, loss_D: 0.186899\n",
      "[Epoch 95/200] [Batch 500/938] loss_G: 3.166697, loss_D: 0.209354\n",
      "[Epoch 95/200] [Batch 510/938] loss_G: 3.002673, loss_D: 0.202347\n",
      "[Epoch 95/200] [Batch 520/938] loss_G: 3.271791, loss_D: 0.248250\n",
      "[Epoch 95/200] [Batch 530/938] loss_G: 3.184256, loss_D: 0.162955\n",
      "[Epoch 95/200] [Batch 540/938] loss_G: 3.455969, loss_D: 0.173302\n",
      "[Epoch 95/200] [Batch 550/938] loss_G: 2.916071, loss_D: 0.223002\n",
      "[Epoch 95/200] [Batch 560/938] loss_G: 3.526323, loss_D: 0.183983\n",
      "[Epoch 95/200] [Batch 570/938] loss_G: 2.893084, loss_D: 0.237029\n",
      "[Epoch 95/200] [Batch 580/938] loss_G: 3.109809, loss_D: 0.326457\n",
      "[Epoch 95/200] [Batch 590/938] loss_G: 2.932118, loss_D: 0.214317\n",
      "[Epoch 95/200] [Batch 600/938] loss_G: 3.450686, loss_D: 0.192849\n",
      "[Epoch 95/200] [Batch 610/938] loss_G: 2.659312, loss_D: 0.131847\n",
      "[Epoch 95/200] [Batch 620/938] loss_G: 3.320974, loss_D: 0.148049\n",
      "[Epoch 95/200] [Batch 630/938] loss_G: 3.425381, loss_D: 0.142986\n",
      "[Epoch 95/200] [Batch 640/938] loss_G: 2.815979, loss_D: 0.198069\n",
      "[Epoch 95/200] [Batch 650/938] loss_G: 3.009178, loss_D: 0.184604\n",
      "[Epoch 95/200] [Batch 660/938] loss_G: 2.876827, loss_D: 0.128465\n",
      "[Epoch 95/200] [Batch 670/938] loss_G: 3.406996, loss_D: 0.270142\n",
      "[Epoch 95/200] [Batch 680/938] loss_G: 2.758537, loss_D: 0.198952\n",
      "[Epoch 95/200] [Batch 690/938] loss_G: 3.309356, loss_D: 0.183940\n",
      "[Epoch 95/200] [Batch 700/938] loss_G: 3.270396, loss_D: 0.251347\n",
      "[Epoch 95/200] [Batch 710/938] loss_G: 3.224205, loss_D: 0.203481\n",
      "[Epoch 95/200] [Batch 720/938] loss_G: 3.233429, loss_D: 0.205238\n",
      "[Epoch 95/200] [Batch 730/938] loss_G: 3.236858, loss_D: 0.162532\n",
      "[Epoch 95/200] [Batch 740/938] loss_G: 3.014162, loss_D: 0.181178\n",
      "[Epoch 95/200] [Batch 750/938] loss_G: 2.789079, loss_D: 0.206911\n",
      "[Epoch 95/200] [Batch 760/938] loss_G: 3.325487, loss_D: 0.258220\n",
      "[Epoch 95/200] [Batch 770/938] loss_G: 3.069003, loss_D: 0.148198\n",
      "[Epoch 95/200] [Batch 780/938] loss_G: 3.033226, loss_D: 0.176299\n",
      "[Epoch 95/200] [Batch 790/938] loss_G: 3.182826, loss_D: 0.224998\n",
      "[Epoch 95/200] [Batch 800/938] loss_G: 2.768751, loss_D: 0.227174\n",
      "[Epoch 95/200] [Batch 810/938] loss_G: 3.251947, loss_D: 0.186816\n",
      "[Epoch 95/200] [Batch 820/938] loss_G: 2.723185, loss_D: 0.254585\n",
      "[Epoch 95/200] [Batch 830/938] loss_G: 3.060102, loss_D: 0.180499\n",
      "[Epoch 95/200] [Batch 840/938] loss_G: 2.875479, loss_D: 0.201836\n",
      "[Epoch 95/200] [Batch 850/938] loss_G: 3.184284, loss_D: 0.185825\n",
      "[Epoch 95/200] [Batch 860/938] loss_G: 2.860052, loss_D: 0.181597\n",
      "[Epoch 95/200] [Batch 870/938] loss_G: 3.042380, loss_D: 0.152841\n",
      "[Epoch 95/200] [Batch 880/938] loss_G: 3.559912, loss_D: 0.199820\n",
      "[Epoch 95/200] [Batch 890/938] loss_G: 2.918267, loss_D: 0.179714\n",
      "[Epoch 95/200] [Batch 900/938] loss_G: 3.019563, loss_D: 0.330451\n",
      "[Epoch 95/200] [Batch 910/938] loss_G: 2.686236, loss_D: 0.230706\n",
      "[Epoch 95/200] [Batch 920/938] loss_G: 2.887887, loss_D: 0.178075\n",
      "[Epoch 95/200] [Batch 930/938] loss_G: 2.488176, loss_D: 0.233460\n",
      "[Epoch 96/200] [Batch 0/938] loss_G: 3.088449, loss_D: 0.152320\n",
      "[Epoch 96/200] [Batch 10/938] loss_G: 2.779603, loss_D: 0.280931\n",
      "[Epoch 96/200] [Batch 20/938] loss_G: 2.970505, loss_D: 0.240045\n",
      "[Epoch 96/200] [Batch 30/938] loss_G: 3.008456, loss_D: 0.161987\n",
      "[Epoch 96/200] [Batch 40/938] loss_G: 3.317436, loss_D: 0.132974\n",
      "[Epoch 96/200] [Batch 50/938] loss_G: 3.156906, loss_D: 0.170159\n",
      "[Epoch 96/200] [Batch 60/938] loss_G: 3.414794, loss_D: 0.148486\n",
      "[Epoch 96/200] [Batch 70/938] loss_G: 2.888105, loss_D: 0.272785\n",
      "[Epoch 96/200] [Batch 80/938] loss_G: 3.245123, loss_D: 0.205630\n",
      "[Epoch 96/200] [Batch 90/938] loss_G: 2.989995, loss_D: 0.174625\n",
      "[Epoch 96/200] [Batch 100/938] loss_G: 2.754206, loss_D: 0.162576\n",
      "[Epoch 96/200] [Batch 110/938] loss_G: 3.055216, loss_D: 0.300974\n",
      "[Epoch 96/200] [Batch 120/938] loss_G: 2.759140, loss_D: 0.180106\n",
      "[Epoch 96/200] [Batch 130/938] loss_G: 3.298693, loss_D: 0.234779\n",
      "[Epoch 96/200] [Batch 140/938] loss_G: 2.700386, loss_D: 0.255360\n",
      "[Epoch 96/200] [Batch 150/938] loss_G: 2.815922, loss_D: 0.326326\n",
      "[Epoch 96/200] [Batch 160/938] loss_G: 2.940609, loss_D: 0.264280\n",
      "[Epoch 96/200] [Batch 170/938] loss_G: 2.872644, loss_D: 0.246587\n",
      "[Epoch 96/200] [Batch 180/938] loss_G: 3.072151, loss_D: 0.154986\n",
      "[Epoch 96/200] [Batch 190/938] loss_G: 2.800203, loss_D: 0.216289\n",
      "[Epoch 96/200] [Batch 200/938] loss_G: 2.869414, loss_D: 0.273980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 96/200] [Batch 210/938] loss_G: 3.041149, loss_D: 0.268633\n",
      "[Epoch 96/200] [Batch 220/938] loss_G: 2.966080, loss_D: 0.212022\n",
      "[Epoch 96/200] [Batch 230/938] loss_G: 2.685570, loss_D: 0.244063\n",
      "[Epoch 96/200] [Batch 240/938] loss_G: 3.114769, loss_D: 0.223816\n",
      "[Epoch 96/200] [Batch 250/938] loss_G: 3.084994, loss_D: 0.189529\n",
      "[Epoch 96/200] [Batch 260/938] loss_G: 3.265447, loss_D: 0.240734\n",
      "[Epoch 96/200] [Batch 270/938] loss_G: 3.366098, loss_D: 0.213104\n",
      "[Epoch 96/200] [Batch 280/938] loss_G: 2.773523, loss_D: 0.244717\n",
      "[Epoch 96/200] [Batch 290/938] loss_G: 2.855728, loss_D: 0.171864\n",
      "[Epoch 96/200] [Batch 300/938] loss_G: 2.863943, loss_D: 0.196691\n",
      "[Epoch 96/200] [Batch 310/938] loss_G: 2.979081, loss_D: 0.149876\n",
      "[Epoch 96/200] [Batch 320/938] loss_G: 3.133028, loss_D: 0.204812\n",
      "[Epoch 96/200] [Batch 330/938] loss_G: 3.112253, loss_D: 0.203839\n",
      "[Epoch 96/200] [Batch 340/938] loss_G: 2.902835, loss_D: 0.204075\n",
      "[Epoch 96/200] [Batch 350/938] loss_G: 3.123948, loss_D: 0.178849\n",
      "[Epoch 96/200] [Batch 360/938] loss_G: 2.975218, loss_D: 0.225591\n",
      "[Epoch 96/200] [Batch 370/938] loss_G: 2.868953, loss_D: 0.309449\n",
      "[Epoch 96/200] [Batch 380/938] loss_G: 2.592536, loss_D: 0.183414\n",
      "[Epoch 96/200] [Batch 390/938] loss_G: 2.699442, loss_D: 0.178985\n",
      "[Epoch 96/200] [Batch 400/938] loss_G: 2.956440, loss_D: 0.162677\n",
      "[Epoch 96/200] [Batch 410/938] loss_G: 3.353486, loss_D: 0.172168\n",
      "[Epoch 96/200] [Batch 420/938] loss_G: 2.949459, loss_D: 0.370509\n",
      "[Epoch 96/200] [Batch 430/938] loss_G: 2.739361, loss_D: 0.265299\n",
      "[Epoch 96/200] [Batch 440/938] loss_G: 3.129819, loss_D: 0.241535\n",
      "[Epoch 96/200] [Batch 450/938] loss_G: 3.133617, loss_D: 0.163265\n",
      "[Epoch 96/200] [Batch 460/938] loss_G: 3.113076, loss_D: 0.213212\n",
      "[Epoch 96/200] [Batch 470/938] loss_G: 3.276186, loss_D: 0.200469\n",
      "[Epoch 96/200] [Batch 480/938] loss_G: 2.685937, loss_D: 0.233814\n",
      "[Epoch 96/200] [Batch 490/938] loss_G: 3.158319, loss_D: 0.205638\n",
      "[Epoch 96/200] [Batch 500/938] loss_G: 2.836184, loss_D: 0.218523\n",
      "[Epoch 96/200] [Batch 510/938] loss_G: 3.161031, loss_D: 0.223110\n",
      "[Epoch 96/200] [Batch 520/938] loss_G: 3.295638, loss_D: 0.192364\n",
      "[Epoch 96/200] [Batch 530/938] loss_G: 2.748500, loss_D: 0.180516\n",
      "[Epoch 96/200] [Batch 540/938] loss_G: 2.997394, loss_D: 0.136205\n",
      "[Epoch 96/200] [Batch 550/938] loss_G: 3.482102, loss_D: 0.212306\n",
      "[Epoch 96/200] [Batch 560/938] loss_G: 3.242300, loss_D: 0.239670\n",
      "[Epoch 96/200] [Batch 570/938] loss_G: 2.930979, loss_D: 0.155447\n",
      "[Epoch 96/200] [Batch 580/938] loss_G: 3.134728, loss_D: 0.201009\n",
      "[Epoch 96/200] [Batch 590/938] loss_G: 2.788543, loss_D: 0.190941\n",
      "[Epoch 96/200] [Batch 600/938] loss_G: 3.022644, loss_D: 0.184993\n",
      "[Epoch 96/200] [Batch 610/938] loss_G: 2.879441, loss_D: 0.207172\n",
      "[Epoch 96/200] [Batch 620/938] loss_G: 2.884162, loss_D: 0.146126\n",
      "[Epoch 96/200] [Batch 630/938] loss_G: 2.860866, loss_D: 0.187423\n",
      "[Epoch 96/200] [Batch 640/938] loss_G: 2.670668, loss_D: 0.191684\n",
      "[Epoch 96/200] [Batch 650/938] loss_G: 2.714621, loss_D: 0.186196\n",
      "[Epoch 96/200] [Batch 660/938] loss_G: 2.720972, loss_D: 0.204662\n",
      "[Epoch 96/200] [Batch 670/938] loss_G: 3.060112, loss_D: 0.183325\n",
      "[Epoch 96/200] [Batch 680/938] loss_G: 3.100485, loss_D: 0.181682\n",
      "[Epoch 96/200] [Batch 690/938] loss_G: 2.949892, loss_D: 0.199733\n",
      "[Epoch 96/200] [Batch 700/938] loss_G: 3.215165, loss_D: 0.164733\n",
      "[Epoch 96/200] [Batch 710/938] loss_G: 2.771492, loss_D: 0.180727\n",
      "[Epoch 96/200] [Batch 720/938] loss_G: 3.574527, loss_D: 0.180437\n",
      "[Epoch 96/200] [Batch 730/938] loss_G: 2.919232, loss_D: 0.180188\n",
      "[Epoch 96/200] [Batch 740/938] loss_G: 3.054075, loss_D: 0.164989\n",
      "[Epoch 96/200] [Batch 750/938] loss_G: 2.934080, loss_D: 0.242182\n",
      "[Epoch 96/200] [Batch 760/938] loss_G: 2.946606, loss_D: 0.225192\n",
      "[Epoch 96/200] [Batch 770/938] loss_G: 3.014319, loss_D: 0.235032\n",
      "[Epoch 96/200] [Batch 780/938] loss_G: 3.172680, loss_D: 0.244973\n",
      "[Epoch 96/200] [Batch 790/938] loss_G: 2.705783, loss_D: 0.237759\n",
      "[Epoch 96/200] [Batch 800/938] loss_G: 3.118186, loss_D: 0.228860\n",
      "[Epoch 96/200] [Batch 810/938] loss_G: 3.055029, loss_D: 0.167250\n",
      "[Epoch 96/200] [Batch 820/938] loss_G: 3.095710, loss_D: 0.188137\n",
      "[Epoch 96/200] [Batch 830/938] loss_G: 3.387338, loss_D: 0.253255\n",
      "[Epoch 96/200] [Batch 840/938] loss_G: 3.247442, loss_D: 0.189470\n",
      "[Epoch 96/200] [Batch 850/938] loss_G: 2.971877, loss_D: 0.202886\n",
      "[Epoch 96/200] [Batch 860/938] loss_G: 3.298177, loss_D: 0.216815\n",
      "[Epoch 96/200] [Batch 870/938] loss_G: 2.582822, loss_D: 0.309566\n",
      "[Epoch 96/200] [Batch 880/938] loss_G: 3.199820, loss_D: 0.202534\n",
      "[Epoch 96/200] [Batch 890/938] loss_G: 2.588561, loss_D: 0.236453\n",
      "[Epoch 96/200] [Batch 900/938] loss_G: 2.905077, loss_D: 0.209595\n",
      "[Epoch 96/200] [Batch 910/938] loss_G: 3.118382, loss_D: 0.249118\n",
      "[Epoch 96/200] [Batch 920/938] loss_G: 2.625753, loss_D: 0.289382\n",
      "[Epoch 96/200] [Batch 930/938] loss_G: 3.295009, loss_D: 0.167037\n",
      "[Epoch 97/200] [Batch 0/938] loss_G: 2.980998, loss_D: 0.254853\n",
      "[Epoch 97/200] [Batch 10/938] loss_G: 3.341454, loss_D: 0.232156\n",
      "[Epoch 97/200] [Batch 20/938] loss_G: 3.269261, loss_D: 0.228257\n",
      "[Epoch 97/200] [Batch 30/938] loss_G: 3.081604, loss_D: 0.193814\n",
      "[Epoch 97/200] [Batch 40/938] loss_G: 2.918704, loss_D: 0.199597\n",
      "[Epoch 97/200] [Batch 50/938] loss_G: 2.577886, loss_D: 0.174525\n",
      "[Epoch 97/200] [Batch 60/938] loss_G: 3.154620, loss_D: 0.183712\n",
      "[Epoch 97/200] [Batch 70/938] loss_G: 2.942433, loss_D: 0.191922\n",
      "[Epoch 97/200] [Batch 80/938] loss_G: 2.543340, loss_D: 0.210957\n",
      "[Epoch 97/200] [Batch 90/938] loss_G: 2.876332, loss_D: 0.233477\n",
      "[Epoch 97/200] [Batch 100/938] loss_G: 2.906600, loss_D: 0.235036\n",
      "[Epoch 97/200] [Batch 110/938] loss_G: 3.350116, loss_D: 0.243143\n",
      "[Epoch 97/200] [Batch 120/938] loss_G: 2.782047, loss_D: 0.149395\n",
      "[Epoch 97/200] [Batch 130/938] loss_G: 3.087358, loss_D: 0.161980\n",
      "[Epoch 97/200] [Batch 140/938] loss_G: 2.452184, loss_D: 0.202286\n",
      "[Epoch 97/200] [Batch 150/938] loss_G: 2.740813, loss_D: 0.180015\n",
      "[Epoch 97/200] [Batch 160/938] loss_G: 2.872499, loss_D: 0.181045\n",
      "[Epoch 97/200] [Batch 170/938] loss_G: 3.087989, loss_D: 0.188107\n",
      "[Epoch 97/200] [Batch 180/938] loss_G: 2.851773, loss_D: 0.226801\n",
      "[Epoch 97/200] [Batch 190/938] loss_G: 2.826669, loss_D: 0.158927\n",
      "[Epoch 97/200] [Batch 200/938] loss_G: 3.170235, loss_D: 0.154749\n",
      "[Epoch 97/200] [Batch 210/938] loss_G: 3.053438, loss_D: 0.197229\n",
      "[Epoch 97/200] [Batch 220/938] loss_G: 2.563843, loss_D: 0.235221\n",
      "[Epoch 97/200] [Batch 230/938] loss_G: 3.335157, loss_D: 0.166887\n",
      "[Epoch 97/200] [Batch 240/938] loss_G: 2.666228, loss_D: 0.244108\n",
      "[Epoch 97/200] [Batch 250/938] loss_G: 3.370488, loss_D: 0.197958\n",
      "[Epoch 97/200] [Batch 260/938] loss_G: 2.791145, loss_D: 0.247800\n",
      "[Epoch 97/200] [Batch 270/938] loss_G: 2.976434, loss_D: 0.208304\n",
      "[Epoch 97/200] [Batch 280/938] loss_G: 3.148424, loss_D: 0.247955\n",
      "[Epoch 97/200] [Batch 290/938] loss_G: 2.575413, loss_D: 0.249999\n",
      "[Epoch 97/200] [Batch 300/938] loss_G: 3.299414, loss_D: 0.186168\n",
      "[Epoch 97/200] [Batch 310/938] loss_G: 3.133545, loss_D: 0.236382\n",
      "[Epoch 97/200] [Batch 320/938] loss_G: 3.080179, loss_D: 0.123664\n",
      "[Epoch 97/200] [Batch 330/938] loss_G: 3.076200, loss_D: 0.245001\n",
      "[Epoch 97/200] [Batch 340/938] loss_G: 3.319405, loss_D: 0.279786\n",
      "[Epoch 97/200] [Batch 350/938] loss_G: 3.310721, loss_D: 0.193430\n",
      "[Epoch 97/200] [Batch 360/938] loss_G: 2.772295, loss_D: 0.271658\n",
      "[Epoch 97/200] [Batch 370/938] loss_G: 3.204701, loss_D: 0.234030\n",
      "[Epoch 97/200] [Batch 380/938] loss_G: 2.913290, loss_D: 0.180056\n",
      "[Epoch 97/200] [Batch 390/938] loss_G: 3.186151, loss_D: 0.200764\n",
      "[Epoch 97/200] [Batch 400/938] loss_G: 3.228167, loss_D: 0.235447\n",
      "[Epoch 97/200] [Batch 410/938] loss_G: 3.193230, loss_D: 0.259491\n",
      "[Epoch 97/200] [Batch 420/938] loss_G: 3.155269, loss_D: 0.163816\n",
      "[Epoch 97/200] [Batch 430/938] loss_G: 2.952878, loss_D: 0.191016\n",
      "[Epoch 97/200] [Batch 440/938] loss_G: 3.087941, loss_D: 0.193924\n",
      "[Epoch 97/200] [Batch 450/938] loss_G: 3.028474, loss_D: 0.257345\n",
      "[Epoch 97/200] [Batch 460/938] loss_G: 3.006877, loss_D: 0.212035\n",
      "[Epoch 97/200] [Batch 470/938] loss_G: 3.041558, loss_D: 0.251537\n",
      "[Epoch 97/200] [Batch 480/938] loss_G: 3.322643, loss_D: 0.206593\n",
      "[Epoch 97/200] [Batch 490/938] loss_G: 2.940214, loss_D: 0.209697\n",
      "[Epoch 97/200] [Batch 500/938] loss_G: 2.691231, loss_D: 0.250043\n",
      "[Epoch 97/200] [Batch 510/938] loss_G: 3.139473, loss_D: 0.242504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 97/200] [Batch 520/938] loss_G: 2.887634, loss_D: 0.180297\n",
      "[Epoch 97/200] [Batch 530/938] loss_G: 3.149999, loss_D: 0.201438\n",
      "[Epoch 97/200] [Batch 540/938] loss_G: 2.896268, loss_D: 0.174060\n",
      "[Epoch 97/200] [Batch 550/938] loss_G: 2.577885, loss_D: 0.329295\n",
      "[Epoch 97/200] [Batch 560/938] loss_G: 3.128282, loss_D: 0.187057\n",
      "[Epoch 97/200] [Batch 570/938] loss_G: 3.182209, loss_D: 0.143623\n",
      "[Epoch 97/200] [Batch 580/938] loss_G: 2.922564, loss_D: 0.176927\n",
      "[Epoch 97/200] [Batch 590/938] loss_G: 2.927682, loss_D: 0.262423\n",
      "[Epoch 97/200] [Batch 600/938] loss_G: 3.184446, loss_D: 0.202176\n",
      "[Epoch 97/200] [Batch 610/938] loss_G: 2.891176, loss_D: 0.309902\n",
      "[Epoch 97/200] [Batch 620/938] loss_G: 3.417396, loss_D: 0.175445\n",
      "[Epoch 97/200] [Batch 630/938] loss_G: 2.644963, loss_D: 0.293379\n",
      "[Epoch 97/200] [Batch 640/938] loss_G: 3.085102, loss_D: 0.185204\n",
      "[Epoch 97/200] [Batch 650/938] loss_G: 3.122219, loss_D: 0.187737\n",
      "[Epoch 97/200] [Batch 660/938] loss_G: 3.240111, loss_D: 0.204475\n",
      "[Epoch 97/200] [Batch 670/938] loss_G: 3.133998, loss_D: 0.185499\n",
      "[Epoch 97/200] [Batch 680/938] loss_G: 2.987157, loss_D: 0.171918\n",
      "[Epoch 97/200] [Batch 690/938] loss_G: 2.633322, loss_D: 0.244881\n",
      "[Epoch 97/200] [Batch 700/938] loss_G: 3.452967, loss_D: 0.199770\n",
      "[Epoch 97/200] [Batch 710/938] loss_G: 3.436922, loss_D: 0.239915\n",
      "[Epoch 97/200] [Batch 720/938] loss_G: 3.141503, loss_D: 0.227647\n",
      "[Epoch 97/200] [Batch 730/938] loss_G: 2.974578, loss_D: 0.312709\n",
      "[Epoch 97/200] [Batch 740/938] loss_G: 2.961216, loss_D: 0.192812\n",
      "[Epoch 97/200] [Batch 750/938] loss_G: 3.182894, loss_D: 0.132506\n",
      "[Epoch 97/200] [Batch 760/938] loss_G: 2.975400, loss_D: 0.164410\n",
      "[Epoch 97/200] [Batch 770/938] loss_G: 3.145559, loss_D: 0.170895\n",
      "[Epoch 97/200] [Batch 780/938] loss_G: 3.114472, loss_D: 0.232818\n",
      "[Epoch 97/200] [Batch 790/938] loss_G: 3.537893, loss_D: 0.178939\n",
      "[Epoch 97/200] [Batch 800/938] loss_G: 2.832230, loss_D: 0.282071\n",
      "[Epoch 97/200] [Batch 810/938] loss_G: 3.317078, loss_D: 0.207707\n",
      "[Epoch 97/200] [Batch 820/938] loss_G: 3.020622, loss_D: 0.177167\n",
      "[Epoch 97/200] [Batch 830/938] loss_G: 3.309105, loss_D: 0.195922\n",
      "[Epoch 97/200] [Batch 840/938] loss_G: 2.761873, loss_D: 0.214266\n",
      "[Epoch 97/200] [Batch 850/938] loss_G: 3.211268, loss_D: 0.122415\n",
      "[Epoch 97/200] [Batch 860/938] loss_G: 3.012916, loss_D: 0.149936\n",
      "[Epoch 97/200] [Batch 870/938] loss_G: 3.139672, loss_D: 0.193959\n",
      "[Epoch 97/200] [Batch 880/938] loss_G: 3.512524, loss_D: 0.171967\n",
      "[Epoch 97/200] [Batch 890/938] loss_G: 3.041172, loss_D: 0.238719\n",
      "[Epoch 97/200] [Batch 900/938] loss_G: 2.493415, loss_D: 0.264982\n",
      "[Epoch 97/200] [Batch 910/938] loss_G: 3.152637, loss_D: 0.201463\n",
      "[Epoch 97/200] [Batch 920/938] loss_G: 3.134755, loss_D: 0.180764\n",
      "[Epoch 97/200] [Batch 930/938] loss_G: 2.942057, loss_D: 0.220482\n",
      "[Epoch 98/200] [Batch 0/938] loss_G: 2.977349, loss_D: 0.204947\n",
      "[Epoch 98/200] [Batch 10/938] loss_G: 2.956510, loss_D: 0.153104\n",
      "[Epoch 98/200] [Batch 20/938] loss_G: 2.818295, loss_D: 0.284608\n",
      "[Epoch 98/200] [Batch 30/938] loss_G: 2.704079, loss_D: 0.254866\n",
      "[Epoch 98/200] [Batch 40/938] loss_G: 2.875517, loss_D: 0.268420\n",
      "[Epoch 98/200] [Batch 50/938] loss_G: 2.973431, loss_D: 0.211239\n",
      "[Epoch 98/200] [Batch 60/938] loss_G: 3.292173, loss_D: 0.143576\n",
      "[Epoch 98/200] [Batch 70/938] loss_G: 3.286647, loss_D: 0.216577\n",
      "[Epoch 98/200] [Batch 80/938] loss_G: 2.757341, loss_D: 0.187677\n",
      "[Epoch 98/200] [Batch 90/938] loss_G: 2.991968, loss_D: 0.186041\n",
      "[Epoch 98/200] [Batch 100/938] loss_G: 2.652174, loss_D: 0.226954\n",
      "[Epoch 98/200] [Batch 110/938] loss_G: 2.762702, loss_D: 0.231000\n",
      "[Epoch 98/200] [Batch 120/938] loss_G: 2.993907, loss_D: 0.262486\n",
      "[Epoch 98/200] [Batch 130/938] loss_G: 3.212220, loss_D: 0.176191\n",
      "[Epoch 98/200] [Batch 140/938] loss_G: 3.035624, loss_D: 0.306598\n",
      "[Epoch 98/200] [Batch 150/938] loss_G: 2.760931, loss_D: 0.253238\n",
      "[Epoch 98/200] [Batch 160/938] loss_G: 2.715746, loss_D: 0.222445\n",
      "[Epoch 98/200] [Batch 170/938] loss_G: 3.354384, loss_D: 0.169997\n",
      "[Epoch 98/200] [Batch 180/938] loss_G: 2.900369, loss_D: 0.151670\n",
      "[Epoch 98/200] [Batch 190/938] loss_G: 3.113885, loss_D: 0.122742\n",
      "[Epoch 98/200] [Batch 200/938] loss_G: 2.738167, loss_D: 0.252302\n",
      "[Epoch 98/200] [Batch 210/938] loss_G: 3.486425, loss_D: 0.173018\n",
      "[Epoch 98/200] [Batch 220/938] loss_G: 3.118326, loss_D: 0.144626\n",
      "[Epoch 98/200] [Batch 230/938] loss_G: 3.183688, loss_D: 0.143084\n",
      "[Epoch 98/200] [Batch 240/938] loss_G: 3.040572, loss_D: 0.156410\n",
      "[Epoch 98/200] [Batch 250/938] loss_G: 3.441610, loss_D: 0.261055\n",
      "[Epoch 98/200] [Batch 260/938] loss_G: 2.736899, loss_D: 0.233237\n",
      "[Epoch 98/200] [Batch 270/938] loss_G: 3.252002, loss_D: 0.214194\n",
      "[Epoch 98/200] [Batch 280/938] loss_G: 3.170168, loss_D: 0.141565\n",
      "[Epoch 98/200] [Batch 290/938] loss_G: 3.094693, loss_D: 0.193367\n",
      "[Epoch 98/200] [Batch 300/938] loss_G: 3.037513, loss_D: 0.129200\n",
      "[Epoch 98/200] [Batch 310/938] loss_G: 3.043750, loss_D: 0.182494\n",
      "[Epoch 98/200] [Batch 320/938] loss_G: 3.668214, loss_D: 0.205682\n",
      "[Epoch 98/200] [Batch 330/938] loss_G: 2.986005, loss_D: 0.235319\n",
      "[Epoch 98/200] [Batch 340/938] loss_G: 3.280890, loss_D: 0.222627\n",
      "[Epoch 98/200] [Batch 350/938] loss_G: 3.321678, loss_D: 0.311055\n",
      "[Epoch 98/200] [Batch 360/938] loss_G: 3.161559, loss_D: 0.232094\n",
      "[Epoch 98/200] [Batch 370/938] loss_G: 2.982078, loss_D: 0.239011\n",
      "[Epoch 98/200] [Batch 380/938] loss_G: 2.546542, loss_D: 0.240402\n",
      "[Epoch 98/200] [Batch 390/938] loss_G: 3.149106, loss_D: 0.136860\n",
      "[Epoch 98/200] [Batch 400/938] loss_G: 3.157975, loss_D: 0.146350\n",
      "[Epoch 98/200] [Batch 410/938] loss_G: 3.024228, loss_D: 0.292498\n",
      "[Epoch 98/200] [Batch 420/938] loss_G: 2.869563, loss_D: 0.241619\n",
      "[Epoch 98/200] [Batch 430/938] loss_G: 3.164227, loss_D: 0.118535\n",
      "[Epoch 98/200] [Batch 440/938] loss_G: 2.543220, loss_D: 0.239095\n",
      "[Epoch 98/200] [Batch 450/938] loss_G: 3.000564, loss_D: 0.237973\n",
      "[Epoch 98/200] [Batch 460/938] loss_G: 2.694851, loss_D: 0.221276\n",
      "[Epoch 98/200] [Batch 470/938] loss_G: 3.210126, loss_D: 0.239448\n",
      "[Epoch 98/200] [Batch 480/938] loss_G: 2.817649, loss_D: 0.196441\n",
      "[Epoch 98/200] [Batch 490/938] loss_G: 2.906450, loss_D: 0.227659\n",
      "[Epoch 98/200] [Batch 500/938] loss_G: 3.326692, loss_D: 0.197438\n",
      "[Epoch 98/200] [Batch 510/938] loss_G: 3.298927, loss_D: 0.194602\n",
      "[Epoch 98/200] [Batch 520/938] loss_G: 2.846597, loss_D: 0.171584\n",
      "[Epoch 98/200] [Batch 530/938] loss_G: 3.268350, loss_D: 0.209394\n",
      "[Epoch 98/200] [Batch 540/938] loss_G: 3.201390, loss_D: 0.152434\n",
      "[Epoch 98/200] [Batch 550/938] loss_G: 2.787236, loss_D: 0.155384\n",
      "[Epoch 98/200] [Batch 560/938] loss_G: 3.343791, loss_D: 0.165309\n",
      "[Epoch 98/200] [Batch 570/938] loss_G: 2.952466, loss_D: 0.317640\n",
      "[Epoch 98/200] [Batch 580/938] loss_G: 3.127034, loss_D: 0.237665\n",
      "[Epoch 98/200] [Batch 590/938] loss_G: 2.894259, loss_D: 0.282127\n",
      "[Epoch 98/200] [Batch 600/938] loss_G: 2.820657, loss_D: 0.239467\n",
      "[Epoch 98/200] [Batch 610/938] loss_G: 3.107373, loss_D: 0.215313\n",
      "[Epoch 98/200] [Batch 620/938] loss_G: 2.847695, loss_D: 0.206983\n",
      "[Epoch 98/200] [Batch 630/938] loss_G: 3.089514, loss_D: 0.158550\n",
      "[Epoch 98/200] [Batch 640/938] loss_G: 3.151629, loss_D: 0.169801\n",
      "[Epoch 98/200] [Batch 650/938] loss_G: 3.225929, loss_D: 0.198911\n",
      "[Epoch 98/200] [Batch 660/938] loss_G: 3.080413, loss_D: 0.158899\n",
      "[Epoch 98/200] [Batch 670/938] loss_G: 3.097454, loss_D: 0.183705\n",
      "[Epoch 98/200] [Batch 680/938] loss_G: 3.007468, loss_D: 0.189575\n",
      "[Epoch 98/200] [Batch 690/938] loss_G: 2.943422, loss_D: 0.179307\n",
      "[Epoch 98/200] [Batch 700/938] loss_G: 2.973323, loss_D: 0.287319\n",
      "[Epoch 98/200] [Batch 710/938] loss_G: 2.892168, loss_D: 0.210216\n",
      "[Epoch 98/200] [Batch 720/938] loss_G: 2.842385, loss_D: 0.221809\n",
      "[Epoch 98/200] [Batch 730/938] loss_G: 3.055371, loss_D: 0.239097\n",
      "[Epoch 98/200] [Batch 740/938] loss_G: 3.150780, loss_D: 0.234962\n",
      "[Epoch 98/200] [Batch 750/938] loss_G: 3.119588, loss_D: 0.167400\n",
      "[Epoch 98/200] [Batch 760/938] loss_G: 2.749441, loss_D: 0.219269\n",
      "[Epoch 98/200] [Batch 770/938] loss_G: 3.008561, loss_D: 0.179006\n",
      "[Epoch 98/200] [Batch 780/938] loss_G: 2.733631, loss_D: 0.212059\n",
      "[Epoch 98/200] [Batch 790/938] loss_G: 3.415078, loss_D: 0.166652\n",
      "[Epoch 98/200] [Batch 800/938] loss_G: 2.921607, loss_D: 0.323797\n",
      "[Epoch 98/200] [Batch 810/938] loss_G: 3.156165, loss_D: 0.200179\n",
      "[Epoch 98/200] [Batch 820/938] loss_G: 3.062930, loss_D: 0.170081\n",
      "[Epoch 98/200] [Batch 830/938] loss_G: 3.034411, loss_D: 0.212323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 98/200] [Batch 840/938] loss_G: 3.046263, loss_D: 0.163582\n",
      "[Epoch 98/200] [Batch 850/938] loss_G: 3.150295, loss_D: 0.219136\n",
      "[Epoch 98/200] [Batch 860/938] loss_G: 2.800140, loss_D: 0.268517\n",
      "[Epoch 98/200] [Batch 870/938] loss_G: 3.236000, loss_D: 0.154320\n",
      "[Epoch 98/200] [Batch 880/938] loss_G: 2.694006, loss_D: 0.246438\n",
      "[Epoch 98/200] [Batch 890/938] loss_G: 2.683969, loss_D: 0.235526\n",
      "[Epoch 98/200] [Batch 900/938] loss_G: 3.296646, loss_D: 0.323992\n",
      "[Epoch 98/200] [Batch 910/938] loss_G: 2.880332, loss_D: 0.152735\n",
      "[Epoch 98/200] [Batch 920/938] loss_G: 2.891894, loss_D: 0.261729\n",
      "[Epoch 98/200] [Batch 930/938] loss_G: 3.308108, loss_D: 0.113743\n",
      "[Epoch 99/200] [Batch 0/938] loss_G: 3.320996, loss_D: 0.185540\n",
      "[Epoch 99/200] [Batch 10/938] loss_G: 2.739701, loss_D: 0.197982\n",
      "[Epoch 99/200] [Batch 20/938] loss_G: 3.070068, loss_D: 0.266854\n",
      "[Epoch 99/200] [Batch 30/938] loss_G: 3.193561, loss_D: 0.179903\n",
      "[Epoch 99/200] [Batch 40/938] loss_G: 3.247951, loss_D: 0.219048\n",
      "[Epoch 99/200] [Batch 50/938] loss_G: 2.985124, loss_D: 0.237739\n",
      "[Epoch 99/200] [Batch 60/938] loss_G: 3.231704, loss_D: 0.188309\n",
      "[Epoch 99/200] [Batch 70/938] loss_G: 2.817099, loss_D: 0.152560\n",
      "[Epoch 99/200] [Batch 80/938] loss_G: 3.173444, loss_D: 0.281038\n",
      "[Epoch 99/200] [Batch 90/938] loss_G: 2.924432, loss_D: 0.209925\n",
      "[Epoch 99/200] [Batch 100/938] loss_G: 3.435451, loss_D: 0.157022\n",
      "[Epoch 99/200] [Batch 110/938] loss_G: 2.812990, loss_D: 0.201515\n",
      "[Epoch 99/200] [Batch 120/938] loss_G: 3.080796, loss_D: 0.193300\n",
      "[Epoch 99/200] [Batch 130/938] loss_G: 3.119804, loss_D: 0.224087\n",
      "[Epoch 99/200] [Batch 140/938] loss_G: 3.362382, loss_D: 0.173738\n",
      "[Epoch 99/200] [Batch 150/938] loss_G: 2.646339, loss_D: 0.225197\n",
      "[Epoch 99/200] [Batch 160/938] loss_G: 2.717045, loss_D: 0.228170\n",
      "[Epoch 99/200] [Batch 170/938] loss_G: 3.615559, loss_D: 0.179709\n",
      "[Epoch 99/200] [Batch 180/938] loss_G: 2.733174, loss_D: 0.152056\n",
      "[Epoch 99/200] [Batch 190/938] loss_G: 3.282917, loss_D: 0.251212\n",
      "[Epoch 99/200] [Batch 200/938] loss_G: 3.289949, loss_D: 0.149800\n",
      "[Epoch 99/200] [Batch 210/938] loss_G: 3.126864, loss_D: 0.295818\n",
      "[Epoch 99/200] [Batch 220/938] loss_G: 2.884528, loss_D: 0.217433\n",
      "[Epoch 99/200] [Batch 230/938] loss_G: 3.217699, loss_D: 0.229325\n",
      "[Epoch 99/200] [Batch 240/938] loss_G: 3.078102, loss_D: 0.141227\n",
      "[Epoch 99/200] [Batch 250/938] loss_G: 2.628317, loss_D: 0.276125\n",
      "[Epoch 99/200] [Batch 260/938] loss_G: 3.209213, loss_D: 0.176569\n",
      "[Epoch 99/200] [Batch 270/938] loss_G: 3.616690, loss_D: 0.205130\n",
      "[Epoch 99/200] [Batch 280/938] loss_G: 2.686429, loss_D: 0.204922\n",
      "[Epoch 99/200] [Batch 290/938] loss_G: 3.173975, loss_D: 0.184355\n",
      "[Epoch 99/200] [Batch 300/938] loss_G: 3.238493, loss_D: 0.189002\n",
      "[Epoch 99/200] [Batch 310/938] loss_G: 3.349743, loss_D: 0.199911\n",
      "[Epoch 99/200] [Batch 320/938] loss_G: 3.016888, loss_D: 0.268360\n",
      "[Epoch 99/200] [Batch 330/938] loss_G: 3.037957, loss_D: 0.302510\n",
      "[Epoch 99/200] [Batch 340/938] loss_G: 3.005766, loss_D: 0.188159\n",
      "[Epoch 99/200] [Batch 350/938] loss_G: 3.209659, loss_D: 0.315278\n",
      "[Epoch 99/200] [Batch 360/938] loss_G: 2.778771, loss_D: 0.218873\n",
      "[Epoch 99/200] [Batch 370/938] loss_G: 3.169704, loss_D: 0.140411\n",
      "[Epoch 99/200] [Batch 380/938] loss_G: 2.796349, loss_D: 0.203192\n",
      "[Epoch 99/200] [Batch 390/938] loss_G: 3.084674, loss_D: 0.150935\n",
      "[Epoch 99/200] [Batch 400/938] loss_G: 3.115006, loss_D: 0.196331\n",
      "[Epoch 99/200] [Batch 410/938] loss_G: 3.205480, loss_D: 0.174176\n",
      "[Epoch 99/200] [Batch 420/938] loss_G: 2.760477, loss_D: 0.200347\n",
      "[Epoch 99/200] [Batch 430/938] loss_G: 2.981155, loss_D: 0.188398\n",
      "[Epoch 99/200] [Batch 440/938] loss_G: 2.849817, loss_D: 0.204211\n",
      "[Epoch 99/200] [Batch 450/938] loss_G: 2.837618, loss_D: 0.164946\n",
      "[Epoch 99/200] [Batch 460/938] loss_G: 3.203003, loss_D: 0.268802\n",
      "[Epoch 99/200] [Batch 470/938] loss_G: 3.116383, loss_D: 0.154082\n",
      "[Epoch 99/200] [Batch 480/938] loss_G: 3.066666, loss_D: 0.261417\n",
      "[Epoch 99/200] [Batch 490/938] loss_G: 2.900211, loss_D: 0.147476\n",
      "[Epoch 99/200] [Batch 500/938] loss_G: 2.953500, loss_D: 0.171005\n",
      "[Epoch 99/200] [Batch 510/938] loss_G: 2.843285, loss_D: 0.149376\n",
      "[Epoch 99/200] [Batch 520/938] loss_G: 3.161403, loss_D: 0.300542\n",
      "[Epoch 99/200] [Batch 530/938] loss_G: 3.169846, loss_D: 0.156611\n",
      "[Epoch 99/200] [Batch 540/938] loss_G: 3.077640, loss_D: 0.230990\n",
      "[Epoch 99/200] [Batch 550/938] loss_G: 3.163057, loss_D: 0.237930\n",
      "[Epoch 99/200] [Batch 560/938] loss_G: 2.583976, loss_D: 0.211529\n",
      "[Epoch 99/200] [Batch 570/938] loss_G: 3.466196, loss_D: 0.152520\n",
      "[Epoch 99/200] [Batch 580/938] loss_G: 3.080753, loss_D: 0.178408\n",
      "[Epoch 99/200] [Batch 590/938] loss_G: 2.867218, loss_D: 0.188225\n",
      "[Epoch 99/200] [Batch 600/938] loss_G: 3.279891, loss_D: 0.230568\n",
      "[Epoch 99/200] [Batch 610/938] loss_G: 2.900123, loss_D: 0.120634\n",
      "[Epoch 99/200] [Batch 620/938] loss_G: 3.304768, loss_D: 0.178253\n",
      "[Epoch 99/200] [Batch 630/938] loss_G: 3.441055, loss_D: 0.179019\n",
      "[Epoch 99/200] [Batch 640/938] loss_G: 2.854985, loss_D: 0.191842\n",
      "[Epoch 99/200] [Batch 650/938] loss_G: 2.821158, loss_D: 0.199761\n",
      "[Epoch 99/200] [Batch 660/938] loss_G: 2.805532, loss_D: 0.173585\n",
      "[Epoch 99/200] [Batch 670/938] loss_G: 2.999485, loss_D: 0.281757\n",
      "[Epoch 99/200] [Batch 680/938] loss_G: 2.853096, loss_D: 0.333477\n",
      "[Epoch 99/200] [Batch 690/938] loss_G: 3.267456, loss_D: 0.142202\n",
      "[Epoch 99/200] [Batch 700/938] loss_G: 2.777261, loss_D: 0.184402\n",
      "[Epoch 99/200] [Batch 710/938] loss_G: 3.182331, loss_D: 0.161853\n",
      "[Epoch 99/200] [Batch 720/938] loss_G: 3.013772, loss_D: 0.224342\n",
      "[Epoch 99/200] [Batch 730/938] loss_G: 2.730294, loss_D: 0.232102\n",
      "[Epoch 99/200] [Batch 740/938] loss_G: 2.854058, loss_D: 0.204815\n",
      "[Epoch 99/200] [Batch 750/938] loss_G: 2.930956, loss_D: 0.208321\n",
      "[Epoch 99/200] [Batch 760/938] loss_G: 2.933767, loss_D: 0.279180\n",
      "[Epoch 99/200] [Batch 770/938] loss_G: 2.642889, loss_D: 0.187845\n",
      "[Epoch 99/200] [Batch 780/938] loss_G: 3.072200, loss_D: 0.175905\n",
      "[Epoch 99/200] [Batch 790/938] loss_G: 2.908510, loss_D: 0.207918\n",
      "[Epoch 99/200] [Batch 800/938] loss_G: 3.056540, loss_D: 0.170669\n",
      "[Epoch 99/200] [Batch 810/938] loss_G: 3.462243, loss_D: 0.192617\n",
      "[Epoch 99/200] [Batch 820/938] loss_G: 2.892965, loss_D: 0.193016\n",
      "[Epoch 99/200] [Batch 830/938] loss_G: 3.000184, loss_D: 0.157873\n",
      "[Epoch 99/200] [Batch 840/938] loss_G: 3.239693, loss_D: 0.266689\n",
      "[Epoch 99/200] [Batch 850/938] loss_G: 3.311504, loss_D: 0.265230\n",
      "[Epoch 99/200] [Batch 860/938] loss_G: 3.110897, loss_D: 0.162442\n",
      "[Epoch 99/200] [Batch 870/938] loss_G: 3.384846, loss_D: 0.228349\n",
      "[Epoch 99/200] [Batch 880/938] loss_G: 2.905737, loss_D: 0.201765\n",
      "[Epoch 99/200] [Batch 890/938] loss_G: 3.182909, loss_D: 0.164523\n",
      "[Epoch 99/200] [Batch 900/938] loss_G: 3.363161, loss_D: 0.173572\n",
      "[Epoch 99/200] [Batch 910/938] loss_G: 2.883771, loss_D: 0.283835\n",
      "[Epoch 99/200] [Batch 920/938] loss_G: 3.186940, loss_D: 0.138819\n",
      "[Epoch 99/200] [Batch 930/938] loss_G: 2.988988, loss_D: 0.197699\n",
      "[Epoch 100/200] [Batch 0/938] loss_G: 3.149116, loss_D: 0.197563\n",
      "[Epoch 100/200] [Batch 10/938] loss_G: 3.016510, loss_D: 0.179376\n",
      "[Epoch 100/200] [Batch 20/938] loss_G: 2.908625, loss_D: 0.231897\n",
      "[Epoch 100/200] [Batch 30/938] loss_G: 3.117133, loss_D: 0.246244\n",
      "[Epoch 100/200] [Batch 40/938] loss_G: 2.736742, loss_D: 0.214517\n",
      "[Epoch 100/200] [Batch 50/938] loss_G: 3.020188, loss_D: 0.237381\n",
      "[Epoch 100/200] [Batch 60/938] loss_G: 2.923691, loss_D: 0.323944\n",
      "[Epoch 100/200] [Batch 70/938] loss_G: 3.265648, loss_D: 0.173444\n",
      "[Epoch 100/200] [Batch 80/938] loss_G: 2.961914, loss_D: 0.192258\n",
      "[Epoch 100/200] [Batch 90/938] loss_G: 3.181734, loss_D: 0.110589\n",
      "[Epoch 100/200] [Batch 100/938] loss_G: 3.451239, loss_D: 0.313603\n",
      "[Epoch 100/200] [Batch 110/938] loss_G: 2.886062, loss_D: 0.293660\n",
      "[Epoch 100/200] [Batch 120/938] loss_G: 3.468160, loss_D: 0.191076\n",
      "[Epoch 100/200] [Batch 130/938] loss_G: 3.022460, loss_D: 0.196863\n",
      "[Epoch 100/200] [Batch 140/938] loss_G: 3.117774, loss_D: 0.240972\n",
      "[Epoch 100/200] [Batch 150/938] loss_G: 3.129699, loss_D: 0.196073\n",
      "[Epoch 100/200] [Batch 160/938] loss_G: 3.151107, loss_D: 0.196049\n",
      "[Epoch 100/200] [Batch 170/938] loss_G: 3.230726, loss_D: 0.253975\n",
      "[Epoch 100/200] [Batch 180/938] loss_G: 2.940275, loss_D: 0.262771\n",
      "[Epoch 100/200] [Batch 190/938] loss_G: 2.839880, loss_D: 0.172346\n",
      "[Epoch 100/200] [Batch 200/938] loss_G: 2.973764, loss_D: 0.170953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 100/200] [Batch 210/938] loss_G: 3.062533, loss_D: 0.176336\n",
      "[Epoch 100/200] [Batch 220/938] loss_G: 3.448200, loss_D: 0.113604\n",
      "[Epoch 100/200] [Batch 230/938] loss_G: 3.077699, loss_D: 0.191477\n",
      "[Epoch 100/200] [Batch 240/938] loss_G: 3.212300, loss_D: 0.220685\n",
      "[Epoch 100/200] [Batch 250/938] loss_G: 3.167696, loss_D: 0.217007\n",
      "[Epoch 100/200] [Batch 260/938] loss_G: 3.056154, loss_D: 0.284557\n",
      "[Epoch 100/200] [Batch 270/938] loss_G: 3.784550, loss_D: 0.184385\n",
      "[Epoch 100/200] [Batch 280/938] loss_G: 3.117059, loss_D: 0.211688\n",
      "[Epoch 100/200] [Batch 290/938] loss_G: 3.103697, loss_D: 0.208052\n",
      "[Epoch 100/200] [Batch 300/938] loss_G: 3.284038, loss_D: 0.141371\n",
      "[Epoch 100/200] [Batch 310/938] loss_G: 3.240715, loss_D: 0.189621\n",
      "[Epoch 100/200] [Batch 320/938] loss_G: 3.061438, loss_D: 0.307967\n",
      "[Epoch 100/200] [Batch 330/938] loss_G: 2.738675, loss_D: 0.235473\n",
      "[Epoch 100/200] [Batch 340/938] loss_G: 2.815831, loss_D: 0.255457\n",
      "[Epoch 100/200] [Batch 350/938] loss_G: 2.912532, loss_D: 0.231744\n",
      "[Epoch 100/200] [Batch 360/938] loss_G: 3.100455, loss_D: 0.139573\n",
      "[Epoch 100/200] [Batch 370/938] loss_G: 3.150292, loss_D: 0.200858\n",
      "[Epoch 100/200] [Batch 380/938] loss_G: 3.193249, loss_D: 0.176064\n",
      "[Epoch 100/200] [Batch 390/938] loss_G: 3.137994, loss_D: 0.288566\n",
      "[Epoch 100/200] [Batch 400/938] loss_G: 2.767129, loss_D: 0.279414\n",
      "[Epoch 100/200] [Batch 410/938] loss_G: 2.971213, loss_D: 0.213705\n",
      "[Epoch 100/200] [Batch 420/938] loss_G: 2.951877, loss_D: 0.257913\n",
      "[Epoch 100/200] [Batch 430/938] loss_G: 2.920067, loss_D: 0.177789\n",
      "[Epoch 100/200] [Batch 440/938] loss_G: 2.725411, loss_D: 0.293047\n",
      "[Epoch 100/200] [Batch 450/938] loss_G: 3.191393, loss_D: 0.233381\n",
      "[Epoch 100/200] [Batch 460/938] loss_G: 2.868238, loss_D: 0.193030\n",
      "[Epoch 100/200] [Batch 470/938] loss_G: 3.256958, loss_D: 0.158138\n",
      "[Epoch 100/200] [Batch 480/938] loss_G: 2.831080, loss_D: 0.116411\n",
      "[Epoch 100/200] [Batch 490/938] loss_G: 3.149922, loss_D: 0.259138\n",
      "[Epoch 100/200] [Batch 500/938] loss_G: 2.640879, loss_D: 0.283571\n",
      "[Epoch 100/200] [Batch 510/938] loss_G: 3.508173, loss_D: 0.213981\n",
      "[Epoch 100/200] [Batch 520/938] loss_G: 2.624424, loss_D: 0.238678\n",
      "[Epoch 100/200] [Batch 530/938] loss_G: 3.094277, loss_D: 0.208259\n",
      "[Epoch 100/200] [Batch 540/938] loss_G: 2.928836, loss_D: 0.212654\n",
      "[Epoch 100/200] [Batch 550/938] loss_G: 2.897776, loss_D: 0.191451\n",
      "[Epoch 100/200] [Batch 560/938] loss_G: 2.883589, loss_D: 0.174277\n",
      "[Epoch 100/200] [Batch 570/938] loss_G: 3.140311, loss_D: 0.195476\n",
      "[Epoch 100/200] [Batch 580/938] loss_G: 2.837780, loss_D: 0.149634\n",
      "[Epoch 100/200] [Batch 590/938] loss_G: 2.797197, loss_D: 0.185078\n",
      "[Epoch 100/200] [Batch 600/938] loss_G: 2.785947, loss_D: 0.272247\n",
      "[Epoch 100/200] [Batch 610/938] loss_G: 2.815515, loss_D: 0.188070\n",
      "[Epoch 100/200] [Batch 620/938] loss_G: 3.279891, loss_D: 0.193616\n",
      "[Epoch 100/200] [Batch 630/938] loss_G: 2.544815, loss_D: 0.228013\n",
      "[Epoch 100/200] [Batch 640/938] loss_G: 2.567572, loss_D: 0.298942\n",
      "[Epoch 100/200] [Batch 650/938] loss_G: 2.944478, loss_D: 0.116263\n",
      "[Epoch 100/200] [Batch 660/938] loss_G: 3.158134, loss_D: 0.239619\n",
      "[Epoch 100/200] [Batch 670/938] loss_G: 2.911231, loss_D: 0.181442\n",
      "[Epoch 100/200] [Batch 680/938] loss_G: 2.935406, loss_D: 0.306307\n",
      "[Epoch 100/200] [Batch 690/938] loss_G: 3.145655, loss_D: 0.231883\n",
      "[Epoch 100/200] [Batch 700/938] loss_G: 3.155485, loss_D: 0.116968\n",
      "[Epoch 100/200] [Batch 710/938] loss_G: 2.959414, loss_D: 0.201806\n",
      "[Epoch 100/200] [Batch 720/938] loss_G: 3.097525, loss_D: 0.186605\n",
      "[Epoch 100/200] [Batch 730/938] loss_G: 3.084120, loss_D: 0.266369\n",
      "[Epoch 100/200] [Batch 740/938] loss_G: 3.102298, loss_D: 0.177763\n",
      "[Epoch 100/200] [Batch 750/938] loss_G: 2.901160, loss_D: 0.197957\n",
      "[Epoch 100/200] [Batch 760/938] loss_G: 3.192051, loss_D: 0.257278\n",
      "[Epoch 100/200] [Batch 770/938] loss_G: 3.087780, loss_D: 0.168647\n",
      "[Epoch 100/200] [Batch 780/938] loss_G: 3.076108, loss_D: 0.167062\n",
      "[Epoch 100/200] [Batch 790/938] loss_G: 3.107505, loss_D: 0.211802\n",
      "[Epoch 100/200] [Batch 800/938] loss_G: 2.988283, loss_D: 0.236006\n",
      "[Epoch 100/200] [Batch 810/938] loss_G: 2.917624, loss_D: 0.251357\n",
      "[Epoch 100/200] [Batch 820/938] loss_G: 2.468724, loss_D: 0.281281\n",
      "[Epoch 100/200] [Batch 830/938] loss_G: 3.002678, loss_D: 0.235089\n",
      "[Epoch 100/200] [Batch 840/938] loss_G: 2.946644, loss_D: 0.151322\n",
      "[Epoch 100/200] [Batch 850/938] loss_G: 2.819566, loss_D: 0.128165\n",
      "[Epoch 100/200] [Batch 860/938] loss_G: 2.867918, loss_D: 0.202823\n",
      "[Epoch 100/200] [Batch 870/938] loss_G: 3.453235, loss_D: 0.172786\n",
      "[Epoch 100/200] [Batch 880/938] loss_G: 2.881560, loss_D: 0.215579\n",
      "[Epoch 100/200] [Batch 890/938] loss_G: 3.043080, loss_D: 0.185691\n",
      "[Epoch 100/200] [Batch 900/938] loss_G: 3.230773, loss_D: 0.194133\n",
      "[Epoch 100/200] [Batch 910/938] loss_G: 3.269903, loss_D: 0.160498\n",
      "[Epoch 100/200] [Batch 920/938] loss_G: 3.413559, loss_D: 0.211822\n",
      "[Epoch 100/200] [Batch 930/938] loss_G: 2.875168, loss_D: 0.203884\n",
      "[Epoch 101/200] [Batch 0/938] loss_G: 3.237306, loss_D: 0.157936\n",
      "[Epoch 101/200] [Batch 10/938] loss_G: 3.621109, loss_D: 0.161120\n",
      "[Epoch 101/200] [Batch 20/938] loss_G: 3.033772, loss_D: 0.219760\n",
      "[Epoch 101/200] [Batch 30/938] loss_G: 2.841024, loss_D: 0.208044\n",
      "[Epoch 101/200] [Batch 40/938] loss_G: 3.167823, loss_D: 0.221524\n",
      "[Epoch 101/200] [Batch 50/938] loss_G: 2.727870, loss_D: 0.258351\n",
      "[Epoch 101/200] [Batch 60/938] loss_G: 3.327865, loss_D: 0.185375\n",
      "[Epoch 101/200] [Batch 70/938] loss_G: 2.945202, loss_D: 0.204100\n",
      "[Epoch 101/200] [Batch 80/938] loss_G: 3.334709, loss_D: 0.137726\n",
      "[Epoch 101/200] [Batch 90/938] loss_G: 3.253482, loss_D: 0.243000\n",
      "[Epoch 101/200] [Batch 100/938] loss_G: 2.737265, loss_D: 0.186833\n",
      "[Epoch 101/200] [Batch 110/938] loss_G: 3.132243, loss_D: 0.190914\n",
      "[Epoch 101/200] [Batch 120/938] loss_G: 2.854019, loss_D: 0.168606\n",
      "[Epoch 101/200] [Batch 130/938] loss_G: 3.001129, loss_D: 0.198057\n",
      "[Epoch 101/200] [Batch 140/938] loss_G: 3.177602, loss_D: 0.170690\n",
      "[Epoch 101/200] [Batch 150/938] loss_G: 3.065850, loss_D: 0.218449\n",
      "[Epoch 101/200] [Batch 160/938] loss_G: 3.185229, loss_D: 0.157273\n",
      "[Epoch 101/200] [Batch 170/938] loss_G: 2.928240, loss_D: 0.235982\n",
      "[Epoch 101/200] [Batch 180/938] loss_G: 2.910800, loss_D: 0.164551\n",
      "[Epoch 101/200] [Batch 190/938] loss_G: 3.606953, loss_D: 0.183279\n",
      "[Epoch 101/200] [Batch 200/938] loss_G: 2.928318, loss_D: 0.215615\n",
      "[Epoch 101/200] [Batch 210/938] loss_G: 2.933025, loss_D: 0.197820\n",
      "[Epoch 101/200] [Batch 220/938] loss_G: 2.893851, loss_D: 0.199179\n",
      "[Epoch 101/200] [Batch 230/938] loss_G: 2.826417, loss_D: 0.242957\n",
      "[Epoch 101/200] [Batch 240/938] loss_G: 3.043717, loss_D: 0.200304\n",
      "[Epoch 101/200] [Batch 250/938] loss_G: 3.337256, loss_D: 0.213912\n",
      "[Epoch 101/200] [Batch 260/938] loss_G: 3.483945, loss_D: 0.158639\n",
      "[Epoch 101/200] [Batch 270/938] loss_G: 3.219892, loss_D: 0.211708\n",
      "[Epoch 101/200] [Batch 280/938] loss_G: 3.183368, loss_D: 0.247474\n",
      "[Epoch 101/200] [Batch 290/938] loss_G: 3.128466, loss_D: 0.178713\n",
      "[Epoch 101/200] [Batch 300/938] loss_G: 3.091086, loss_D: 0.225294\n",
      "[Epoch 101/200] [Batch 310/938] loss_G: 3.057481, loss_D: 0.138550\n",
      "[Epoch 101/200] [Batch 320/938] loss_G: 2.879190, loss_D: 0.198070\n",
      "[Epoch 101/200] [Batch 330/938] loss_G: 3.172001, loss_D: 0.144914\n",
      "[Epoch 101/200] [Batch 340/938] loss_G: 2.705714, loss_D: 0.234891\n",
      "[Epoch 101/200] [Batch 350/938] loss_G: 2.848748, loss_D: 0.188764\n",
      "[Epoch 101/200] [Batch 360/938] loss_G: 2.964445, loss_D: 0.165384\n",
      "[Epoch 101/200] [Batch 370/938] loss_G: 2.695225, loss_D: 0.220523\n",
      "[Epoch 101/200] [Batch 380/938] loss_G: 3.180742, loss_D: 0.131837\n",
      "[Epoch 101/200] [Batch 390/938] loss_G: 3.100929, loss_D: 0.222639\n",
      "[Epoch 101/200] [Batch 400/938] loss_G: 2.794146, loss_D: 0.201288\n",
      "[Epoch 101/200] [Batch 410/938] loss_G: 3.063991, loss_D: 0.294423\n",
      "[Epoch 101/200] [Batch 420/938] loss_G: 3.075893, loss_D: 0.176093\n",
      "[Epoch 101/200] [Batch 430/938] loss_G: 3.348107, loss_D: 0.147661\n",
      "[Epoch 101/200] [Batch 440/938] loss_G: 2.687934, loss_D: 0.288319\n",
      "[Epoch 101/200] [Batch 450/938] loss_G: 2.910166, loss_D: 0.200946\n",
      "[Epoch 101/200] [Batch 460/938] loss_G: 2.652263, loss_D: 0.231323\n",
      "[Epoch 101/200] [Batch 470/938] loss_G: 2.800881, loss_D: 0.228754\n",
      "[Epoch 101/200] [Batch 480/938] loss_G: 3.230427, loss_D: 0.144732\n",
      "[Epoch 101/200] [Batch 490/938] loss_G: 2.938068, loss_D: 0.217548\n",
      "[Epoch 101/200] [Batch 500/938] loss_G: 3.092082, loss_D: 0.162225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 101/200] [Batch 510/938] loss_G: 2.783853, loss_D: 0.248734\n",
      "[Epoch 101/200] [Batch 520/938] loss_G: 2.985388, loss_D: 0.250751\n",
      "[Epoch 101/200] [Batch 530/938] loss_G: 3.239265, loss_D: 0.103301\n",
      "[Epoch 101/200] [Batch 540/938] loss_G: 3.001784, loss_D: 0.180384\n",
      "[Epoch 101/200] [Batch 550/938] loss_G: 3.039433, loss_D: 0.230771\n",
      "[Epoch 101/200] [Batch 560/938] loss_G: 2.855211, loss_D: 0.242406\n",
      "[Epoch 101/200] [Batch 570/938] loss_G: 3.141496, loss_D: 0.124386\n",
      "[Epoch 101/200] [Batch 580/938] loss_G: 2.804319, loss_D: 0.189492\n",
      "[Epoch 101/200] [Batch 590/938] loss_G: 3.219457, loss_D: 0.155288\n",
      "[Epoch 101/200] [Batch 600/938] loss_G: 3.119745, loss_D: 0.272993\n",
      "[Epoch 101/200] [Batch 610/938] loss_G: 2.990841, loss_D: 0.297110\n",
      "[Epoch 101/200] [Batch 620/938] loss_G: 2.898198, loss_D: 0.177860\n",
      "[Epoch 101/200] [Batch 630/938] loss_G: 3.015803, loss_D: 0.248557\n",
      "[Epoch 101/200] [Batch 640/938] loss_G: 3.177085, loss_D: 0.203637\n",
      "[Epoch 101/200] [Batch 650/938] loss_G: 2.655063, loss_D: 0.232912\n",
      "[Epoch 101/200] [Batch 660/938] loss_G: 2.813683, loss_D: 0.251312\n",
      "[Epoch 101/200] [Batch 670/938] loss_G: 2.739166, loss_D: 0.274240\n",
      "[Epoch 101/200] [Batch 680/938] loss_G: 2.782197, loss_D: 0.167775\n",
      "[Epoch 101/200] [Batch 690/938] loss_G: 2.891059, loss_D: 0.279678\n",
      "[Epoch 101/200] [Batch 700/938] loss_G: 3.152086, loss_D: 0.243347\n",
      "[Epoch 101/200] [Batch 710/938] loss_G: 3.306911, loss_D: 0.219336\n",
      "[Epoch 101/200] [Batch 720/938] loss_G: 3.125814, loss_D: 0.139243\n",
      "[Epoch 101/200] [Batch 730/938] loss_G: 3.344075, loss_D: 0.208216\n",
      "[Epoch 101/200] [Batch 740/938] loss_G: 3.188380, loss_D: 0.236993\n",
      "[Epoch 101/200] [Batch 750/938] loss_G: 3.349329, loss_D: 0.191832\n",
      "[Epoch 101/200] [Batch 760/938] loss_G: 3.239100, loss_D: 0.297594\n",
      "[Epoch 101/200] [Batch 770/938] loss_G: 2.891344, loss_D: 0.203654\n",
      "[Epoch 101/200] [Batch 780/938] loss_G: 2.902663, loss_D: 0.176125\n",
      "[Epoch 101/200] [Batch 790/938] loss_G: 3.202485, loss_D: 0.153311\n",
      "[Epoch 101/200] [Batch 800/938] loss_G: 2.862667, loss_D: 0.175922\n",
      "[Epoch 101/200] [Batch 810/938] loss_G: 3.125275, loss_D: 0.219089\n",
      "[Epoch 101/200] [Batch 820/938] loss_G: 3.062130, loss_D: 0.178922\n",
      "[Epoch 101/200] [Batch 830/938] loss_G: 3.078240, loss_D: 0.185457\n",
      "[Epoch 101/200] [Batch 840/938] loss_G: 2.877909, loss_D: 0.227903\n",
      "[Epoch 101/200] [Batch 850/938] loss_G: 2.949063, loss_D: 0.227141\n",
      "[Epoch 101/200] [Batch 860/938] loss_G: 3.182483, loss_D: 0.202034\n",
      "[Epoch 101/200] [Batch 870/938] loss_G: 3.010139, loss_D: 0.244547\n",
      "[Epoch 101/200] [Batch 880/938] loss_G: 3.585576, loss_D: 0.146482\n",
      "[Epoch 101/200] [Batch 890/938] loss_G: 3.102958, loss_D: 0.217029\n",
      "[Epoch 101/200] [Batch 900/938] loss_G: 3.065704, loss_D: 0.187313\n",
      "[Epoch 101/200] [Batch 910/938] loss_G: 2.997891, loss_D: 0.196522\n",
      "[Epoch 101/200] [Batch 920/938] loss_G: 2.916578, loss_D: 0.169840\n",
      "[Epoch 101/200] [Batch 930/938] loss_G: 2.968701, loss_D: 0.235364\n",
      "[Epoch 102/200] [Batch 0/938] loss_G: 2.888350, loss_D: 0.272944\n",
      "[Epoch 102/200] [Batch 10/938] loss_G: 2.857239, loss_D: 0.145527\n",
      "[Epoch 102/200] [Batch 20/938] loss_G: 3.005037, loss_D: 0.161791\n",
      "[Epoch 102/200] [Batch 30/938] loss_G: 2.951656, loss_D: 0.170702\n",
      "[Epoch 102/200] [Batch 40/938] loss_G: 2.755603, loss_D: 0.229696\n",
      "[Epoch 102/200] [Batch 50/938] loss_G: 3.262302, loss_D: 0.169679\n",
      "[Epoch 102/200] [Batch 60/938] loss_G: 3.027988, loss_D: 0.251544\n",
      "[Epoch 102/200] [Batch 70/938] loss_G: 2.928318, loss_D: 0.235582\n",
      "[Epoch 102/200] [Batch 80/938] loss_G: 3.402712, loss_D: 0.160037\n",
      "[Epoch 102/200] [Batch 90/938] loss_G: 3.068096, loss_D: 0.214897\n",
      "[Epoch 102/200] [Batch 100/938] loss_G: 3.316558, loss_D: 0.131388\n",
      "[Epoch 102/200] [Batch 110/938] loss_G: 2.836128, loss_D: 0.205185\n",
      "[Epoch 102/200] [Batch 120/938] loss_G: 2.988715, loss_D: 0.202521\n",
      "[Epoch 102/200] [Batch 130/938] loss_G: 2.991340, loss_D: 0.285047\n",
      "[Epoch 102/200] [Batch 140/938] loss_G: 3.015915, loss_D: 0.185747\n",
      "[Epoch 102/200] [Batch 150/938] loss_G: 3.206524, loss_D: 0.199035\n",
      "[Epoch 102/200] [Batch 160/938] loss_G: 2.999961, loss_D: 0.207362\n",
      "[Epoch 102/200] [Batch 170/938] loss_G: 3.014229, loss_D: 0.156736\n",
      "[Epoch 102/200] [Batch 180/938] loss_G: 2.942076, loss_D: 0.264210\n",
      "[Epoch 102/200] [Batch 190/938] loss_G: 2.529255, loss_D: 0.300589\n",
      "[Epoch 102/200] [Batch 200/938] loss_G: 3.204318, loss_D: 0.157836\n",
      "[Epoch 102/200] [Batch 210/938] loss_G: 2.868802, loss_D: 0.190443\n",
      "[Epoch 102/200] [Batch 220/938] loss_G: 2.975061, loss_D: 0.264235\n",
      "[Epoch 102/200] [Batch 230/938] loss_G: 3.047100, loss_D: 0.315255\n",
      "[Epoch 102/200] [Batch 240/938] loss_G: 2.889698, loss_D: 0.212404\n",
      "[Epoch 102/200] [Batch 250/938] loss_G: 3.047172, loss_D: 0.245153\n",
      "[Epoch 102/200] [Batch 260/938] loss_G: 3.120425, loss_D: 0.183526\n",
      "[Epoch 102/200] [Batch 270/938] loss_G: 3.123305, loss_D: 0.185187\n",
      "[Epoch 102/200] [Batch 280/938] loss_G: 3.083681, loss_D: 0.138586\n",
      "[Epoch 102/200] [Batch 290/938] loss_G: 2.942198, loss_D: 0.232086\n",
      "[Epoch 102/200] [Batch 300/938] loss_G: 2.970536, loss_D: 0.149622\n",
      "[Epoch 102/200] [Batch 310/938] loss_G: 2.815418, loss_D: 0.167715\n",
      "[Epoch 102/200] [Batch 320/938] loss_G: 3.064133, loss_D: 0.179515\n",
      "[Epoch 102/200] [Batch 330/938] loss_G: 2.947536, loss_D: 0.184143\n",
      "[Epoch 102/200] [Batch 340/938] loss_G: 3.139272, loss_D: 0.170695\n",
      "[Epoch 102/200] [Batch 350/938] loss_G: 3.096506, loss_D: 0.194104\n",
      "[Epoch 102/200] [Batch 360/938] loss_G: 3.051972, loss_D: 0.191038\n",
      "[Epoch 102/200] [Batch 370/938] loss_G: 2.793549, loss_D: 0.232357\n",
      "[Epoch 102/200] [Batch 380/938] loss_G: 3.109882, loss_D: 0.166623\n",
      "[Epoch 102/200] [Batch 390/938] loss_G: 2.984476, loss_D: 0.130224\n",
      "[Epoch 102/200] [Batch 400/938] loss_G: 3.080474, loss_D: 0.192406\n",
      "[Epoch 102/200] [Batch 410/938] loss_G: 3.552777, loss_D: 0.230293\n",
      "[Epoch 102/200] [Batch 420/938] loss_G: 2.830270, loss_D: 0.136151\n",
      "[Epoch 102/200] [Batch 430/938] loss_G: 3.145572, loss_D: 0.158502\n",
      "[Epoch 102/200] [Batch 440/938] loss_G: 3.151522, loss_D: 0.228047\n",
      "[Epoch 102/200] [Batch 450/938] loss_G: 2.732786, loss_D: 0.244550\n",
      "[Epoch 102/200] [Batch 460/938] loss_G: 2.868758, loss_D: 0.220677\n",
      "[Epoch 102/200] [Batch 470/938] loss_G: 3.099792, loss_D: 0.185927\n",
      "[Epoch 102/200] [Batch 480/938] loss_G: 3.237699, loss_D: 0.182776\n",
      "[Epoch 102/200] [Batch 490/938] loss_G: 2.795145, loss_D: 0.205379\n",
      "[Epoch 102/200] [Batch 500/938] loss_G: 3.014944, loss_D: 0.186298\n",
      "[Epoch 102/200] [Batch 510/938] loss_G: 2.695390, loss_D: 0.249748\n",
      "[Epoch 102/200] [Batch 520/938] loss_G: 3.213835, loss_D: 0.235383\n",
      "[Epoch 102/200] [Batch 530/938] loss_G: 3.092216, loss_D: 0.186293\n",
      "[Epoch 102/200] [Batch 540/938] loss_G: 3.100098, loss_D: 0.168640\n",
      "[Epoch 102/200] [Batch 550/938] loss_G: 3.207067, loss_D: 0.193583\n",
      "[Epoch 102/200] [Batch 560/938] loss_G: 3.068491, loss_D: 0.244562\n",
      "[Epoch 102/200] [Batch 570/938] loss_G: 3.458278, loss_D: 0.170937\n",
      "[Epoch 102/200] [Batch 580/938] loss_G: 2.978254, loss_D: 0.280325\n",
      "[Epoch 102/200] [Batch 590/938] loss_G: 3.128095, loss_D: 0.220607\n",
      "[Epoch 102/200] [Batch 600/938] loss_G: 2.934114, loss_D: 0.194385\n",
      "[Epoch 102/200] [Batch 610/938] loss_G: 3.120680, loss_D: 0.187478\n",
      "[Epoch 102/200] [Batch 620/938] loss_G: 3.460418, loss_D: 0.191086\n",
      "[Epoch 102/200] [Batch 630/938] loss_G: 3.195567, loss_D: 0.207523\n",
      "[Epoch 102/200] [Batch 640/938] loss_G: 2.652191, loss_D: 0.148080\n",
      "[Epoch 102/200] [Batch 650/938] loss_G: 2.922930, loss_D: 0.295763\n",
      "[Epoch 102/200] [Batch 660/938] loss_G: 2.801735, loss_D: 0.274714\n",
      "[Epoch 102/200] [Batch 670/938] loss_G: 3.285375, loss_D: 0.202079\n",
      "[Epoch 102/200] [Batch 680/938] loss_G: 2.760651, loss_D: 0.250632\n",
      "[Epoch 102/200] [Batch 690/938] loss_G: 2.905937, loss_D: 0.174381\n",
      "[Epoch 102/200] [Batch 700/938] loss_G: 2.970252, loss_D: 0.181806\n",
      "[Epoch 102/200] [Batch 710/938] loss_G: 3.366336, loss_D: 0.298682\n",
      "[Epoch 102/200] [Batch 720/938] loss_G: 2.819169, loss_D: 0.214743\n",
      "[Epoch 102/200] [Batch 730/938] loss_G: 2.914045, loss_D: 0.230057\n",
      "[Epoch 102/200] [Batch 740/938] loss_G: 3.128599, loss_D: 0.192916\n",
      "[Epoch 102/200] [Batch 750/938] loss_G: 3.170203, loss_D: 0.195001\n",
      "[Epoch 102/200] [Batch 760/938] loss_G: 3.177444, loss_D: 0.260783\n",
      "[Epoch 102/200] [Batch 770/938] loss_G: 3.131047, loss_D: 0.211689\n",
      "[Epoch 102/200] [Batch 780/938] loss_G: 2.961097, loss_D: 0.221071\n",
      "[Epoch 102/200] [Batch 790/938] loss_G: 3.021801, loss_D: 0.199733\n",
      "[Epoch 102/200] [Batch 800/938] loss_G: 2.645350, loss_D: 0.212121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 102/200] [Batch 810/938] loss_G: 2.981621, loss_D: 0.173300\n",
      "[Epoch 102/200] [Batch 820/938] loss_G: 3.390988, loss_D: 0.194387\n",
      "[Epoch 102/200] [Batch 830/938] loss_G: 2.934750, loss_D: 0.132929\n",
      "[Epoch 102/200] [Batch 840/938] loss_G: 3.023348, loss_D: 0.208760\n",
      "[Epoch 102/200] [Batch 850/938] loss_G: 3.114887, loss_D: 0.175404\n",
      "[Epoch 102/200] [Batch 860/938] loss_G: 2.648197, loss_D: 0.243852\n",
      "[Epoch 102/200] [Batch 870/938] loss_G: 3.295939, loss_D: 0.147296\n",
      "[Epoch 102/200] [Batch 880/938] loss_G: 2.812083, loss_D: 0.138479\n",
      "[Epoch 102/200] [Batch 890/938] loss_G: 2.645372, loss_D: 0.216777\n",
      "[Epoch 102/200] [Batch 900/938] loss_G: 2.866934, loss_D: 0.258279\n",
      "[Epoch 102/200] [Batch 910/938] loss_G: 3.195733, loss_D: 0.134445\n",
      "[Epoch 102/200] [Batch 920/938] loss_G: 3.272328, loss_D: 0.157093\n",
      "[Epoch 102/200] [Batch 930/938] loss_G: 2.839067, loss_D: 0.263499\n",
      "[Epoch 103/200] [Batch 0/938] loss_G: 3.038630, loss_D: 0.165977\n",
      "[Epoch 103/200] [Batch 10/938] loss_G: 3.184850, loss_D: 0.197693\n",
      "[Epoch 103/200] [Batch 20/938] loss_G: 3.359535, loss_D: 0.186708\n",
      "[Epoch 103/200] [Batch 30/938] loss_G: 2.946095, loss_D: 0.214589\n",
      "[Epoch 103/200] [Batch 40/938] loss_G: 2.948524, loss_D: 0.143569\n",
      "[Epoch 103/200] [Batch 50/938] loss_G: 2.808202, loss_D: 0.177928\n",
      "[Epoch 103/200] [Batch 60/938] loss_G: 2.998604, loss_D: 0.237573\n",
      "[Epoch 103/200] [Batch 70/938] loss_G: 2.879129, loss_D: 0.218498\n",
      "[Epoch 103/200] [Batch 80/938] loss_G: 2.685115, loss_D: 0.306641\n",
      "[Epoch 103/200] [Batch 90/938] loss_G: 3.104653, loss_D: 0.123933\n",
      "[Epoch 103/200] [Batch 100/938] loss_G: 2.655493, loss_D: 0.276863\n",
      "[Epoch 103/200] [Batch 110/938] loss_G: 2.957013, loss_D: 0.238948\n",
      "[Epoch 103/200] [Batch 120/938] loss_G: 3.090495, loss_D: 0.140347\n",
      "[Epoch 103/200] [Batch 130/938] loss_G: 3.022949, loss_D: 0.164604\n",
      "[Epoch 103/200] [Batch 140/938] loss_G: 2.692019, loss_D: 0.242030\n",
      "[Epoch 103/200] [Batch 150/938] loss_G: 2.977396, loss_D: 0.189930\n",
      "[Epoch 103/200] [Batch 160/938] loss_G: 2.965884, loss_D: 0.160734\n",
      "[Epoch 103/200] [Batch 170/938] loss_G: 3.013375, loss_D: 0.201323\n",
      "[Epoch 103/200] [Batch 180/938] loss_G: 2.859034, loss_D: 0.232974\n",
      "[Epoch 103/200] [Batch 190/938] loss_G: 2.972616, loss_D: 0.179892\n",
      "[Epoch 103/200] [Batch 200/938] loss_G: 2.660321, loss_D: 0.216662\n",
      "[Epoch 103/200] [Batch 210/938] loss_G: 2.761216, loss_D: 0.270131\n",
      "[Epoch 103/200] [Batch 220/938] loss_G: 2.893645, loss_D: 0.299471\n",
      "[Epoch 103/200] [Batch 230/938] loss_G: 3.261923, loss_D: 0.281374\n",
      "[Epoch 103/200] [Batch 240/938] loss_G: 3.034866, loss_D: 0.174593\n",
      "[Epoch 103/200] [Batch 250/938] loss_G: 2.674600, loss_D: 0.310112\n",
      "[Epoch 103/200] [Batch 260/938] loss_G: 2.900193, loss_D: 0.119090\n",
      "[Epoch 103/200] [Batch 270/938] loss_G: 3.010048, loss_D: 0.171549\n",
      "[Epoch 103/200] [Batch 280/938] loss_G: 3.197317, loss_D: 0.267036\n",
      "[Epoch 103/200] [Batch 290/938] loss_G: 2.729146, loss_D: 0.295894\n",
      "[Epoch 103/200] [Batch 300/938] loss_G: 3.239541, loss_D: 0.175849\n",
      "[Epoch 103/200] [Batch 310/938] loss_G: 3.055607, loss_D: 0.151836\n",
      "[Epoch 103/200] [Batch 320/938] loss_G: 2.686645, loss_D: 0.193014\n",
      "[Epoch 103/200] [Batch 330/938] loss_G: 3.125301, loss_D: 0.197954\n",
      "[Epoch 103/200] [Batch 340/938] loss_G: 3.241372, loss_D: 0.155614\n",
      "[Epoch 103/200] [Batch 350/938] loss_G: 3.099905, loss_D: 0.233183\n",
      "[Epoch 103/200] [Batch 360/938] loss_G: 3.098769, loss_D: 0.203549\n",
      "[Epoch 103/200] [Batch 370/938] loss_G: 2.820364, loss_D: 0.200305\n",
      "[Epoch 103/200] [Batch 380/938] loss_G: 2.925519, loss_D: 0.175666\n",
      "[Epoch 103/200] [Batch 390/938] loss_G: 2.812753, loss_D: 0.231051\n",
      "[Epoch 103/200] [Batch 400/938] loss_G: 3.442458, loss_D: 0.197280\n",
      "[Epoch 103/200] [Batch 410/938] loss_G: 3.072063, loss_D: 0.240944\n",
      "[Epoch 103/200] [Batch 420/938] loss_G: 3.229694, loss_D: 0.150160\n",
      "[Epoch 103/200] [Batch 430/938] loss_G: 3.182600, loss_D: 0.222495\n",
      "[Epoch 103/200] [Batch 440/938] loss_G: 2.809392, loss_D: 0.282121\n",
      "[Epoch 103/200] [Batch 450/938] loss_G: 3.099337, loss_D: 0.221077\n",
      "[Epoch 103/200] [Batch 460/938] loss_G: 3.086083, loss_D: 0.299506\n",
      "[Epoch 103/200] [Batch 470/938] loss_G: 3.286628, loss_D: 0.152828\n",
      "[Epoch 103/200] [Batch 480/938] loss_G: 3.253139, loss_D: 0.179061\n",
      "[Epoch 103/200] [Batch 490/938] loss_G: 3.310333, loss_D: 0.218465\n",
      "[Epoch 103/200] [Batch 500/938] loss_G: 3.271365, loss_D: 0.215666\n",
      "[Epoch 103/200] [Batch 510/938] loss_G: 3.066950, loss_D: 0.175166\n",
      "[Epoch 103/200] [Batch 520/938] loss_G: 3.097188, loss_D: 0.186754\n",
      "[Epoch 103/200] [Batch 530/938] loss_G: 3.464548, loss_D: 0.195563\n",
      "[Epoch 103/200] [Batch 540/938] loss_G: 3.003309, loss_D: 0.146330\n",
      "[Epoch 103/200] [Batch 550/938] loss_G: 3.261784, loss_D: 0.212802\n",
      "[Epoch 103/200] [Batch 560/938] loss_G: 2.841722, loss_D: 0.223273\n",
      "[Epoch 103/200] [Batch 570/938] loss_G: 3.064101, loss_D: 0.193484\n",
      "[Epoch 103/200] [Batch 580/938] loss_G: 3.318523, loss_D: 0.248296\n",
      "[Epoch 103/200] [Batch 590/938] loss_G: 2.922613, loss_D: 0.175414\n",
      "[Epoch 103/200] [Batch 600/938] loss_G: 3.158701, loss_D: 0.167916\n",
      "[Epoch 103/200] [Batch 610/938] loss_G: 3.213019, loss_D: 0.183767\n",
      "[Epoch 103/200] [Batch 620/938] loss_G: 3.463345, loss_D: 0.282755\n",
      "[Epoch 103/200] [Batch 630/938] loss_G: 3.375260, loss_D: 0.179549\n",
      "[Epoch 103/200] [Batch 640/938] loss_G: 2.916611, loss_D: 0.161264\n",
      "[Epoch 103/200] [Batch 650/938] loss_G: 2.930841, loss_D: 0.187867\n",
      "[Epoch 103/200] [Batch 660/938] loss_G: 3.316221, loss_D: 0.166113\n",
      "[Epoch 103/200] [Batch 670/938] loss_G: 3.198061, loss_D: 0.204742\n",
      "[Epoch 103/200] [Batch 680/938] loss_G: 2.969832, loss_D: 0.273126\n",
      "[Epoch 103/200] [Batch 690/938] loss_G: 3.149631, loss_D: 0.176485\n",
      "[Epoch 103/200] [Batch 700/938] loss_G: 2.385335, loss_D: 0.273263\n",
      "[Epoch 103/200] [Batch 710/938] loss_G: 3.239964, loss_D: 0.260558\n",
      "[Epoch 103/200] [Batch 720/938] loss_G: 3.105781, loss_D: 0.288198\n",
      "[Epoch 103/200] [Batch 730/938] loss_G: 2.977415, loss_D: 0.204500\n",
      "[Epoch 103/200] [Batch 740/938] loss_G: 2.665784, loss_D: 0.264304\n",
      "[Epoch 103/200] [Batch 750/938] loss_G: 3.032666, loss_D: 0.223688\n",
      "[Epoch 103/200] [Batch 760/938] loss_G: 2.886687, loss_D: 0.285784\n",
      "[Epoch 103/200] [Batch 770/938] loss_G: 3.161293, loss_D: 0.240542\n",
      "[Epoch 103/200] [Batch 780/938] loss_G: 3.055537, loss_D: 0.206396\n",
      "[Epoch 103/200] [Batch 790/938] loss_G: 3.005034, loss_D: 0.189750\n",
      "[Epoch 103/200] [Batch 800/938] loss_G: 3.226994, loss_D: 0.229198\n",
      "[Epoch 103/200] [Batch 810/938] loss_G: 2.856270, loss_D: 0.229059\n",
      "[Epoch 103/200] [Batch 820/938] loss_G: 2.856658, loss_D: 0.284560\n",
      "[Epoch 103/200] [Batch 830/938] loss_G: 2.739365, loss_D: 0.174826\n",
      "[Epoch 103/200] [Batch 840/938] loss_G: 3.038251, loss_D: 0.132377\n",
      "[Epoch 103/200] [Batch 850/938] loss_G: 2.947330, loss_D: 0.256637\n",
      "[Epoch 103/200] [Batch 860/938] loss_G: 3.084883, loss_D: 0.257471\n",
      "[Epoch 103/200] [Batch 870/938] loss_G: 3.175243, loss_D: 0.288553\n",
      "[Epoch 103/200] [Batch 880/938] loss_G: 3.222148, loss_D: 0.214916\n",
      "[Epoch 103/200] [Batch 890/938] loss_G: 2.901464, loss_D: 0.176998\n",
      "[Epoch 103/200] [Batch 900/938] loss_G: 3.104850, loss_D: 0.180907\n",
      "[Epoch 103/200] [Batch 910/938] loss_G: 3.000597, loss_D: 0.280323\n",
      "[Epoch 103/200] [Batch 920/938] loss_G: 2.667947, loss_D: 0.221652\n",
      "[Epoch 103/200] [Batch 930/938] loss_G: 3.059183, loss_D: 0.179855\n",
      "[Epoch 104/200] [Batch 0/938] loss_G: 2.927766, loss_D: 0.201950\n",
      "[Epoch 104/200] [Batch 10/938] loss_G: 2.984457, loss_D: 0.223465\n",
      "[Epoch 104/200] [Batch 20/938] loss_G: 2.849984, loss_D: 0.230062\n",
      "[Epoch 104/200] [Batch 30/938] loss_G: 2.925574, loss_D: 0.148327\n",
      "[Epoch 104/200] [Batch 40/938] loss_G: 3.144608, loss_D: 0.195282\n",
      "[Epoch 104/200] [Batch 50/938] loss_G: 3.240140, loss_D: 0.239803\n",
      "[Epoch 104/200] [Batch 60/938] loss_G: 2.766028, loss_D: 0.198043\n",
      "[Epoch 104/200] [Batch 70/938] loss_G: 3.222211, loss_D: 0.219462\n",
      "[Epoch 104/200] [Batch 80/938] loss_G: 3.122968, loss_D: 0.214341\n",
      "[Epoch 104/200] [Batch 90/938] loss_G: 3.077113, loss_D: 0.182140\n",
      "[Epoch 104/200] [Batch 100/938] loss_G: 2.910231, loss_D: 0.193127\n",
      "[Epoch 104/200] [Batch 110/938] loss_G: 2.991427, loss_D: 0.218083\n",
      "[Epoch 104/200] [Batch 120/938] loss_G: 3.319273, loss_D: 0.323134\n",
      "[Epoch 104/200] [Batch 130/938] loss_G: 2.886371, loss_D: 0.214314\n",
      "[Epoch 104/200] [Batch 140/938] loss_G: 2.816078, loss_D: 0.265902\n",
      "[Epoch 104/200] [Batch 150/938] loss_G: 3.087665, loss_D: 0.185697\n",
      "[Epoch 104/200] [Batch 160/938] loss_G: 2.936488, loss_D: 0.210495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 104/200] [Batch 170/938] loss_G: 2.988770, loss_D: 0.123647\n",
      "[Epoch 104/200] [Batch 180/938] loss_G: 3.119409, loss_D: 0.255549\n",
      "[Epoch 104/200] [Batch 190/938] loss_G: 3.071031, loss_D: 0.156487\n",
      "[Epoch 104/200] [Batch 200/938] loss_G: 2.991598, loss_D: 0.177268\n",
      "[Epoch 104/200] [Batch 210/938] loss_G: 2.935938, loss_D: 0.201311\n",
      "[Epoch 104/200] [Batch 220/938] loss_G: 2.866624, loss_D: 0.235805\n",
      "[Epoch 104/200] [Batch 230/938] loss_G: 3.037322, loss_D: 0.170004\n",
      "[Epoch 104/200] [Batch 240/938] loss_G: 2.847626, loss_D: 0.251175\n",
      "[Epoch 104/200] [Batch 250/938] loss_G: 3.326931, loss_D: 0.220541\n",
      "[Epoch 104/200] [Batch 260/938] loss_G: 2.859092, loss_D: 0.200840\n",
      "[Epoch 104/200] [Batch 270/938] loss_G: 3.027131, loss_D: 0.224747\n",
      "[Epoch 104/200] [Batch 280/938] loss_G: 3.104267, loss_D: 0.132091\n",
      "[Epoch 104/200] [Batch 290/938] loss_G: 2.950730, loss_D: 0.252328\n",
      "[Epoch 104/200] [Batch 300/938] loss_G: 3.224794, loss_D: 0.160354\n",
      "[Epoch 104/200] [Batch 310/938] loss_G: 3.360292, loss_D: 0.225122\n",
      "[Epoch 104/200] [Batch 320/938] loss_G: 3.261739, loss_D: 0.154470\n",
      "[Epoch 104/200] [Batch 330/938] loss_G: 3.222820, loss_D: 0.120044\n",
      "[Epoch 104/200] [Batch 340/938] loss_G: 2.862718, loss_D: 0.221355\n",
      "[Epoch 104/200] [Batch 350/938] loss_G: 3.072329, loss_D: 0.151017\n",
      "[Epoch 104/200] [Batch 360/938] loss_G: 2.740950, loss_D: 0.257522\n",
      "[Epoch 104/200] [Batch 370/938] loss_G: 3.344216, loss_D: 0.211634\n",
      "[Epoch 104/200] [Batch 380/938] loss_G: 3.049562, loss_D: 0.168036\n",
      "[Epoch 104/200] [Batch 390/938] loss_G: 2.861962, loss_D: 0.205710\n",
      "[Epoch 104/200] [Batch 400/938] loss_G: 2.931537, loss_D: 0.134765\n",
      "[Epoch 104/200] [Batch 410/938] loss_G: 3.265160, loss_D: 0.178498\n",
      "[Epoch 104/200] [Batch 420/938] loss_G: 2.851029, loss_D: 0.180699\n",
      "[Epoch 104/200] [Batch 430/938] loss_G: 3.564292, loss_D: 0.238794\n",
      "[Epoch 104/200] [Batch 440/938] loss_G: 2.820668, loss_D: 0.337470\n",
      "[Epoch 104/200] [Batch 450/938] loss_G: 3.442571, loss_D: 0.182510\n",
      "[Epoch 104/200] [Batch 460/938] loss_G: 2.979932, loss_D: 0.191399\n",
      "[Epoch 104/200] [Batch 470/938] loss_G: 2.885024, loss_D: 0.223542\n",
      "[Epoch 104/200] [Batch 480/938] loss_G: 2.867594, loss_D: 0.195891\n",
      "[Epoch 104/200] [Batch 490/938] loss_G: 3.264849, loss_D: 0.165354\n",
      "[Epoch 104/200] [Batch 500/938] loss_G: 2.919251, loss_D: 0.272500\n",
      "[Epoch 104/200] [Batch 510/938] loss_G: 3.076606, loss_D: 0.245603\n",
      "[Epoch 104/200] [Batch 520/938] loss_G: 2.727089, loss_D: 0.206963\n",
      "[Epoch 104/200] [Batch 530/938] loss_G: 2.907644, loss_D: 0.189165\n",
      "[Epoch 104/200] [Batch 540/938] loss_G: 2.921731, loss_D: 0.272742\n",
      "[Epoch 104/200] [Batch 550/938] loss_G: 2.914367, loss_D: 0.273582\n",
      "[Epoch 104/200] [Batch 560/938] loss_G: 3.301343, loss_D: 0.139920\n",
      "[Epoch 104/200] [Batch 570/938] loss_G: 2.934925, loss_D: 0.196003\n",
      "[Epoch 104/200] [Batch 580/938] loss_G: 3.239348, loss_D: 0.159616\n",
      "[Epoch 104/200] [Batch 590/938] loss_G: 2.735294, loss_D: 0.182557\n",
      "[Epoch 104/200] [Batch 600/938] loss_G: 3.456783, loss_D: 0.159625\n",
      "[Epoch 104/200] [Batch 610/938] loss_G: 3.460092, loss_D: 0.217916\n",
      "[Epoch 104/200] [Batch 620/938] loss_G: 3.411303, loss_D: 0.179060\n",
      "[Epoch 104/200] [Batch 630/938] loss_G: 2.909443, loss_D: 0.206792\n",
      "[Epoch 104/200] [Batch 640/938] loss_G: 3.042997, loss_D: 0.214571\n",
      "[Epoch 104/200] [Batch 650/938] loss_G: 3.249772, loss_D: 0.175983\n",
      "[Epoch 104/200] [Batch 660/938] loss_G: 3.125653, loss_D: 0.186521\n",
      "[Epoch 104/200] [Batch 670/938] loss_G: 3.443804, loss_D: 0.167068\n",
      "[Epoch 104/200] [Batch 680/938] loss_G: 3.553416, loss_D: 0.158809\n",
      "[Epoch 104/200] [Batch 690/938] loss_G: 3.073900, loss_D: 0.295239\n",
      "[Epoch 104/200] [Batch 700/938] loss_G: 2.933903, loss_D: 0.231271\n",
      "[Epoch 104/200] [Batch 710/938] loss_G: 2.946779, loss_D: 0.243573\n",
      "[Epoch 104/200] [Batch 720/938] loss_G: 2.956537, loss_D: 0.229393\n",
      "[Epoch 104/200] [Batch 730/938] loss_G: 3.032234, loss_D: 0.218960\n",
      "[Epoch 104/200] [Batch 740/938] loss_G: 3.057405, loss_D: 0.194291\n",
      "[Epoch 104/200] [Batch 750/938] loss_G: 2.990057, loss_D: 0.202106\n",
      "[Epoch 104/200] [Batch 760/938] loss_G: 3.077970, loss_D: 0.212216\n",
      "[Epoch 104/200] [Batch 770/938] loss_G: 3.190409, loss_D: 0.206224\n",
      "[Epoch 104/200] [Batch 780/938] loss_G: 2.594535, loss_D: 0.259369\n",
      "[Epoch 104/200] [Batch 790/938] loss_G: 2.611055, loss_D: 0.213958\n",
      "[Epoch 104/200] [Batch 800/938] loss_G: 3.164679, loss_D: 0.268691\n",
      "[Epoch 104/200] [Batch 810/938] loss_G: 3.243234, loss_D: 0.196439\n",
      "[Epoch 104/200] [Batch 820/938] loss_G: 3.181088, loss_D: 0.224152\n",
      "[Epoch 104/200] [Batch 830/938] loss_G: 2.574894, loss_D: 0.272307\n",
      "[Epoch 104/200] [Batch 840/938] loss_G: 3.151410, loss_D: 0.166705\n",
      "[Epoch 104/200] [Batch 850/938] loss_G: 2.849293, loss_D: 0.291926\n",
      "[Epoch 104/200] [Batch 860/938] loss_G: 2.906169, loss_D: 0.192928\n",
      "[Epoch 104/200] [Batch 870/938] loss_G: 3.475232, loss_D: 0.213032\n",
      "[Epoch 104/200] [Batch 880/938] loss_G: 3.324083, loss_D: 0.190860\n",
      "[Epoch 104/200] [Batch 890/938] loss_G: 2.698977, loss_D: 0.268225\n",
      "[Epoch 104/200] [Batch 900/938] loss_G: 3.263714, loss_D: 0.246152\n",
      "[Epoch 104/200] [Batch 910/938] loss_G: 2.840050, loss_D: 0.118165\n",
      "[Epoch 104/200] [Batch 920/938] loss_G: 2.568789, loss_D: 0.221424\n",
      "[Epoch 104/200] [Batch 930/938] loss_G: 3.378691, loss_D: 0.153690\n",
      "[Epoch 105/200] [Batch 0/938] loss_G: 3.102071, loss_D: 0.185100\n",
      "[Epoch 105/200] [Batch 10/938] loss_G: 2.943125, loss_D: 0.230236\n",
      "[Epoch 105/200] [Batch 20/938] loss_G: 2.982472, loss_D: 0.193652\n",
      "[Epoch 105/200] [Batch 30/938] loss_G: 2.929760, loss_D: 0.144432\n",
      "[Epoch 105/200] [Batch 40/938] loss_G: 2.693417, loss_D: 0.188418\n",
      "[Epoch 105/200] [Batch 50/938] loss_G: 2.878515, loss_D: 0.239586\n",
      "[Epoch 105/200] [Batch 60/938] loss_G: 3.073290, loss_D: 0.230426\n",
      "[Epoch 105/200] [Batch 70/938] loss_G: 3.046382, loss_D: 0.167319\n",
      "[Epoch 105/200] [Batch 80/938] loss_G: 2.786524, loss_D: 0.304867\n",
      "[Epoch 105/200] [Batch 90/938] loss_G: 2.906831, loss_D: 0.269691\n",
      "[Epoch 105/200] [Batch 100/938] loss_G: 2.660663, loss_D: 0.285331\n",
      "[Epoch 105/200] [Batch 110/938] loss_G: 3.170918, loss_D: 0.217728\n",
      "[Epoch 105/200] [Batch 120/938] loss_G: 2.858443, loss_D: 0.166150\n",
      "[Epoch 105/200] [Batch 130/938] loss_G: 3.128601, loss_D: 0.162862\n",
      "[Epoch 105/200] [Batch 140/938] loss_G: 2.997713, loss_D: 0.170702\n",
      "[Epoch 105/200] [Batch 150/938] loss_G: 3.035831, loss_D: 0.242394\n",
      "[Epoch 105/200] [Batch 160/938] loss_G: 3.141164, loss_D: 0.176188\n",
      "[Epoch 105/200] [Batch 170/938] loss_G: 3.082492, loss_D: 0.243916\n",
      "[Epoch 105/200] [Batch 180/938] loss_G: 3.111995, loss_D: 0.209771\n",
      "[Epoch 105/200] [Batch 190/938] loss_G: 3.020746, loss_D: 0.235007\n",
      "[Epoch 105/200] [Batch 200/938] loss_G: 3.358323, loss_D: 0.287054\n",
      "[Epoch 105/200] [Batch 210/938] loss_G: 3.090879, loss_D: 0.179255\n",
      "[Epoch 105/200] [Batch 220/938] loss_G: 2.871322, loss_D: 0.152374\n",
      "[Epoch 105/200] [Batch 230/938] loss_G: 3.135700, loss_D: 0.223077\n",
      "[Epoch 105/200] [Batch 240/938] loss_G: 2.752241, loss_D: 0.162322\n",
      "[Epoch 105/200] [Batch 250/938] loss_G: 3.195248, loss_D: 0.107851\n",
      "[Epoch 105/200] [Batch 260/938] loss_G: 3.365909, loss_D: 0.216678\n",
      "[Epoch 105/200] [Batch 270/938] loss_G: 2.975660, loss_D: 0.162814\n",
      "[Epoch 105/200] [Batch 280/938] loss_G: 3.054081, loss_D: 0.136422\n",
      "[Epoch 105/200] [Batch 290/938] loss_G: 2.862081, loss_D: 0.173869\n",
      "[Epoch 105/200] [Batch 300/938] loss_G: 3.123633, loss_D: 0.142762\n",
      "[Epoch 105/200] [Batch 310/938] loss_G: 3.098033, loss_D: 0.184559\n",
      "[Epoch 105/200] [Batch 320/938] loss_G: 3.365818, loss_D: 0.169425\n",
      "[Epoch 105/200] [Batch 330/938] loss_G: 2.644506, loss_D: 0.167342\n",
      "[Epoch 105/200] [Batch 340/938] loss_G: 2.521283, loss_D: 0.277192\n",
      "[Epoch 105/200] [Batch 350/938] loss_G: 3.250741, loss_D: 0.298001\n",
      "[Epoch 105/200] [Batch 360/938] loss_G: 3.312025, loss_D: 0.126319\n",
      "[Epoch 105/200] [Batch 370/938] loss_G: 2.650189, loss_D: 0.226248\n",
      "[Epoch 105/200] [Batch 380/938] loss_G: 3.255125, loss_D: 0.214280\n",
      "[Epoch 105/200] [Batch 390/938] loss_G: 3.173532, loss_D: 0.190643\n",
      "[Epoch 105/200] [Batch 400/938] loss_G: 2.989741, loss_D: 0.195385\n",
      "[Epoch 105/200] [Batch 410/938] loss_G: 3.138156, loss_D: 0.160825\n",
      "[Epoch 105/200] [Batch 420/938] loss_G: 3.743763, loss_D: 0.146973\n",
      "[Epoch 105/200] [Batch 430/938] loss_G: 2.770505, loss_D: 0.261468\n",
      "[Epoch 105/200] [Batch 440/938] loss_G: 3.014189, loss_D: 0.179098\n",
      "[Epoch 105/200] [Batch 450/938] loss_G: 2.996543, loss_D: 0.151690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 105/200] [Batch 460/938] loss_G: 3.093560, loss_D: 0.268297\n",
      "[Epoch 105/200] [Batch 470/938] loss_G: 3.010680, loss_D: 0.221413\n",
      "[Epoch 105/200] [Batch 480/938] loss_G: 3.379810, loss_D: 0.176116\n",
      "[Epoch 105/200] [Batch 490/938] loss_G: 2.975366, loss_D: 0.136161\n",
      "[Epoch 105/200] [Batch 500/938] loss_G: 2.972338, loss_D: 0.204230\n",
      "[Epoch 105/200] [Batch 510/938] loss_G: 3.199574, loss_D: 0.175325\n",
      "[Epoch 105/200] [Batch 520/938] loss_G: 3.133915, loss_D: 0.179152\n",
      "[Epoch 105/200] [Batch 530/938] loss_G: 3.147285, loss_D: 0.197914\n",
      "[Epoch 105/200] [Batch 540/938] loss_G: 3.618590, loss_D: 0.189125\n",
      "[Epoch 105/200] [Batch 550/938] loss_G: 3.262569, loss_D: 0.221095\n",
      "[Epoch 105/200] [Batch 560/938] loss_G: 3.243710, loss_D: 0.180198\n",
      "[Epoch 105/200] [Batch 570/938] loss_G: 2.901261, loss_D: 0.165561\n",
      "[Epoch 105/200] [Batch 580/938] loss_G: 3.098976, loss_D: 0.285482\n",
      "[Epoch 105/200] [Batch 590/938] loss_G: 2.642598, loss_D: 0.327943\n",
      "[Epoch 105/200] [Batch 600/938] loss_G: 2.948124, loss_D: 0.245139\n",
      "[Epoch 105/200] [Batch 610/938] loss_G: 3.347928, loss_D: 0.198333\n",
      "[Epoch 105/200] [Batch 620/938] loss_G: 3.427772, loss_D: 0.208553\n",
      "[Epoch 105/200] [Batch 630/938] loss_G: 3.086372, loss_D: 0.191970\n",
      "[Epoch 105/200] [Batch 640/938] loss_G: 2.867331, loss_D: 0.197883\n",
      "[Epoch 105/200] [Batch 650/938] loss_G: 2.916586, loss_D: 0.204549\n",
      "[Epoch 105/200] [Batch 660/938] loss_G: 3.401396, loss_D: 0.221447\n",
      "[Epoch 105/200] [Batch 670/938] loss_G: 2.957553, loss_D: 0.189017\n",
      "[Epoch 105/200] [Batch 680/938] loss_G: 3.030833, loss_D: 0.207632\n",
      "[Epoch 105/200] [Batch 690/938] loss_G: 2.880034, loss_D: 0.231814\n",
      "[Epoch 105/200] [Batch 700/938] loss_G: 2.982365, loss_D: 0.123544\n",
      "[Epoch 105/200] [Batch 710/938] loss_G: 2.974108, loss_D: 0.287751\n",
      "[Epoch 105/200] [Batch 720/938] loss_G: 3.341340, loss_D: 0.227141\n",
      "[Epoch 105/200] [Batch 730/938] loss_G: 2.678102, loss_D: 0.236759\n",
      "[Epoch 105/200] [Batch 740/938] loss_G: 2.783277, loss_D: 0.166269\n",
      "[Epoch 105/200] [Batch 750/938] loss_G: 2.768335, loss_D: 0.246628\n",
      "[Epoch 105/200] [Batch 760/938] loss_G: 3.140122, loss_D: 0.197335\n",
      "[Epoch 105/200] [Batch 770/938] loss_G: 2.791463, loss_D: 0.168610\n",
      "[Epoch 105/200] [Batch 780/938] loss_G: 2.876285, loss_D: 0.186058\n",
      "[Epoch 105/200] [Batch 790/938] loss_G: 3.213019, loss_D: 0.241098\n",
      "[Epoch 105/200] [Batch 800/938] loss_G: 2.997408, loss_D: 0.303508\n",
      "[Epoch 105/200] [Batch 810/938] loss_G: 3.370045, loss_D: 0.154978\n",
      "[Epoch 105/200] [Batch 820/938] loss_G: 2.850075, loss_D: 0.284838\n",
      "[Epoch 105/200] [Batch 830/938] loss_G: 2.731364, loss_D: 0.214529\n",
      "[Epoch 105/200] [Batch 840/938] loss_G: 3.249564, loss_D: 0.159523\n",
      "[Epoch 105/200] [Batch 850/938] loss_G: 3.275968, loss_D: 0.212381\n",
      "[Epoch 105/200] [Batch 860/938] loss_G: 3.089066, loss_D: 0.178693\n",
      "[Epoch 105/200] [Batch 870/938] loss_G: 3.125619, loss_D: 0.333347\n",
      "[Epoch 105/200] [Batch 880/938] loss_G: 3.050787, loss_D: 0.161341\n",
      "[Epoch 105/200] [Batch 890/938] loss_G: 2.932782, loss_D: 0.155310\n",
      "[Epoch 105/200] [Batch 900/938] loss_G: 2.555606, loss_D: 0.226560\n",
      "[Epoch 105/200] [Batch 910/938] loss_G: 3.213690, loss_D: 0.153409\n",
      "[Epoch 105/200] [Batch 920/938] loss_G: 2.978398, loss_D: 0.195918\n",
      "[Epoch 105/200] [Batch 930/938] loss_G: 3.154002, loss_D: 0.198297\n",
      "[Epoch 106/200] [Batch 0/938] loss_G: 3.247340, loss_D: 0.164991\n",
      "[Epoch 106/200] [Batch 10/938] loss_G: 2.929614, loss_D: 0.300586\n",
      "[Epoch 106/200] [Batch 20/938] loss_G: 3.235518, loss_D: 0.138758\n",
      "[Epoch 106/200] [Batch 30/938] loss_G: 2.902845, loss_D: 0.173955\n",
      "[Epoch 106/200] [Batch 40/938] loss_G: 3.214581, loss_D: 0.241153\n",
      "[Epoch 106/200] [Batch 50/938] loss_G: 3.176785, loss_D: 0.125734\n",
      "[Epoch 106/200] [Batch 60/938] loss_G: 3.236329, loss_D: 0.184018\n",
      "[Epoch 106/200] [Batch 70/938] loss_G: 3.250186, loss_D: 0.171629\n",
      "[Epoch 106/200] [Batch 80/938] loss_G: 2.566869, loss_D: 0.297512\n",
      "[Epoch 106/200] [Batch 90/938] loss_G: 2.969901, loss_D: 0.281371\n",
      "[Epoch 106/200] [Batch 100/938] loss_G: 3.031986, loss_D: 0.141827\n",
      "[Epoch 106/200] [Batch 110/938] loss_G: 3.150326, loss_D: 0.226888\n",
      "[Epoch 106/200] [Batch 120/938] loss_G: 3.319801, loss_D: 0.131574\n",
      "[Epoch 106/200] [Batch 130/938] loss_G: 2.870941, loss_D: 0.176996\n",
      "[Epoch 106/200] [Batch 140/938] loss_G: 2.899414, loss_D: 0.201638\n",
      "[Epoch 106/200] [Batch 150/938] loss_G: 3.214185, loss_D: 0.207808\n",
      "[Epoch 106/200] [Batch 160/938] loss_G: 2.970144, loss_D: 0.152756\n",
      "[Epoch 106/200] [Batch 170/938] loss_G: 3.141740, loss_D: 0.161018\n",
      "[Epoch 106/200] [Batch 180/938] loss_G: 2.798846, loss_D: 0.199021\n",
      "[Epoch 106/200] [Batch 190/938] loss_G: 3.461609, loss_D: 0.183533\n",
      "[Epoch 106/200] [Batch 200/938] loss_G: 3.103338, loss_D: 0.121439\n",
      "[Epoch 106/200] [Batch 210/938] loss_G: 2.824329, loss_D: 0.199929\n",
      "[Epoch 106/200] [Batch 220/938] loss_G: 2.968512, loss_D: 0.247279\n",
      "[Epoch 106/200] [Batch 230/938] loss_G: 2.827247, loss_D: 0.175402\n",
      "[Epoch 106/200] [Batch 240/938] loss_G: 3.019729, loss_D: 0.127985\n",
      "[Epoch 106/200] [Batch 250/938] loss_G: 3.412947, loss_D: 0.222041\n",
      "[Epoch 106/200] [Batch 260/938] loss_G: 2.837248, loss_D: 0.253411\n",
      "[Epoch 106/200] [Batch 270/938] loss_G: 2.804461, loss_D: 0.218998\n",
      "[Epoch 106/200] [Batch 280/938] loss_G: 3.087947, loss_D: 0.228410\n",
      "[Epoch 106/200] [Batch 290/938] loss_G: 3.190964, loss_D: 0.261805\n",
      "[Epoch 106/200] [Batch 300/938] loss_G: 3.489141, loss_D: 0.142244\n",
      "[Epoch 106/200] [Batch 310/938] loss_G: 2.976408, loss_D: 0.224065\n",
      "[Epoch 106/200] [Batch 320/938] loss_G: 3.155888, loss_D: 0.179946\n",
      "[Epoch 106/200] [Batch 330/938] loss_G: 3.132081, loss_D: 0.238008\n",
      "[Epoch 106/200] [Batch 340/938] loss_G: 2.918688, loss_D: 0.223241\n",
      "[Epoch 106/200] [Batch 350/938] loss_G: 3.610484, loss_D: 0.233299\n",
      "[Epoch 106/200] [Batch 360/938] loss_G: 3.108320, loss_D: 0.231908\n",
      "[Epoch 106/200] [Batch 370/938] loss_G: 3.247524, loss_D: 0.170015\n",
      "[Epoch 106/200] [Batch 380/938] loss_G: 2.963396, loss_D: 0.215514\n",
      "[Epoch 106/200] [Batch 390/938] loss_G: 3.276752, loss_D: 0.186999\n",
      "[Epoch 106/200] [Batch 400/938] loss_G: 3.063160, loss_D: 0.171290\n",
      "[Epoch 106/200] [Batch 410/938] loss_G: 3.052834, loss_D: 0.161020\n",
      "[Epoch 106/200] [Batch 420/938] loss_G: 3.054833, loss_D: 0.218755\n",
      "[Epoch 106/200] [Batch 430/938] loss_G: 3.057231, loss_D: 0.223305\n",
      "[Epoch 106/200] [Batch 440/938] loss_G: 2.827922, loss_D: 0.134265\n",
      "[Epoch 106/200] [Batch 450/938] loss_G: 3.056312, loss_D: 0.142029\n",
      "[Epoch 106/200] [Batch 460/938] loss_G: 3.044408, loss_D: 0.260001\n",
      "[Epoch 106/200] [Batch 470/938] loss_G: 2.782072, loss_D: 0.227709\n",
      "[Epoch 106/200] [Batch 480/938] loss_G: 2.964705, loss_D: 0.219600\n",
      "[Epoch 106/200] [Batch 490/938] loss_G: 2.678035, loss_D: 0.228231\n",
      "[Epoch 106/200] [Batch 500/938] loss_G: 3.142320, loss_D: 0.163536\n",
      "[Epoch 106/200] [Batch 510/938] loss_G: 2.843773, loss_D: 0.189610\n",
      "[Epoch 106/200] [Batch 520/938] loss_G: 2.833021, loss_D: 0.230086\n",
      "[Epoch 106/200] [Batch 530/938] loss_G: 3.060872, loss_D: 0.201499\n",
      "[Epoch 106/200] [Batch 540/938] loss_G: 3.092404, loss_D: 0.224844\n",
      "[Epoch 106/200] [Batch 550/938] loss_G: 2.746413, loss_D: 0.141509\n",
      "[Epoch 106/200] [Batch 560/938] loss_G: 3.019272, loss_D: 0.185381\n",
      "[Epoch 106/200] [Batch 570/938] loss_G: 2.912823, loss_D: 0.216700\n",
      "[Epoch 106/200] [Batch 580/938] loss_G: 2.925555, loss_D: 0.124293\n",
      "[Epoch 106/200] [Batch 590/938] loss_G: 3.182731, loss_D: 0.200817\n",
      "[Epoch 106/200] [Batch 600/938] loss_G: 2.933900, loss_D: 0.222902\n",
      "[Epoch 106/200] [Batch 610/938] loss_G: 3.008912, loss_D: 0.366476\n",
      "[Epoch 106/200] [Batch 620/938] loss_G: 3.143821, loss_D: 0.248800\n",
      "[Epoch 106/200] [Batch 630/938] loss_G: 3.071660, loss_D: 0.217227\n",
      "[Epoch 106/200] [Batch 640/938] loss_G: 3.145515, loss_D: 0.162161\n",
      "[Epoch 106/200] [Batch 650/938] loss_G: 2.769361, loss_D: 0.216924\n",
      "[Epoch 106/200] [Batch 660/938] loss_G: 2.660347, loss_D: 0.294260\n",
      "[Epoch 106/200] [Batch 670/938] loss_G: 3.043447, loss_D: 0.174941\n",
      "[Epoch 106/200] [Batch 680/938] loss_G: 3.205057, loss_D: 0.198014\n",
      "[Epoch 106/200] [Batch 690/938] loss_G: 2.659430, loss_D: 0.291680\n",
      "[Epoch 106/200] [Batch 700/938] loss_G: 3.111576, loss_D: 0.140643\n",
      "[Epoch 106/200] [Batch 710/938] loss_G: 3.152816, loss_D: 0.236952\n",
      "[Epoch 106/200] [Batch 720/938] loss_G: 3.309965, loss_D: 0.252169\n",
      "[Epoch 106/200] [Batch 730/938] loss_G: 2.737384, loss_D: 0.193482\n",
      "[Epoch 106/200] [Batch 740/938] loss_G: 2.962133, loss_D: 0.289607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 106/200] [Batch 750/938] loss_G: 3.334231, loss_D: 0.190528\n",
      "[Epoch 106/200] [Batch 760/938] loss_G: 3.115411, loss_D: 0.219463\n",
      "[Epoch 106/200] [Batch 770/938] loss_G: 2.704793, loss_D: 0.213664\n",
      "[Epoch 106/200] [Batch 780/938] loss_G: 2.652696, loss_D: 0.189241\n",
      "[Epoch 106/200] [Batch 790/938] loss_G: 2.924517, loss_D: 0.220503\n",
      "[Epoch 106/200] [Batch 800/938] loss_G: 2.946716, loss_D: 0.167185\n",
      "[Epoch 106/200] [Batch 810/938] loss_G: 2.890636, loss_D: 0.216696\n",
      "[Epoch 106/200] [Batch 820/938] loss_G: 3.033204, loss_D: 0.148424\n",
      "[Epoch 106/200] [Batch 830/938] loss_G: 2.877704, loss_D: 0.262075\n",
      "[Epoch 106/200] [Batch 840/938] loss_G: 2.959371, loss_D: 0.220060\n",
      "[Epoch 106/200] [Batch 850/938] loss_G: 3.389089, loss_D: 0.186933\n",
      "[Epoch 106/200] [Batch 860/938] loss_G: 2.956452, loss_D: 0.189002\n",
      "[Epoch 106/200] [Batch 870/938] loss_G: 2.976456, loss_D: 0.232019\n",
      "[Epoch 106/200] [Batch 880/938] loss_G: 3.128687, loss_D: 0.208012\n",
      "[Epoch 106/200] [Batch 890/938] loss_G: 2.999768, loss_D: 0.189916\n",
      "[Epoch 106/200] [Batch 900/938] loss_G: 3.093114, loss_D: 0.173473\n",
      "[Epoch 106/200] [Batch 910/938] loss_G: 2.680387, loss_D: 0.213209\n",
      "[Epoch 106/200] [Batch 920/938] loss_G: 2.811432, loss_D: 0.209445\n",
      "[Epoch 106/200] [Batch 930/938] loss_G: 3.029468, loss_D: 0.186992\n",
      "[Epoch 107/200] [Batch 0/938] loss_G: 2.915280, loss_D: 0.211029\n",
      "[Epoch 107/200] [Batch 10/938] loss_G: 2.845409, loss_D: 0.212142\n",
      "[Epoch 107/200] [Batch 20/938] loss_G: 3.001204, loss_D: 0.253967\n",
      "[Epoch 107/200] [Batch 30/938] loss_G: 3.322793, loss_D: 0.193924\n",
      "[Epoch 107/200] [Batch 40/938] loss_G: 2.747036, loss_D: 0.250027\n",
      "[Epoch 107/200] [Batch 50/938] loss_G: 2.936065, loss_D: 0.172843\n",
      "[Epoch 107/200] [Batch 60/938] loss_G: 2.695312, loss_D: 0.195319\n",
      "[Epoch 107/200] [Batch 70/938] loss_G: 2.658402, loss_D: 0.192358\n",
      "[Epoch 107/200] [Batch 80/938] loss_G: 2.996802, loss_D: 0.205673\n",
      "[Epoch 107/200] [Batch 90/938] loss_G: 2.862672, loss_D: 0.232017\n",
      "[Epoch 107/200] [Batch 100/938] loss_G: 3.435491, loss_D: 0.153166\n",
      "[Epoch 107/200] [Batch 110/938] loss_G: 3.079526, loss_D: 0.166759\n",
      "[Epoch 107/200] [Batch 120/938] loss_G: 3.138938, loss_D: 0.150235\n",
      "[Epoch 107/200] [Batch 130/938] loss_G: 3.111119, loss_D: 0.294494\n",
      "[Epoch 107/200] [Batch 140/938] loss_G: 3.272563, loss_D: 0.158255\n",
      "[Epoch 107/200] [Batch 150/938] loss_G: 3.128438, loss_D: 0.150640\n",
      "[Epoch 107/200] [Batch 160/938] loss_G: 2.911057, loss_D: 0.210228\n",
      "[Epoch 107/200] [Batch 170/938] loss_G: 3.012582, loss_D: 0.229008\n",
      "[Epoch 107/200] [Batch 180/938] loss_G: 2.835300, loss_D: 0.144135\n",
      "[Epoch 107/200] [Batch 190/938] loss_G: 2.855305, loss_D: 0.195843\n",
      "[Epoch 107/200] [Batch 200/938] loss_G: 2.969703, loss_D: 0.240049\n",
      "[Epoch 107/200] [Batch 210/938] loss_G: 2.969829, loss_D: 0.169484\n",
      "[Epoch 107/200] [Batch 220/938] loss_G: 3.238871, loss_D: 0.198295\n",
      "[Epoch 107/200] [Batch 230/938] loss_G: 3.056191, loss_D: 0.201318\n",
      "[Epoch 107/200] [Batch 240/938] loss_G: 3.277233, loss_D: 0.234828\n",
      "[Epoch 107/200] [Batch 250/938] loss_G: 2.766222, loss_D: 0.239547\n",
      "[Epoch 107/200] [Batch 260/938] loss_G: 2.851113, loss_D: 0.115500\n",
      "[Epoch 107/200] [Batch 270/938] loss_G: 3.199450, loss_D: 0.127887\n",
      "[Epoch 107/200] [Batch 280/938] loss_G: 2.822297, loss_D: 0.208542\n",
      "[Epoch 107/200] [Batch 290/938] loss_G: 3.224349, loss_D: 0.145369\n",
      "[Epoch 107/200] [Batch 300/938] loss_G: 2.796223, loss_D: 0.225566\n",
      "[Epoch 107/200] [Batch 310/938] loss_G: 3.600461, loss_D: 0.297297\n",
      "[Epoch 107/200] [Batch 320/938] loss_G: 3.169988, loss_D: 0.251278\n",
      "[Epoch 107/200] [Batch 330/938] loss_G: 2.825531, loss_D: 0.239647\n",
      "[Epoch 107/200] [Batch 340/938] loss_G: 3.069227, loss_D: 0.219610\n",
      "[Epoch 107/200] [Batch 350/938] loss_G: 3.308844, loss_D: 0.159526\n",
      "[Epoch 107/200] [Batch 360/938] loss_G: 3.468294, loss_D: 0.181234\n",
      "[Epoch 107/200] [Batch 370/938] loss_G: 2.859072, loss_D: 0.167587\n",
      "[Epoch 107/200] [Batch 380/938] loss_G: 3.094632, loss_D: 0.166395\n",
      "[Epoch 107/200] [Batch 390/938] loss_G: 3.354661, loss_D: 0.171410\n",
      "[Epoch 107/200] [Batch 400/938] loss_G: 3.042711, loss_D: 0.201957\n",
      "[Epoch 107/200] [Batch 410/938] loss_G: 2.986046, loss_D: 0.213195\n",
      "[Epoch 107/200] [Batch 420/938] loss_G: 3.212387, loss_D: 0.210885\n",
      "[Epoch 107/200] [Batch 430/938] loss_G: 3.050591, loss_D: 0.170675\n",
      "[Epoch 107/200] [Batch 440/938] loss_G: 3.131185, loss_D: 0.233143\n",
      "[Epoch 107/200] [Batch 450/938] loss_G: 2.702273, loss_D: 0.349843\n",
      "[Epoch 107/200] [Batch 460/938] loss_G: 2.881866, loss_D: 0.156973\n",
      "[Epoch 107/200] [Batch 470/938] loss_G: 3.241740, loss_D: 0.207575\n",
      "[Epoch 107/200] [Batch 480/938] loss_G: 2.976799, loss_D: 0.246223\n",
      "[Epoch 107/200] [Batch 490/938] loss_G: 3.657654, loss_D: 0.150256\n",
      "[Epoch 107/200] [Batch 500/938] loss_G: 3.205130, loss_D: 0.158914\n",
      "[Epoch 107/200] [Batch 510/938] loss_G: 3.124548, loss_D: 0.138310\n",
      "[Epoch 107/200] [Batch 520/938] loss_G: 2.789659, loss_D: 0.187335\n",
      "[Epoch 107/200] [Batch 530/938] loss_G: 2.898789, loss_D: 0.185873\n",
      "[Epoch 107/200] [Batch 540/938] loss_G: 3.486968, loss_D: 0.245811\n",
      "[Epoch 107/200] [Batch 550/938] loss_G: 2.818546, loss_D: 0.242018\n",
      "[Epoch 107/200] [Batch 560/938] loss_G: 3.073822, loss_D: 0.215800\n",
      "[Epoch 107/200] [Batch 570/938] loss_G: 3.286304, loss_D: 0.259157\n",
      "[Epoch 107/200] [Batch 580/938] loss_G: 3.228824, loss_D: 0.157579\n",
      "[Epoch 107/200] [Batch 590/938] loss_G: 3.061500, loss_D: 0.170936\n",
      "[Epoch 107/200] [Batch 600/938] loss_G: 3.025496, loss_D: 0.216558\n",
      "[Epoch 107/200] [Batch 610/938] loss_G: 3.199430, loss_D: 0.191557\n",
      "[Epoch 107/200] [Batch 620/938] loss_G: 2.782245, loss_D: 0.284252\n",
      "[Epoch 107/200] [Batch 630/938] loss_G: 2.752192, loss_D: 0.191079\n",
      "[Epoch 107/200] [Batch 640/938] loss_G: 2.592564, loss_D: 0.190206\n",
      "[Epoch 107/200] [Batch 650/938] loss_G: 3.074116, loss_D: 0.236945\n",
      "[Epoch 107/200] [Batch 660/938] loss_G: 3.298710, loss_D: 0.155035\n",
      "[Epoch 107/200] [Batch 670/938] loss_G: 2.770349, loss_D: 0.280557\n",
      "[Epoch 107/200] [Batch 680/938] loss_G: 2.997864, loss_D: 0.166994\n",
      "[Epoch 107/200] [Batch 690/938] loss_G: 3.051231, loss_D: 0.280119\n",
      "[Epoch 107/200] [Batch 700/938] loss_G: 3.088405, loss_D: 0.247635\n",
      "[Epoch 107/200] [Batch 710/938] loss_G: 2.920365, loss_D: 0.173259\n",
      "[Epoch 107/200] [Batch 720/938] loss_G: 2.979507, loss_D: 0.202224\n",
      "[Epoch 107/200] [Batch 730/938] loss_G: 3.071322, loss_D: 0.251360\n",
      "[Epoch 107/200] [Batch 740/938] loss_G: 2.838263, loss_D: 0.205165\n",
      "[Epoch 107/200] [Batch 750/938] loss_G: 3.130519, loss_D: 0.180625\n",
      "[Epoch 107/200] [Batch 760/938] loss_G: 3.062732, loss_D: 0.178137\n",
      "[Epoch 107/200] [Batch 770/938] loss_G: 3.194141, loss_D: 0.180269\n",
      "[Epoch 107/200] [Batch 780/938] loss_G: 3.111766, loss_D: 0.126211\n",
      "[Epoch 107/200] [Batch 790/938] loss_G: 3.056490, loss_D: 0.142078\n",
      "[Epoch 107/200] [Batch 800/938] loss_G: 3.600652, loss_D: 0.138369\n",
      "[Epoch 107/200] [Batch 810/938] loss_G: 2.890921, loss_D: 0.142864\n",
      "[Epoch 107/200] [Batch 820/938] loss_G: 3.019716, loss_D: 0.222491\n",
      "[Epoch 107/200] [Batch 830/938] loss_G: 2.990448, loss_D: 0.191020\n",
      "[Epoch 107/200] [Batch 840/938] loss_G: 3.007759, loss_D: 0.182237\n",
      "[Epoch 107/200] [Batch 850/938] loss_G: 3.200499, loss_D: 0.247406\n",
      "[Epoch 107/200] [Batch 860/938] loss_G: 2.859226, loss_D: 0.190015\n",
      "[Epoch 107/200] [Batch 870/938] loss_G: 3.289238, loss_D: 0.202885\n",
      "[Epoch 107/200] [Batch 880/938] loss_G: 2.664247, loss_D: 0.230093\n",
      "[Epoch 107/200] [Batch 890/938] loss_G: 3.015509, loss_D: 0.174702\n",
      "[Epoch 107/200] [Batch 900/938] loss_G: 3.236852, loss_D: 0.158451\n",
      "[Epoch 107/200] [Batch 910/938] loss_G: 2.968342, loss_D: 0.199876\n",
      "[Epoch 107/200] [Batch 920/938] loss_G: 2.982835, loss_D: 0.218740\n",
      "[Epoch 107/200] [Batch 930/938] loss_G: 2.804033, loss_D: 0.258978\n",
      "[Epoch 108/200] [Batch 0/938] loss_G: 3.300414, loss_D: 0.204163\n",
      "[Epoch 108/200] [Batch 10/938] loss_G: 2.981259, loss_D: 0.201684\n",
      "[Epoch 108/200] [Batch 20/938] loss_G: 3.246608, loss_D: 0.238336\n",
      "[Epoch 108/200] [Batch 30/938] loss_G: 3.093765, loss_D: 0.143081\n",
      "[Epoch 108/200] [Batch 40/938] loss_G: 2.750359, loss_D: 0.172558\n",
      "[Epoch 108/200] [Batch 50/938] loss_G: 3.502469, loss_D: 0.288270\n",
      "[Epoch 108/200] [Batch 60/938] loss_G: 2.446712, loss_D: 0.288451\n",
      "[Epoch 108/200] [Batch 70/938] loss_G: 2.890540, loss_D: 0.183692\n",
      "[Epoch 108/200] [Batch 80/938] loss_G: 3.106969, loss_D: 0.279453\n",
      "[Epoch 108/200] [Batch 90/938] loss_G: 2.897572, loss_D: 0.244600\n",
      "[Epoch 108/200] [Batch 100/938] loss_G: 2.839098, loss_D: 0.176593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 108/200] [Batch 110/938] loss_G: 3.286466, loss_D: 0.183926\n",
      "[Epoch 108/200] [Batch 120/938] loss_G: 3.507540, loss_D: 0.124896\n",
      "[Epoch 108/200] [Batch 130/938] loss_G: 2.903125, loss_D: 0.205581\n",
      "[Epoch 108/200] [Batch 140/938] loss_G: 2.834026, loss_D: 0.198005\n",
      "[Epoch 108/200] [Batch 150/938] loss_G: 3.187085, loss_D: 0.248285\n",
      "[Epoch 108/200] [Batch 160/938] loss_G: 2.744313, loss_D: 0.252634\n",
      "[Epoch 108/200] [Batch 170/938] loss_G: 2.716176, loss_D: 0.220713\n",
      "[Epoch 108/200] [Batch 180/938] loss_G: 3.106033, loss_D: 0.313034\n",
      "[Epoch 108/200] [Batch 190/938] loss_G: 3.196052, loss_D: 0.215940\n",
      "[Epoch 108/200] [Batch 200/938] loss_G: 2.836561, loss_D: 0.183815\n",
      "[Epoch 108/200] [Batch 210/938] loss_G: 2.877916, loss_D: 0.178845\n",
      "[Epoch 108/200] [Batch 220/938] loss_G: 2.871207, loss_D: 0.161276\n",
      "[Epoch 108/200] [Batch 230/938] loss_G: 2.804615, loss_D: 0.188534\n",
      "[Epoch 108/200] [Batch 240/938] loss_G: 2.949566, loss_D: 0.184844\n",
      "[Epoch 108/200] [Batch 250/938] loss_G: 3.279487, loss_D: 0.231731\n",
      "[Epoch 108/200] [Batch 260/938] loss_G: 2.973073, loss_D: 0.211952\n",
      "[Epoch 108/200] [Batch 270/938] loss_G: 3.001349, loss_D: 0.136046\n",
      "[Epoch 108/200] [Batch 280/938] loss_G: 2.874435, loss_D: 0.217190\n",
      "[Epoch 108/200] [Batch 290/938] loss_G: 2.778682, loss_D: 0.261630\n",
      "[Epoch 108/200] [Batch 300/938] loss_G: 2.942394, loss_D: 0.205970\n",
      "[Epoch 108/200] [Batch 310/938] loss_G: 3.585116, loss_D: 0.154049\n",
      "[Epoch 108/200] [Batch 320/938] loss_G: 3.317477, loss_D: 0.142072\n",
      "[Epoch 108/200] [Batch 330/938] loss_G: 2.622106, loss_D: 0.230461\n",
      "[Epoch 108/200] [Batch 340/938] loss_G: 2.780108, loss_D: 0.212918\n",
      "[Epoch 108/200] [Batch 350/938] loss_G: 3.177740, loss_D: 0.215013\n",
      "[Epoch 108/200] [Batch 360/938] loss_G: 2.392017, loss_D: 0.186031\n",
      "[Epoch 108/200] [Batch 370/938] loss_G: 3.156286, loss_D: 0.198143\n",
      "[Epoch 108/200] [Batch 380/938] loss_G: 3.209560, loss_D: 0.163075\n",
      "[Epoch 108/200] [Batch 390/938] loss_G: 2.940440, loss_D: 0.237528\n",
      "[Epoch 108/200] [Batch 400/938] loss_G: 3.381003, loss_D: 0.158023\n",
      "[Epoch 108/200] [Batch 410/938] loss_G: 3.104089, loss_D: 0.166958\n",
      "[Epoch 108/200] [Batch 420/938] loss_G: 3.165581, loss_D: 0.162042\n",
      "[Epoch 108/200] [Batch 430/938] loss_G: 2.900002, loss_D: 0.190154\n",
      "[Epoch 108/200] [Batch 440/938] loss_G: 3.185476, loss_D: 0.210526\n",
      "[Epoch 108/200] [Batch 450/938] loss_G: 3.175960, loss_D: 0.163241\n",
      "[Epoch 108/200] [Batch 460/938] loss_G: 3.167807, loss_D: 0.224763\n",
      "[Epoch 108/200] [Batch 470/938] loss_G: 3.277823, loss_D: 0.220519\n",
      "[Epoch 108/200] [Batch 480/938] loss_G: 3.113583, loss_D: 0.160296\n",
      "[Epoch 108/200] [Batch 490/938] loss_G: 3.060654, loss_D: 0.290110\n",
      "[Epoch 108/200] [Batch 500/938] loss_G: 3.292403, loss_D: 0.179247\n",
      "[Epoch 108/200] [Batch 510/938] loss_G: 3.108715, loss_D: 0.214803\n",
      "[Epoch 108/200] [Batch 520/938] loss_G: 3.406630, loss_D: 0.203681\n",
      "[Epoch 108/200] [Batch 530/938] loss_G: 2.918804, loss_D: 0.247000\n",
      "[Epoch 108/200] [Batch 540/938] loss_G: 2.784883, loss_D: 0.239597\n",
      "[Epoch 108/200] [Batch 550/938] loss_G: 2.849716, loss_D: 0.185658\n",
      "[Epoch 108/200] [Batch 560/938] loss_G: 3.043107, loss_D: 0.253387\n",
      "[Epoch 108/200] [Batch 570/938] loss_G: 2.969827, loss_D: 0.253121\n",
      "[Epoch 108/200] [Batch 580/938] loss_G: 3.471732, loss_D: 0.175489\n",
      "[Epoch 108/200] [Batch 590/938] loss_G: 3.290820, loss_D: 0.197315\n",
      "[Epoch 108/200] [Batch 600/938] loss_G: 2.814715, loss_D: 0.189523\n",
      "[Epoch 108/200] [Batch 610/938] loss_G: 2.892214, loss_D: 0.188998\n",
      "[Epoch 108/200] [Batch 620/938] loss_G: 2.686563, loss_D: 0.216101\n",
      "[Epoch 108/200] [Batch 630/938] loss_G: 3.406430, loss_D: 0.178097\n",
      "[Epoch 108/200] [Batch 640/938] loss_G: 3.262262, loss_D: 0.174894\n",
      "[Epoch 108/200] [Batch 650/938] loss_G: 3.221775, loss_D: 0.131937\n",
      "[Epoch 108/200] [Batch 660/938] loss_G: 2.675915, loss_D: 0.245704\n",
      "[Epoch 108/200] [Batch 670/938] loss_G: 3.608972, loss_D: 0.217992\n",
      "[Epoch 108/200] [Batch 680/938] loss_G: 2.802394, loss_D: 0.228285\n",
      "[Epoch 108/200] [Batch 690/938] loss_G: 2.905141, loss_D: 0.170663\n",
      "[Epoch 108/200] [Batch 700/938] loss_G: 3.169757, loss_D: 0.154845\n",
      "[Epoch 108/200] [Batch 710/938] loss_G: 3.196422, loss_D: 0.128003\n",
      "[Epoch 108/200] [Batch 720/938] loss_G: 3.166984, loss_D: 0.199626\n",
      "[Epoch 108/200] [Batch 730/938] loss_G: 2.833677, loss_D: 0.190904\n",
      "[Epoch 108/200] [Batch 740/938] loss_G: 2.808920, loss_D: 0.322038\n",
      "[Epoch 108/200] [Batch 750/938] loss_G: 3.414055, loss_D: 0.239128\n",
      "[Epoch 108/200] [Batch 760/938] loss_G: 2.900303, loss_D: 0.324985\n",
      "[Epoch 108/200] [Batch 770/938] loss_G: 3.685370, loss_D: 0.216377\n",
      "[Epoch 108/200] [Batch 780/938] loss_G: 2.947956, loss_D: 0.258135\n",
      "[Epoch 108/200] [Batch 790/938] loss_G: 2.934890, loss_D: 0.205414\n",
      "[Epoch 108/200] [Batch 800/938] loss_G: 2.398639, loss_D: 0.178181\n",
      "[Epoch 108/200] [Batch 810/938] loss_G: 2.710763, loss_D: 0.338908\n",
      "[Epoch 108/200] [Batch 820/938] loss_G: 3.130127, loss_D: 0.157188\n",
      "[Epoch 108/200] [Batch 830/938] loss_G: 2.804761, loss_D: 0.219230\n",
      "[Epoch 108/200] [Batch 840/938] loss_G: 3.124699, loss_D: 0.219955\n",
      "[Epoch 108/200] [Batch 850/938] loss_G: 3.056134, loss_D: 0.219302\n",
      "[Epoch 108/200] [Batch 860/938] loss_G: 3.039011, loss_D: 0.216659\n",
      "[Epoch 108/200] [Batch 870/938] loss_G: 3.261966, loss_D: 0.267024\n",
      "[Epoch 108/200] [Batch 880/938] loss_G: 2.946940, loss_D: 0.143057\n",
      "[Epoch 108/200] [Batch 890/938] loss_G: 2.946801, loss_D: 0.243554\n",
      "[Epoch 108/200] [Batch 900/938] loss_G: 3.087088, loss_D: 0.218792\n",
      "[Epoch 108/200] [Batch 910/938] loss_G: 3.021945, loss_D: 0.181744\n",
      "[Epoch 108/200] [Batch 920/938] loss_G: 3.228688, loss_D: 0.155406\n",
      "[Epoch 108/200] [Batch 930/938] loss_G: 3.096868, loss_D: 0.245091\n",
      "[Epoch 109/200] [Batch 0/938] loss_G: 2.933272, loss_D: 0.135566\n",
      "[Epoch 109/200] [Batch 10/938] loss_G: 2.892261, loss_D: 0.214738\n",
      "[Epoch 109/200] [Batch 20/938] loss_G: 3.167238, loss_D: 0.106495\n",
      "[Epoch 109/200] [Batch 30/938] loss_G: 3.235996, loss_D: 0.151948\n",
      "[Epoch 109/200] [Batch 40/938] loss_G: 2.772954, loss_D: 0.189501\n",
      "[Epoch 109/200] [Batch 50/938] loss_G: 3.115879, loss_D: 0.258592\n",
      "[Epoch 109/200] [Batch 60/938] loss_G: 2.792053, loss_D: 0.136942\n",
      "[Epoch 109/200] [Batch 70/938] loss_G: 2.888235, loss_D: 0.215226\n",
      "[Epoch 109/200] [Batch 80/938] loss_G: 3.487647, loss_D: 0.149533\n",
      "[Epoch 109/200] [Batch 90/938] loss_G: 2.834381, loss_D: 0.246636\n",
      "[Epoch 109/200] [Batch 100/938] loss_G: 3.076830, loss_D: 0.194198\n",
      "[Epoch 109/200] [Batch 110/938] loss_G: 3.275969, loss_D: 0.236701\n",
      "[Epoch 109/200] [Batch 120/938] loss_G: 3.199557, loss_D: 0.116404\n",
      "[Epoch 109/200] [Batch 130/938] loss_G: 3.356412, loss_D: 0.217306\n",
      "[Epoch 109/200] [Batch 140/938] loss_G: 2.959917, loss_D: 0.247891\n",
      "[Epoch 109/200] [Batch 150/938] loss_G: 2.980409, loss_D: 0.240107\n",
      "[Epoch 109/200] [Batch 160/938] loss_G: 2.921195, loss_D: 0.193530\n",
      "[Epoch 109/200] [Batch 170/938] loss_G: 3.570704, loss_D: 0.174355\n",
      "[Epoch 109/200] [Batch 180/938] loss_G: 3.098293, loss_D: 0.165400\n",
      "[Epoch 109/200] [Batch 190/938] loss_G: 2.873884, loss_D: 0.221384\n",
      "[Epoch 109/200] [Batch 200/938] loss_G: 2.692026, loss_D: 0.194148\n",
      "[Epoch 109/200] [Batch 210/938] loss_G: 2.903567, loss_D: 0.287906\n",
      "[Epoch 109/200] [Batch 220/938] loss_G: 2.879391, loss_D: 0.194720\n",
      "[Epoch 109/200] [Batch 230/938] loss_G: 3.001982, loss_D: 0.212155\n",
      "[Epoch 109/200] [Batch 240/938] loss_G: 3.156993, loss_D: 0.201202\n",
      "[Epoch 109/200] [Batch 250/938] loss_G: 3.550676, loss_D: 0.219086\n",
      "[Epoch 109/200] [Batch 260/938] loss_G: 3.066165, loss_D: 0.225709\n",
      "[Epoch 109/200] [Batch 270/938] loss_G: 2.951993, loss_D: 0.215752\n",
      "[Epoch 109/200] [Batch 280/938] loss_G: 2.866247, loss_D: 0.210484\n",
      "[Epoch 109/200] [Batch 290/938] loss_G: 3.433673, loss_D: 0.206280\n",
      "[Epoch 109/200] [Batch 300/938] loss_G: 2.795345, loss_D: 0.267129\n",
      "[Epoch 109/200] [Batch 310/938] loss_G: 2.600477, loss_D: 0.184456\n",
      "[Epoch 109/200] [Batch 320/938] loss_G: 3.140563, loss_D: 0.196638\n",
      "[Epoch 109/200] [Batch 330/938] loss_G: 3.121623, loss_D: 0.113127\n",
      "[Epoch 109/200] [Batch 340/938] loss_G: 3.022068, loss_D: 0.228375\n",
      "[Epoch 109/200] [Batch 350/938] loss_G: 2.578526, loss_D: 0.198244\n",
      "[Epoch 109/200] [Batch 360/938] loss_G: 2.739950, loss_D: 0.188881\n",
      "[Epoch 109/200] [Batch 370/938] loss_G: 3.100959, loss_D: 0.132194\n",
      "[Epoch 109/200] [Batch 380/938] loss_G: 3.032706, loss_D: 0.272056\n",
      "[Epoch 109/200] [Batch 390/938] loss_G: 2.684913, loss_D: 0.233582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 109/200] [Batch 400/938] loss_G: 3.017513, loss_D: 0.256592\n",
      "[Epoch 109/200] [Batch 410/938] loss_G: 3.284164, loss_D: 0.222321\n",
      "[Epoch 109/200] [Batch 420/938] loss_G: 3.255250, loss_D: 0.191685\n",
      "[Epoch 109/200] [Batch 430/938] loss_G: 2.527979, loss_D: 0.210476\n",
      "[Epoch 109/200] [Batch 440/938] loss_G: 2.990988, loss_D: 0.165925\n",
      "[Epoch 109/200] [Batch 450/938] loss_G: 2.863237, loss_D: 0.197614\n",
      "[Epoch 109/200] [Batch 460/938] loss_G: 3.071745, loss_D: 0.175910\n",
      "[Epoch 109/200] [Batch 470/938] loss_G: 3.306488, loss_D: 0.230107\n",
      "[Epoch 109/200] [Batch 480/938] loss_G: 3.286568, loss_D: 0.183976\n",
      "[Epoch 109/200] [Batch 490/938] loss_G: 3.119524, loss_D: 0.131126\n",
      "[Epoch 109/200] [Batch 500/938] loss_G: 2.835485, loss_D: 0.210169\n",
      "[Epoch 109/200] [Batch 510/938] loss_G: 3.252713, loss_D: 0.163831\n",
      "[Epoch 109/200] [Batch 520/938] loss_G: 3.152920, loss_D: 0.167533\n",
      "[Epoch 109/200] [Batch 530/938] loss_G: 3.038078, loss_D: 0.178508\n",
      "[Epoch 109/200] [Batch 540/938] loss_G: 2.847518, loss_D: 0.188799\n",
      "[Epoch 109/200] [Batch 550/938] loss_G: 2.874550, loss_D: 0.239292\n",
      "[Epoch 109/200] [Batch 560/938] loss_G: 2.913606, loss_D: 0.180042\n",
      "[Epoch 109/200] [Batch 570/938] loss_G: 3.150151, loss_D: 0.231250\n",
      "[Epoch 109/200] [Batch 580/938] loss_G: 3.190610, loss_D: 0.179658\n",
      "[Epoch 109/200] [Batch 590/938] loss_G: 2.796243, loss_D: 0.204037\n",
      "[Epoch 109/200] [Batch 600/938] loss_G: 3.057783, loss_D: 0.240995\n",
      "[Epoch 109/200] [Batch 610/938] loss_G: 3.443477, loss_D: 0.128216\n",
      "[Epoch 109/200] [Batch 620/938] loss_G: 2.886716, loss_D: 0.210105\n",
      "[Epoch 109/200] [Batch 630/938] loss_G: 3.579432, loss_D: 0.232457\n",
      "[Epoch 109/200] [Batch 640/938] loss_G: 3.418695, loss_D: 0.248646\n",
      "[Epoch 109/200] [Batch 650/938] loss_G: 3.315229, loss_D: 0.241284\n",
      "[Epoch 109/200] [Batch 660/938] loss_G: 2.990024, loss_D: 0.219322\n",
      "[Epoch 109/200] [Batch 670/938] loss_G: 3.064418, loss_D: 0.228364\n",
      "[Epoch 109/200] [Batch 680/938] loss_G: 3.152223, loss_D: 0.243181\n",
      "[Epoch 109/200] [Batch 690/938] loss_G: 2.969098, loss_D: 0.207467\n",
      "[Epoch 109/200] [Batch 700/938] loss_G: 3.055017, loss_D: 0.204986\n",
      "[Epoch 109/200] [Batch 710/938] loss_G: 3.071982, loss_D: 0.209802\n",
      "[Epoch 109/200] [Batch 720/938] loss_G: 2.761504, loss_D: 0.213539\n",
      "[Epoch 109/200] [Batch 730/938] loss_G: 2.871502, loss_D: 0.231351\n",
      "[Epoch 109/200] [Batch 740/938] loss_G: 2.769536, loss_D: 0.177718\n",
      "[Epoch 109/200] [Batch 750/938] loss_G: 3.320152, loss_D: 0.264963\n",
      "[Epoch 109/200] [Batch 760/938] loss_G: 2.791329, loss_D: 0.210915\n",
      "[Epoch 109/200] [Batch 770/938] loss_G: 3.367667, loss_D: 0.205276\n",
      "[Epoch 109/200] [Batch 780/938] loss_G: 3.086703, loss_D: 0.160677\n",
      "[Epoch 109/200] [Batch 790/938] loss_G: 3.201097, loss_D: 0.159395\n",
      "[Epoch 109/200] [Batch 800/938] loss_G: 3.269453, loss_D: 0.227531\n",
      "[Epoch 109/200] [Batch 810/938] loss_G: 3.204497, loss_D: 0.135763\n",
      "[Epoch 109/200] [Batch 820/938] loss_G: 2.950431, loss_D: 0.238951\n",
      "[Epoch 109/200] [Batch 830/938] loss_G: 2.857261, loss_D: 0.275912\n",
      "[Epoch 109/200] [Batch 840/938] loss_G: 2.961133, loss_D: 0.163539\n",
      "[Epoch 109/200] [Batch 850/938] loss_G: 2.823431, loss_D: 0.274914\n",
      "[Epoch 109/200] [Batch 860/938] loss_G: 3.030753, loss_D: 0.211480\n",
      "[Epoch 109/200] [Batch 870/938] loss_G: 2.620378, loss_D: 0.222513\n",
      "[Epoch 109/200] [Batch 880/938] loss_G: 3.039546, loss_D: 0.188450\n",
      "[Epoch 109/200] [Batch 890/938] loss_G: 3.347452, loss_D: 0.210210\n",
      "[Epoch 109/200] [Batch 900/938] loss_G: 3.109656, loss_D: 0.164625\n",
      "[Epoch 109/200] [Batch 910/938] loss_G: 2.956558, loss_D: 0.199940\n",
      "[Epoch 109/200] [Batch 920/938] loss_G: 3.019668, loss_D: 0.257167\n",
      "[Epoch 109/200] [Batch 930/938] loss_G: 3.004665, loss_D: 0.160914\n",
      "[Epoch 110/200] [Batch 0/938] loss_G: 3.263011, loss_D: 0.228243\n",
      "[Epoch 110/200] [Batch 10/938] loss_G: 2.947322, loss_D: 0.182848\n",
      "[Epoch 110/200] [Batch 20/938] loss_G: 3.261638, loss_D: 0.241502\n",
      "[Epoch 110/200] [Batch 30/938] loss_G: 3.113108, loss_D: 0.178715\n",
      "[Epoch 110/200] [Batch 40/938] loss_G: 3.669456, loss_D: 0.202505\n",
      "[Epoch 110/200] [Batch 50/938] loss_G: 3.091722, loss_D: 0.203516\n",
      "[Epoch 110/200] [Batch 60/938] loss_G: 3.087536, loss_D: 0.183753\n",
      "[Epoch 110/200] [Batch 70/938] loss_G: 3.138181, loss_D: 0.286086\n",
      "[Epoch 110/200] [Batch 80/938] loss_G: 2.857090, loss_D: 0.249228\n",
      "[Epoch 110/200] [Batch 90/938] loss_G: 3.326124, loss_D: 0.199975\n",
      "[Epoch 110/200] [Batch 100/938] loss_G: 3.242174, loss_D: 0.227549\n",
      "[Epoch 110/200] [Batch 110/938] loss_G: 3.290320, loss_D: 0.246558\n",
      "[Epoch 110/200] [Batch 120/938] loss_G: 3.022393, loss_D: 0.197105\n",
      "[Epoch 110/200] [Batch 130/938] loss_G: 3.185523, loss_D: 0.183105\n",
      "[Epoch 110/200] [Batch 140/938] loss_G: 2.987218, loss_D: 0.169838\n",
      "[Epoch 110/200] [Batch 150/938] loss_G: 3.417421, loss_D: 0.156207\n",
      "[Epoch 110/200] [Batch 160/938] loss_G: 3.161088, loss_D: 0.188407\n",
      "[Epoch 110/200] [Batch 170/938] loss_G: 2.958387, loss_D: 0.241272\n",
      "[Epoch 110/200] [Batch 180/938] loss_G: 3.188859, loss_D: 0.165038\n",
      "[Epoch 110/200] [Batch 190/938] loss_G: 3.125703, loss_D: 0.127233\n",
      "[Epoch 110/200] [Batch 200/938] loss_G: 2.949523, loss_D: 0.126376\n",
      "[Epoch 110/200] [Batch 210/938] loss_G: 2.807006, loss_D: 0.231776\n",
      "[Epoch 110/200] [Batch 220/938] loss_G: 2.755831, loss_D: 0.151749\n",
      "[Epoch 110/200] [Batch 230/938] loss_G: 3.349459, loss_D: 0.172266\n",
      "[Epoch 110/200] [Batch 240/938] loss_G: 3.106964, loss_D: 0.222528\n",
      "[Epoch 110/200] [Batch 250/938] loss_G: 3.139029, loss_D: 0.127316\n",
      "[Epoch 110/200] [Batch 260/938] loss_G: 2.753963, loss_D: 0.238388\n",
      "[Epoch 110/200] [Batch 270/938] loss_G: 2.718333, loss_D: 0.247365\n",
      "[Epoch 110/200] [Batch 280/938] loss_G: 3.086435, loss_D: 0.210967\n",
      "[Epoch 110/200] [Batch 290/938] loss_G: 3.275890, loss_D: 0.176391\n",
      "[Epoch 110/200] [Batch 300/938] loss_G: 3.008597, loss_D: 0.200814\n",
      "[Epoch 110/200] [Batch 310/938] loss_G: 2.828850, loss_D: 0.235362\n",
      "[Epoch 110/200] [Batch 320/938] loss_G: 3.476727, loss_D: 0.199988\n",
      "[Epoch 110/200] [Batch 330/938] loss_G: 2.985660, loss_D: 0.146430\n",
      "[Epoch 110/200] [Batch 340/938] loss_G: 2.969704, loss_D: 0.159100\n",
      "[Epoch 110/200] [Batch 350/938] loss_G: 2.936851, loss_D: 0.200934\n",
      "[Epoch 110/200] [Batch 360/938] loss_G: 3.070590, loss_D: 0.174697\n",
      "[Epoch 110/200] [Batch 370/938] loss_G: 3.170737, loss_D: 0.258186\n",
      "[Epoch 110/200] [Batch 380/938] loss_G: 3.015157, loss_D: 0.191630\n",
      "[Epoch 110/200] [Batch 390/938] loss_G: 2.931051, loss_D: 0.171626\n",
      "[Epoch 110/200] [Batch 400/938] loss_G: 3.303697, loss_D: 0.165629\n",
      "[Epoch 110/200] [Batch 410/938] loss_G: 2.944984, loss_D: 0.245957\n",
      "[Epoch 110/200] [Batch 420/938] loss_G: 3.195951, loss_D: 0.260506\n",
      "[Epoch 110/200] [Batch 430/938] loss_G: 2.908779, loss_D: 0.209406\n",
      "[Epoch 110/200] [Batch 440/938] loss_G: 3.028562, loss_D: 0.225286\n",
      "[Epoch 110/200] [Batch 450/938] loss_G: 2.807539, loss_D: 0.155819\n",
      "[Epoch 110/200] [Batch 460/938] loss_G: 3.029587, loss_D: 0.239900\n",
      "[Epoch 110/200] [Batch 470/938] loss_G: 3.227710, loss_D: 0.225556\n",
      "[Epoch 110/200] [Batch 480/938] loss_G: 3.058827, loss_D: 0.216425\n",
      "[Epoch 110/200] [Batch 490/938] loss_G: 2.852693, loss_D: 0.190719\n",
      "[Epoch 110/200] [Batch 500/938] loss_G: 3.315256, loss_D: 0.130562\n",
      "[Epoch 110/200] [Batch 510/938] loss_G: 2.750268, loss_D: 0.244170\n",
      "[Epoch 110/200] [Batch 520/938] loss_G: 3.126022, loss_D: 0.136170\n",
      "[Epoch 110/200] [Batch 530/938] loss_G: 3.052030, loss_D: 0.168447\n",
      "[Epoch 110/200] [Batch 540/938] loss_G: 2.863110, loss_D: 0.146273\n",
      "[Epoch 110/200] [Batch 550/938] loss_G: 3.378253, loss_D: 0.150340\n",
      "[Epoch 110/200] [Batch 560/938] loss_G: 3.367063, loss_D: 0.222436\n",
      "[Epoch 110/200] [Batch 570/938] loss_G: 3.204870, loss_D: 0.242986\n",
      "[Epoch 110/200] [Batch 580/938] loss_G: 2.946093, loss_D: 0.218447\n",
      "[Epoch 110/200] [Batch 590/938] loss_G: 2.912636, loss_D: 0.263534\n",
      "[Epoch 110/200] [Batch 600/938] loss_G: 3.079354, loss_D: 0.140239\n",
      "[Epoch 110/200] [Batch 610/938] loss_G: 3.318084, loss_D: 0.259905\n",
      "[Epoch 110/200] [Batch 620/938] loss_G: 3.011212, loss_D: 0.232268\n",
      "[Epoch 110/200] [Batch 630/938] loss_G: 2.686870, loss_D: 0.181414\n",
      "[Epoch 110/200] [Batch 640/938] loss_G: 2.588442, loss_D: 0.217060\n",
      "[Epoch 110/200] [Batch 650/938] loss_G: 2.857286, loss_D: 0.250219\n",
      "[Epoch 110/200] [Batch 660/938] loss_G: 3.002192, loss_D: 0.246969\n",
      "[Epoch 110/200] [Batch 670/938] loss_G: 2.918480, loss_D: 0.236278\n",
      "[Epoch 110/200] [Batch 680/938] loss_G: 2.417176, loss_D: 0.208745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 110/200] [Batch 690/938] loss_G: 3.140640, loss_D: 0.127560\n",
      "[Epoch 110/200] [Batch 700/938] loss_G: 3.326544, loss_D: 0.210285\n",
      "[Epoch 110/200] [Batch 710/938] loss_G: 2.810716, loss_D: 0.172341\n",
      "[Epoch 110/200] [Batch 720/938] loss_G: 2.974108, loss_D: 0.214309\n",
      "[Epoch 110/200] [Batch 730/938] loss_G: 2.866732, loss_D: 0.137285\n",
      "[Epoch 110/200] [Batch 740/938] loss_G: 3.046774, loss_D: 0.201697\n",
      "[Epoch 110/200] [Batch 750/938] loss_G: 2.710531, loss_D: 0.220046\n",
      "[Epoch 110/200] [Batch 760/938] loss_G: 3.175801, loss_D: 0.284750\n",
      "[Epoch 110/200] [Batch 770/938] loss_G: 3.237744, loss_D: 0.176953\n",
      "[Epoch 110/200] [Batch 780/938] loss_G: 2.810978, loss_D: 0.202902\n",
      "[Epoch 110/200] [Batch 790/938] loss_G: 3.068493, loss_D: 0.193852\n",
      "[Epoch 110/200] [Batch 800/938] loss_G: 2.936644, loss_D: 0.156922\n",
      "[Epoch 110/200] [Batch 810/938] loss_G: 2.930746, loss_D: 0.225708\n",
      "[Epoch 110/200] [Batch 820/938] loss_G: 2.931887, loss_D: 0.188091\n",
      "[Epoch 110/200] [Batch 830/938] loss_G: 2.827380, loss_D: 0.117045\n",
      "[Epoch 110/200] [Batch 840/938] loss_G: 3.177155, loss_D: 0.210251\n",
      "[Epoch 110/200] [Batch 850/938] loss_G: 3.456130, loss_D: 0.206017\n",
      "[Epoch 110/200] [Batch 860/938] loss_G: 3.075949, loss_D: 0.146707\n",
      "[Epoch 110/200] [Batch 870/938] loss_G: 3.092386, loss_D: 0.172139\n",
      "[Epoch 110/200] [Batch 880/938] loss_G: 2.736472, loss_D: 0.194514\n",
      "[Epoch 110/200] [Batch 890/938] loss_G: 3.198564, loss_D: 0.148976\n",
      "[Epoch 110/200] [Batch 900/938] loss_G: 2.947453, loss_D: 0.213458\n",
      "[Epoch 110/200] [Batch 910/938] loss_G: 2.746338, loss_D: 0.153449\n",
      "[Epoch 110/200] [Batch 920/938] loss_G: 2.958188, loss_D: 0.175850\n",
      "[Epoch 110/200] [Batch 930/938] loss_G: 2.798064, loss_D: 0.226279\n",
      "[Epoch 111/200] [Batch 0/938] loss_G: 2.853501, loss_D: 0.266335\n",
      "[Epoch 111/200] [Batch 10/938] loss_G: 3.285703, loss_D: 0.210026\n",
      "[Epoch 111/200] [Batch 20/938] loss_G: 3.152740, loss_D: 0.288276\n",
      "[Epoch 111/200] [Batch 30/938] loss_G: 2.550793, loss_D: 0.214985\n",
      "[Epoch 111/200] [Batch 40/938] loss_G: 2.921969, loss_D: 0.246419\n",
      "[Epoch 111/200] [Batch 50/938] loss_G: 3.163117, loss_D: 0.238109\n",
      "[Epoch 111/200] [Batch 60/938] loss_G: 2.690675, loss_D: 0.195308\n",
      "[Epoch 111/200] [Batch 70/938] loss_G: 3.105253, loss_D: 0.202458\n",
      "[Epoch 111/200] [Batch 80/938] loss_G: 3.208383, loss_D: 0.242998\n",
      "[Epoch 111/200] [Batch 90/938] loss_G: 3.071232, loss_D: 0.166041\n",
      "[Epoch 111/200] [Batch 100/938] loss_G: 2.779425, loss_D: 0.121806\n",
      "[Epoch 111/200] [Batch 110/938] loss_G: 2.603457, loss_D: 0.274680\n",
      "[Epoch 111/200] [Batch 120/938] loss_G: 2.832018, loss_D: 0.225332\n",
      "[Epoch 111/200] [Batch 130/938] loss_G: 3.387392, loss_D: 0.167765\n",
      "[Epoch 111/200] [Batch 140/938] loss_G: 3.351310, loss_D: 0.204446\n",
      "[Epoch 111/200] [Batch 150/938] loss_G: 2.673651, loss_D: 0.251615\n",
      "[Epoch 111/200] [Batch 160/938] loss_G: 3.096105, loss_D: 0.159794\n",
      "[Epoch 111/200] [Batch 170/938] loss_G: 3.463664, loss_D: 0.205148\n",
      "[Epoch 111/200] [Batch 180/938] loss_G: 3.041913, loss_D: 0.302359\n",
      "[Epoch 111/200] [Batch 190/938] loss_G: 3.051543, loss_D: 0.177588\n",
      "[Epoch 111/200] [Batch 200/938] loss_G: 2.887454, loss_D: 0.204741\n",
      "[Epoch 111/200] [Batch 210/938] loss_G: 2.882667, loss_D: 0.217371\n",
      "[Epoch 111/200] [Batch 220/938] loss_G: 3.160775, loss_D: 0.198014\n",
      "[Epoch 111/200] [Batch 230/938] loss_G: 3.240435, loss_D: 0.208488\n",
      "[Epoch 111/200] [Batch 240/938] loss_G: 2.736896, loss_D: 0.151280\n",
      "[Epoch 111/200] [Batch 250/938] loss_G: 3.048702, loss_D: 0.189722\n",
      "[Epoch 111/200] [Batch 260/938] loss_G: 3.125902, loss_D: 0.230426\n",
      "[Epoch 111/200] [Batch 270/938] loss_G: 3.118289, loss_D: 0.197600\n",
      "[Epoch 111/200] [Batch 280/938] loss_G: 3.058400, loss_D: 0.235663\n",
      "[Epoch 111/200] [Batch 290/938] loss_G: 3.368545, loss_D: 0.152473\n",
      "[Epoch 111/200] [Batch 300/938] loss_G: 2.933050, loss_D: 0.295691\n",
      "[Epoch 111/200] [Batch 310/938] loss_G: 3.313951, loss_D: 0.215721\n",
      "[Epoch 111/200] [Batch 320/938] loss_G: 3.293439, loss_D: 0.211093\n",
      "[Epoch 111/200] [Batch 330/938] loss_G: 3.095200, loss_D: 0.188502\n",
      "[Epoch 111/200] [Batch 340/938] loss_G: 3.100280, loss_D: 0.127246\n",
      "[Epoch 111/200] [Batch 350/938] loss_G: 3.405518, loss_D: 0.172920\n",
      "[Epoch 111/200] [Batch 360/938] loss_G: 2.834452, loss_D: 0.212825\n",
      "[Epoch 111/200] [Batch 370/938] loss_G: 3.291197, loss_D: 0.224526\n",
      "[Epoch 111/200] [Batch 380/938] loss_G: 2.586226, loss_D: 0.195902\n",
      "[Epoch 111/200] [Batch 390/938] loss_G: 3.124227, loss_D: 0.159141\n",
      "[Epoch 111/200] [Batch 400/938] loss_G: 3.016983, loss_D: 0.164609\n",
      "[Epoch 111/200] [Batch 410/938] loss_G: 3.269978, loss_D: 0.184530\n",
      "[Epoch 111/200] [Batch 420/938] loss_G: 2.614376, loss_D: 0.256760\n",
      "[Epoch 111/200] [Batch 430/938] loss_G: 3.153003, loss_D: 0.109167\n",
      "[Epoch 111/200] [Batch 440/938] loss_G: 3.461426, loss_D: 0.242836\n",
      "[Epoch 111/200] [Batch 450/938] loss_G: 3.133376, loss_D: 0.179788\n",
      "[Epoch 111/200] [Batch 460/938] loss_G: 2.823703, loss_D: 0.172401\n",
      "[Epoch 111/200] [Batch 470/938] loss_G: 2.965559, loss_D: 0.225808\n",
      "[Epoch 111/200] [Batch 480/938] loss_G: 3.266596, loss_D: 0.190241\n",
      "[Epoch 111/200] [Batch 490/938] loss_G: 3.466248, loss_D: 0.168774\n",
      "[Epoch 111/200] [Batch 500/938] loss_G: 2.981541, loss_D: 0.210302\n",
      "[Epoch 111/200] [Batch 510/938] loss_G: 3.525909, loss_D: 0.215839\n",
      "[Epoch 111/200] [Batch 520/938] loss_G: 3.392771, loss_D: 0.160214\n",
      "[Epoch 111/200] [Batch 530/938] loss_G: 3.245293, loss_D: 0.143034\n",
      "[Epoch 111/200] [Batch 540/938] loss_G: 3.024518, loss_D: 0.247173\n",
      "[Epoch 111/200] [Batch 550/938] loss_G: 2.868919, loss_D: 0.183524\n",
      "[Epoch 111/200] [Batch 560/938] loss_G: 2.979210, loss_D: 0.244689\n",
      "[Epoch 111/200] [Batch 570/938] loss_G: 3.064795, loss_D: 0.262503\n",
      "[Epoch 111/200] [Batch 580/938] loss_G: 3.029594, loss_D: 0.297167\n",
      "[Epoch 111/200] [Batch 590/938] loss_G: 2.874557, loss_D: 0.281180\n",
      "[Epoch 111/200] [Batch 600/938] loss_G: 3.420156, loss_D: 0.235813\n",
      "[Epoch 111/200] [Batch 610/938] loss_G: 2.891787, loss_D: 0.222916\n",
      "[Epoch 111/200] [Batch 620/938] loss_G: 2.821482, loss_D: 0.212468\n",
      "[Epoch 111/200] [Batch 630/938] loss_G: 2.986180, loss_D: 0.180346\n",
      "[Epoch 111/200] [Batch 640/938] loss_G: 3.218172, loss_D: 0.205842\n",
      "[Epoch 111/200] [Batch 650/938] loss_G: 3.120374, loss_D: 0.216081\n",
      "[Epoch 111/200] [Batch 660/938] loss_G: 3.215046, loss_D: 0.229040\n",
      "[Epoch 111/200] [Batch 670/938] loss_G: 3.098148, loss_D: 0.227115\n",
      "[Epoch 111/200] [Batch 680/938] loss_G: 2.898350, loss_D: 0.165537\n",
      "[Epoch 111/200] [Batch 690/938] loss_G: 3.274886, loss_D: 0.248199\n",
      "[Epoch 111/200] [Batch 700/938] loss_G: 2.935086, loss_D: 0.229567\n",
      "[Epoch 111/200] [Batch 710/938] loss_G: 2.627434, loss_D: 0.223214\n",
      "[Epoch 111/200] [Batch 720/938] loss_G: 2.854009, loss_D: 0.224500\n",
      "[Epoch 111/200] [Batch 730/938] loss_G: 2.667963, loss_D: 0.162100\n",
      "[Epoch 111/200] [Batch 740/938] loss_G: 3.322828, loss_D: 0.160308\n",
      "[Epoch 111/200] [Batch 750/938] loss_G: 2.917571, loss_D: 0.207912\n",
      "[Epoch 111/200] [Batch 760/938] loss_G: 2.947949, loss_D: 0.196286\n",
      "[Epoch 111/200] [Batch 770/938] loss_G: 2.993545, loss_D: 0.264448\n",
      "[Epoch 111/200] [Batch 780/938] loss_G: 3.151887, loss_D: 0.154335\n",
      "[Epoch 111/200] [Batch 790/938] loss_G: 2.796407, loss_D: 0.197029\n",
      "[Epoch 111/200] [Batch 800/938] loss_G: 2.812444, loss_D: 0.254894\n",
      "[Epoch 111/200] [Batch 810/938] loss_G: 3.075721, loss_D: 0.199553\n",
      "[Epoch 111/200] [Batch 820/938] loss_G: 2.891144, loss_D: 0.299505\n",
      "[Epoch 111/200] [Batch 830/938] loss_G: 3.240671, loss_D: 0.105474\n",
      "[Epoch 111/200] [Batch 840/938] loss_G: 3.092345, loss_D: 0.228068\n",
      "[Epoch 111/200] [Batch 850/938] loss_G: 2.896395, loss_D: 0.190627\n",
      "[Epoch 111/200] [Batch 860/938] loss_G: 3.120589, loss_D: 0.217336\n",
      "[Epoch 111/200] [Batch 870/938] loss_G: 3.383109, loss_D: 0.148787\n",
      "[Epoch 111/200] [Batch 880/938] loss_G: 2.492958, loss_D: 0.217300\n",
      "[Epoch 111/200] [Batch 890/938] loss_G: 3.356708, loss_D: 0.168570\n",
      "[Epoch 111/200] [Batch 900/938] loss_G: 2.857917, loss_D: 0.203093\n",
      "[Epoch 111/200] [Batch 910/938] loss_G: 2.668632, loss_D: 0.255069\n",
      "[Epoch 111/200] [Batch 920/938] loss_G: 3.326272, loss_D: 0.177897\n",
      "[Epoch 111/200] [Batch 930/938] loss_G: 3.020880, loss_D: 0.276672\n",
      "[Epoch 112/200] [Batch 0/938] loss_G: 2.891073, loss_D: 0.283458\n",
      "[Epoch 112/200] [Batch 10/938] loss_G: 2.751712, loss_D: 0.167264\n",
      "[Epoch 112/200] [Batch 20/938] loss_G: 2.772429, loss_D: 0.220961\n",
      "[Epoch 112/200] [Batch 30/938] loss_G: 3.057249, loss_D: 0.177917\n",
      "[Epoch 112/200] [Batch 40/938] loss_G: 3.271287, loss_D: 0.214307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 112/200] [Batch 50/938] loss_G: 2.940352, loss_D: 0.225436\n",
      "[Epoch 112/200] [Batch 60/938] loss_G: 3.324921, loss_D: 0.161906\n",
      "[Epoch 112/200] [Batch 70/938] loss_G: 3.217425, loss_D: 0.230887\n",
      "[Epoch 112/200] [Batch 80/938] loss_G: 2.996849, loss_D: 0.243402\n",
      "[Epoch 112/200] [Batch 90/938] loss_G: 2.897715, loss_D: 0.129772\n",
      "[Epoch 112/200] [Batch 100/938] loss_G: 3.496387, loss_D: 0.280190\n",
      "[Epoch 112/200] [Batch 110/938] loss_G: 3.143528, loss_D: 0.221036\n",
      "[Epoch 112/200] [Batch 120/938] loss_G: 3.043012, loss_D: 0.165542\n",
      "[Epoch 112/200] [Batch 130/938] loss_G: 2.891731, loss_D: 0.179002\n",
      "[Epoch 112/200] [Batch 140/938] loss_G: 2.841289, loss_D: 0.188535\n",
      "[Epoch 112/200] [Batch 150/938] loss_G: 2.753921, loss_D: 0.229136\n",
      "[Epoch 112/200] [Batch 160/938] loss_G: 3.114706, loss_D: 0.165326\n",
      "[Epoch 112/200] [Batch 170/938] loss_G: 2.895957, loss_D: 0.201927\n",
      "[Epoch 112/200] [Batch 180/938] loss_G: 2.922524, loss_D: 0.251716\n",
      "[Epoch 112/200] [Batch 190/938] loss_G: 3.184171, loss_D: 0.266010\n",
      "[Epoch 112/200] [Batch 200/938] loss_G: 3.123362, loss_D: 0.142757\n",
      "[Epoch 112/200] [Batch 210/938] loss_G: 3.076516, loss_D: 0.205178\n",
      "[Epoch 112/200] [Batch 220/938] loss_G: 3.008490, loss_D: 0.220083\n",
      "[Epoch 112/200] [Batch 230/938] loss_G: 2.970312, loss_D: 0.258216\n",
      "[Epoch 112/200] [Batch 240/938] loss_G: 2.993027, loss_D: 0.202190\n",
      "[Epoch 112/200] [Batch 250/938] loss_G: 3.212751, loss_D: 0.129456\n",
      "[Epoch 112/200] [Batch 260/938] loss_G: 2.739523, loss_D: 0.241854\n",
      "[Epoch 112/200] [Batch 270/938] loss_G: 3.336231, loss_D: 0.211705\n",
      "[Epoch 112/200] [Batch 280/938] loss_G: 2.805896, loss_D: 0.229680\n",
      "[Epoch 112/200] [Batch 290/938] loss_G: 2.633780, loss_D: 0.186451\n",
      "[Epoch 112/200] [Batch 300/938] loss_G: 2.771476, loss_D: 0.221676\n",
      "[Epoch 112/200] [Batch 310/938] loss_G: 3.024690, loss_D: 0.160699\n",
      "[Epoch 112/200] [Batch 320/938] loss_G: 3.125531, loss_D: 0.247983\n",
      "[Epoch 112/200] [Batch 330/938] loss_G: 3.232587, loss_D: 0.191476\n",
      "[Epoch 112/200] [Batch 340/938] loss_G: 3.034791, loss_D: 0.202032\n",
      "[Epoch 112/200] [Batch 350/938] loss_G: 3.047965, loss_D: 0.183285\n",
      "[Epoch 112/200] [Batch 360/938] loss_G: 2.768201, loss_D: 0.211149\n",
      "[Epoch 112/200] [Batch 370/938] loss_G: 2.839488, loss_D: 0.218983\n",
      "[Epoch 112/200] [Batch 380/938] loss_G: 3.040088, loss_D: 0.143798\n",
      "[Epoch 112/200] [Batch 390/938] loss_G: 3.620698, loss_D: 0.155041\n",
      "[Epoch 112/200] [Batch 400/938] loss_G: 3.201154, loss_D: 0.187906\n",
      "[Epoch 112/200] [Batch 410/938] loss_G: 2.737269, loss_D: 0.267658\n",
      "[Epoch 112/200] [Batch 420/938] loss_G: 2.593557, loss_D: 0.217616\n",
      "[Epoch 112/200] [Batch 430/938] loss_G: 3.180293, loss_D: 0.207704\n",
      "[Epoch 112/200] [Batch 440/938] loss_G: 2.854910, loss_D: 0.208831\n",
      "[Epoch 112/200] [Batch 450/938] loss_G: 3.118060, loss_D: 0.176871\n",
      "[Epoch 112/200] [Batch 460/938] loss_G: 2.932500, loss_D: 0.179970\n",
      "[Epoch 112/200] [Batch 470/938] loss_G: 2.946684, loss_D: 0.243686\n",
      "[Epoch 112/200] [Batch 480/938] loss_G: 3.014867, loss_D: 0.149150\n",
      "[Epoch 112/200] [Batch 490/938] loss_G: 2.918808, loss_D: 0.185244\n",
      "[Epoch 112/200] [Batch 500/938] loss_G: 2.826276, loss_D: 0.198851\n",
      "[Epoch 112/200] [Batch 510/938] loss_G: 3.353042, loss_D: 0.194840\n",
      "[Epoch 112/200] [Batch 520/938] loss_G: 2.843051, loss_D: 0.210107\n",
      "[Epoch 112/200] [Batch 530/938] loss_G: 2.797168, loss_D: 0.197335\n",
      "[Epoch 112/200] [Batch 540/938] loss_G: 2.828894, loss_D: 0.132151\n",
      "[Epoch 112/200] [Batch 550/938] loss_G: 3.473102, loss_D: 0.107303\n",
      "[Epoch 112/200] [Batch 560/938] loss_G: 2.974236, loss_D: 0.165856\n",
      "[Epoch 112/200] [Batch 570/938] loss_G: 2.867235, loss_D: 0.267359\n",
      "[Epoch 112/200] [Batch 580/938] loss_G: 2.862911, loss_D: 0.160065\n",
      "[Epoch 112/200] [Batch 590/938] loss_G: 2.682322, loss_D: 0.241545\n",
      "[Epoch 112/200] [Batch 600/938] loss_G: 3.114593, loss_D: 0.227388\n",
      "[Epoch 112/200] [Batch 610/938] loss_G: 2.992178, loss_D: 0.124000\n",
      "[Epoch 112/200] [Batch 620/938] loss_G: 2.889581, loss_D: 0.195927\n",
      "[Epoch 112/200] [Batch 630/938] loss_G: 3.244261, loss_D: 0.179953\n",
      "[Epoch 112/200] [Batch 640/938] loss_G: 3.127888, loss_D: 0.194415\n",
      "[Epoch 112/200] [Batch 650/938] loss_G: 3.188827, loss_D: 0.230351\n",
      "[Epoch 112/200] [Batch 660/938] loss_G: 2.600008, loss_D: 0.357865\n",
      "[Epoch 112/200] [Batch 670/938] loss_G: 3.271525, loss_D: 0.140933\n",
      "[Epoch 112/200] [Batch 680/938] loss_G: 2.727293, loss_D: 0.328968\n",
      "[Epoch 112/200] [Batch 690/938] loss_G: 2.684422, loss_D: 0.321463\n",
      "[Epoch 112/200] [Batch 700/938] loss_G: 3.114356, loss_D: 0.229287\n",
      "[Epoch 112/200] [Batch 710/938] loss_G: 3.040320, loss_D: 0.239477\n",
      "[Epoch 112/200] [Batch 720/938] loss_G: 3.088374, loss_D: 0.164628\n",
      "[Epoch 112/200] [Batch 730/938] loss_G: 2.767184, loss_D: 0.202099\n",
      "[Epoch 112/200] [Batch 740/938] loss_G: 2.986344, loss_D: 0.174206\n",
      "[Epoch 112/200] [Batch 750/938] loss_G: 2.381191, loss_D: 0.292524\n",
      "[Epoch 112/200] [Batch 760/938] loss_G: 3.353334, loss_D: 0.156600\n",
      "[Epoch 112/200] [Batch 770/938] loss_G: 2.787362, loss_D: 0.191745\n",
      "[Epoch 112/200] [Batch 780/938] loss_G: 2.760848, loss_D: 0.251340\n",
      "[Epoch 112/200] [Batch 790/938] loss_G: 2.894462, loss_D: 0.248009\n",
      "[Epoch 112/200] [Batch 800/938] loss_G: 3.032369, loss_D: 0.198864\n",
      "[Epoch 112/200] [Batch 810/938] loss_G: 3.165198, loss_D: 0.255392\n",
      "[Epoch 112/200] [Batch 820/938] loss_G: 2.903924, loss_D: 0.267009\n",
      "[Epoch 112/200] [Batch 830/938] loss_G: 2.358630, loss_D: 0.204539\n",
      "[Epoch 112/200] [Batch 840/938] loss_G: 3.253278, loss_D: 0.153639\n",
      "[Epoch 112/200] [Batch 850/938] loss_G: 2.941080, loss_D: 0.192324\n",
      "[Epoch 112/200] [Batch 860/938] loss_G: 3.061787, loss_D: 0.164513\n",
      "[Epoch 112/200] [Batch 870/938] loss_G: 3.209116, loss_D: 0.207882\n",
      "[Epoch 112/200] [Batch 880/938] loss_G: 3.035291, loss_D: 0.154318\n",
      "[Epoch 112/200] [Batch 890/938] loss_G: 3.237777, loss_D: 0.183497\n",
      "[Epoch 112/200] [Batch 900/938] loss_G: 2.722459, loss_D: 0.186621\n",
      "[Epoch 112/200] [Batch 910/938] loss_G: 2.911756, loss_D: 0.288108\n",
      "[Epoch 112/200] [Batch 920/938] loss_G: 2.885556, loss_D: 0.238104\n",
      "[Epoch 112/200] [Batch 930/938] loss_G: 3.260683, loss_D: 0.231164\n",
      "[Epoch 113/200] [Batch 0/938] loss_G: 2.806037, loss_D: 0.250260\n",
      "[Epoch 113/200] [Batch 10/938] loss_G: 2.982596, loss_D: 0.203556\n",
      "[Epoch 113/200] [Batch 20/938] loss_G: 3.183934, loss_D: 0.244098\n",
      "[Epoch 113/200] [Batch 30/938] loss_G: 2.645429, loss_D: 0.297689\n",
      "[Epoch 113/200] [Batch 40/938] loss_G: 2.765516, loss_D: 0.198345\n",
      "[Epoch 113/200] [Batch 50/938] loss_G: 3.175685, loss_D: 0.222648\n",
      "[Epoch 113/200] [Batch 60/938] loss_G: 3.144441, loss_D: 0.195902\n",
      "[Epoch 113/200] [Batch 70/938] loss_G: 3.164049, loss_D: 0.163369\n",
      "[Epoch 113/200] [Batch 80/938] loss_G: 3.017209, loss_D: 0.176676\n",
      "[Epoch 113/200] [Batch 90/938] loss_G: 3.095021, loss_D: 0.163555\n",
      "[Epoch 113/200] [Batch 100/938] loss_G: 3.029065, loss_D: 0.193390\n",
      "[Epoch 113/200] [Batch 110/938] loss_G: 3.034970, loss_D: 0.243865\n",
      "[Epoch 113/200] [Batch 120/938] loss_G: 2.947843, loss_D: 0.305385\n",
      "[Epoch 113/200] [Batch 130/938] loss_G: 2.562887, loss_D: 0.189172\n",
      "[Epoch 113/200] [Batch 140/938] loss_G: 2.892812, loss_D: 0.291312\n",
      "[Epoch 113/200] [Batch 150/938] loss_G: 2.805730, loss_D: 0.287918\n",
      "[Epoch 113/200] [Batch 160/938] loss_G: 3.190193, loss_D: 0.109842\n",
      "[Epoch 113/200] [Batch 170/938] loss_G: 3.030574, loss_D: 0.250256\n",
      "[Epoch 113/200] [Batch 180/938] loss_G: 3.019701, loss_D: 0.165058\n",
      "[Epoch 113/200] [Batch 190/938] loss_G: 2.633219, loss_D: 0.184858\n",
      "[Epoch 113/200] [Batch 200/938] loss_G: 3.013258, loss_D: 0.188735\n",
      "[Epoch 113/200] [Batch 210/938] loss_G: 3.174279, loss_D: 0.185209\n",
      "[Epoch 113/200] [Batch 220/938] loss_G: 2.834145, loss_D: 0.245962\n",
      "[Epoch 113/200] [Batch 230/938] loss_G: 2.954870, loss_D: 0.216783\n",
      "[Epoch 113/200] [Batch 240/938] loss_G: 2.812743, loss_D: 0.200774\n",
      "[Epoch 113/200] [Batch 250/938] loss_G: 3.040997, loss_D: 0.161246\n",
      "[Epoch 113/200] [Batch 260/938] loss_G: 2.891158, loss_D: 0.160501\n",
      "[Epoch 113/200] [Batch 270/938] loss_G: 3.059656, loss_D: 0.234484\n",
      "[Epoch 113/200] [Batch 280/938] loss_G: 2.892111, loss_D: 0.153735\n",
      "[Epoch 113/200] [Batch 290/938] loss_G: 3.241464, loss_D: 0.226700\n",
      "[Epoch 113/200] [Batch 300/938] loss_G: 2.956258, loss_D: 0.136481\n",
      "[Epoch 113/200] [Batch 310/938] loss_G: 3.381596, loss_D: 0.215474\n",
      "[Epoch 113/200] [Batch 320/938] loss_G: 3.359125, loss_D: 0.175532\n",
      "[Epoch 113/200] [Batch 330/938] loss_G: 3.297373, loss_D: 0.207952\n",
      "[Epoch 113/200] [Batch 340/938] loss_G: 3.265545, loss_D: 0.145057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 113/200] [Batch 350/938] loss_G: 2.943304, loss_D: 0.198480\n",
      "[Epoch 113/200] [Batch 360/938] loss_G: 3.107801, loss_D: 0.213341\n",
      "[Epoch 113/200] [Batch 370/938] loss_G: 2.795609, loss_D: 0.185273\n",
      "[Epoch 113/200] [Batch 380/938] loss_G: 3.029724, loss_D: 0.200566\n",
      "[Epoch 113/200] [Batch 390/938] loss_G: 2.922051, loss_D: 0.189795\n",
      "[Epoch 113/200] [Batch 400/938] loss_G: 2.853758, loss_D: 0.247121\n",
      "[Epoch 113/200] [Batch 410/938] loss_G: 2.886859, loss_D: 0.290259\n",
      "[Epoch 113/200] [Batch 420/938] loss_G: 3.097796, loss_D: 0.199468\n",
      "[Epoch 113/200] [Batch 430/938] loss_G: 3.390920, loss_D: 0.187545\n",
      "[Epoch 113/200] [Batch 440/938] loss_G: 2.792479, loss_D: 0.256289\n",
      "[Epoch 113/200] [Batch 450/938] loss_G: 3.252213, loss_D: 0.208042\n",
      "[Epoch 113/200] [Batch 460/938] loss_G: 3.065469, loss_D: 0.267776\n",
      "[Epoch 113/200] [Batch 470/938] loss_G: 2.998218, loss_D: 0.285072\n",
      "[Epoch 113/200] [Batch 480/938] loss_G: 3.032671, loss_D: 0.199408\n",
      "[Epoch 113/200] [Batch 490/938] loss_G: 3.211937, loss_D: 0.224760\n",
      "[Epoch 113/200] [Batch 500/938] loss_G: 3.330900, loss_D: 0.204930\n",
      "[Epoch 113/200] [Batch 510/938] loss_G: 2.779800, loss_D: 0.280781\n",
      "[Epoch 113/200] [Batch 520/938] loss_G: 2.965067, loss_D: 0.218159\n",
      "[Epoch 113/200] [Batch 530/938] loss_G: 3.444646, loss_D: 0.195180\n",
      "[Epoch 113/200] [Batch 540/938] loss_G: 3.090755, loss_D: 0.162907\n",
      "[Epoch 113/200] [Batch 550/938] loss_G: 3.024274, loss_D: 0.196347\n",
      "[Epoch 113/200] [Batch 560/938] loss_G: 2.837991, loss_D: 0.288281\n",
      "[Epoch 113/200] [Batch 570/938] loss_G: 2.823508, loss_D: 0.215544\n",
      "[Epoch 113/200] [Batch 580/938] loss_G: 2.911936, loss_D: 0.220970\n",
      "[Epoch 113/200] [Batch 590/938] loss_G: 3.056269, loss_D: 0.190634\n",
      "[Epoch 113/200] [Batch 600/938] loss_G: 2.979425, loss_D: 0.197663\n",
      "[Epoch 113/200] [Batch 610/938] loss_G: 3.043203, loss_D: 0.250696\n",
      "[Epoch 113/200] [Batch 620/938] loss_G: 2.887191, loss_D: 0.216428\n",
      "[Epoch 113/200] [Batch 630/938] loss_G: 2.508163, loss_D: 0.207487\n",
      "[Epoch 113/200] [Batch 640/938] loss_G: 2.932541, loss_D: 0.204113\n",
      "[Epoch 113/200] [Batch 650/938] loss_G: 3.085156, loss_D: 0.232995\n",
      "[Epoch 113/200] [Batch 660/938] loss_G: 2.966583, loss_D: 0.221939\n",
      "[Epoch 113/200] [Batch 670/938] loss_G: 3.004105, loss_D: 0.175234\n",
      "[Epoch 113/200] [Batch 680/938] loss_G: 2.815489, loss_D: 0.176112\n",
      "[Epoch 113/200] [Batch 690/938] loss_G: 2.954371, loss_D: 0.302135\n",
      "[Epoch 113/200] [Batch 700/938] loss_G: 2.792986, loss_D: 0.218612\n",
      "[Epoch 113/200] [Batch 710/938] loss_G: 2.925215, loss_D: 0.208652\n",
      "[Epoch 113/200] [Batch 720/938] loss_G: 3.022674, loss_D: 0.251183\n",
      "[Epoch 113/200] [Batch 730/938] loss_G: 3.131194, loss_D: 0.125899\n",
      "[Epoch 113/200] [Batch 740/938] loss_G: 3.061584, loss_D: 0.320822\n",
      "[Epoch 113/200] [Batch 750/938] loss_G: 3.050141, loss_D: 0.177611\n",
      "[Epoch 113/200] [Batch 760/938] loss_G: 2.826190, loss_D: 0.198184\n",
      "[Epoch 113/200] [Batch 770/938] loss_G: 3.230042, loss_D: 0.207715\n",
      "[Epoch 113/200] [Batch 780/938] loss_G: 3.290025, loss_D: 0.153901\n",
      "[Epoch 113/200] [Batch 790/938] loss_G: 3.075951, loss_D: 0.158610\n",
      "[Epoch 113/200] [Batch 800/938] loss_G: 3.170208, loss_D: 0.243017\n",
      "[Epoch 113/200] [Batch 810/938] loss_G: 3.043217, loss_D: 0.186593\n",
      "[Epoch 113/200] [Batch 820/938] loss_G: 2.888155, loss_D: 0.117632\n",
      "[Epoch 113/200] [Batch 830/938] loss_G: 3.340364, loss_D: 0.196921\n",
      "[Epoch 113/200] [Batch 840/938] loss_G: 3.028445, loss_D: 0.234097\n",
      "[Epoch 113/200] [Batch 850/938] loss_G: 2.801686, loss_D: 0.197153\n",
      "[Epoch 113/200] [Batch 860/938] loss_G: 2.592260, loss_D: 0.321696\n",
      "[Epoch 113/200] [Batch 870/938] loss_G: 2.875198, loss_D: 0.234027\n",
      "[Epoch 113/200] [Batch 880/938] loss_G: 3.103559, loss_D: 0.298032\n",
      "[Epoch 113/200] [Batch 890/938] loss_G: 2.813524, loss_D: 0.259193\n",
      "[Epoch 113/200] [Batch 900/938] loss_G: 2.927214, loss_D: 0.200256\n",
      "[Epoch 113/200] [Batch 910/938] loss_G: 2.695264, loss_D: 0.220167\n",
      "[Epoch 113/200] [Batch 920/938] loss_G: 2.495237, loss_D: 0.195607\n",
      "[Epoch 113/200] [Batch 930/938] loss_G: 3.030086, loss_D: 0.230888\n",
      "[Epoch 114/200] [Batch 0/938] loss_G: 2.921764, loss_D: 0.204375\n",
      "[Epoch 114/200] [Batch 10/938] loss_G: 3.040151, loss_D: 0.164717\n",
      "[Epoch 114/200] [Batch 20/938] loss_G: 2.942080, loss_D: 0.225324\n",
      "[Epoch 114/200] [Batch 30/938] loss_G: 3.028570, loss_D: 0.170417\n",
      "[Epoch 114/200] [Batch 40/938] loss_G: 3.113300, loss_D: 0.184274\n",
      "[Epoch 114/200] [Batch 50/938] loss_G: 2.541235, loss_D: 0.317134\n",
      "[Epoch 114/200] [Batch 60/938] loss_G: 3.239013, loss_D: 0.150118\n",
      "[Epoch 114/200] [Batch 70/938] loss_G: 2.776660, loss_D: 0.342063\n",
      "[Epoch 114/200] [Batch 80/938] loss_G: 3.240712, loss_D: 0.173878\n",
      "[Epoch 114/200] [Batch 90/938] loss_G: 3.169578, loss_D: 0.232905\n",
      "[Epoch 114/200] [Batch 100/938] loss_G: 3.165454, loss_D: 0.237407\n",
      "[Epoch 114/200] [Batch 110/938] loss_G: 2.816884, loss_D: 0.280562\n",
      "[Epoch 114/200] [Batch 120/938] loss_G: 3.039824, loss_D: 0.254238\n",
      "[Epoch 114/200] [Batch 130/938] loss_G: 2.880166, loss_D: 0.240673\n",
      "[Epoch 114/200] [Batch 140/938] loss_G: 2.739002, loss_D: 0.231629\n",
      "[Epoch 114/200] [Batch 150/938] loss_G: 2.981669, loss_D: 0.226586\n",
      "[Epoch 114/200] [Batch 160/938] loss_G: 2.980742, loss_D: 0.222604\n",
      "[Epoch 114/200] [Batch 170/938] loss_G: 2.719385, loss_D: 0.175312\n",
      "[Epoch 114/200] [Batch 180/938] loss_G: 2.912437, loss_D: 0.258615\n",
      "[Epoch 114/200] [Batch 190/938] loss_G: 3.141310, loss_D: 0.185963\n",
      "[Epoch 114/200] [Batch 200/938] loss_G: 3.068781, loss_D: 0.169861\n",
      "[Epoch 114/200] [Batch 210/938] loss_G: 3.151690, loss_D: 0.162312\n",
      "[Epoch 114/200] [Batch 220/938] loss_G: 3.144629, loss_D: 0.258467\n",
      "[Epoch 114/200] [Batch 230/938] loss_G: 3.129344, loss_D: 0.245482\n",
      "[Epoch 114/200] [Batch 240/938] loss_G: 3.088878, loss_D: 0.240119\n",
      "[Epoch 114/200] [Batch 250/938] loss_G: 2.957240, loss_D: 0.166127\n",
      "[Epoch 114/200] [Batch 260/938] loss_G: 3.496638, loss_D: 0.185788\n",
      "[Epoch 114/200] [Batch 270/938] loss_G: 2.494547, loss_D: 0.365794\n",
      "[Epoch 114/200] [Batch 280/938] loss_G: 3.074604, loss_D: 0.143142\n",
      "[Epoch 114/200] [Batch 290/938] loss_G: 2.732069, loss_D: 0.256662\n",
      "[Epoch 114/200] [Batch 300/938] loss_G: 3.107330, loss_D: 0.190414\n",
      "[Epoch 114/200] [Batch 310/938] loss_G: 3.151826, loss_D: 0.211423\n",
      "[Epoch 114/200] [Batch 320/938] loss_G: 2.963519, loss_D: 0.130796\n",
      "[Epoch 114/200] [Batch 330/938] loss_G: 2.451223, loss_D: 0.252665\n",
      "[Epoch 114/200] [Batch 340/938] loss_G: 2.904670, loss_D: 0.197885\n",
      "[Epoch 114/200] [Batch 350/938] loss_G: 3.068889, loss_D: 0.227307\n",
      "[Epoch 114/200] [Batch 360/938] loss_G: 2.805442, loss_D: 0.290053\n",
      "[Epoch 114/200] [Batch 370/938] loss_G: 2.828551, loss_D: 0.174030\n",
      "[Epoch 114/200] [Batch 380/938] loss_G: 2.991774, loss_D: 0.183323\n",
      "[Epoch 114/200] [Batch 390/938] loss_G: 2.844523, loss_D: 0.204377\n",
      "[Epoch 114/200] [Batch 400/938] loss_G: 3.161865, loss_D: 0.211091\n",
      "[Epoch 114/200] [Batch 410/938] loss_G: 2.905861, loss_D: 0.150809\n",
      "[Epoch 114/200] [Batch 420/938] loss_G: 2.732987, loss_D: 0.307541\n",
      "[Epoch 114/200] [Batch 430/938] loss_G: 3.173687, loss_D: 0.154727\n",
      "[Epoch 114/200] [Batch 440/938] loss_G: 2.811691, loss_D: 0.214830\n",
      "[Epoch 114/200] [Batch 450/938] loss_G: 2.984994, loss_D: 0.233969\n",
      "[Epoch 114/200] [Batch 460/938] loss_G: 3.329197, loss_D: 0.162569\n",
      "[Epoch 114/200] [Batch 470/938] loss_G: 2.794313, loss_D: 0.200620\n",
      "[Epoch 114/200] [Batch 480/938] loss_G: 3.237793, loss_D: 0.100280\n",
      "[Epoch 114/200] [Batch 490/938] loss_G: 3.072193, loss_D: 0.164960\n",
      "[Epoch 114/200] [Batch 500/938] loss_G: 2.873887, loss_D: 0.189178\n",
      "[Epoch 114/200] [Batch 510/938] loss_G: 3.139892, loss_D: 0.367777\n",
      "[Epoch 114/200] [Batch 520/938] loss_G: 2.922904, loss_D: 0.253275\n",
      "[Epoch 114/200] [Batch 530/938] loss_G: 3.326529, loss_D: 0.267515\n",
      "[Epoch 114/200] [Batch 540/938] loss_G: 2.943305, loss_D: 0.194754\n",
      "[Epoch 114/200] [Batch 550/938] loss_G: 3.005851, loss_D: 0.305764\n",
      "[Epoch 114/200] [Batch 560/938] loss_G: 2.565083, loss_D: 0.255395\n",
      "[Epoch 114/200] [Batch 570/938] loss_G: 2.997540, loss_D: 0.159286\n",
      "[Epoch 114/200] [Batch 580/938] loss_G: 2.584612, loss_D: 0.328187\n",
      "[Epoch 114/200] [Batch 590/938] loss_G: 3.148918, loss_D: 0.191248\n",
      "[Epoch 114/200] [Batch 600/938] loss_G: 3.113618, loss_D: 0.230692\n",
      "[Epoch 114/200] [Batch 610/938] loss_G: 2.891252, loss_D: 0.227212\n",
      "[Epoch 114/200] [Batch 620/938] loss_G: 3.263582, loss_D: 0.228356\n",
      "[Epoch 114/200] [Batch 630/938] loss_G: 2.825987, loss_D: 0.190267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 114/200] [Batch 640/938] loss_G: 3.423058, loss_D: 0.246069\n",
      "[Epoch 114/200] [Batch 650/938] loss_G: 2.934302, loss_D: 0.171856\n",
      "[Epoch 114/200] [Batch 660/938] loss_G: 2.757762, loss_D: 0.135503\n",
      "[Epoch 114/200] [Batch 670/938] loss_G: 3.103595, loss_D: 0.216208\n",
      "[Epoch 114/200] [Batch 680/938] loss_G: 2.773044, loss_D: 0.255321\n",
      "[Epoch 114/200] [Batch 690/938] loss_G: 3.179209, loss_D: 0.244087\n",
      "[Epoch 114/200] [Batch 700/938] loss_G: 3.265185, loss_D: 0.268923\n",
      "[Epoch 114/200] [Batch 710/938] loss_G: 2.875325, loss_D: 0.181357\n",
      "[Epoch 114/200] [Batch 720/938] loss_G: 3.037214, loss_D: 0.240129\n",
      "[Epoch 114/200] [Batch 730/938] loss_G: 3.227169, loss_D: 0.197216\n",
      "[Epoch 114/200] [Batch 740/938] loss_G: 3.056754, loss_D: 0.245524\n",
      "[Epoch 114/200] [Batch 750/938] loss_G: 2.891125, loss_D: 0.144155\n",
      "[Epoch 114/200] [Batch 760/938] loss_G: 2.877123, loss_D: 0.214152\n",
      "[Epoch 114/200] [Batch 770/938] loss_G: 2.959826, loss_D: 0.294235\n",
      "[Epoch 114/200] [Batch 780/938] loss_G: 2.922123, loss_D: 0.278944\n",
      "[Epoch 114/200] [Batch 790/938] loss_G: 2.977398, loss_D: 0.183859\n",
      "[Epoch 114/200] [Batch 800/938] loss_G: 3.083086, loss_D: 0.186434\n",
      "[Epoch 114/200] [Batch 810/938] loss_G: 2.993072, loss_D: 0.235930\n",
      "[Epoch 114/200] [Batch 820/938] loss_G: 3.175609, loss_D: 0.198254\n",
      "[Epoch 114/200] [Batch 830/938] loss_G: 3.098721, loss_D: 0.136331\n",
      "[Epoch 114/200] [Batch 840/938] loss_G: 2.832554, loss_D: 0.249702\n",
      "[Epoch 114/200] [Batch 850/938] loss_G: 2.897339, loss_D: 0.267488\n",
      "[Epoch 114/200] [Batch 860/938] loss_G: 3.156774, loss_D: 0.214893\n",
      "[Epoch 114/200] [Batch 870/938] loss_G: 3.167393, loss_D: 0.209849\n",
      "[Epoch 114/200] [Batch 880/938] loss_G: 2.678219, loss_D: 0.252597\n",
      "[Epoch 114/200] [Batch 890/938] loss_G: 3.004294, loss_D: 0.214681\n",
      "[Epoch 114/200] [Batch 900/938] loss_G: 2.748573, loss_D: 0.239128\n",
      "[Epoch 114/200] [Batch 910/938] loss_G: 3.338488, loss_D: 0.191508\n",
      "[Epoch 114/200] [Batch 920/938] loss_G: 3.021936, loss_D: 0.277214\n",
      "[Epoch 114/200] [Batch 930/938] loss_G: 3.300996, loss_D: 0.253661\n",
      "[Epoch 115/200] [Batch 0/938] loss_G: 2.732755, loss_D: 0.163981\n",
      "[Epoch 115/200] [Batch 10/938] loss_G: 3.323279, loss_D: 0.211754\n",
      "[Epoch 115/200] [Batch 20/938] loss_G: 3.138909, loss_D: 0.167899\n",
      "[Epoch 115/200] [Batch 30/938] loss_G: 3.231925, loss_D: 0.204500\n",
      "[Epoch 115/200] [Batch 40/938] loss_G: 3.048640, loss_D: 0.171913\n",
      "[Epoch 115/200] [Batch 50/938] loss_G: 3.040903, loss_D: 0.122800\n",
      "[Epoch 115/200] [Batch 60/938] loss_G: 3.454741, loss_D: 0.128603\n",
      "[Epoch 115/200] [Batch 70/938] loss_G: 3.241828, loss_D: 0.163191\n",
      "[Epoch 115/200] [Batch 80/938] loss_G: 3.110448, loss_D: 0.154150\n",
      "[Epoch 115/200] [Batch 90/938] loss_G: 3.425923, loss_D: 0.144686\n",
      "[Epoch 115/200] [Batch 100/938] loss_G: 2.815557, loss_D: 0.211703\n",
      "[Epoch 115/200] [Batch 110/938] loss_G: 2.790373, loss_D: 0.189215\n",
      "[Epoch 115/200] [Batch 120/938] loss_G: 2.973413, loss_D: 0.260107\n",
      "[Epoch 115/200] [Batch 130/938] loss_G: 2.928565, loss_D: 0.180404\n",
      "[Epoch 115/200] [Batch 140/938] loss_G: 2.845049, loss_D: 0.260715\n",
      "[Epoch 115/200] [Batch 150/938] loss_G: 2.758501, loss_D: 0.213331\n",
      "[Epoch 115/200] [Batch 160/938] loss_G: 3.149573, loss_D: 0.298629\n",
      "[Epoch 115/200] [Batch 170/938] loss_G: 3.379491, loss_D: 0.187306\n",
      "[Epoch 115/200] [Batch 180/938] loss_G: 2.658607, loss_D: 0.205465\n",
      "[Epoch 115/200] [Batch 190/938] loss_G: 3.181816, loss_D: 0.156687\n",
      "[Epoch 115/200] [Batch 200/938] loss_G: 3.085636, loss_D: 0.180011\n",
      "[Epoch 115/200] [Batch 210/938] loss_G: 2.739739, loss_D: 0.270991\n",
      "[Epoch 115/200] [Batch 220/938] loss_G: 3.141617, loss_D: 0.150606\n",
      "[Epoch 115/200] [Batch 230/938] loss_G: 3.147312, loss_D: 0.257826\n",
      "[Epoch 115/200] [Batch 240/938] loss_G: 3.036747, loss_D: 0.153912\n",
      "[Epoch 115/200] [Batch 250/938] loss_G: 3.028640, loss_D: 0.135041\n",
      "[Epoch 115/200] [Batch 260/938] loss_G: 2.844527, loss_D: 0.149872\n",
      "[Epoch 115/200] [Batch 270/938] loss_G: 2.835869, loss_D: 0.176162\n",
      "[Epoch 115/200] [Batch 280/938] loss_G: 2.897786, loss_D: 0.155293\n",
      "[Epoch 115/200] [Batch 290/938] loss_G: 3.116693, loss_D: 0.093410\n",
      "[Epoch 115/200] [Batch 300/938] loss_G: 2.968156, loss_D: 0.226333\n",
      "[Epoch 115/200] [Batch 310/938] loss_G: 2.697967, loss_D: 0.182658\n",
      "[Epoch 115/200] [Batch 320/938] loss_G: 3.427060, loss_D: 0.197735\n",
      "[Epoch 115/200] [Batch 330/938] loss_G: 2.615704, loss_D: 0.140607\n",
      "[Epoch 115/200] [Batch 340/938] loss_G: 2.807897, loss_D: 0.161055\n",
      "[Epoch 115/200] [Batch 350/938] loss_G: 2.994988, loss_D: 0.145038\n",
      "[Epoch 115/200] [Batch 360/938] loss_G: 2.623833, loss_D: 0.211374\n",
      "[Epoch 115/200] [Batch 370/938] loss_G: 2.857292, loss_D: 0.196572\n",
      "[Epoch 115/200] [Batch 380/938] loss_G: 3.200532, loss_D: 0.210776\n",
      "[Epoch 115/200] [Batch 390/938] loss_G: 2.623092, loss_D: 0.250820\n",
      "[Epoch 115/200] [Batch 400/938] loss_G: 2.951019, loss_D: 0.203762\n",
      "[Epoch 115/200] [Batch 410/938] loss_G: 3.138875, loss_D: 0.155688\n",
      "[Epoch 115/200] [Batch 420/938] loss_G: 2.847208, loss_D: 0.226492\n",
      "[Epoch 115/200] [Batch 430/938] loss_G: 2.887144, loss_D: 0.234428\n",
      "[Epoch 115/200] [Batch 440/938] loss_G: 3.175728, loss_D: 0.202880\n",
      "[Epoch 115/200] [Batch 450/938] loss_G: 3.084215, loss_D: 0.217867\n",
      "[Epoch 115/200] [Batch 460/938] loss_G: 2.820896, loss_D: 0.212012\n",
      "[Epoch 115/200] [Batch 470/938] loss_G: 3.054889, loss_D: 0.265814\n",
      "[Epoch 115/200] [Batch 480/938] loss_G: 2.879524, loss_D: 0.232691\n",
      "[Epoch 115/200] [Batch 490/938] loss_G: 2.974198, loss_D: 0.265886\n",
      "[Epoch 115/200] [Batch 500/938] loss_G: 2.960482, loss_D: 0.294251\n",
      "[Epoch 115/200] [Batch 510/938] loss_G: 3.266129, loss_D: 0.238304\n",
      "[Epoch 115/200] [Batch 520/938] loss_G: 3.384687, loss_D: 0.166569\n",
      "[Epoch 115/200] [Batch 530/938] loss_G: 2.690626, loss_D: 0.143768\n",
      "[Epoch 115/200] [Batch 540/938] loss_G: 3.142656, loss_D: 0.356605\n",
      "[Epoch 115/200] [Batch 550/938] loss_G: 3.111723, loss_D: 0.261124\n",
      "[Epoch 115/200] [Batch 560/938] loss_G: 2.484120, loss_D: 0.171816\n",
      "[Epoch 115/200] [Batch 570/938] loss_G: 3.275017, loss_D: 0.183250\n",
      "[Epoch 115/200] [Batch 580/938] loss_G: 3.259914, loss_D: 0.170743\n",
      "[Epoch 115/200] [Batch 590/938] loss_G: 3.242552, loss_D: 0.177729\n",
      "[Epoch 115/200] [Batch 600/938] loss_G: 2.800975, loss_D: 0.367618\n",
      "[Epoch 115/200] [Batch 610/938] loss_G: 2.688627, loss_D: 0.191460\n",
      "[Epoch 115/200] [Batch 620/938] loss_G: 3.134978, loss_D: 0.206597\n",
      "[Epoch 115/200] [Batch 630/938] loss_G: 2.715128, loss_D: 0.170133\n",
      "[Epoch 115/200] [Batch 640/938] loss_G: 3.166864, loss_D: 0.189523\n",
      "[Epoch 115/200] [Batch 650/938] loss_G: 3.085263, loss_D: 0.185155\n",
      "[Epoch 115/200] [Batch 660/938] loss_G: 2.960843, loss_D: 0.191552\n",
      "[Epoch 115/200] [Batch 670/938] loss_G: 2.946221, loss_D: 0.194199\n",
      "[Epoch 115/200] [Batch 680/938] loss_G: 3.032973, loss_D: 0.174254\n",
      "[Epoch 115/200] [Batch 690/938] loss_G: 2.862310, loss_D: 0.289431\n",
      "[Epoch 115/200] [Batch 700/938] loss_G: 2.991356, loss_D: 0.249277\n",
      "[Epoch 115/200] [Batch 710/938] loss_G: 3.132787, loss_D: 0.190886\n",
      "[Epoch 115/200] [Batch 720/938] loss_G: 2.960024, loss_D: 0.188056\n",
      "[Epoch 115/200] [Batch 730/938] loss_G: 2.887405, loss_D: 0.245498\n",
      "[Epoch 115/200] [Batch 740/938] loss_G: 3.218377, loss_D: 0.149001\n",
      "[Epoch 115/200] [Batch 750/938] loss_G: 3.001481, loss_D: 0.297299\n",
      "[Epoch 115/200] [Batch 760/938] loss_G: 2.720373, loss_D: 0.270905\n",
      "[Epoch 115/200] [Batch 770/938] loss_G: 2.643845, loss_D: 0.250046\n",
      "[Epoch 115/200] [Batch 780/938] loss_G: 3.454827, loss_D: 0.126985\n",
      "[Epoch 115/200] [Batch 790/938] loss_G: 2.941563, loss_D: 0.195853\n",
      "[Epoch 115/200] [Batch 800/938] loss_G: 2.980477, loss_D: 0.206014\n",
      "[Epoch 115/200] [Batch 810/938] loss_G: 3.163963, loss_D: 0.205356\n",
      "[Epoch 115/200] [Batch 820/938] loss_G: 2.991057, loss_D: 0.120064\n",
      "[Epoch 115/200] [Batch 830/938] loss_G: 3.057279, loss_D: 0.221128\n",
      "[Epoch 115/200] [Batch 840/938] loss_G: 3.051083, loss_D: 0.186956\n",
      "[Epoch 115/200] [Batch 850/938] loss_G: 2.938717, loss_D: 0.257962\n",
      "[Epoch 115/200] [Batch 860/938] loss_G: 2.795996, loss_D: 0.232010\n",
      "[Epoch 115/200] [Batch 870/938] loss_G: 3.407431, loss_D: 0.159676\n",
      "[Epoch 115/200] [Batch 880/938] loss_G: 3.089352, loss_D: 0.170403\n",
      "[Epoch 115/200] [Batch 890/938] loss_G: 2.954127, loss_D: 0.235431\n",
      "[Epoch 115/200] [Batch 900/938] loss_G: 3.085920, loss_D: 0.219235\n",
      "[Epoch 115/200] [Batch 910/938] loss_G: 2.898959, loss_D: 0.172976\n",
      "[Epoch 115/200] [Batch 920/938] loss_G: 2.803444, loss_D: 0.275449\n",
      "[Epoch 115/200] [Batch 930/938] loss_G: 2.943844, loss_D: 0.199111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 116/200] [Batch 0/938] loss_G: 2.987492, loss_D: 0.246162\n",
      "[Epoch 116/200] [Batch 10/938] loss_G: 3.387830, loss_D: 0.162359\n",
      "[Epoch 116/200] [Batch 20/938] loss_G: 2.941456, loss_D: 0.262369\n",
      "[Epoch 116/200] [Batch 30/938] loss_G: 3.126667, loss_D: 0.234112\n",
      "[Epoch 116/200] [Batch 40/938] loss_G: 2.958530, loss_D: 0.150859\n",
      "[Epoch 116/200] [Batch 50/938] loss_G: 3.268414, loss_D: 0.174708\n",
      "[Epoch 116/200] [Batch 60/938] loss_G: 3.298044, loss_D: 0.143136\n",
      "[Epoch 116/200] [Batch 70/938] loss_G: 2.765379, loss_D: 0.264350\n",
      "[Epoch 116/200] [Batch 80/938] loss_G: 3.214908, loss_D: 0.168819\n",
      "[Epoch 116/200] [Batch 90/938] loss_G: 3.150639, loss_D: 0.276904\n",
      "[Epoch 116/200] [Batch 100/938] loss_G: 2.891153, loss_D: 0.207975\n",
      "[Epoch 116/200] [Batch 110/938] loss_G: 3.455699, loss_D: 0.190746\n",
      "[Epoch 116/200] [Batch 120/938] loss_G: 3.250532, loss_D: 0.339950\n",
      "[Epoch 116/200] [Batch 130/938] loss_G: 3.056387, loss_D: 0.150310\n",
      "[Epoch 116/200] [Batch 140/938] loss_G: 2.836059, loss_D: 0.291929\n",
      "[Epoch 116/200] [Batch 150/938] loss_G: 2.776923, loss_D: 0.241934\n",
      "[Epoch 116/200] [Batch 160/938] loss_G: 2.932652, loss_D: 0.218048\n",
      "[Epoch 116/200] [Batch 170/938] loss_G: 2.628072, loss_D: 0.278390\n",
      "[Epoch 116/200] [Batch 180/938] loss_G: 3.014715, loss_D: 0.174081\n",
      "[Epoch 116/200] [Batch 190/938] loss_G: 3.116402, loss_D: 0.193146\n",
      "[Epoch 116/200] [Batch 200/938] loss_G: 2.799030, loss_D: 0.253594\n",
      "[Epoch 116/200] [Batch 210/938] loss_G: 2.883776, loss_D: 0.251473\n",
      "[Epoch 116/200] [Batch 220/938] loss_G: 2.449833, loss_D: 0.287653\n",
      "[Epoch 116/200] [Batch 230/938] loss_G: 2.950373, loss_D: 0.185337\n",
      "[Epoch 116/200] [Batch 240/938] loss_G: 2.983384, loss_D: 0.229721\n",
      "[Epoch 116/200] [Batch 250/938] loss_G: 3.186524, loss_D: 0.280407\n",
      "[Epoch 116/200] [Batch 260/938] loss_G: 2.985925, loss_D: 0.285713\n",
      "[Epoch 116/200] [Batch 270/938] loss_G: 3.090132, loss_D: 0.213120\n",
      "[Epoch 116/200] [Batch 280/938] loss_G: 2.749480, loss_D: 0.193007\n",
      "[Epoch 116/200] [Batch 290/938] loss_G: 3.142111, loss_D: 0.135295\n",
      "[Epoch 116/200] [Batch 300/938] loss_G: 2.839039, loss_D: 0.201633\n",
      "[Epoch 116/200] [Batch 310/938] loss_G: 3.207200, loss_D: 0.181357\n",
      "[Epoch 116/200] [Batch 320/938] loss_G: 3.046395, loss_D: 0.191496\n",
      "[Epoch 116/200] [Batch 330/938] loss_G: 3.063204, loss_D: 0.126693\n",
      "[Epoch 116/200] [Batch 340/938] loss_G: 3.174327, loss_D: 0.223215\n",
      "[Epoch 116/200] [Batch 350/938] loss_G: 3.151618, loss_D: 0.160161\n",
      "[Epoch 116/200] [Batch 360/938] loss_G: 2.812177, loss_D: 0.234568\n",
      "[Epoch 116/200] [Batch 370/938] loss_G: 3.080417, loss_D: 0.147350\n",
      "[Epoch 116/200] [Batch 380/938] loss_G: 2.946764, loss_D: 0.212375\n",
      "[Epoch 116/200] [Batch 390/938] loss_G: 3.077472, loss_D: 0.205251\n",
      "[Epoch 116/200] [Batch 400/938] loss_G: 2.893091, loss_D: 0.224343\n",
      "[Epoch 116/200] [Batch 410/938] loss_G: 3.048945, loss_D: 0.146323\n",
      "[Epoch 116/200] [Batch 420/938] loss_G: 3.227305, loss_D: 0.261748\n",
      "[Epoch 116/200] [Batch 430/938] loss_G: 3.406560, loss_D: 0.168242\n",
      "[Epoch 116/200] [Batch 440/938] loss_G: 2.825991, loss_D: 0.224004\n",
      "[Epoch 116/200] [Batch 450/938] loss_G: 3.027203, loss_D: 0.179139\n",
      "[Epoch 116/200] [Batch 460/938] loss_G: 3.029683, loss_D: 0.201046\n",
      "[Epoch 116/200] [Batch 470/938] loss_G: 2.754455, loss_D: 0.210046\n",
      "[Epoch 116/200] [Batch 480/938] loss_G: 3.289159, loss_D: 0.176078\n",
      "[Epoch 116/200] [Batch 490/938] loss_G: 3.163671, loss_D: 0.221349\n",
      "[Epoch 116/200] [Batch 500/938] loss_G: 2.989322, loss_D: 0.205715\n",
      "[Epoch 116/200] [Batch 510/938] loss_G: 3.046269, loss_D: 0.169115\n",
      "[Epoch 116/200] [Batch 520/938] loss_G: 3.006843, loss_D: 0.204568\n",
      "[Epoch 116/200] [Batch 530/938] loss_G: 3.157341, loss_D: 0.152711\n",
      "[Epoch 116/200] [Batch 540/938] loss_G: 2.748726, loss_D: 0.248910\n",
      "[Epoch 116/200] [Batch 550/938] loss_G: 3.298860, loss_D: 0.206816\n",
      "[Epoch 116/200] [Batch 560/938] loss_G: 2.972308, loss_D: 0.153415\n",
      "[Epoch 116/200] [Batch 570/938] loss_G: 3.219164, loss_D: 0.180787\n",
      "[Epoch 116/200] [Batch 580/938] loss_G: 2.996278, loss_D: 0.191214\n",
      "[Epoch 116/200] [Batch 590/938] loss_G: 3.124309, loss_D: 0.163244\n",
      "[Epoch 116/200] [Batch 600/938] loss_G: 2.724462, loss_D: 0.163787\n",
      "[Epoch 116/200] [Batch 610/938] loss_G: 3.160969, loss_D: 0.154086\n",
      "[Epoch 116/200] [Batch 620/938] loss_G: 3.079320, loss_D: 0.166409\n",
      "[Epoch 116/200] [Batch 630/938] loss_G: 2.810615, loss_D: 0.239175\n",
      "[Epoch 116/200] [Batch 640/938] loss_G: 2.770770, loss_D: 0.237808\n",
      "[Epoch 116/200] [Batch 650/938] loss_G: 3.170801, loss_D: 0.224198\n",
      "[Epoch 116/200] [Batch 660/938] loss_G: 2.854263, loss_D: 0.325243\n",
      "[Epoch 116/200] [Batch 670/938] loss_G: 3.137535, loss_D: 0.200059\n",
      "[Epoch 116/200] [Batch 680/938] loss_G: 2.974884, loss_D: 0.164116\n",
      "[Epoch 116/200] [Batch 690/938] loss_G: 3.134489, loss_D: 0.237995\n",
      "[Epoch 116/200] [Batch 700/938] loss_G: 2.847215, loss_D: 0.167299\n",
      "[Epoch 116/200] [Batch 710/938] loss_G: 2.886189, loss_D: 0.147006\n",
      "[Epoch 116/200] [Batch 720/938] loss_G: 3.305587, loss_D: 0.187451\n",
      "[Epoch 116/200] [Batch 730/938] loss_G: 3.197680, loss_D: 0.196841\n",
      "[Epoch 116/200] [Batch 740/938] loss_G: 3.037728, loss_D: 0.168856\n",
      "[Epoch 116/200] [Batch 750/938] loss_G: 3.072062, loss_D: 0.308065\n",
      "[Epoch 116/200] [Batch 760/938] loss_G: 3.208769, loss_D: 0.145794\n",
      "[Epoch 116/200] [Batch 770/938] loss_G: 2.971148, loss_D: 0.168187\n",
      "[Epoch 116/200] [Batch 780/938] loss_G: 2.732800, loss_D: 0.243208\n",
      "[Epoch 116/200] [Batch 790/938] loss_G: 2.600668, loss_D: 0.232172\n",
      "[Epoch 116/200] [Batch 800/938] loss_G: 3.271868, loss_D: 0.166310\n",
      "[Epoch 116/200] [Batch 810/938] loss_G: 2.695753, loss_D: 0.290861\n",
      "[Epoch 116/200] [Batch 820/938] loss_G: 2.989798, loss_D: 0.183478\n",
      "[Epoch 116/200] [Batch 830/938] loss_G: 3.082094, loss_D: 0.235126\n",
      "[Epoch 116/200] [Batch 840/938] loss_G: 2.822919, loss_D: 0.209268\n",
      "[Epoch 116/200] [Batch 850/938] loss_G: 3.028962, loss_D: 0.249172\n",
      "[Epoch 116/200] [Batch 860/938] loss_G: 2.811107, loss_D: 0.194810\n",
      "[Epoch 116/200] [Batch 870/938] loss_G: 2.939725, loss_D: 0.172443\n",
      "[Epoch 116/200] [Batch 880/938] loss_G: 3.388560, loss_D: 0.224662\n",
      "[Epoch 116/200] [Batch 890/938] loss_G: 2.952253, loss_D: 0.276878\n",
      "[Epoch 116/200] [Batch 900/938] loss_G: 2.857361, loss_D: 0.199377\n",
      "[Epoch 116/200] [Batch 910/938] loss_G: 3.152254, loss_D: 0.241098\n",
      "[Epoch 116/200] [Batch 920/938] loss_G: 2.742894, loss_D: 0.235097\n",
      "[Epoch 116/200] [Batch 930/938] loss_G: 3.163219, loss_D: 0.254967\n",
      "[Epoch 117/200] [Batch 0/938] loss_G: 2.956270, loss_D: 0.360934\n",
      "[Epoch 117/200] [Batch 10/938] loss_G: 3.079111, loss_D: 0.119623\n",
      "[Epoch 117/200] [Batch 20/938] loss_G: 2.941456, loss_D: 0.207901\n",
      "[Epoch 117/200] [Batch 30/938] loss_G: 2.761686, loss_D: 0.180826\n",
      "[Epoch 117/200] [Batch 40/938] loss_G: 3.235955, loss_D: 0.153664\n",
      "[Epoch 117/200] [Batch 50/938] loss_G: 3.104944, loss_D: 0.170761\n",
      "[Epoch 117/200] [Batch 60/938] loss_G: 2.860305, loss_D: 0.220261\n",
      "[Epoch 117/200] [Batch 70/938] loss_G: 3.322809, loss_D: 0.212996\n",
      "[Epoch 117/200] [Batch 80/938] loss_G: 3.185516, loss_D: 0.225163\n",
      "[Epoch 117/200] [Batch 90/938] loss_G: 3.269889, loss_D: 0.282789\n",
      "[Epoch 117/200] [Batch 100/938] loss_G: 3.235075, loss_D: 0.168810\n",
      "[Epoch 117/200] [Batch 110/938] loss_G: 2.933709, loss_D: 0.253688\n",
      "[Epoch 117/200] [Batch 120/938] loss_G: 3.335527, loss_D: 0.249065\n",
      "[Epoch 117/200] [Batch 130/938] loss_G: 2.982159, loss_D: 0.158997\n",
      "[Epoch 117/200] [Batch 140/938] loss_G: 3.450822, loss_D: 0.168804\n",
      "[Epoch 117/200] [Batch 150/938] loss_G: 3.440296, loss_D: 0.195693\n",
      "[Epoch 117/200] [Batch 160/938] loss_G: 2.882856, loss_D: 0.192020\n",
      "[Epoch 117/200] [Batch 170/938] loss_G: 2.744398, loss_D: 0.197813\n",
      "[Epoch 117/200] [Batch 180/938] loss_G: 3.036076, loss_D: 0.123023\n",
      "[Epoch 117/200] [Batch 190/938] loss_G: 2.815698, loss_D: 0.256426\n",
      "[Epoch 117/200] [Batch 200/938] loss_G: 3.075616, loss_D: 0.186950\n",
      "[Epoch 117/200] [Batch 210/938] loss_G: 3.118035, loss_D: 0.240650\n",
      "[Epoch 117/200] [Batch 220/938] loss_G: 2.752502, loss_D: 0.217821\n",
      "[Epoch 117/200] [Batch 230/938] loss_G: 3.239183, loss_D: 0.212875\n",
      "[Epoch 117/200] [Batch 240/938] loss_G: 3.040622, loss_D: 0.191562\n",
      "[Epoch 117/200] [Batch 250/938] loss_G: 3.058215, loss_D: 0.226943\n",
      "[Epoch 117/200] [Batch 260/938] loss_G: 3.076234, loss_D: 0.145220\n",
      "[Epoch 117/200] [Batch 270/938] loss_G: 3.120315, loss_D: 0.231501\n",
      "[Epoch 117/200] [Batch 280/938] loss_G: 3.151720, loss_D: 0.161884\n",
      "[Epoch 117/200] [Batch 290/938] loss_G: 3.081769, loss_D: 0.206403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 117/200] [Batch 300/938] loss_G: 3.111352, loss_D: 0.274027\n",
      "[Epoch 117/200] [Batch 310/938] loss_G: 3.032871, loss_D: 0.320077\n",
      "[Epoch 117/200] [Batch 320/938] loss_G: 3.105844, loss_D: 0.178790\n",
      "[Epoch 117/200] [Batch 330/938] loss_G: 3.224208, loss_D: 0.220735\n",
      "[Epoch 117/200] [Batch 340/938] loss_G: 3.225841, loss_D: 0.187021\n",
      "[Epoch 117/200] [Batch 350/938] loss_G: 3.230279, loss_D: 0.169719\n",
      "[Epoch 117/200] [Batch 360/938] loss_G: 2.803572, loss_D: 0.192005\n",
      "[Epoch 117/200] [Batch 370/938] loss_G: 2.949732, loss_D: 0.209173\n",
      "[Epoch 117/200] [Batch 380/938] loss_G: 2.700248, loss_D: 0.231067\n",
      "[Epoch 117/200] [Batch 390/938] loss_G: 3.233274, loss_D: 0.196287\n",
      "[Epoch 117/200] [Batch 400/938] loss_G: 3.084600, loss_D: 0.219559\n",
      "[Epoch 117/200] [Batch 410/938] loss_G: 2.885845, loss_D: 0.223321\n",
      "[Epoch 117/200] [Batch 420/938] loss_G: 2.816103, loss_D: 0.174939\n",
      "[Epoch 117/200] [Batch 430/938] loss_G: 3.140085, loss_D: 0.242805\n",
      "[Epoch 117/200] [Batch 440/938] loss_G: 2.910947, loss_D: 0.197590\n",
      "[Epoch 117/200] [Batch 450/938] loss_G: 2.995752, loss_D: 0.348483\n",
      "[Epoch 117/200] [Batch 460/938] loss_G: 3.119280, loss_D: 0.144897\n",
      "[Epoch 117/200] [Batch 470/938] loss_G: 2.853212, loss_D: 0.256201\n",
      "[Epoch 117/200] [Batch 480/938] loss_G: 2.683819, loss_D: 0.305946\n",
      "[Epoch 117/200] [Batch 490/938] loss_G: 3.038270, loss_D: 0.294633\n",
      "[Epoch 117/200] [Batch 500/938] loss_G: 3.067538, loss_D: 0.218768\n",
      "[Epoch 117/200] [Batch 510/938] loss_G: 3.014588, loss_D: 0.246767\n",
      "[Epoch 117/200] [Batch 520/938] loss_G: 2.999293, loss_D: 0.209134\n",
      "[Epoch 117/200] [Batch 530/938] loss_G: 2.905176, loss_D: 0.193269\n",
      "[Epoch 117/200] [Batch 540/938] loss_G: 2.604344, loss_D: 0.233968\n",
      "[Epoch 117/200] [Batch 550/938] loss_G: 2.985666, loss_D: 0.281503\n",
      "[Epoch 117/200] [Batch 560/938] loss_G: 3.050931, loss_D: 0.128757\n",
      "[Epoch 117/200] [Batch 570/938] loss_G: 3.342093, loss_D: 0.289884\n",
      "[Epoch 117/200] [Batch 580/938] loss_G: 3.221076, loss_D: 0.184380\n",
      "[Epoch 117/200] [Batch 590/938] loss_G: 3.340230, loss_D: 0.134344\n",
      "[Epoch 117/200] [Batch 600/938] loss_G: 2.641907, loss_D: 0.188978\n",
      "[Epoch 117/200] [Batch 610/938] loss_G: 2.954900, loss_D: 0.174636\n",
      "[Epoch 117/200] [Batch 620/938] loss_G: 3.088770, loss_D: 0.295587\n",
      "[Epoch 117/200] [Batch 630/938] loss_G: 3.127321, loss_D: 0.216726\n",
      "[Epoch 117/200] [Batch 640/938] loss_G: 2.901916, loss_D: 0.165153\n",
      "[Epoch 117/200] [Batch 650/938] loss_G: 2.788836, loss_D: 0.209615\n",
      "[Epoch 117/200] [Batch 660/938] loss_G: 2.861301, loss_D: 0.282612\n",
      "[Epoch 117/200] [Batch 670/938] loss_G: 2.956250, loss_D: 0.211663\n",
      "[Epoch 117/200] [Batch 680/938] loss_G: 2.860908, loss_D: 0.202388\n",
      "[Epoch 117/200] [Batch 690/938] loss_G: 2.672820, loss_D: 0.265414\n",
      "[Epoch 117/200] [Batch 700/938] loss_G: 3.057675, loss_D: 0.206542\n",
      "[Epoch 117/200] [Batch 710/938] loss_G: 3.011207, loss_D: 0.165201\n",
      "[Epoch 117/200] [Batch 720/938] loss_G: 2.953761, loss_D: 0.205063\n",
      "[Epoch 117/200] [Batch 730/938] loss_G: 2.990275, loss_D: 0.236308\n",
      "[Epoch 117/200] [Batch 740/938] loss_G: 2.820289, loss_D: 0.249991\n",
      "[Epoch 117/200] [Batch 750/938] loss_G: 3.542131, loss_D: 0.194874\n",
      "[Epoch 117/200] [Batch 760/938] loss_G: 2.791518, loss_D: 0.224471\n",
      "[Epoch 117/200] [Batch 770/938] loss_G: 3.569368, loss_D: 0.211083\n",
      "[Epoch 117/200] [Batch 780/938] loss_G: 3.395913, loss_D: 0.219399\n",
      "[Epoch 117/200] [Batch 790/938] loss_G: 3.100779, loss_D: 0.191695\n",
      "[Epoch 117/200] [Batch 800/938] loss_G: 2.919952, loss_D: 0.211987\n",
      "[Epoch 117/200] [Batch 810/938] loss_G: 2.929756, loss_D: 0.202144\n",
      "[Epoch 117/200] [Batch 820/938] loss_G: 2.522282, loss_D: 0.311741\n",
      "[Epoch 117/200] [Batch 830/938] loss_G: 3.052162, loss_D: 0.161034\n",
      "[Epoch 117/200] [Batch 840/938] loss_G: 2.766047, loss_D: 0.185800\n",
      "[Epoch 117/200] [Batch 850/938] loss_G: 3.231726, loss_D: 0.202780\n",
      "[Epoch 117/200] [Batch 860/938] loss_G: 3.156769, loss_D: 0.211109\n",
      "[Epoch 117/200] [Batch 870/938] loss_G: 3.338065, loss_D: 0.265562\n",
      "[Epoch 117/200] [Batch 880/938] loss_G: 3.183385, loss_D: 0.132571\n",
      "[Epoch 117/200] [Batch 890/938] loss_G: 3.123022, loss_D: 0.279328\n",
      "[Epoch 117/200] [Batch 900/938] loss_G: 3.072230, loss_D: 0.184711\n",
      "[Epoch 117/200] [Batch 910/938] loss_G: 2.937277, loss_D: 0.128992\n",
      "[Epoch 117/200] [Batch 920/938] loss_G: 2.708475, loss_D: 0.191235\n",
      "[Epoch 117/200] [Batch 930/938] loss_G: 2.889512, loss_D: 0.193229\n",
      "[Epoch 118/200] [Batch 0/938] loss_G: 2.834962, loss_D: 0.140522\n",
      "[Epoch 118/200] [Batch 10/938] loss_G: 3.197292, loss_D: 0.209055\n",
      "[Epoch 118/200] [Batch 20/938] loss_G: 3.137726, loss_D: 0.253334\n",
      "[Epoch 118/200] [Batch 30/938] loss_G: 2.942847, loss_D: 0.261745\n",
      "[Epoch 118/200] [Batch 40/938] loss_G: 3.326546, loss_D: 0.194826\n",
      "[Epoch 118/200] [Batch 50/938] loss_G: 2.972178, loss_D: 0.186484\n",
      "[Epoch 118/200] [Batch 60/938] loss_G: 3.041375, loss_D: 0.218514\n",
      "[Epoch 118/200] [Batch 70/938] loss_G: 3.311365, loss_D: 0.135663\n",
      "[Epoch 118/200] [Batch 80/938] loss_G: 3.134454, loss_D: 0.170524\n",
      "[Epoch 118/200] [Batch 90/938] loss_G: 3.174008, loss_D: 0.285800\n",
      "[Epoch 118/200] [Batch 100/938] loss_G: 2.974448, loss_D: 0.211126\n",
      "[Epoch 118/200] [Batch 110/938] loss_G: 3.226753, loss_D: 0.190373\n",
      "[Epoch 118/200] [Batch 120/938] loss_G: 3.250974, loss_D: 0.195181\n",
      "[Epoch 118/200] [Batch 130/938] loss_G: 3.119987, loss_D: 0.184437\n",
      "[Epoch 118/200] [Batch 140/938] loss_G: 2.893351, loss_D: 0.214387\n",
      "[Epoch 118/200] [Batch 150/938] loss_G: 3.199876, loss_D: 0.242708\n",
      "[Epoch 118/200] [Batch 160/938] loss_G: 2.981004, loss_D: 0.212590\n",
      "[Epoch 118/200] [Batch 170/938] loss_G: 3.100320, loss_D: 0.260092\n",
      "[Epoch 118/200] [Batch 180/938] loss_G: 3.533234, loss_D: 0.197630\n",
      "[Epoch 118/200] [Batch 190/938] loss_G: 3.340428, loss_D: 0.115724\n",
      "[Epoch 118/200] [Batch 200/938] loss_G: 3.193366, loss_D: 0.158963\n",
      "[Epoch 118/200] [Batch 210/938] loss_G: 2.743899, loss_D: 0.146087\n",
      "[Epoch 118/200] [Batch 220/938] loss_G: 2.696525, loss_D: 0.299822\n",
      "[Epoch 118/200] [Batch 230/938] loss_G: 2.874647, loss_D: 0.189447\n",
      "[Epoch 118/200] [Batch 240/938] loss_G: 2.998075, loss_D: 0.111202\n",
      "[Epoch 118/200] [Batch 250/938] loss_G: 3.147368, loss_D: 0.267364\n",
      "[Epoch 118/200] [Batch 260/938] loss_G: 2.998217, loss_D: 0.220756\n",
      "[Epoch 118/200] [Batch 270/938] loss_G: 3.100175, loss_D: 0.378771\n",
      "[Epoch 118/200] [Batch 280/938] loss_G: 3.103404, loss_D: 0.175317\n",
      "[Epoch 118/200] [Batch 290/938] loss_G: 3.388715, loss_D: 0.169448\n",
      "[Epoch 118/200] [Batch 300/938] loss_G: 3.177149, loss_D: 0.241065\n",
      "[Epoch 118/200] [Batch 310/938] loss_G: 3.223931, loss_D: 0.140821\n",
      "[Epoch 118/200] [Batch 320/938] loss_G: 3.177913, loss_D: 0.308448\n",
      "[Epoch 118/200] [Batch 330/938] loss_G: 3.368864, loss_D: 0.133975\n",
      "[Epoch 118/200] [Batch 340/938] loss_G: 3.447934, loss_D: 0.189320\n",
      "[Epoch 118/200] [Batch 350/938] loss_G: 3.137990, loss_D: 0.246875\n",
      "[Epoch 118/200] [Batch 360/938] loss_G: 3.490190, loss_D: 0.216647\n",
      "[Epoch 118/200] [Batch 370/938] loss_G: 3.245850, loss_D: 0.184737\n",
      "[Epoch 118/200] [Batch 380/938] loss_G: 2.703022, loss_D: 0.237596\n",
      "[Epoch 118/200] [Batch 390/938] loss_G: 2.874716, loss_D: 0.235449\n",
      "[Epoch 118/200] [Batch 400/938] loss_G: 3.098310, loss_D: 0.215555\n",
      "[Epoch 118/200] [Batch 410/938] loss_G: 3.195390, loss_D: 0.272442\n",
      "[Epoch 118/200] [Batch 420/938] loss_G: 3.372625, loss_D: 0.226608\n",
      "[Epoch 118/200] [Batch 430/938] loss_G: 3.039989, loss_D: 0.217968\n",
      "[Epoch 118/200] [Batch 440/938] loss_G: 3.264378, loss_D: 0.176452\n",
      "[Epoch 118/200] [Batch 450/938] loss_G: 2.918380, loss_D: 0.313689\n",
      "[Epoch 118/200] [Batch 460/938] loss_G: 3.221670, loss_D: 0.289892\n",
      "[Epoch 118/200] [Batch 470/938] loss_G: 3.419109, loss_D: 0.199082\n",
      "[Epoch 118/200] [Batch 480/938] loss_G: 3.091709, loss_D: 0.241656\n",
      "[Epoch 118/200] [Batch 490/938] loss_G: 3.218646, loss_D: 0.152278\n",
      "[Epoch 118/200] [Batch 500/938] loss_G: 3.081761, loss_D: 0.271785\n",
      "[Epoch 118/200] [Batch 510/938] loss_G: 2.831829, loss_D: 0.175460\n",
      "[Epoch 118/200] [Batch 520/938] loss_G: 2.864599, loss_D: 0.212649\n",
      "[Epoch 118/200] [Batch 530/938] loss_G: 3.029978, loss_D: 0.218686\n",
      "[Epoch 118/200] [Batch 540/938] loss_G: 3.082845, loss_D: 0.182112\n",
      "[Epoch 118/200] [Batch 550/938] loss_G: 3.018678, loss_D: 0.172865\n",
      "[Epoch 118/200] [Batch 560/938] loss_G: 2.829548, loss_D: 0.219086\n",
      "[Epoch 118/200] [Batch 570/938] loss_G: 2.830369, loss_D: 0.207670\n",
      "[Epoch 118/200] [Batch 580/938] loss_G: 2.747561, loss_D: 0.241477\n",
      "[Epoch 118/200] [Batch 590/938] loss_G: 3.085980, loss_D: 0.205859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 118/200] [Batch 600/938] loss_G: 3.099613, loss_D: 0.167170\n",
      "[Epoch 118/200] [Batch 610/938] loss_G: 3.180488, loss_D: 0.216021\n",
      "[Epoch 118/200] [Batch 620/938] loss_G: 3.043360, loss_D: 0.150132\n",
      "[Epoch 118/200] [Batch 630/938] loss_G: 2.887715, loss_D: 0.180515\n",
      "[Epoch 118/200] [Batch 640/938] loss_G: 2.980687, loss_D: 0.160472\n",
      "[Epoch 118/200] [Batch 650/938] loss_G: 3.078135, loss_D: 0.153606\n",
      "[Epoch 118/200] [Batch 660/938] loss_G: 2.918559, loss_D: 0.170609\n",
      "[Epoch 118/200] [Batch 670/938] loss_G: 3.468262, loss_D: 0.139218\n",
      "[Epoch 118/200] [Batch 680/938] loss_G: 3.065572, loss_D: 0.126158\n",
      "[Epoch 118/200] [Batch 690/938] loss_G: 2.979584, loss_D: 0.260492\n",
      "[Epoch 118/200] [Batch 700/938] loss_G: 3.341253, loss_D: 0.134181\n",
      "[Epoch 118/200] [Batch 710/938] loss_G: 2.765062, loss_D: 0.163220\n",
      "[Epoch 118/200] [Batch 720/938] loss_G: 3.054231, loss_D: 0.209945\n",
      "[Epoch 118/200] [Batch 730/938] loss_G: 2.640694, loss_D: 0.282088\n",
      "[Epoch 118/200] [Batch 740/938] loss_G: 2.886340, loss_D: 0.209691\n",
      "[Epoch 118/200] [Batch 750/938] loss_G: 3.294963, loss_D: 0.243964\n",
      "[Epoch 118/200] [Batch 760/938] loss_G: 2.961695, loss_D: 0.153288\n",
      "[Epoch 118/200] [Batch 770/938] loss_G: 2.693742, loss_D: 0.164665\n",
      "[Epoch 118/200] [Batch 780/938] loss_G: 2.831340, loss_D: 0.218625\n",
      "[Epoch 118/200] [Batch 790/938] loss_G: 3.299007, loss_D: 0.237008\n",
      "[Epoch 118/200] [Batch 800/938] loss_G: 3.273340, loss_D: 0.169953\n",
      "[Epoch 118/200] [Batch 810/938] loss_G: 2.944986, loss_D: 0.241322\n",
      "[Epoch 118/200] [Batch 820/938] loss_G: 3.322289, loss_D: 0.152598\n",
      "[Epoch 118/200] [Batch 830/938] loss_G: 3.365944, loss_D: 0.126948\n",
      "[Epoch 118/200] [Batch 840/938] loss_G: 3.035855, loss_D: 0.127880\n",
      "[Epoch 118/200] [Batch 850/938] loss_G: 3.287700, loss_D: 0.172175\n",
      "[Epoch 118/200] [Batch 860/938] loss_G: 2.911464, loss_D: 0.210955\n",
      "[Epoch 118/200] [Batch 870/938] loss_G: 3.115162, loss_D: 0.193006\n",
      "[Epoch 118/200] [Batch 880/938] loss_G: 3.125962, loss_D: 0.156262\n",
      "[Epoch 118/200] [Batch 890/938] loss_G: 2.941690, loss_D: 0.134171\n",
      "[Epoch 118/200] [Batch 900/938] loss_G: 2.929013, loss_D: 0.218757\n",
      "[Epoch 118/200] [Batch 910/938] loss_G: 3.346318, loss_D: 0.198403\n",
      "[Epoch 118/200] [Batch 920/938] loss_G: 3.036223, loss_D: 0.187201\n",
      "[Epoch 118/200] [Batch 930/938] loss_G: 2.806273, loss_D: 0.222364\n",
      "[Epoch 119/200] [Batch 0/938] loss_G: 2.937097, loss_D: 0.182360\n",
      "[Epoch 119/200] [Batch 10/938] loss_G: 2.943218, loss_D: 0.154570\n",
      "[Epoch 119/200] [Batch 20/938] loss_G: 3.270996, loss_D: 0.189511\n",
      "[Epoch 119/200] [Batch 30/938] loss_G: 3.092622, loss_D: 0.250731\n",
      "[Epoch 119/200] [Batch 40/938] loss_G: 2.966849, loss_D: 0.154870\n",
      "[Epoch 119/200] [Batch 50/938] loss_G: 3.198393, loss_D: 0.159210\n",
      "[Epoch 119/200] [Batch 60/938] loss_G: 3.641132, loss_D: 0.185069\n",
      "[Epoch 119/200] [Batch 70/938] loss_G: 2.735191, loss_D: 0.147924\n",
      "[Epoch 119/200] [Batch 80/938] loss_G: 3.053030, loss_D: 0.379111\n",
      "[Epoch 119/200] [Batch 90/938] loss_G: 2.911644, loss_D: 0.172361\n",
      "[Epoch 119/200] [Batch 100/938] loss_G: 3.188592, loss_D: 0.190317\n",
      "[Epoch 119/200] [Batch 110/938] loss_G: 3.138419, loss_D: 0.145822\n",
      "[Epoch 119/200] [Batch 120/938] loss_G: 3.283064, loss_D: 0.187338\n",
      "[Epoch 119/200] [Batch 130/938] loss_G: 2.859507, loss_D: 0.188274\n",
      "[Epoch 119/200] [Batch 140/938] loss_G: 3.344383, loss_D: 0.261037\n",
      "[Epoch 119/200] [Batch 150/938] loss_G: 3.331129, loss_D: 0.178677\n",
      "[Epoch 119/200] [Batch 160/938] loss_G: 3.102672, loss_D: 0.209024\n",
      "[Epoch 119/200] [Batch 170/938] loss_G: 3.163383, loss_D: 0.240084\n",
      "[Epoch 119/200] [Batch 180/938] loss_G: 3.393020, loss_D: 0.156616\n",
      "[Epoch 119/200] [Batch 190/938] loss_G: 3.558269, loss_D: 0.357280\n",
      "[Epoch 119/200] [Batch 200/938] loss_G: 3.236143, loss_D: 0.204297\n",
      "[Epoch 119/200] [Batch 210/938] loss_G: 2.861955, loss_D: 0.270789\n",
      "[Epoch 119/200] [Batch 220/938] loss_G: 3.191048, loss_D: 0.203581\n",
      "[Epoch 119/200] [Batch 230/938] loss_G: 3.087350, loss_D: 0.198104\n",
      "[Epoch 119/200] [Batch 240/938] loss_G: 3.188168, loss_D: 0.175317\n",
      "[Epoch 119/200] [Batch 250/938] loss_G: 2.861143, loss_D: 0.280052\n",
      "[Epoch 119/200] [Batch 260/938] loss_G: 3.268405, loss_D: 0.185620\n",
      "[Epoch 119/200] [Batch 270/938] loss_G: 2.970992, loss_D: 0.293514\n",
      "[Epoch 119/200] [Batch 280/938] loss_G: 3.220460, loss_D: 0.193749\n",
      "[Epoch 119/200] [Batch 290/938] loss_G: 2.833320, loss_D: 0.201041\n",
      "[Epoch 119/200] [Batch 300/938] loss_G: 3.475562, loss_D: 0.239004\n",
      "[Epoch 119/200] [Batch 310/938] loss_G: 3.171793, loss_D: 0.332857\n",
      "[Epoch 119/200] [Batch 320/938] loss_G: 3.340561, loss_D: 0.235762\n",
      "[Epoch 119/200] [Batch 330/938] loss_G: 2.929093, loss_D: 0.243108\n",
      "[Epoch 119/200] [Batch 340/938] loss_G: 3.240171, loss_D: 0.203128\n",
      "[Epoch 119/200] [Batch 350/938] loss_G: 2.966525, loss_D: 0.213431\n",
      "[Epoch 119/200] [Batch 360/938] loss_G: 2.741882, loss_D: 0.219012\n",
      "[Epoch 119/200] [Batch 370/938] loss_G: 2.867115, loss_D: 0.187446\n",
      "[Epoch 119/200] [Batch 380/938] loss_G: 3.140129, loss_D: 0.277776\n",
      "[Epoch 119/200] [Batch 390/938] loss_G: 3.021846, loss_D: 0.198790\n",
      "[Epoch 119/200] [Batch 400/938] loss_G: 3.044364, loss_D: 0.213779\n",
      "[Epoch 119/200] [Batch 410/938] loss_G: 2.780934, loss_D: 0.225163\n",
      "[Epoch 119/200] [Batch 420/938] loss_G: 3.009721, loss_D: 0.183101\n",
      "[Epoch 119/200] [Batch 430/938] loss_G: 3.065138, loss_D: 0.132617\n",
      "[Epoch 119/200] [Batch 440/938] loss_G: 3.013231, loss_D: 0.208530\n",
      "[Epoch 119/200] [Batch 450/938] loss_G: 3.229480, loss_D: 0.244533\n",
      "[Epoch 119/200] [Batch 460/938] loss_G: 3.061325, loss_D: 0.172320\n",
      "[Epoch 119/200] [Batch 470/938] loss_G: 2.734431, loss_D: 0.161053\n",
      "[Epoch 119/200] [Batch 480/938] loss_G: 3.117406, loss_D: 0.230194\n",
      "[Epoch 119/200] [Batch 490/938] loss_G: 2.873314, loss_D: 0.276088\n",
      "[Epoch 119/200] [Batch 500/938] loss_G: 2.860033, loss_D: 0.208838\n",
      "[Epoch 119/200] [Batch 510/938] loss_G: 2.469473, loss_D: 0.176732\n",
      "[Epoch 119/200] [Batch 520/938] loss_G: 3.125739, loss_D: 0.168009\n",
      "[Epoch 119/200] [Batch 530/938] loss_G: 2.904866, loss_D: 0.264262\n",
      "[Epoch 119/200] [Batch 540/938] loss_G: 3.202862, loss_D: 0.194364\n",
      "[Epoch 119/200] [Batch 550/938] loss_G: 2.910063, loss_D: 0.217261\n",
      "[Epoch 119/200] [Batch 560/938] loss_G: 3.081784, loss_D: 0.117991\n",
      "[Epoch 119/200] [Batch 570/938] loss_G: 2.801955, loss_D: 0.210471\n",
      "[Epoch 119/200] [Batch 580/938] loss_G: 2.794558, loss_D: 0.141757\n",
      "[Epoch 119/200] [Batch 590/938] loss_G: 2.857324, loss_D: 0.203204\n",
      "[Epoch 119/200] [Batch 600/938] loss_G: 3.085284, loss_D: 0.160664\n",
      "[Epoch 119/200] [Batch 610/938] loss_G: 3.047424, loss_D: 0.179426\n",
      "[Epoch 119/200] [Batch 620/938] loss_G: 3.213538, loss_D: 0.184361\n",
      "[Epoch 119/200] [Batch 630/938] loss_G: 3.085096, loss_D: 0.219116\n",
      "[Epoch 119/200] [Batch 640/938] loss_G: 3.103441, loss_D: 0.167201\n",
      "[Epoch 119/200] [Batch 650/938] loss_G: 3.319535, loss_D: 0.183447\n",
      "[Epoch 119/200] [Batch 660/938] loss_G: 3.083935, loss_D: 0.171311\n",
      "[Epoch 119/200] [Batch 670/938] loss_G: 2.959972, loss_D: 0.232246\n",
      "[Epoch 119/200] [Batch 680/938] loss_G: 3.009505, loss_D: 0.265949\n",
      "[Epoch 119/200] [Batch 690/938] loss_G: 2.684776, loss_D: 0.247012\n",
      "[Epoch 119/200] [Batch 700/938] loss_G: 3.117720, loss_D: 0.257675\n",
      "[Epoch 119/200] [Batch 710/938] loss_G: 2.888747, loss_D: 0.166310\n",
      "[Epoch 119/200] [Batch 720/938] loss_G: 3.077860, loss_D: 0.247774\n",
      "[Epoch 119/200] [Batch 730/938] loss_G: 3.085120, loss_D: 0.231239\n",
      "[Epoch 119/200] [Batch 740/938] loss_G: 3.022487, loss_D: 0.175247\n",
      "[Epoch 119/200] [Batch 750/938] loss_G: 2.899454, loss_D: 0.249522\n",
      "[Epoch 119/200] [Batch 760/938] loss_G: 3.182336, loss_D: 0.211040\n",
      "[Epoch 119/200] [Batch 770/938] loss_G: 2.806011, loss_D: 0.126708\n",
      "[Epoch 119/200] [Batch 780/938] loss_G: 3.283832, loss_D: 0.254522\n",
      "[Epoch 119/200] [Batch 790/938] loss_G: 2.958102, loss_D: 0.181548\n",
      "[Epoch 119/200] [Batch 800/938] loss_G: 3.265738, loss_D: 0.204749\n",
      "[Epoch 119/200] [Batch 810/938] loss_G: 3.535257, loss_D: 0.183838\n",
      "[Epoch 119/200] [Batch 820/938] loss_G: 2.427535, loss_D: 0.322911\n",
      "[Epoch 119/200] [Batch 830/938] loss_G: 3.024018, loss_D: 0.159765\n",
      "[Epoch 119/200] [Batch 840/938] loss_G: 2.948883, loss_D: 0.180123\n",
      "[Epoch 119/200] [Batch 850/938] loss_G: 2.988943, loss_D: 0.145957\n",
      "[Epoch 119/200] [Batch 860/938] loss_G: 3.023184, loss_D: 0.210834\n",
      "[Epoch 119/200] [Batch 870/938] loss_G: 2.906222, loss_D: 0.237196\n",
      "[Epoch 119/200] [Batch 880/938] loss_G: 2.765540, loss_D: 0.201816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 119/200] [Batch 890/938] loss_G: 3.018128, loss_D: 0.179902\n",
      "[Epoch 119/200] [Batch 900/938] loss_G: 3.112452, loss_D: 0.132266\n",
      "[Epoch 119/200] [Batch 910/938] loss_G: 2.922225, loss_D: 0.222345\n",
      "[Epoch 119/200] [Batch 920/938] loss_G: 2.735805, loss_D: 0.215435\n",
      "[Epoch 119/200] [Batch 930/938] loss_G: 3.384370, loss_D: 0.143853\n",
      "[Epoch 120/200] [Batch 0/938] loss_G: 3.557639, loss_D: 0.220365\n",
      "[Epoch 120/200] [Batch 10/938] loss_G: 2.710456, loss_D: 0.183348\n",
      "[Epoch 120/200] [Batch 20/938] loss_G: 3.218565, loss_D: 0.225965\n",
      "[Epoch 120/200] [Batch 30/938] loss_G: 3.173542, loss_D: 0.218557\n",
      "[Epoch 120/200] [Batch 40/938] loss_G: 3.047872, loss_D: 0.200496\n",
      "[Epoch 120/200] [Batch 50/938] loss_G: 3.495842, loss_D: 0.126000\n",
      "[Epoch 120/200] [Batch 60/938] loss_G: 3.261423, loss_D: 0.200323\n",
      "[Epoch 120/200] [Batch 70/938] loss_G: 3.334203, loss_D: 0.194541\n",
      "[Epoch 120/200] [Batch 80/938] loss_G: 3.254039, loss_D: 0.223791\n",
      "[Epoch 120/200] [Batch 90/938] loss_G: 2.744453, loss_D: 0.211248\n",
      "[Epoch 120/200] [Batch 100/938] loss_G: 3.215285, loss_D: 0.248164\n",
      "[Epoch 120/200] [Batch 110/938] loss_G: 3.260463, loss_D: 0.177798\n",
      "[Epoch 120/200] [Batch 120/938] loss_G: 2.841681, loss_D: 0.195319\n",
      "[Epoch 120/200] [Batch 130/938] loss_G: 3.087266, loss_D: 0.239330\n",
      "[Epoch 120/200] [Batch 140/938] loss_G: 3.162126, loss_D: 0.251649\n",
      "[Epoch 120/200] [Batch 150/938] loss_G: 2.891276, loss_D: 0.188142\n",
      "[Epoch 120/200] [Batch 160/938] loss_G: 3.488753, loss_D: 0.158296\n",
      "[Epoch 120/200] [Batch 170/938] loss_G: 3.102474, loss_D: 0.173297\n",
      "[Epoch 120/200] [Batch 180/938] loss_G: 3.099764, loss_D: 0.227329\n",
      "[Epoch 120/200] [Batch 190/938] loss_G: 3.071085, loss_D: 0.218579\n",
      "[Epoch 120/200] [Batch 200/938] loss_G: 3.090561, loss_D: 0.203121\n",
      "[Epoch 120/200] [Batch 210/938] loss_G: 3.491425, loss_D: 0.288521\n",
      "[Epoch 120/200] [Batch 220/938] loss_G: 2.976955, loss_D: 0.220701\n",
      "[Epoch 120/200] [Batch 230/938] loss_G: 3.204346, loss_D: 0.166615\n",
      "[Epoch 120/200] [Batch 240/938] loss_G: 2.864184, loss_D: 0.184423\n",
      "[Epoch 120/200] [Batch 250/938] loss_G: 3.369188, loss_D: 0.209800\n",
      "[Epoch 120/200] [Batch 260/938] loss_G: 3.179868, loss_D: 0.106026\n",
      "[Epoch 120/200] [Batch 270/938] loss_G: 2.825230, loss_D: 0.189764\n",
      "[Epoch 120/200] [Batch 280/938] loss_G: 3.070251, loss_D: 0.264309\n",
      "[Epoch 120/200] [Batch 290/938] loss_G: 3.495324, loss_D: 0.167793\n",
      "[Epoch 120/200] [Batch 300/938] loss_G: 3.113568, loss_D: 0.233658\n",
      "[Epoch 120/200] [Batch 310/938] loss_G: 3.267845, loss_D: 0.198629\n",
      "[Epoch 120/200] [Batch 320/938] loss_G: 2.887697, loss_D: 0.291056\n",
      "[Epoch 120/200] [Batch 330/938] loss_G: 3.048210, loss_D: 0.261873\n",
      "[Epoch 120/200] [Batch 340/938] loss_G: 3.067245, loss_D: 0.174649\n",
      "[Epoch 120/200] [Batch 350/938] loss_G: 3.323973, loss_D: 0.280834\n",
      "[Epoch 120/200] [Batch 360/938] loss_G: 3.301774, loss_D: 0.237420\n",
      "[Epoch 120/200] [Batch 370/938] loss_G: 2.882524, loss_D: 0.156004\n",
      "[Epoch 120/200] [Batch 380/938] loss_G: 3.134002, loss_D: 0.178774\n",
      "[Epoch 120/200] [Batch 390/938] loss_G: 3.239753, loss_D: 0.226811\n",
      "[Epoch 120/200] [Batch 400/938] loss_G: 2.727680, loss_D: 0.188134\n",
      "[Epoch 120/200] [Batch 410/938] loss_G: 3.219584, loss_D: 0.246232\n",
      "[Epoch 120/200] [Batch 420/938] loss_G: 2.764185, loss_D: 0.264827\n",
      "[Epoch 120/200] [Batch 430/938] loss_G: 3.587966, loss_D: 0.203448\n",
      "[Epoch 120/200] [Batch 440/938] loss_G: 3.130950, loss_D: 0.269407\n",
      "[Epoch 120/200] [Batch 450/938] loss_G: 3.128933, loss_D: 0.175737\n",
      "[Epoch 120/200] [Batch 460/938] loss_G: 3.175807, loss_D: 0.223371\n",
      "[Epoch 120/200] [Batch 470/938] loss_G: 3.197000, loss_D: 0.182102\n",
      "[Epoch 120/200] [Batch 480/938] loss_G: 3.544713, loss_D: 0.171819\n",
      "[Epoch 120/200] [Batch 490/938] loss_G: 2.472770, loss_D: 0.217085\n",
      "[Epoch 120/200] [Batch 500/938] loss_G: 2.956101, loss_D: 0.200797\n",
      "[Epoch 120/200] [Batch 510/938] loss_G: 2.810287, loss_D: 0.240232\n",
      "[Epoch 120/200] [Batch 520/938] loss_G: 2.956208, loss_D: 0.155652\n",
      "[Epoch 120/200] [Batch 530/938] loss_G: 3.068297, loss_D: 0.163462\n",
      "[Epoch 120/200] [Batch 540/938] loss_G: 2.984581, loss_D: 0.188473\n",
      "[Epoch 120/200] [Batch 550/938] loss_G: 2.961697, loss_D: 0.175236\n",
      "[Epoch 120/200] [Batch 560/938] loss_G: 3.184094, loss_D: 0.202793\n",
      "[Epoch 120/200] [Batch 570/938] loss_G: 3.030287, loss_D: 0.276626\n",
      "[Epoch 120/200] [Batch 580/938] loss_G: 3.246502, loss_D: 0.158527\n",
      "[Epoch 120/200] [Batch 590/938] loss_G: 2.902941, loss_D: 0.131700\n",
      "[Epoch 120/200] [Batch 600/938] loss_G: 2.893469, loss_D: 0.136341\n",
      "[Epoch 120/200] [Batch 610/938] loss_G: 3.202392, loss_D: 0.164603\n",
      "[Epoch 120/200] [Batch 620/938] loss_G: 3.010131, loss_D: 0.213829\n",
      "[Epoch 120/200] [Batch 630/938] loss_G: 2.751838, loss_D: 0.255397\n",
      "[Epoch 120/200] [Batch 640/938] loss_G: 3.066854, loss_D: 0.151007\n",
      "[Epoch 120/200] [Batch 650/938] loss_G: 3.216368, loss_D: 0.254184\n",
      "[Epoch 120/200] [Batch 660/938] loss_G: 3.103263, loss_D: 0.184061\n",
      "[Epoch 120/200] [Batch 670/938] loss_G: 2.832451, loss_D: 0.154682\n",
      "[Epoch 120/200] [Batch 680/938] loss_G: 3.175833, loss_D: 0.217623\n",
      "[Epoch 120/200] [Batch 690/938] loss_G: 3.220456, loss_D: 0.216135\n",
      "[Epoch 120/200] [Batch 700/938] loss_G: 2.793955, loss_D: 0.308115\n",
      "[Epoch 120/200] [Batch 710/938] loss_G: 3.009824, loss_D: 0.170915\n",
      "[Epoch 120/200] [Batch 720/938] loss_G: 3.090942, loss_D: 0.179004\n",
      "[Epoch 120/200] [Batch 730/938] loss_G: 3.191627, loss_D: 0.202164\n",
      "[Epoch 120/200] [Batch 740/938] loss_G: 2.733015, loss_D: 0.220054\n",
      "[Epoch 120/200] [Batch 750/938] loss_G: 3.047672, loss_D: 0.233415\n",
      "[Epoch 120/200] [Batch 760/938] loss_G: 2.992104, loss_D: 0.189499\n",
      "[Epoch 120/200] [Batch 770/938] loss_G: 2.861760, loss_D: 0.208525\n",
      "[Epoch 120/200] [Batch 780/938] loss_G: 2.944569, loss_D: 0.168504\n",
      "[Epoch 120/200] [Batch 790/938] loss_G: 3.446624, loss_D: 0.173422\n",
      "[Epoch 120/200] [Batch 800/938] loss_G: 3.205370, loss_D: 0.182868\n",
      "[Epoch 120/200] [Batch 810/938] loss_G: 2.762771, loss_D: 0.158970\n",
      "[Epoch 120/200] [Batch 820/938] loss_G: 2.864311, loss_D: 0.235774\n",
      "[Epoch 120/200] [Batch 830/938] loss_G: 3.302808, loss_D: 0.171347\n",
      "[Epoch 120/200] [Batch 840/938] loss_G: 3.239481, loss_D: 0.191735\n",
      "[Epoch 120/200] [Batch 850/938] loss_G: 3.195535, loss_D: 0.155290\n",
      "[Epoch 120/200] [Batch 860/938] loss_G: 3.051680, loss_D: 0.214824\n",
      "[Epoch 120/200] [Batch 870/938] loss_G: 3.327430, loss_D: 0.188105\n",
      "[Epoch 120/200] [Batch 880/938] loss_G: 3.267568, loss_D: 0.202416\n",
      "[Epoch 120/200] [Batch 890/938] loss_G: 3.293302, loss_D: 0.213248\n",
      "[Epoch 120/200] [Batch 900/938] loss_G: 3.108652, loss_D: 0.222282\n",
      "[Epoch 120/200] [Batch 910/938] loss_G: 3.099892, loss_D: 0.233251\n",
      "[Epoch 120/200] [Batch 920/938] loss_G: 3.002897, loss_D: 0.154601\n",
      "[Epoch 120/200] [Batch 930/938] loss_G: 2.823596, loss_D: 0.216142\n",
      "[Epoch 121/200] [Batch 0/938] loss_G: 3.041705, loss_D: 0.232580\n",
      "[Epoch 121/200] [Batch 10/938] loss_G: 3.188170, loss_D: 0.246808\n",
      "[Epoch 121/200] [Batch 20/938] loss_G: 2.753984, loss_D: 0.294262\n",
      "[Epoch 121/200] [Batch 30/938] loss_G: 3.244562, loss_D: 0.252914\n",
      "[Epoch 121/200] [Batch 40/938] loss_G: 3.221051, loss_D: 0.168313\n",
      "[Epoch 121/200] [Batch 50/938] loss_G: 2.831718, loss_D: 0.223353\n",
      "[Epoch 121/200] [Batch 60/938] loss_G: 2.866562, loss_D: 0.287753\n",
      "[Epoch 121/200] [Batch 70/938] loss_G: 3.191973, loss_D: 0.174544\n",
      "[Epoch 121/200] [Batch 80/938] loss_G: 2.881569, loss_D: 0.240426\n",
      "[Epoch 121/200] [Batch 90/938] loss_G: 3.030314, loss_D: 0.213114\n",
      "[Epoch 121/200] [Batch 100/938] loss_G: 3.001385, loss_D: 0.132983\n",
      "[Epoch 121/200] [Batch 110/938] loss_G: 2.938366, loss_D: 0.170867\n",
      "[Epoch 121/200] [Batch 120/938] loss_G: 3.062093, loss_D: 0.148709\n",
      "[Epoch 121/200] [Batch 130/938] loss_G: 3.199408, loss_D: 0.192663\n",
      "[Epoch 121/200] [Batch 140/938] loss_G: 3.216932, loss_D: 0.210928\n",
      "[Epoch 121/200] [Batch 150/938] loss_G: 3.265157, loss_D: 0.184927\n",
      "[Epoch 121/200] [Batch 160/938] loss_G: 3.176250, loss_D: 0.279484\n",
      "[Epoch 121/200] [Batch 170/938] loss_G: 2.831790, loss_D: 0.171398\n",
      "[Epoch 121/200] [Batch 180/938] loss_G: 3.080265, loss_D: 0.185707\n",
      "[Epoch 121/200] [Batch 190/938] loss_G: 3.186299, loss_D: 0.215941\n",
      "[Epoch 121/200] [Batch 200/938] loss_G: 3.132293, loss_D: 0.152565\n",
      "[Epoch 121/200] [Batch 210/938] loss_G: 3.136786, loss_D: 0.251097\n",
      "[Epoch 121/200] [Batch 220/938] loss_G: 3.438229, loss_D: 0.189394\n",
      "[Epoch 121/200] [Batch 230/938] loss_G: 3.202900, loss_D: 0.173528\n",
      "[Epoch 121/200] [Batch 240/938] loss_G: 3.014366, loss_D: 0.172605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 121/200] [Batch 250/938] loss_G: 3.393564, loss_D: 0.261537\n",
      "[Epoch 121/200] [Batch 260/938] loss_G: 3.226440, loss_D: 0.241636\n",
      "[Epoch 121/200] [Batch 270/938] loss_G: 3.013457, loss_D: 0.190831\n",
      "[Epoch 121/200] [Batch 280/938] loss_G: 2.921245, loss_D: 0.183067\n",
      "[Epoch 121/200] [Batch 290/938] loss_G: 3.171015, loss_D: 0.133838\n",
      "[Epoch 121/200] [Batch 300/938] loss_G: 2.949355, loss_D: 0.217413\n",
      "[Epoch 121/200] [Batch 310/938] loss_G: 3.360950, loss_D: 0.207843\n",
      "[Epoch 121/200] [Batch 320/938] loss_G: 3.178159, loss_D: 0.192386\n",
      "[Epoch 121/200] [Batch 330/938] loss_G: 2.863514, loss_D: 0.178588\n",
      "[Epoch 121/200] [Batch 340/938] loss_G: 3.201135, loss_D: 0.192825\n",
      "[Epoch 121/200] [Batch 350/938] loss_G: 2.904449, loss_D: 0.171909\n",
      "[Epoch 121/200] [Batch 360/938] loss_G: 3.271616, loss_D: 0.209779\n",
      "[Epoch 121/200] [Batch 370/938] loss_G: 2.820959, loss_D: 0.178841\n",
      "[Epoch 121/200] [Batch 380/938] loss_G: 3.115479, loss_D: 0.279760\n",
      "[Epoch 121/200] [Batch 390/938] loss_G: 3.289524, loss_D: 0.189046\n",
      "[Epoch 121/200] [Batch 400/938] loss_G: 2.844340, loss_D: 0.245001\n",
      "[Epoch 121/200] [Batch 410/938] loss_G: 3.460363, loss_D: 0.169938\n",
      "[Epoch 121/200] [Batch 420/938] loss_G: 2.995598, loss_D: 0.172452\n",
      "[Epoch 121/200] [Batch 430/938] loss_G: 2.972818, loss_D: 0.200270\n",
      "[Epoch 121/200] [Batch 440/938] loss_G: 3.194291, loss_D: 0.245550\n",
      "[Epoch 121/200] [Batch 450/938] loss_G: 3.028267, loss_D: 0.179830\n",
      "[Epoch 121/200] [Batch 460/938] loss_G: 3.367159, loss_D: 0.193379\n",
      "[Epoch 121/200] [Batch 470/938] loss_G: 3.383419, loss_D: 0.179361\n",
      "[Epoch 121/200] [Batch 480/938] loss_G: 2.891008, loss_D: 0.231211\n",
      "[Epoch 121/200] [Batch 490/938] loss_G: 3.226812, loss_D: 0.236933\n",
      "[Epoch 121/200] [Batch 500/938] loss_G: 3.227660, loss_D: 0.166177\n",
      "[Epoch 121/200] [Batch 510/938] loss_G: 3.234297, loss_D: 0.193970\n",
      "[Epoch 121/200] [Batch 520/938] loss_G: 3.307873, loss_D: 0.175140\n",
      "[Epoch 121/200] [Batch 530/938] loss_G: 3.258912, loss_D: 0.243762\n",
      "[Epoch 121/200] [Batch 540/938] loss_G: 3.172508, loss_D: 0.221501\n",
      "[Epoch 121/200] [Batch 550/938] loss_G: 2.950152, loss_D: 0.140351\n",
      "[Epoch 121/200] [Batch 560/938] loss_G: 3.181346, loss_D: 0.180620\n",
      "[Epoch 121/200] [Batch 570/938] loss_G: 3.245555, loss_D: 0.109873\n",
      "[Epoch 121/200] [Batch 580/938] loss_G: 3.200740, loss_D: 0.212417\n",
      "[Epoch 121/200] [Batch 590/938] loss_G: 2.782934, loss_D: 0.244091\n",
      "[Epoch 121/200] [Batch 600/938] loss_G: 3.220304, loss_D: 0.177152\n",
      "[Epoch 121/200] [Batch 610/938] loss_G: 3.268568, loss_D: 0.182510\n",
      "[Epoch 121/200] [Batch 620/938] loss_G: 2.938719, loss_D: 0.207566\n",
      "[Epoch 121/200] [Batch 630/938] loss_G: 3.300745, loss_D: 0.190175\n",
      "[Epoch 121/200] [Batch 640/938] loss_G: 3.328047, loss_D: 0.156413\n",
      "[Epoch 121/200] [Batch 650/938] loss_G: 2.959030, loss_D: 0.196469\n",
      "[Epoch 121/200] [Batch 660/938] loss_G: 3.018681, loss_D: 0.170321\n",
      "[Epoch 121/200] [Batch 670/938] loss_G: 2.684787, loss_D: 0.222370\n",
      "[Epoch 121/200] [Batch 680/938] loss_G: 3.407572, loss_D: 0.289637\n",
      "[Epoch 121/200] [Batch 690/938] loss_G: 3.390781, loss_D: 0.219538\n",
      "[Epoch 121/200] [Batch 700/938] loss_G: 3.463458, loss_D: 0.110154\n",
      "[Epoch 121/200] [Batch 710/938] loss_G: 3.166499, loss_D: 0.242690\n",
      "[Epoch 121/200] [Batch 720/938] loss_G: 2.831909, loss_D: 0.268013\n",
      "[Epoch 121/200] [Batch 730/938] loss_G: 2.761863, loss_D: 0.213298\n",
      "[Epoch 121/200] [Batch 740/938] loss_G: 3.174421, loss_D: 0.119540\n",
      "[Epoch 121/200] [Batch 750/938] loss_G: 2.961501, loss_D: 0.206089\n",
      "[Epoch 121/200] [Batch 760/938] loss_G: 2.991419, loss_D: 0.204533\n",
      "[Epoch 121/200] [Batch 770/938] loss_G: 3.084277, loss_D: 0.183347\n",
      "[Epoch 121/200] [Batch 780/938] loss_G: 3.449470, loss_D: 0.243898\n",
      "[Epoch 121/200] [Batch 790/938] loss_G: 3.208803, loss_D: 0.114672\n",
      "[Epoch 121/200] [Batch 800/938] loss_G: 2.900466, loss_D: 0.178505\n",
      "[Epoch 121/200] [Batch 810/938] loss_G: 2.922158, loss_D: 0.159751\n",
      "[Epoch 121/200] [Batch 820/938] loss_G: 2.851172, loss_D: 0.249677\n",
      "[Epoch 121/200] [Batch 830/938] loss_G: 3.065303, loss_D: 0.218269\n",
      "[Epoch 121/200] [Batch 840/938] loss_G: 2.943202, loss_D: 0.225012\n",
      "[Epoch 121/200] [Batch 850/938] loss_G: 3.044148, loss_D: 0.223929\n",
      "[Epoch 121/200] [Batch 860/938] loss_G: 2.885664, loss_D: 0.184065\n",
      "[Epoch 121/200] [Batch 870/938] loss_G: 2.880004, loss_D: 0.227114\n",
      "[Epoch 121/200] [Batch 880/938] loss_G: 3.287974, loss_D: 0.102917\n",
      "[Epoch 121/200] [Batch 890/938] loss_G: 3.227597, loss_D: 0.284586\n",
      "[Epoch 121/200] [Batch 900/938] loss_G: 2.623964, loss_D: 0.188288\n",
      "[Epoch 121/200] [Batch 910/938] loss_G: 3.226539, loss_D: 0.204057\n",
      "[Epoch 121/200] [Batch 920/938] loss_G: 2.497627, loss_D: 0.275768\n",
      "[Epoch 121/200] [Batch 930/938] loss_G: 3.150628, loss_D: 0.223003\n",
      "[Epoch 122/200] [Batch 0/938] loss_G: 2.928647, loss_D: 0.197721\n",
      "[Epoch 122/200] [Batch 10/938] loss_G: 2.996935, loss_D: 0.179766\n",
      "[Epoch 122/200] [Batch 20/938] loss_G: 3.047417, loss_D: 0.192447\n",
      "[Epoch 122/200] [Batch 30/938] loss_G: 3.184196, loss_D: 0.161225\n",
      "[Epoch 122/200] [Batch 40/938] loss_G: 3.002673, loss_D: 0.233161\n",
      "[Epoch 122/200] [Batch 50/938] loss_G: 3.379950, loss_D: 0.279121\n",
      "[Epoch 122/200] [Batch 60/938] loss_G: 2.974276, loss_D: 0.169710\n",
      "[Epoch 122/200] [Batch 70/938] loss_G: 2.977246, loss_D: 0.153958\n",
      "[Epoch 122/200] [Batch 80/938] loss_G: 3.081403, loss_D: 0.232728\n",
      "[Epoch 122/200] [Batch 90/938] loss_G: 3.044793, loss_D: 0.212669\n",
      "[Epoch 122/200] [Batch 100/938] loss_G: 3.110804, loss_D: 0.188560\n",
      "[Epoch 122/200] [Batch 110/938] loss_G: 3.440851, loss_D: 0.145672\n",
      "[Epoch 122/200] [Batch 120/938] loss_G: 2.870822, loss_D: 0.202626\n",
      "[Epoch 122/200] [Batch 130/938] loss_G: 2.628953, loss_D: 0.184080\n",
      "[Epoch 122/200] [Batch 140/938] loss_G: 2.959745, loss_D: 0.221587\n",
      "[Epoch 122/200] [Batch 150/938] loss_G: 2.945783, loss_D: 0.213827\n",
      "[Epoch 122/200] [Batch 160/938] loss_G: 3.006299, loss_D: 0.130777\n",
      "[Epoch 122/200] [Batch 170/938] loss_G: 3.183689, loss_D: 0.219651\n",
      "[Epoch 122/200] [Batch 180/938] loss_G: 3.225024, loss_D: 0.207950\n",
      "[Epoch 122/200] [Batch 190/938] loss_G: 3.007531, loss_D: 0.201947\n",
      "[Epoch 122/200] [Batch 200/938] loss_G: 3.013966, loss_D: 0.209119\n",
      "[Epoch 122/200] [Batch 210/938] loss_G: 3.081171, loss_D: 0.154135\n",
      "[Epoch 122/200] [Batch 220/938] loss_G: 3.288627, loss_D: 0.176062\n",
      "[Epoch 122/200] [Batch 230/938] loss_G: 3.255739, loss_D: 0.223989\n",
      "[Epoch 122/200] [Batch 240/938] loss_G: 3.113251, loss_D: 0.220476\n",
      "[Epoch 122/200] [Batch 250/938] loss_G: 3.297525, loss_D: 0.232969\n",
      "[Epoch 122/200] [Batch 260/938] loss_G: 3.235287, loss_D: 0.212900\n",
      "[Epoch 122/200] [Batch 270/938] loss_G: 3.044385, loss_D: 0.131895\n",
      "[Epoch 122/200] [Batch 280/938] loss_G: 2.779611, loss_D: 0.210832\n",
      "[Epoch 122/200] [Batch 290/938] loss_G: 2.796728, loss_D: 0.256037\n",
      "[Epoch 122/200] [Batch 300/938] loss_G: 3.370430, loss_D: 0.207865\n",
      "[Epoch 122/200] [Batch 310/938] loss_G: 3.229240, loss_D: 0.322864\n",
      "[Epoch 122/200] [Batch 320/938] loss_G: 2.983610, loss_D: 0.220975\n",
      "[Epoch 122/200] [Batch 330/938] loss_G: 3.321973, loss_D: 0.229951\n",
      "[Epoch 122/200] [Batch 340/938] loss_G: 3.274201, loss_D: 0.141469\n",
      "[Epoch 122/200] [Batch 350/938] loss_G: 3.052394, loss_D: 0.234549\n",
      "[Epoch 122/200] [Batch 360/938] loss_G: 3.150550, loss_D: 0.190853\n",
      "[Epoch 122/200] [Batch 370/938] loss_G: 3.386345, loss_D: 0.241892\n",
      "[Epoch 122/200] [Batch 380/938] loss_G: 3.090738, loss_D: 0.223265\n",
      "[Epoch 122/200] [Batch 390/938] loss_G: 3.468303, loss_D: 0.105807\n",
      "[Epoch 122/200] [Batch 400/938] loss_G: 3.122728, loss_D: 0.238549\n",
      "[Epoch 122/200] [Batch 410/938] loss_G: 3.054684, loss_D: 0.213821\n",
      "[Epoch 122/200] [Batch 420/938] loss_G: 3.142814, loss_D: 0.194640\n",
      "[Epoch 122/200] [Batch 430/938] loss_G: 3.577656, loss_D: 0.195601\n",
      "[Epoch 122/200] [Batch 440/938] loss_G: 3.292730, loss_D: 0.233333\n",
      "[Epoch 122/200] [Batch 450/938] loss_G: 3.487774, loss_D: 0.193225\n",
      "[Epoch 122/200] [Batch 460/938] loss_G: 3.198328, loss_D: 0.262525\n",
      "[Epoch 122/200] [Batch 470/938] loss_G: 3.135671, loss_D: 0.185779\n",
      "[Epoch 122/200] [Batch 480/938] loss_G: 3.010076, loss_D: 0.180210\n",
      "[Epoch 122/200] [Batch 490/938] loss_G: 2.901124, loss_D: 0.170873\n",
      "[Epoch 122/200] [Batch 500/938] loss_G: 3.284883, loss_D: 0.214713\n",
      "[Epoch 122/200] [Batch 510/938] loss_G: 3.404764, loss_D: 0.188949\n",
      "[Epoch 122/200] [Batch 520/938] loss_G: 2.784263, loss_D: 0.245007\n",
      "[Epoch 122/200] [Batch 530/938] loss_G: 3.364158, loss_D: 0.175819\n",
      "[Epoch 122/200] [Batch 540/938] loss_G: 3.322782, loss_D: 0.174906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 122/200] [Batch 550/938] loss_G: 3.006579, loss_D: 0.101849\n",
      "[Epoch 122/200] [Batch 560/938] loss_G: 3.397505, loss_D: 0.259802\n",
      "[Epoch 122/200] [Batch 570/938] loss_G: 3.362405, loss_D: 0.181040\n",
      "[Epoch 122/200] [Batch 580/938] loss_G: 2.797413, loss_D: 0.138798\n",
      "[Epoch 122/200] [Batch 590/938] loss_G: 3.059669, loss_D: 0.239401\n",
      "[Epoch 122/200] [Batch 600/938] loss_G: 3.488081, loss_D: 0.198500\n",
      "[Epoch 122/200] [Batch 610/938] loss_G: 3.411301, loss_D: 0.172302\n",
      "[Epoch 122/200] [Batch 620/938] loss_G: 2.881191, loss_D: 0.191517\n",
      "[Epoch 122/200] [Batch 630/938] loss_G: 3.117278, loss_D: 0.167225\n",
      "[Epoch 122/200] [Batch 640/938] loss_G: 3.021112, loss_D: 0.209550\n",
      "[Epoch 122/200] [Batch 650/938] loss_G: 3.248483, loss_D: 0.214665\n",
      "[Epoch 122/200] [Batch 660/938] loss_G: 3.185254, loss_D: 0.174401\n",
      "[Epoch 122/200] [Batch 670/938] loss_G: 3.330078, loss_D: 0.239850\n",
      "[Epoch 122/200] [Batch 680/938] loss_G: 3.202059, loss_D: 0.268401\n",
      "[Epoch 122/200] [Batch 690/938] loss_G: 3.402115, loss_D: 0.117850\n",
      "[Epoch 122/200] [Batch 700/938] loss_G: 3.383210, loss_D: 0.149703\n",
      "[Epoch 122/200] [Batch 710/938] loss_G: 2.823768, loss_D: 0.216985\n",
      "[Epoch 122/200] [Batch 720/938] loss_G: 3.134608, loss_D: 0.202069\n",
      "[Epoch 122/200] [Batch 730/938] loss_G: 3.114900, loss_D: 0.285210\n",
      "[Epoch 122/200] [Batch 740/938] loss_G: 3.207013, loss_D: 0.157516\n",
      "[Epoch 122/200] [Batch 750/938] loss_G: 2.802338, loss_D: 0.168569\n",
      "[Epoch 122/200] [Batch 760/938] loss_G: 3.104836, loss_D: 0.152632\n",
      "[Epoch 122/200] [Batch 770/938] loss_G: 3.339308, loss_D: 0.212789\n",
      "[Epoch 122/200] [Batch 780/938] loss_G: 3.751665, loss_D: 0.181970\n",
      "[Epoch 122/200] [Batch 790/938] loss_G: 2.691898, loss_D: 0.159150\n",
      "[Epoch 122/200] [Batch 800/938] loss_G: 3.181858, loss_D: 0.133380\n",
      "[Epoch 122/200] [Batch 810/938] loss_G: 3.813833, loss_D: 0.192917\n",
      "[Epoch 122/200] [Batch 820/938] loss_G: 3.260911, loss_D: 0.183045\n",
      "[Epoch 122/200] [Batch 830/938] loss_G: 3.249308, loss_D: 0.194607\n",
      "[Epoch 122/200] [Batch 840/938] loss_G: 3.182085, loss_D: 0.222104\n",
      "[Epoch 122/200] [Batch 850/938] loss_G: 3.004233, loss_D: 0.255257\n",
      "[Epoch 122/200] [Batch 860/938] loss_G: 3.176170, loss_D: 0.190644\n",
      "[Epoch 122/200] [Batch 870/938] loss_G: 3.245637, loss_D: 0.215322\n",
      "[Epoch 122/200] [Batch 880/938] loss_G: 2.956241, loss_D: 0.171783\n",
      "[Epoch 122/200] [Batch 890/938] loss_G: 2.908586, loss_D: 0.182852\n",
      "[Epoch 122/200] [Batch 900/938] loss_G: 2.851421, loss_D: 0.218099\n",
      "[Epoch 122/200] [Batch 910/938] loss_G: 2.666226, loss_D: 0.191997\n",
      "[Epoch 122/200] [Batch 920/938] loss_G: 3.346781, loss_D: 0.162192\n",
      "[Epoch 122/200] [Batch 930/938] loss_G: 3.150499, loss_D: 0.280510\n",
      "[Epoch 123/200] [Batch 0/938] loss_G: 2.920844, loss_D: 0.243696\n",
      "[Epoch 123/200] [Batch 10/938] loss_G: 3.122134, loss_D: 0.192621\n",
      "[Epoch 123/200] [Batch 20/938] loss_G: 3.034841, loss_D: 0.122063\n",
      "[Epoch 123/200] [Batch 30/938] loss_G: 3.449759, loss_D: 0.204110\n",
      "[Epoch 123/200] [Batch 40/938] loss_G: 2.735520, loss_D: 0.267472\n",
      "[Epoch 123/200] [Batch 50/938] loss_G: 3.528450, loss_D: 0.197159\n",
      "[Epoch 123/200] [Batch 60/938] loss_G: 3.466129, loss_D: 0.152389\n",
      "[Epoch 123/200] [Batch 70/938] loss_G: 3.355208, loss_D: 0.221471\n",
      "[Epoch 123/200] [Batch 80/938] loss_G: 3.227895, loss_D: 0.224763\n",
      "[Epoch 123/200] [Batch 90/938] loss_G: 3.065527, loss_D: 0.212443\n",
      "[Epoch 123/200] [Batch 100/938] loss_G: 3.077696, loss_D: 0.271643\n",
      "[Epoch 123/200] [Batch 110/938] loss_G: 3.044099, loss_D: 0.184861\n",
      "[Epoch 123/200] [Batch 120/938] loss_G: 3.472086, loss_D: 0.203234\n",
      "[Epoch 123/200] [Batch 130/938] loss_G: 3.133625, loss_D: 0.165066\n",
      "[Epoch 123/200] [Batch 140/938] loss_G: 3.433412, loss_D: 0.157981\n",
      "[Epoch 123/200] [Batch 150/938] loss_G: 3.056515, loss_D: 0.168719\n",
      "[Epoch 123/200] [Batch 160/938] loss_G: 3.251923, loss_D: 0.206597\n",
      "[Epoch 123/200] [Batch 170/938] loss_G: 3.462446, loss_D: 0.140534\n",
      "[Epoch 123/200] [Batch 180/938] loss_G: 3.113740, loss_D: 0.162072\n",
      "[Epoch 123/200] [Batch 190/938] loss_G: 3.285536, loss_D: 0.209782\n",
      "[Epoch 123/200] [Batch 200/938] loss_G: 2.895233, loss_D: 0.237131\n",
      "[Epoch 123/200] [Batch 210/938] loss_G: 3.519017, loss_D: 0.162217\n",
      "[Epoch 123/200] [Batch 220/938] loss_G: 3.273160, loss_D: 0.211484\n",
      "[Epoch 123/200] [Batch 230/938] loss_G: 3.015121, loss_D: 0.215694\n",
      "[Epoch 123/200] [Batch 240/938] loss_G: 3.442300, loss_D: 0.167601\n",
      "[Epoch 123/200] [Batch 250/938] loss_G: 2.826990, loss_D: 0.250704\n",
      "[Epoch 123/200] [Batch 260/938] loss_G: 3.387834, loss_D: 0.215783\n",
      "[Epoch 123/200] [Batch 270/938] loss_G: 3.596396, loss_D: 0.106649\n",
      "[Epoch 123/200] [Batch 280/938] loss_G: 3.206968, loss_D: 0.218782\n",
      "[Epoch 123/200] [Batch 290/938] loss_G: 2.701093, loss_D: 0.224036\n",
      "[Epoch 123/200] [Batch 300/938] loss_G: 2.992213, loss_D: 0.257942\n",
      "[Epoch 123/200] [Batch 310/938] loss_G: 3.425897, loss_D: 0.175251\n",
      "[Epoch 123/200] [Batch 320/938] loss_G: 3.273044, loss_D: 0.164967\n",
      "[Epoch 123/200] [Batch 330/938] loss_G: 3.335357, loss_D: 0.196042\n",
      "[Epoch 123/200] [Batch 340/938] loss_G: 2.894578, loss_D: 0.246375\n",
      "[Epoch 123/200] [Batch 350/938] loss_G: 3.121364, loss_D: 0.203133\n",
      "[Epoch 123/200] [Batch 360/938] loss_G: 3.140052, loss_D: 0.179722\n",
      "[Epoch 123/200] [Batch 370/938] loss_G: 2.996395, loss_D: 0.203299\n",
      "[Epoch 123/200] [Batch 380/938] loss_G: 3.191030, loss_D: 0.161807\n",
      "[Epoch 123/200] [Batch 390/938] loss_G: 3.281131, loss_D: 0.258914\n",
      "[Epoch 123/200] [Batch 400/938] loss_G: 3.332268, loss_D: 0.162176\n",
      "[Epoch 123/200] [Batch 410/938] loss_G: 3.085836, loss_D: 0.219835\n",
      "[Epoch 123/200] [Batch 420/938] loss_G: 2.931017, loss_D: 0.250111\n",
      "[Epoch 123/200] [Batch 430/938] loss_G: 3.034791, loss_D: 0.112204\n",
      "[Epoch 123/200] [Batch 440/938] loss_G: 3.119905, loss_D: 0.125934\n",
      "[Epoch 123/200] [Batch 450/938] loss_G: 3.281124, loss_D: 0.143156\n",
      "[Epoch 123/200] [Batch 460/938] loss_G: 3.050921, loss_D: 0.164090\n",
      "[Epoch 123/200] [Batch 470/938] loss_G: 2.953995, loss_D: 0.190843\n",
      "[Epoch 123/200] [Batch 480/938] loss_G: 2.552446, loss_D: 0.259091\n",
      "[Epoch 123/200] [Batch 490/938] loss_G: 2.894176, loss_D: 0.258374\n",
      "[Epoch 123/200] [Batch 500/938] loss_G: 3.280350, loss_D: 0.193045\n",
      "[Epoch 123/200] [Batch 510/938] loss_G: 3.378633, loss_D: 0.259375\n",
      "[Epoch 123/200] [Batch 520/938] loss_G: 3.002734, loss_D: 0.199551\n",
      "[Epoch 123/200] [Batch 530/938] loss_G: 3.140663, loss_D: 0.147338\n",
      "[Epoch 123/200] [Batch 540/938] loss_G: 3.008385, loss_D: 0.217129\n",
      "[Epoch 123/200] [Batch 550/938] loss_G: 3.260580, loss_D: 0.193187\n",
      "[Epoch 123/200] [Batch 560/938] loss_G: 3.327614, loss_D: 0.163787\n",
      "[Epoch 123/200] [Batch 570/938] loss_G: 3.067052, loss_D: 0.247833\n",
      "[Epoch 123/200] [Batch 580/938] loss_G: 3.298531, loss_D: 0.254671\n",
      "[Epoch 123/200] [Batch 590/938] loss_G: 3.037201, loss_D: 0.220096\n",
      "[Epoch 123/200] [Batch 600/938] loss_G: 3.428628, loss_D: 0.172105\n",
      "[Epoch 123/200] [Batch 610/938] loss_G: 3.409165, loss_D: 0.198354\n",
      "[Epoch 123/200] [Batch 620/938] loss_G: 3.162769, loss_D: 0.217457\n",
      "[Epoch 123/200] [Batch 630/938] loss_G: 2.962749, loss_D: 0.299214\n",
      "[Epoch 123/200] [Batch 640/938] loss_G: 3.725171, loss_D: 0.148395\n",
      "[Epoch 123/200] [Batch 650/938] loss_G: 3.360332, loss_D: 0.210258\n",
      "[Epoch 123/200] [Batch 660/938] loss_G: 3.062883, loss_D: 0.305726\n",
      "[Epoch 123/200] [Batch 670/938] loss_G: 3.387529, loss_D: 0.125802\n",
      "[Epoch 123/200] [Batch 680/938] loss_G: 2.892806, loss_D: 0.191539\n",
      "[Epoch 123/200] [Batch 690/938] loss_G: 3.132134, loss_D: 0.171708\n",
      "[Epoch 123/200] [Batch 700/938] loss_G: 3.335883, loss_D: 0.179134\n",
      "[Epoch 123/200] [Batch 710/938] loss_G: 3.108140, loss_D: 0.277868\n",
      "[Epoch 123/200] [Batch 720/938] loss_G: 2.984638, loss_D: 0.203906\n",
      "[Epoch 123/200] [Batch 730/938] loss_G: 3.622692, loss_D: 0.200443\n",
      "[Epoch 123/200] [Batch 740/938] loss_G: 3.325813, loss_D: 0.144986\n",
      "[Epoch 123/200] [Batch 750/938] loss_G: 3.080836, loss_D: 0.220184\n",
      "[Epoch 123/200] [Batch 760/938] loss_G: 3.155985, loss_D: 0.223936\n",
      "[Epoch 123/200] [Batch 770/938] loss_G: 3.194434, loss_D: 0.178211\n",
      "[Epoch 123/200] [Batch 780/938] loss_G: 3.161203, loss_D: 0.215354\n",
      "[Epoch 123/200] [Batch 790/938] loss_G: 3.123479, loss_D: 0.203924\n",
      "[Epoch 123/200] [Batch 800/938] loss_G: 2.952272, loss_D: 0.175669\n",
      "[Epoch 123/200] [Batch 810/938] loss_G: 3.322680, loss_D: 0.253988\n",
      "[Epoch 123/200] [Batch 820/938] loss_G: 3.136132, loss_D: 0.174441\n",
      "[Epoch 123/200] [Batch 830/938] loss_G: 3.312444, loss_D: 0.160259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 123/200] [Batch 840/938] loss_G: 3.204360, loss_D: 0.145177\n",
      "[Epoch 123/200] [Batch 850/938] loss_G: 3.198542, loss_D: 0.260626\n",
      "[Epoch 123/200] [Batch 860/938] loss_G: 3.666126, loss_D: 0.187967\n",
      "[Epoch 123/200] [Batch 870/938] loss_G: 3.466978, loss_D: 0.155988\n",
      "[Epoch 123/200] [Batch 880/938] loss_G: 2.919598, loss_D: 0.185200\n",
      "[Epoch 123/200] [Batch 890/938] loss_G: 3.068309, loss_D: 0.206515\n",
      "[Epoch 123/200] [Batch 900/938] loss_G: 2.726748, loss_D: 0.290909\n",
      "[Epoch 123/200] [Batch 910/938] loss_G: 3.185489, loss_D: 0.380875\n",
      "[Epoch 123/200] [Batch 920/938] loss_G: 3.054004, loss_D: 0.208590\n",
      "[Epoch 123/200] [Batch 930/938] loss_G: 2.844328, loss_D: 0.187769\n",
      "[Epoch 124/200] [Batch 0/938] loss_G: 2.986629, loss_D: 0.343773\n",
      "[Epoch 124/200] [Batch 10/938] loss_G: 2.884170, loss_D: 0.180767\n",
      "[Epoch 124/200] [Batch 20/938] loss_G: 3.248692, loss_D: 0.219810\n",
      "[Epoch 124/200] [Batch 30/938] loss_G: 2.902772, loss_D: 0.149485\n",
      "[Epoch 124/200] [Batch 40/938] loss_G: 2.889098, loss_D: 0.221500\n",
      "[Epoch 124/200] [Batch 50/938] loss_G: 3.320405, loss_D: 0.173163\n",
      "[Epoch 124/200] [Batch 60/938] loss_G: 3.315335, loss_D: 0.167203\n",
      "[Epoch 124/200] [Batch 70/938] loss_G: 2.918088, loss_D: 0.255230\n",
      "[Epoch 124/200] [Batch 80/938] loss_G: 3.170799, loss_D: 0.185582\n",
      "[Epoch 124/200] [Batch 90/938] loss_G: 2.849623, loss_D: 0.190562\n",
      "[Epoch 124/200] [Batch 100/938] loss_G: 3.473555, loss_D: 0.191193\n",
      "[Epoch 124/200] [Batch 110/938] loss_G: 3.124918, loss_D: 0.116462\n",
      "[Epoch 124/200] [Batch 120/938] loss_G: 2.762924, loss_D: 0.185961\n",
      "[Epoch 124/200] [Batch 130/938] loss_G: 3.458032, loss_D: 0.221770\n",
      "[Epoch 124/200] [Batch 140/938] loss_G: 2.877460, loss_D: 0.184813\n",
      "[Epoch 124/200] [Batch 150/938] loss_G: 2.808247, loss_D: 0.181333\n",
      "[Epoch 124/200] [Batch 160/938] loss_G: 2.526674, loss_D: 0.186787\n",
      "[Epoch 124/200] [Batch 170/938] loss_G: 3.320519, loss_D: 0.120573\n",
      "[Epoch 124/200] [Batch 180/938] loss_G: 3.206619, loss_D: 0.251884\n",
      "[Epoch 124/200] [Batch 190/938] loss_G: 3.286031, loss_D: 0.222357\n",
      "[Epoch 124/200] [Batch 200/938] loss_G: 3.379908, loss_D: 0.180750\n",
      "[Epoch 124/200] [Batch 210/938] loss_G: 3.238702, loss_D: 0.164207\n",
      "[Epoch 124/200] [Batch 220/938] loss_G: 2.804279, loss_D: 0.178218\n",
      "[Epoch 124/200] [Batch 230/938] loss_G: 3.297892, loss_D: 0.156609\n",
      "[Epoch 124/200] [Batch 240/938] loss_G: 2.609140, loss_D: 0.179771\n",
      "[Epoch 124/200] [Batch 250/938] loss_G: 3.115980, loss_D: 0.191565\n",
      "[Epoch 124/200] [Batch 260/938] loss_G: 3.069125, loss_D: 0.165563\n",
      "[Epoch 124/200] [Batch 270/938] loss_G: 2.933157, loss_D: 0.167603\n",
      "[Epoch 124/200] [Batch 280/938] loss_G: 2.874382, loss_D: 0.206417\n",
      "[Epoch 124/200] [Batch 290/938] loss_G: 3.336362, loss_D: 0.232617\n",
      "[Epoch 124/200] [Batch 300/938] loss_G: 3.254771, loss_D: 0.164970\n",
      "[Epoch 124/200] [Batch 310/938] loss_G: 3.111284, loss_D: 0.209616\n",
      "[Epoch 124/200] [Batch 320/938] loss_G: 3.144038, loss_D: 0.109672\n",
      "[Epoch 124/200] [Batch 330/938] loss_G: 3.120558, loss_D: 0.204947\n",
      "[Epoch 124/200] [Batch 340/938] loss_G: 3.216533, loss_D: 0.179626\n",
      "[Epoch 124/200] [Batch 350/938] loss_G: 3.123420, loss_D: 0.238110\n",
      "[Epoch 124/200] [Batch 360/938] loss_G: 3.030135, loss_D: 0.184434\n",
      "[Epoch 124/200] [Batch 370/938] loss_G: 3.335773, loss_D: 0.206037\n",
      "[Epoch 124/200] [Batch 380/938] loss_G: 2.951339, loss_D: 0.241458\n",
      "[Epoch 124/200] [Batch 390/938] loss_G: 3.114089, loss_D: 0.293171\n",
      "[Epoch 124/200] [Batch 400/938] loss_G: 3.727450, loss_D: 0.250320\n",
      "[Epoch 124/200] [Batch 410/938] loss_G: 2.959161, loss_D: 0.201371\n",
      "[Epoch 124/200] [Batch 420/938] loss_G: 3.240451, loss_D: 0.199703\n",
      "[Epoch 124/200] [Batch 430/938] loss_G: 3.229740, loss_D: 0.233283\n",
      "[Epoch 124/200] [Batch 440/938] loss_G: 2.812705, loss_D: 0.156830\n",
      "[Epoch 124/200] [Batch 450/938] loss_G: 3.170315, loss_D: 0.113700\n",
      "[Epoch 124/200] [Batch 460/938] loss_G: 3.479079, loss_D: 0.218614\n",
      "[Epoch 124/200] [Batch 470/938] loss_G: 3.280994, loss_D: 0.174072\n",
      "[Epoch 124/200] [Batch 480/938] loss_G: 3.255787, loss_D: 0.195666\n",
      "[Epoch 124/200] [Batch 490/938] loss_G: 2.720093, loss_D: 0.203993\n",
      "[Epoch 124/200] [Batch 500/938] loss_G: 3.276059, loss_D: 0.101784\n",
      "[Epoch 124/200] [Batch 510/938] loss_G: 3.372166, loss_D: 0.218576\n",
      "[Epoch 124/200] [Batch 520/938] loss_G: 3.422530, loss_D: 0.215705\n",
      "[Epoch 124/200] [Batch 530/938] loss_G: 3.401110, loss_D: 0.203512\n",
      "[Epoch 124/200] [Batch 540/938] loss_G: 2.995738, loss_D: 0.267261\n",
      "[Epoch 124/200] [Batch 550/938] loss_G: 3.484295, loss_D: 0.142791\n",
      "[Epoch 124/200] [Batch 560/938] loss_G: 3.258818, loss_D: 0.173580\n",
      "[Epoch 124/200] [Batch 570/938] loss_G: 2.901597, loss_D: 0.182027\n",
      "[Epoch 124/200] [Batch 580/938] loss_G: 3.277791, loss_D: 0.231976\n",
      "[Epoch 124/200] [Batch 590/938] loss_G: 3.661316, loss_D: 0.201643\n",
      "[Epoch 124/200] [Batch 600/938] loss_G: 3.255578, loss_D: 0.222034\n",
      "[Epoch 124/200] [Batch 610/938] loss_G: 3.348728, loss_D: 0.145526\n",
      "[Epoch 124/200] [Batch 620/938] loss_G: 3.211601, loss_D: 0.220629\n",
      "[Epoch 124/200] [Batch 630/938] loss_G: 3.254206, loss_D: 0.178595\n",
      "[Epoch 124/200] [Batch 640/938] loss_G: 2.736965, loss_D: 0.182866\n",
      "[Epoch 124/200] [Batch 650/938] loss_G: 3.406850, loss_D: 0.171926\n",
      "[Epoch 124/200] [Batch 660/938] loss_G: 3.048727, loss_D: 0.277387\n",
      "[Epoch 124/200] [Batch 670/938] loss_G: 3.106882, loss_D: 0.216592\n",
      "[Epoch 124/200] [Batch 680/938] loss_G: 2.895717, loss_D: 0.182597\n",
      "[Epoch 124/200] [Batch 690/938] loss_G: 2.987841, loss_D: 0.230423\n",
      "[Epoch 124/200] [Batch 700/938] loss_G: 3.061407, loss_D: 0.200911\n",
      "[Epoch 124/200] [Batch 710/938] loss_G: 3.038583, loss_D: 0.149353\n",
      "[Epoch 124/200] [Batch 720/938] loss_G: 3.149522, loss_D: 0.194803\n",
      "[Epoch 124/200] [Batch 730/938] loss_G: 3.215107, loss_D: 0.189487\n",
      "[Epoch 124/200] [Batch 740/938] loss_G: 3.200192, loss_D: 0.172854\n",
      "[Epoch 124/200] [Batch 750/938] loss_G: 2.906075, loss_D: 0.199858\n",
      "[Epoch 124/200] [Batch 760/938] loss_G: 3.285941, loss_D: 0.132922\n",
      "[Epoch 124/200] [Batch 770/938] loss_G: 3.384867, loss_D: 0.162746\n",
      "[Epoch 124/200] [Batch 780/938] loss_G: 2.885150, loss_D: 0.216712\n",
      "[Epoch 124/200] [Batch 790/938] loss_G: 3.171548, loss_D: 0.160936\n",
      "[Epoch 124/200] [Batch 800/938] loss_G: 3.434421, loss_D: 0.215729\n",
      "[Epoch 124/200] [Batch 810/938] loss_G: 3.247080, loss_D: 0.197728\n",
      "[Epoch 124/200] [Batch 820/938] loss_G: 3.112010, loss_D: 0.199094\n",
      "[Epoch 124/200] [Batch 830/938] loss_G: 2.962485, loss_D: 0.260008\n",
      "[Epoch 124/200] [Batch 840/938] loss_G: 3.378183, loss_D: 0.283561\n",
      "[Epoch 124/200] [Batch 850/938] loss_G: 3.553593, loss_D: 0.184277\n",
      "[Epoch 124/200] [Batch 860/938] loss_G: 3.070481, loss_D: 0.215459\n",
      "[Epoch 124/200] [Batch 870/938] loss_G: 3.370225, loss_D: 0.255726\n",
      "[Epoch 124/200] [Batch 880/938] loss_G: 3.080317, loss_D: 0.179303\n",
      "[Epoch 124/200] [Batch 890/938] loss_G: 3.284399, loss_D: 0.271030\n",
      "[Epoch 124/200] [Batch 900/938] loss_G: 3.069999, loss_D: 0.283058\n",
      "[Epoch 124/200] [Batch 910/938] loss_G: 3.415083, loss_D: 0.171288\n",
      "[Epoch 124/200] [Batch 920/938] loss_G: 3.647585, loss_D: 0.114293\n",
      "[Epoch 124/200] [Batch 930/938] loss_G: 3.141218, loss_D: 0.202303\n",
      "[Epoch 125/200] [Batch 0/938] loss_G: 3.388104, loss_D: 0.180448\n",
      "[Epoch 125/200] [Batch 10/938] loss_G: 3.184431, loss_D: 0.195134\n",
      "[Epoch 125/200] [Batch 20/938] loss_G: 3.302492, loss_D: 0.156661\n",
      "[Epoch 125/200] [Batch 30/938] loss_G: 3.094478, loss_D: 0.213507\n",
      "[Epoch 125/200] [Batch 40/938] loss_G: 3.039260, loss_D: 0.168559\n",
      "[Epoch 125/200] [Batch 50/938] loss_G: 3.250195, loss_D: 0.258884\n",
      "[Epoch 125/200] [Batch 60/938] loss_G: 3.253084, loss_D: 0.200583\n",
      "[Epoch 125/200] [Batch 70/938] loss_G: 3.369845, loss_D: 0.213711\n",
      "[Epoch 125/200] [Batch 80/938] loss_G: 3.331570, loss_D: 0.127570\n",
      "[Epoch 125/200] [Batch 90/938] loss_G: 3.272225, loss_D: 0.213243\n",
      "[Epoch 125/200] [Batch 100/938] loss_G: 3.615748, loss_D: 0.239003\n",
      "[Epoch 125/200] [Batch 110/938] loss_G: 3.184652, loss_D: 0.277119\n",
      "[Epoch 125/200] [Batch 120/938] loss_G: 3.300595, loss_D: 0.107026\n",
      "[Epoch 125/200] [Batch 130/938] loss_G: 3.232780, loss_D: 0.150946\n",
      "[Epoch 125/200] [Batch 140/938] loss_G: 3.525681, loss_D: 0.130980\n",
      "[Epoch 125/200] [Batch 150/938] loss_G: 3.659982, loss_D: 0.139723\n",
      "[Epoch 125/200] [Batch 160/938] loss_G: 3.507622, loss_D: 0.183572\n",
      "[Epoch 125/200] [Batch 170/938] loss_G: 3.094949, loss_D: 0.142073\n",
      "[Epoch 125/200] [Batch 180/938] loss_G: 3.021795, loss_D: 0.170125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 125/200] [Batch 190/938] loss_G: 2.966482, loss_D: 0.201140\n",
      "[Epoch 125/200] [Batch 200/938] loss_G: 2.939257, loss_D: 0.231281\n",
      "[Epoch 125/200] [Batch 210/938] loss_G: 3.073516, loss_D: 0.136304\n",
      "[Epoch 125/200] [Batch 220/938] loss_G: 2.812488, loss_D: 0.221902\n",
      "[Epoch 125/200] [Batch 230/938] loss_G: 3.256225, loss_D: 0.145057\n",
      "[Epoch 125/200] [Batch 240/938] loss_G: 3.115126, loss_D: 0.217275\n",
      "[Epoch 125/200] [Batch 250/938] loss_G: 3.310353, loss_D: 0.224348\n",
      "[Epoch 125/200] [Batch 260/938] loss_G: 3.333833, loss_D: 0.138875\n",
      "[Epoch 125/200] [Batch 270/938] loss_G: 3.031378, loss_D: 0.236234\n",
      "[Epoch 125/200] [Batch 280/938] loss_G: 2.895761, loss_D: 0.202910\n",
      "[Epoch 125/200] [Batch 290/938] loss_G: 2.821989, loss_D: 0.230435\n",
      "[Epoch 125/200] [Batch 300/938] loss_G: 3.308420, loss_D: 0.202383\n",
      "[Epoch 125/200] [Batch 310/938] loss_G: 3.208740, loss_D: 0.144801\n",
      "[Epoch 125/200] [Batch 320/938] loss_G: 3.132082, loss_D: 0.260623\n",
      "[Epoch 125/200] [Batch 330/938] loss_G: 3.313223, loss_D: 0.171584\n",
      "[Epoch 125/200] [Batch 340/938] loss_G: 2.892495, loss_D: 0.213809\n",
      "[Epoch 125/200] [Batch 350/938] loss_G: 3.445024, loss_D: 0.198400\n",
      "[Epoch 125/200] [Batch 360/938] loss_G: 2.772147, loss_D: 0.284040\n",
      "[Epoch 125/200] [Batch 370/938] loss_G: 3.229614, loss_D: 0.232031\n",
      "[Epoch 125/200] [Batch 380/938] loss_G: 3.293380, loss_D: 0.173577\n",
      "[Epoch 125/200] [Batch 390/938] loss_G: 3.226225, loss_D: 0.212024\n",
      "[Epoch 125/200] [Batch 400/938] loss_G: 3.092517, loss_D: 0.222491\n",
      "[Epoch 125/200] [Batch 410/938] loss_G: 3.411000, loss_D: 0.171252\n",
      "[Epoch 125/200] [Batch 420/938] loss_G: 2.945088, loss_D: 0.174272\n",
      "[Epoch 125/200] [Batch 430/938] loss_G: 3.179060, loss_D: 0.179270\n",
      "[Epoch 125/200] [Batch 440/938] loss_G: 3.441817, loss_D: 0.123271\n",
      "[Epoch 125/200] [Batch 450/938] loss_G: 3.273582, loss_D: 0.175662\n",
      "[Epoch 125/200] [Batch 460/938] loss_G: 2.989766, loss_D: 0.170443\n",
      "[Epoch 125/200] [Batch 470/938] loss_G: 2.925903, loss_D: 0.221677\n",
      "[Epoch 125/200] [Batch 480/938] loss_G: 3.049637, loss_D: 0.180457\n",
      "[Epoch 125/200] [Batch 490/938] loss_G: 3.592867, loss_D: 0.172407\n",
      "[Epoch 125/200] [Batch 500/938] loss_G: 3.096724, loss_D: 0.192528\n",
      "[Epoch 125/200] [Batch 510/938] loss_G: 3.234944, loss_D: 0.185655\n",
      "[Epoch 125/200] [Batch 520/938] loss_G: 3.172302, loss_D: 0.275157\n",
      "[Epoch 125/200] [Batch 530/938] loss_G: 3.172059, loss_D: 0.194244\n",
      "[Epoch 125/200] [Batch 540/938] loss_G: 3.100736, loss_D: 0.083409\n",
      "[Epoch 125/200] [Batch 550/938] loss_G: 3.317510, loss_D: 0.083900\n",
      "[Epoch 125/200] [Batch 560/938] loss_G: 2.993472, loss_D: 0.205030\n",
      "[Epoch 125/200] [Batch 570/938] loss_G: 2.861443, loss_D: 0.175361\n",
      "[Epoch 125/200] [Batch 580/938] loss_G: 3.043088, loss_D: 0.227957\n",
      "[Epoch 125/200] [Batch 590/938] loss_G: 3.487685, loss_D: 0.242802\n",
      "[Epoch 125/200] [Batch 600/938] loss_G: 3.377984, loss_D: 0.223218\n",
      "[Epoch 125/200] [Batch 610/938] loss_G: 3.103407, loss_D: 0.206701\n",
      "[Epoch 125/200] [Batch 620/938] loss_G: 3.127712, loss_D: 0.191536\n",
      "[Epoch 125/200] [Batch 630/938] loss_G: 2.990495, loss_D: 0.128502\n",
      "[Epoch 125/200] [Batch 640/938] loss_G: 3.388052, loss_D: 0.154638\n",
      "[Epoch 125/200] [Batch 650/938] loss_G: 3.154791, loss_D: 0.219971\n",
      "[Epoch 125/200] [Batch 660/938] loss_G: 2.800433, loss_D: 0.169462\n",
      "[Epoch 125/200] [Batch 670/938] loss_G: 3.447250, loss_D: 0.171215\n",
      "[Epoch 125/200] [Batch 680/938] loss_G: 2.771276, loss_D: 0.204729\n",
      "[Epoch 125/200] [Batch 690/938] loss_G: 3.184823, loss_D: 0.136720\n",
      "[Epoch 125/200] [Batch 700/938] loss_G: 3.252095, loss_D: 0.176360\n",
      "[Epoch 125/200] [Batch 710/938] loss_G: 2.836357, loss_D: 0.220846\n",
      "[Epoch 125/200] [Batch 720/938] loss_G: 3.084508, loss_D: 0.142780\n",
      "[Epoch 125/200] [Batch 730/938] loss_G: 3.289659, loss_D: 0.110531\n",
      "[Epoch 125/200] [Batch 740/938] loss_G: 3.486537, loss_D: 0.066246\n",
      "[Epoch 125/200] [Batch 750/938] loss_G: 3.252754, loss_D: 0.203513\n",
      "[Epoch 125/200] [Batch 760/938] loss_G: 3.442458, loss_D: 0.149263\n",
      "[Epoch 125/200] [Batch 770/938] loss_G: 3.087232, loss_D: 0.227441\n",
      "[Epoch 125/200] [Batch 780/938] loss_G: 3.224113, loss_D: 0.185329\n",
      "[Epoch 125/200] [Batch 790/938] loss_G: 3.319900, loss_D: 0.166804\n",
      "[Epoch 125/200] [Batch 800/938] loss_G: 3.558493, loss_D: 0.196371\n",
      "[Epoch 125/200] [Batch 810/938] loss_G: 3.359262, loss_D: 0.153834\n",
      "[Epoch 125/200] [Batch 820/938] loss_G: 3.278449, loss_D: 0.286688\n",
      "[Epoch 125/200] [Batch 830/938] loss_G: 3.080692, loss_D: 0.161929\n",
      "[Epoch 125/200] [Batch 840/938] loss_G: 3.166815, loss_D: 0.197251\n",
      "[Epoch 125/200] [Batch 850/938] loss_G: 3.390993, loss_D: 0.221218\n",
      "[Epoch 125/200] [Batch 860/938] loss_G: 3.021194, loss_D: 0.170540\n",
      "[Epoch 125/200] [Batch 870/938] loss_G: 2.939857, loss_D: 0.309528\n",
      "[Epoch 125/200] [Batch 880/938] loss_G: 3.392859, loss_D: 0.209640\n",
      "[Epoch 125/200] [Batch 890/938] loss_G: 2.872352, loss_D: 0.191984\n",
      "[Epoch 125/200] [Batch 900/938] loss_G: 3.350403, loss_D: 0.276768\n",
      "[Epoch 125/200] [Batch 910/938] loss_G: 3.394693, loss_D: 0.208608\n",
      "[Epoch 125/200] [Batch 920/938] loss_G: 3.344374, loss_D: 0.212889\n",
      "[Epoch 125/200] [Batch 930/938] loss_G: 3.412207, loss_D: 0.096445\n",
      "[Epoch 126/200] [Batch 0/938] loss_G: 2.955145, loss_D: 0.192171\n",
      "[Epoch 126/200] [Batch 10/938] loss_G: 3.028759, loss_D: 0.176249\n",
      "[Epoch 126/200] [Batch 20/938] loss_G: 3.310449, loss_D: 0.182272\n",
      "[Epoch 126/200] [Batch 30/938] loss_G: 3.315036, loss_D: 0.201735\n",
      "[Epoch 126/200] [Batch 40/938] loss_G: 3.014575, loss_D: 0.143699\n",
      "[Epoch 126/200] [Batch 50/938] loss_G: 3.093781, loss_D: 0.238981\n",
      "[Epoch 126/200] [Batch 60/938] loss_G: 3.420542, loss_D: 0.185808\n",
      "[Epoch 126/200] [Batch 70/938] loss_G: 2.841473, loss_D: 0.301243\n",
      "[Epoch 126/200] [Batch 80/938] loss_G: 3.613398, loss_D: 0.237773\n",
      "[Epoch 126/200] [Batch 90/938] loss_G: 3.700958, loss_D: 0.148919\n",
      "[Epoch 126/200] [Batch 100/938] loss_G: 2.739954, loss_D: 0.224159\n",
      "[Epoch 126/200] [Batch 110/938] loss_G: 2.817989, loss_D: 0.170949\n",
      "[Epoch 126/200] [Batch 120/938] loss_G: 2.669613, loss_D: 0.252619\n",
      "[Epoch 126/200] [Batch 130/938] loss_G: 3.118044, loss_D: 0.208821\n",
      "[Epoch 126/200] [Batch 140/938] loss_G: 3.223536, loss_D: 0.178658\n",
      "[Epoch 126/200] [Batch 150/938] loss_G: 2.968604, loss_D: 0.240778\n",
      "[Epoch 126/200] [Batch 160/938] loss_G: 2.832433, loss_D: 0.137745\n",
      "[Epoch 126/200] [Batch 170/938] loss_G: 3.407213, loss_D: 0.280410\n",
      "[Epoch 126/200] [Batch 180/938] loss_G: 2.964146, loss_D: 0.259534\n",
      "[Epoch 126/200] [Batch 190/938] loss_G: 3.027635, loss_D: 0.183544\n",
      "[Epoch 126/200] [Batch 200/938] loss_G: 3.143395, loss_D: 0.197752\n",
      "[Epoch 126/200] [Batch 210/938] loss_G: 2.737503, loss_D: 0.166708\n",
      "[Epoch 126/200] [Batch 220/938] loss_G: 3.208798, loss_D: 0.189905\n",
      "[Epoch 126/200] [Batch 230/938] loss_G: 2.427696, loss_D: 0.185572\n",
      "[Epoch 126/200] [Batch 240/938] loss_G: 3.280951, loss_D: 0.128181\n",
      "[Epoch 126/200] [Batch 250/938] loss_G: 3.610080, loss_D: 0.136305\n",
      "[Epoch 126/200] [Batch 260/938] loss_G: 2.876958, loss_D: 0.223402\n",
      "[Epoch 126/200] [Batch 270/938] loss_G: 2.836479, loss_D: 0.196046\n",
      "[Epoch 126/200] [Batch 280/938] loss_G: 3.288654, loss_D: 0.158071\n",
      "[Epoch 126/200] [Batch 290/938] loss_G: 3.042728, loss_D: 0.266641\n",
      "[Epoch 126/200] [Batch 300/938] loss_G: 2.838413, loss_D: 0.168908\n",
      "[Epoch 126/200] [Batch 310/938] loss_G: 3.074527, loss_D: 0.151693\n",
      "[Epoch 126/200] [Batch 320/938] loss_G: 3.019855, loss_D: 0.286324\n",
      "[Epoch 126/200] [Batch 330/938] loss_G: 3.527179, loss_D: 0.189176\n",
      "[Epoch 126/200] [Batch 340/938] loss_G: 3.297813, loss_D: 0.260097\n",
      "[Epoch 126/200] [Batch 350/938] loss_G: 2.805104, loss_D: 0.226483\n",
      "[Epoch 126/200] [Batch 360/938] loss_G: 2.894423, loss_D: 0.251407\n",
      "[Epoch 126/200] [Batch 370/938] loss_G: 3.290892, loss_D: 0.204359\n",
      "[Epoch 126/200] [Batch 380/938] loss_G: 3.274774, loss_D: 0.194274\n",
      "[Epoch 126/200] [Batch 390/938] loss_G: 2.651366, loss_D: 0.162349\n",
      "[Epoch 126/200] [Batch 400/938] loss_G: 2.998209, loss_D: 0.316391\n",
      "[Epoch 126/200] [Batch 410/938] loss_G: 3.037120, loss_D: 0.214633\n",
      "[Epoch 126/200] [Batch 420/938] loss_G: 2.657986, loss_D: 0.207882\n",
      "[Epoch 126/200] [Batch 430/938] loss_G: 2.919469, loss_D: 0.166559\n",
      "[Epoch 126/200] [Batch 440/938] loss_G: 3.182809, loss_D: 0.177060\n",
      "[Epoch 126/200] [Batch 450/938] loss_G: 3.329864, loss_D: 0.185385\n",
      "[Epoch 126/200] [Batch 460/938] loss_G: 3.261416, loss_D: 0.238421\n",
      "[Epoch 126/200] [Batch 470/938] loss_G: 3.236486, loss_D: 0.159895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 126/200] [Batch 480/938] loss_G: 3.054197, loss_D: 0.216573\n",
      "[Epoch 126/200] [Batch 490/938] loss_G: 3.067762, loss_D: 0.164174\n",
      "[Epoch 126/200] [Batch 500/938] loss_G: 3.164047, loss_D: 0.142809\n",
      "[Epoch 126/200] [Batch 510/938] loss_G: 3.098955, loss_D: 0.150747\n",
      "[Epoch 126/200] [Batch 520/938] loss_G: 3.193111, loss_D: 0.154532\n",
      "[Epoch 126/200] [Batch 530/938] loss_G: 3.112479, loss_D: 0.254296\n",
      "[Epoch 126/200] [Batch 540/938] loss_G: 3.087173, loss_D: 0.128312\n",
      "[Epoch 126/200] [Batch 550/938] loss_G: 3.178858, loss_D: 0.168710\n",
      "[Epoch 126/200] [Batch 560/938] loss_G: 3.251694, loss_D: 0.205611\n",
      "[Epoch 126/200] [Batch 570/938] loss_G: 2.863969, loss_D: 0.131714\n",
      "[Epoch 126/200] [Batch 580/938] loss_G: 3.040628, loss_D: 0.163485\n",
      "[Epoch 126/200] [Batch 590/938] loss_G: 3.357101, loss_D: 0.164439\n",
      "[Epoch 126/200] [Batch 600/938] loss_G: 3.179611, loss_D: 0.155740\n",
      "[Epoch 126/200] [Batch 610/938] loss_G: 2.845717, loss_D: 0.220827\n",
      "[Epoch 126/200] [Batch 620/938] loss_G: 3.114310, loss_D: 0.152753\n",
      "[Epoch 126/200] [Batch 630/938] loss_G: 2.906992, loss_D: 0.221431\n",
      "[Epoch 126/200] [Batch 640/938] loss_G: 3.026458, loss_D: 0.224702\n",
      "[Epoch 126/200] [Batch 650/938] loss_G: 3.017457, loss_D: 0.199947\n",
      "[Epoch 126/200] [Batch 660/938] loss_G: 3.043067, loss_D: 0.138856\n",
      "[Epoch 126/200] [Batch 670/938] loss_G: 3.239441, loss_D: 0.216641\n",
      "[Epoch 126/200] [Batch 680/938] loss_G: 2.959993, loss_D: 0.199199\n",
      "[Epoch 126/200] [Batch 690/938] loss_G: 3.118644, loss_D: 0.258308\n",
      "[Epoch 126/200] [Batch 700/938] loss_G: 2.979492, loss_D: 0.167612\n",
      "[Epoch 126/200] [Batch 710/938] loss_G: 2.992488, loss_D: 0.183349\n",
      "[Epoch 126/200] [Batch 720/938] loss_G: 3.227485, loss_D: 0.191140\n",
      "[Epoch 126/200] [Batch 730/938] loss_G: 3.332617, loss_D: 0.221487\n",
      "[Epoch 126/200] [Batch 740/938] loss_G: 3.227539, loss_D: 0.165635\n",
      "[Epoch 126/200] [Batch 750/938] loss_G: 3.281736, loss_D: 0.174853\n",
      "[Epoch 126/200] [Batch 760/938] loss_G: 2.768075, loss_D: 0.219552\n",
      "[Epoch 126/200] [Batch 770/938] loss_G: 2.873250, loss_D: 0.295322\n",
      "[Epoch 126/200] [Batch 780/938] loss_G: 2.893534, loss_D: 0.213718\n",
      "[Epoch 126/200] [Batch 790/938] loss_G: 3.154506, loss_D: 0.223227\n",
      "[Epoch 126/200] [Batch 800/938] loss_G: 2.905692, loss_D: 0.175343\n",
      "[Epoch 126/200] [Batch 810/938] loss_G: 3.680906, loss_D: 0.140405\n",
      "[Epoch 126/200] [Batch 820/938] loss_G: 2.818123, loss_D: 0.242088\n",
      "[Epoch 126/200] [Batch 830/938] loss_G: 2.881410, loss_D: 0.199211\n",
      "[Epoch 126/200] [Batch 840/938] loss_G: 2.878201, loss_D: 0.186877\n",
      "[Epoch 126/200] [Batch 850/938] loss_G: 3.252507, loss_D: 0.169631\n",
      "[Epoch 126/200] [Batch 860/938] loss_G: 3.209945, loss_D: 0.171562\n",
      "[Epoch 126/200] [Batch 870/938] loss_G: 3.252568, loss_D: 0.246144\n",
      "[Epoch 126/200] [Batch 880/938] loss_G: 3.291887, loss_D: 0.234916\n",
      "[Epoch 126/200] [Batch 890/938] loss_G: 3.292313, loss_D: 0.201599\n",
      "[Epoch 126/200] [Batch 900/938] loss_G: 3.002839, loss_D: 0.275320\n",
      "[Epoch 126/200] [Batch 910/938] loss_G: 2.704875, loss_D: 0.249938\n",
      "[Epoch 126/200] [Batch 920/938] loss_G: 3.577410, loss_D: 0.206624\n",
      "[Epoch 126/200] [Batch 930/938] loss_G: 2.988920, loss_D: 0.308317\n",
      "[Epoch 127/200] [Batch 0/938] loss_G: 3.112226, loss_D: 0.312999\n",
      "[Epoch 127/200] [Batch 10/938] loss_G: 3.180597, loss_D: 0.217474\n",
      "[Epoch 127/200] [Batch 20/938] loss_G: 3.209030, loss_D: 0.181387\n",
      "[Epoch 127/200] [Batch 30/938] loss_G: 2.958647, loss_D: 0.209151\n",
      "[Epoch 127/200] [Batch 40/938] loss_G: 2.919794, loss_D: 0.213501\n",
      "[Epoch 127/200] [Batch 50/938] loss_G: 3.516542, loss_D: 0.259392\n",
      "[Epoch 127/200] [Batch 60/938] loss_G: 2.978437, loss_D: 0.185155\n",
      "[Epoch 127/200] [Batch 70/938] loss_G: 3.158273, loss_D: 0.222889\n",
      "[Epoch 127/200] [Batch 80/938] loss_G: 3.186295, loss_D: 0.201520\n",
      "[Epoch 127/200] [Batch 90/938] loss_G: 3.220440, loss_D: 0.176710\n",
      "[Epoch 127/200] [Batch 100/938] loss_G: 3.033861, loss_D: 0.247131\n",
      "[Epoch 127/200] [Batch 110/938] loss_G: 3.623220, loss_D: 0.178487\n",
      "[Epoch 127/200] [Batch 120/938] loss_G: 3.173076, loss_D: 0.201619\n",
      "[Epoch 127/200] [Batch 130/938] loss_G: 3.264206, loss_D: 0.268580\n",
      "[Epoch 127/200] [Batch 140/938] loss_G: 3.289626, loss_D: 0.234522\n",
      "[Epoch 127/200] [Batch 150/938] loss_G: 3.161162, loss_D: 0.276109\n",
      "[Epoch 127/200] [Batch 160/938] loss_G: 3.051692, loss_D: 0.209326\n",
      "[Epoch 127/200] [Batch 170/938] loss_G: 3.285197, loss_D: 0.160460\n",
      "[Epoch 127/200] [Batch 180/938] loss_G: 3.408204, loss_D: 0.191607\n",
      "[Epoch 127/200] [Batch 190/938] loss_G: 3.030827, loss_D: 0.137874\n",
      "[Epoch 127/200] [Batch 200/938] loss_G: 3.092237, loss_D: 0.156766\n",
      "[Epoch 127/200] [Batch 210/938] loss_G: 2.839519, loss_D: 0.129931\n",
      "[Epoch 127/200] [Batch 220/938] loss_G: 2.903281, loss_D: 0.177578\n",
      "[Epoch 127/200] [Batch 230/938] loss_G: 3.182110, loss_D: 0.184317\n",
      "[Epoch 127/200] [Batch 240/938] loss_G: 3.026006, loss_D: 0.181282\n",
      "[Epoch 127/200] [Batch 250/938] loss_G: 2.818360, loss_D: 0.223066\n",
      "[Epoch 127/200] [Batch 260/938] loss_G: 3.372570, loss_D: 0.171965\n",
      "[Epoch 127/200] [Batch 270/938] loss_G: 3.163125, loss_D: 0.184658\n",
      "[Epoch 127/200] [Batch 280/938] loss_G: 2.874663, loss_D: 0.241884\n",
      "[Epoch 127/200] [Batch 290/938] loss_G: 3.171025, loss_D: 0.266602\n",
      "[Epoch 127/200] [Batch 300/938] loss_G: 2.810740, loss_D: 0.153619\n",
      "[Epoch 127/200] [Batch 310/938] loss_G: 3.056668, loss_D: 0.164709\n",
      "[Epoch 127/200] [Batch 320/938] loss_G: 3.145355, loss_D: 0.181518\n",
      "[Epoch 127/200] [Batch 330/938] loss_G: 3.090167, loss_D: 0.174544\n",
      "[Epoch 127/200] [Batch 340/938] loss_G: 3.215648, loss_D: 0.210402\n",
      "[Epoch 127/200] [Batch 350/938] loss_G: 2.907999, loss_D: 0.232758\n",
      "[Epoch 127/200] [Batch 360/938] loss_G: 3.127697, loss_D: 0.241866\n",
      "[Epoch 127/200] [Batch 370/938] loss_G: 3.377509, loss_D: 0.176547\n",
      "[Epoch 127/200] [Batch 380/938] loss_G: 2.902046, loss_D: 0.200883\n",
      "[Epoch 127/200] [Batch 390/938] loss_G: 3.519037, loss_D: 0.207037\n",
      "[Epoch 127/200] [Batch 400/938] loss_G: 3.233651, loss_D: 0.236192\n",
      "[Epoch 127/200] [Batch 410/938] loss_G: 3.252136, loss_D: 0.133879\n",
      "[Epoch 127/200] [Batch 420/938] loss_G: 2.923771, loss_D: 0.182841\n",
      "[Epoch 127/200] [Batch 430/938] loss_G: 3.138092, loss_D: 0.200528\n",
      "[Epoch 127/200] [Batch 440/938] loss_G: 2.937201, loss_D: 0.224717\n",
      "[Epoch 127/200] [Batch 450/938] loss_G: 3.162721, loss_D: 0.128150\n",
      "[Epoch 127/200] [Batch 460/938] loss_G: 2.767052, loss_D: 0.267529\n",
      "[Epoch 127/200] [Batch 470/938] loss_G: 3.333905, loss_D: 0.225613\n",
      "[Epoch 127/200] [Batch 480/938] loss_G: 3.476932, loss_D: 0.186978\n",
      "[Epoch 127/200] [Batch 490/938] loss_G: 3.058254, loss_D: 0.186263\n",
      "[Epoch 127/200] [Batch 500/938] loss_G: 3.542169, loss_D: 0.174455\n",
      "[Epoch 127/200] [Batch 510/938] loss_G: 3.178748, loss_D: 0.214056\n",
      "[Epoch 127/200] [Batch 520/938] loss_G: 2.903932, loss_D: 0.220020\n",
      "[Epoch 127/200] [Batch 530/938] loss_G: 3.207578, loss_D: 0.190837\n",
      "[Epoch 127/200] [Batch 540/938] loss_G: 3.009571, loss_D: 0.186228\n",
      "[Epoch 127/200] [Batch 550/938] loss_G: 3.001778, loss_D: 0.122237\n",
      "[Epoch 127/200] [Batch 560/938] loss_G: 3.107955, loss_D: 0.142258\n",
      "[Epoch 127/200] [Batch 570/938] loss_G: 3.153963, loss_D: 0.220266\n",
      "[Epoch 127/200] [Batch 580/938] loss_G: 3.368016, loss_D: 0.275284\n",
      "[Epoch 127/200] [Batch 590/938] loss_G: 3.126392, loss_D: 0.182925\n",
      "[Epoch 127/200] [Batch 600/938] loss_G: 3.265656, loss_D: 0.239534\n",
      "[Epoch 127/200] [Batch 610/938] loss_G: 3.043515, loss_D: 0.228824\n",
      "[Epoch 127/200] [Batch 620/938] loss_G: 3.409575, loss_D: 0.161867\n",
      "[Epoch 127/200] [Batch 630/938] loss_G: 3.277024, loss_D: 0.117008\n",
      "[Epoch 127/200] [Batch 640/938] loss_G: 2.893982, loss_D: 0.219967\n",
      "[Epoch 127/200] [Batch 650/938] loss_G: 3.106012, loss_D: 0.172221\n",
      "[Epoch 127/200] [Batch 660/938] loss_G: 3.207339, loss_D: 0.148859\n",
      "[Epoch 127/200] [Batch 670/938] loss_G: 3.101248, loss_D: 0.219764\n",
      "[Epoch 127/200] [Batch 680/938] loss_G: 3.418003, loss_D: 0.188266\n",
      "[Epoch 127/200] [Batch 690/938] loss_G: 3.139788, loss_D: 0.295112\n",
      "[Epoch 127/200] [Batch 700/938] loss_G: 3.346952, loss_D: 0.175988\n",
      "[Epoch 127/200] [Batch 710/938] loss_G: 3.229965, loss_D: 0.205404\n",
      "[Epoch 127/200] [Batch 720/938] loss_G: 3.059719, loss_D: 0.130629\n",
      "[Epoch 127/200] [Batch 730/938] loss_G: 2.843533, loss_D: 0.230345\n",
      "[Epoch 127/200] [Batch 740/938] loss_G: 3.163546, loss_D: 0.148360\n",
      "[Epoch 127/200] [Batch 750/938] loss_G: 3.204128, loss_D: 0.154725\n",
      "[Epoch 127/200] [Batch 760/938] loss_G: 3.436013, loss_D: 0.207427\n",
      "[Epoch 127/200] [Batch 770/938] loss_G: 2.606956, loss_D: 0.167623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 127/200] [Batch 780/938] loss_G: 2.877865, loss_D: 0.098461\n",
      "[Epoch 127/200] [Batch 790/938] loss_G: 3.188211, loss_D: 0.170253\n",
      "[Epoch 127/200] [Batch 800/938] loss_G: 3.248660, loss_D: 0.154532\n",
      "[Epoch 127/200] [Batch 810/938] loss_G: 2.936954, loss_D: 0.177467\n",
      "[Epoch 127/200] [Batch 820/938] loss_G: 3.037888, loss_D: 0.247068\n",
      "[Epoch 127/200] [Batch 830/938] loss_G: 3.058390, loss_D: 0.134106\n",
      "[Epoch 127/200] [Batch 840/938] loss_G: 3.179246, loss_D: 0.122526\n",
      "[Epoch 127/200] [Batch 850/938] loss_G: 3.276402, loss_D: 0.156231\n",
      "[Epoch 127/200] [Batch 860/938] loss_G: 2.958116, loss_D: 0.245077\n",
      "[Epoch 127/200] [Batch 870/938] loss_G: 3.301148, loss_D: 0.238866\n",
      "[Epoch 127/200] [Batch 880/938] loss_G: 2.806310, loss_D: 0.238938\n",
      "[Epoch 127/200] [Batch 890/938] loss_G: 3.097682, loss_D: 0.205654\n",
      "[Epoch 127/200] [Batch 900/938] loss_G: 3.180842, loss_D: 0.182400\n",
      "[Epoch 127/200] [Batch 910/938] loss_G: 2.865724, loss_D: 0.206892\n",
      "[Epoch 127/200] [Batch 920/938] loss_G: 3.135576, loss_D: 0.168197\n",
      "[Epoch 127/200] [Batch 930/938] loss_G: 2.982955, loss_D: 0.190384\n",
      "[Epoch 128/200] [Batch 0/938] loss_G: 3.253084, loss_D: 0.169550\n",
      "[Epoch 128/200] [Batch 10/938] loss_G: 2.815095, loss_D: 0.213331\n",
      "[Epoch 128/200] [Batch 20/938] loss_G: 3.573178, loss_D: 0.229579\n",
      "[Epoch 128/200] [Batch 30/938] loss_G: 3.161489, loss_D: 0.244566\n",
      "[Epoch 128/200] [Batch 40/938] loss_G: 3.161484, loss_D: 0.242265\n",
      "[Epoch 128/200] [Batch 50/938] loss_G: 3.477966, loss_D: 0.094128\n",
      "[Epoch 128/200] [Batch 60/938] loss_G: 3.441905, loss_D: 0.231829\n",
      "[Epoch 128/200] [Batch 70/938] loss_G: 3.157320, loss_D: 0.170042\n",
      "[Epoch 128/200] [Batch 80/938] loss_G: 2.925605, loss_D: 0.237488\n",
      "[Epoch 128/200] [Batch 90/938] loss_G: 3.034410, loss_D: 0.125110\n",
      "[Epoch 128/200] [Batch 100/938] loss_G: 3.241277, loss_D: 0.167026\n",
      "[Epoch 128/200] [Batch 110/938] loss_G: 2.707052, loss_D: 0.250357\n",
      "[Epoch 128/200] [Batch 120/938] loss_G: 2.978913, loss_D: 0.133156\n",
      "[Epoch 128/200] [Batch 130/938] loss_G: 3.365291, loss_D: 0.185035\n",
      "[Epoch 128/200] [Batch 140/938] loss_G: 3.257678, loss_D: 0.198794\n",
      "[Epoch 128/200] [Batch 150/938] loss_G: 3.227613, loss_D: 0.171112\n",
      "[Epoch 128/200] [Batch 160/938] loss_G: 3.266550, loss_D: 0.229396\n",
      "[Epoch 128/200] [Batch 170/938] loss_G: 3.372725, loss_D: 0.201993\n",
      "[Epoch 128/200] [Batch 180/938] loss_G: 3.186172, loss_D: 0.167692\n",
      "[Epoch 128/200] [Batch 190/938] loss_G: 3.136202, loss_D: 0.191675\n",
      "[Epoch 128/200] [Batch 200/938] loss_G: 3.508059, loss_D: 0.339229\n",
      "[Epoch 128/200] [Batch 210/938] loss_G: 3.434793, loss_D: 0.123080\n",
      "[Epoch 128/200] [Batch 220/938] loss_G: 3.109183, loss_D: 0.157618\n",
      "[Epoch 128/200] [Batch 230/938] loss_G: 3.310025, loss_D: 0.170892\n",
      "[Epoch 128/200] [Batch 240/938] loss_G: 3.212021, loss_D: 0.278188\n",
      "[Epoch 128/200] [Batch 250/938] loss_G: 3.030916, loss_D: 0.196632\n",
      "[Epoch 128/200] [Batch 260/938] loss_G: 3.461408, loss_D: 0.225882\n",
      "[Epoch 128/200] [Batch 270/938] loss_G: 2.926556, loss_D: 0.226007\n",
      "[Epoch 128/200] [Batch 280/938] loss_G: 3.027868, loss_D: 0.177110\n",
      "[Epoch 128/200] [Batch 290/938] loss_G: 3.516616, loss_D: 0.272644\n",
      "[Epoch 128/200] [Batch 300/938] loss_G: 2.617300, loss_D: 0.204163\n",
      "[Epoch 128/200] [Batch 310/938] loss_G: 3.432744, loss_D: 0.287661\n",
      "[Epoch 128/200] [Batch 320/938] loss_G: 2.676934, loss_D: 0.252341\n",
      "[Epoch 128/200] [Batch 330/938] loss_G: 2.861203, loss_D: 0.250764\n",
      "[Epoch 128/200] [Batch 340/938] loss_G: 3.329947, loss_D: 0.161926\n",
      "[Epoch 128/200] [Batch 350/938] loss_G: 3.222098, loss_D: 0.184542\n",
      "[Epoch 128/200] [Batch 360/938] loss_G: 3.347442, loss_D: 0.134370\n",
      "[Epoch 128/200] [Batch 370/938] loss_G: 2.754839, loss_D: 0.272184\n",
      "[Epoch 128/200] [Batch 380/938] loss_G: 3.403434, loss_D: 0.219536\n",
      "[Epoch 128/200] [Batch 390/938] loss_G: 3.290462, loss_D: 0.132768\n",
      "[Epoch 128/200] [Batch 400/938] loss_G: 3.190545, loss_D: 0.130742\n",
      "[Epoch 128/200] [Batch 410/938] loss_G: 3.434821, loss_D: 0.228363\n",
      "[Epoch 128/200] [Batch 420/938] loss_G: 3.033997, loss_D: 0.134323\n",
      "[Epoch 128/200] [Batch 430/938] loss_G: 3.370915, loss_D: 0.198121\n",
      "[Epoch 128/200] [Batch 440/938] loss_G: 3.000542, loss_D: 0.129742\n",
      "[Epoch 128/200] [Batch 450/938] loss_G: 3.285869, loss_D: 0.239159\n",
      "[Epoch 128/200] [Batch 460/938] loss_G: 3.498863, loss_D: 0.144855\n",
      "[Epoch 128/200] [Batch 470/938] loss_G: 3.271344, loss_D: 0.160834\n",
      "[Epoch 128/200] [Batch 480/938] loss_G: 2.892712, loss_D: 0.367920\n",
      "[Epoch 128/200] [Batch 490/938] loss_G: 3.318733, loss_D: 0.171946\n",
      "[Epoch 128/200] [Batch 500/938] loss_G: 3.375547, loss_D: 0.210593\n",
      "[Epoch 128/200] [Batch 510/938] loss_G: 3.394633, loss_D: 0.165276\n",
      "[Epoch 128/200] [Batch 520/938] loss_G: 3.054187, loss_D: 0.155700\n",
      "[Epoch 128/200] [Batch 530/938] loss_G: 3.044006, loss_D: 0.175809\n",
      "[Epoch 128/200] [Batch 540/938] loss_G: 3.329878, loss_D: 0.243999\n",
      "[Epoch 128/200] [Batch 550/938] loss_G: 2.961950, loss_D: 0.196421\n",
      "[Epoch 128/200] [Batch 560/938] loss_G: 3.380005, loss_D: 0.147910\n",
      "[Epoch 128/200] [Batch 570/938] loss_G: 2.938087, loss_D: 0.301831\n",
      "[Epoch 128/200] [Batch 580/938] loss_G: 2.927116, loss_D: 0.152599\n",
      "[Epoch 128/200] [Batch 590/938] loss_G: 3.070442, loss_D: 0.202649\n",
      "[Epoch 128/200] [Batch 600/938] loss_G: 3.107953, loss_D: 0.202800\n",
      "[Epoch 128/200] [Batch 610/938] loss_G: 3.322338, loss_D: 0.152362\n",
      "[Epoch 128/200] [Batch 620/938] loss_G: 3.186264, loss_D: 0.176623\n",
      "[Epoch 128/200] [Batch 630/938] loss_G: 2.902964, loss_D: 0.243283\n",
      "[Epoch 128/200] [Batch 640/938] loss_G: 2.947879, loss_D: 0.150663\n",
      "[Epoch 128/200] [Batch 650/938] loss_G: 3.113047, loss_D: 0.144053\n",
      "[Epoch 128/200] [Batch 660/938] loss_G: 3.123851, loss_D: 0.185929\n",
      "[Epoch 128/200] [Batch 670/938] loss_G: 3.067357, loss_D: 0.153983\n",
      "[Epoch 128/200] [Batch 680/938] loss_G: 3.065803, loss_D: 0.160018\n",
      "[Epoch 128/200] [Batch 690/938] loss_G: 3.214065, loss_D: 0.177944\n",
      "[Epoch 128/200] [Batch 700/938] loss_G: 3.169708, loss_D: 0.153459\n",
      "[Epoch 128/200] [Batch 710/938] loss_G: 3.407945, loss_D: 0.136544\n",
      "[Epoch 128/200] [Batch 720/938] loss_G: 3.335409, loss_D: 0.140429\n",
      "[Epoch 128/200] [Batch 730/938] loss_G: 3.252075, loss_D: 0.203197\n",
      "[Epoch 128/200] [Batch 740/938] loss_G: 3.391476, loss_D: 0.178725\n",
      "[Epoch 128/200] [Batch 750/938] loss_G: 3.401922, loss_D: 0.164201\n",
      "[Epoch 128/200] [Batch 760/938] loss_G: 2.928734, loss_D: 0.203435\n",
      "[Epoch 128/200] [Batch 770/938] loss_G: 3.391392, loss_D: 0.195700\n",
      "[Epoch 128/200] [Batch 780/938] loss_G: 3.240712, loss_D: 0.172614\n",
      "[Epoch 128/200] [Batch 790/938] loss_G: 2.796646, loss_D: 0.172699\n",
      "[Epoch 128/200] [Batch 800/938] loss_G: 3.226710, loss_D: 0.225616\n",
      "[Epoch 128/200] [Batch 810/938] loss_G: 3.025194, loss_D: 0.180103\n",
      "[Epoch 128/200] [Batch 820/938] loss_G: 2.835408, loss_D: 0.190417\n",
      "[Epoch 128/200] [Batch 830/938] loss_G: 3.420531, loss_D: 0.163667\n",
      "[Epoch 128/200] [Batch 840/938] loss_G: 3.276688, loss_D: 0.189936\n",
      "[Epoch 128/200] [Batch 850/938] loss_G: 3.307566, loss_D: 0.150887\n",
      "[Epoch 128/200] [Batch 860/938] loss_G: 3.117295, loss_D: 0.170902\n",
      "[Epoch 128/200] [Batch 870/938] loss_G: 2.855783, loss_D: 0.171800\n",
      "[Epoch 128/200] [Batch 880/938] loss_G: 3.309044, loss_D: 0.200245\n",
      "[Epoch 128/200] [Batch 890/938] loss_G: 3.797106, loss_D: 0.182842\n",
      "[Epoch 128/200] [Batch 900/938] loss_G: 3.452217, loss_D: 0.166185\n",
      "[Epoch 128/200] [Batch 910/938] loss_G: 3.275405, loss_D: 0.189260\n",
      "[Epoch 128/200] [Batch 920/938] loss_G: 3.349823, loss_D: 0.128915\n",
      "[Epoch 128/200] [Batch 930/938] loss_G: 3.180542, loss_D: 0.167818\n",
      "[Epoch 129/200] [Batch 0/938] loss_G: 3.326578, loss_D: 0.242527\n",
      "[Epoch 129/200] [Batch 10/938] loss_G: 3.555361, loss_D: 0.161737\n",
      "[Epoch 129/200] [Batch 20/938] loss_G: 3.038649, loss_D: 0.182166\n",
      "[Epoch 129/200] [Batch 30/938] loss_G: 3.032646, loss_D: 0.280205\n",
      "[Epoch 129/200] [Batch 40/938] loss_G: 3.242208, loss_D: 0.206882\n",
      "[Epoch 129/200] [Batch 50/938] loss_G: 3.124296, loss_D: 0.160194\n",
      "[Epoch 129/200] [Batch 60/938] loss_G: 3.060091, loss_D: 0.176767\n",
      "[Epoch 129/200] [Batch 70/938] loss_G: 3.455670, loss_D: 0.157487\n",
      "[Epoch 129/200] [Batch 80/938] loss_G: 3.388937, loss_D: 0.189741\n",
      "[Epoch 129/200] [Batch 90/938] loss_G: 3.224604, loss_D: 0.213184\n",
      "[Epoch 129/200] [Batch 100/938] loss_G: 3.131632, loss_D: 0.211186\n",
      "[Epoch 129/200] [Batch 110/938] loss_G: 3.103870, loss_D: 0.213852\n",
      "[Epoch 129/200] [Batch 120/938] loss_G: 3.026395, loss_D: 0.235443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 129/200] [Batch 130/938] loss_G: 3.620871, loss_D: 0.201239\n",
      "[Epoch 129/200] [Batch 140/938] loss_G: 3.234495, loss_D: 0.214499\n",
      "[Epoch 129/200] [Batch 150/938] loss_G: 3.405331, loss_D: 0.162998\n",
      "[Epoch 129/200] [Batch 160/938] loss_G: 2.906676, loss_D: 0.267640\n",
      "[Epoch 129/200] [Batch 170/938] loss_G: 3.060541, loss_D: 0.261734\n",
      "[Epoch 129/200] [Batch 180/938] loss_G: 3.680661, loss_D: 0.153253\n",
      "[Epoch 129/200] [Batch 190/938] loss_G: 3.233248, loss_D: 0.356634\n",
      "[Epoch 129/200] [Batch 200/938] loss_G: 2.966243, loss_D: 0.168310\n",
      "[Epoch 129/200] [Batch 210/938] loss_G: 3.179501, loss_D: 0.152886\n",
      "[Epoch 129/200] [Batch 220/938] loss_G: 3.218514, loss_D: 0.197787\n",
      "[Epoch 129/200] [Batch 230/938] loss_G: 3.453475, loss_D: 0.190050\n",
      "[Epoch 129/200] [Batch 240/938] loss_G: 2.997862, loss_D: 0.295112\n",
      "[Epoch 129/200] [Batch 250/938] loss_G: 2.979091, loss_D: 0.127187\n",
      "[Epoch 129/200] [Batch 260/938] loss_G: 3.474625, loss_D: 0.232425\n",
      "[Epoch 129/200] [Batch 270/938] loss_G: 3.405841, loss_D: 0.260754\n",
      "[Epoch 129/200] [Batch 280/938] loss_G: 3.133627, loss_D: 0.164425\n",
      "[Epoch 129/200] [Batch 290/938] loss_G: 3.093283, loss_D: 0.137691\n",
      "[Epoch 129/200] [Batch 300/938] loss_G: 3.031714, loss_D: 0.207022\n",
      "[Epoch 129/200] [Batch 310/938] loss_G: 3.106194, loss_D: 0.153939\n",
      "[Epoch 129/200] [Batch 320/938] loss_G: 3.232511, loss_D: 0.244090\n",
      "[Epoch 129/200] [Batch 330/938] loss_G: 2.840050, loss_D: 0.285819\n",
      "[Epoch 129/200] [Batch 340/938] loss_G: 2.953990, loss_D: 0.251254\n",
      "[Epoch 129/200] [Batch 350/938] loss_G: 3.457325, loss_D: 0.152363\n",
      "[Epoch 129/200] [Batch 360/938] loss_G: 3.278984, loss_D: 0.157421\n",
      "[Epoch 129/200] [Batch 370/938] loss_G: 3.370822, loss_D: 0.211408\n",
      "[Epoch 129/200] [Batch 380/938] loss_G: 2.816624, loss_D: 0.276354\n",
      "[Epoch 129/200] [Batch 390/938] loss_G: 3.092969, loss_D: 0.259783\n",
      "[Epoch 129/200] [Batch 400/938] loss_G: 3.264530, loss_D: 0.176062\n",
      "[Epoch 129/200] [Batch 410/938] loss_G: 2.773318, loss_D: 0.212504\n",
      "[Epoch 129/200] [Batch 420/938] loss_G: 3.297943, loss_D: 0.177719\n",
      "[Epoch 129/200] [Batch 430/938] loss_G: 2.889876, loss_D: 0.220966\n",
      "[Epoch 129/200] [Batch 440/938] loss_G: 3.024552, loss_D: 0.196291\n",
      "[Epoch 129/200] [Batch 450/938] loss_G: 3.380924, loss_D: 0.136683\n",
      "[Epoch 129/200] [Batch 460/938] loss_G: 2.849888, loss_D: 0.202638\n",
      "[Epoch 129/200] [Batch 470/938] loss_G: 2.797440, loss_D: 0.291474\n",
      "[Epoch 129/200] [Batch 480/938] loss_G: 3.427927, loss_D: 0.157048\n",
      "[Epoch 129/200] [Batch 490/938] loss_G: 3.486434, loss_D: 0.209670\n",
      "[Epoch 129/200] [Batch 500/938] loss_G: 3.715220, loss_D: 0.100160\n",
      "[Epoch 129/200] [Batch 510/938] loss_G: 3.280026, loss_D: 0.130533\n",
      "[Epoch 129/200] [Batch 520/938] loss_G: 3.454117, loss_D: 0.201638\n",
      "[Epoch 129/200] [Batch 530/938] loss_G: 3.094462, loss_D: 0.259166\n",
      "[Epoch 129/200] [Batch 540/938] loss_G: 3.238586, loss_D: 0.202247\n",
      "[Epoch 129/200] [Batch 550/938] loss_G: 3.564890, loss_D: 0.195048\n",
      "[Epoch 129/200] [Batch 560/938] loss_G: 3.274867, loss_D: 0.236556\n",
      "[Epoch 129/200] [Batch 570/938] loss_G: 3.349177, loss_D: 0.174845\n",
      "[Epoch 129/200] [Batch 580/938] loss_G: 3.175944, loss_D: 0.257858\n",
      "[Epoch 129/200] [Batch 590/938] loss_G: 3.565035, loss_D: 0.210146\n",
      "[Epoch 129/200] [Batch 600/938] loss_G: 3.574238, loss_D: 0.246216\n",
      "[Epoch 129/200] [Batch 610/938] loss_G: 2.606201, loss_D: 0.262145\n",
      "[Epoch 129/200] [Batch 620/938] loss_G: 3.354925, loss_D: 0.154042\n",
      "[Epoch 129/200] [Batch 630/938] loss_G: 3.404438, loss_D: 0.253230\n",
      "[Epoch 129/200] [Batch 640/938] loss_G: 3.705770, loss_D: 0.180284\n",
      "[Epoch 129/200] [Batch 650/938] loss_G: 3.193398, loss_D: 0.298529\n",
      "[Epoch 129/200] [Batch 660/938] loss_G: 3.340005, loss_D: 0.153869\n",
      "[Epoch 129/200] [Batch 670/938] loss_G: 3.193003, loss_D: 0.207943\n",
      "[Epoch 129/200] [Batch 680/938] loss_G: 3.768804, loss_D: 0.166856\n",
      "[Epoch 129/200] [Batch 690/938] loss_G: 3.130337, loss_D: 0.178312\n",
      "[Epoch 129/200] [Batch 700/938] loss_G: 2.744812, loss_D: 0.170756\n",
      "[Epoch 129/200] [Batch 710/938] loss_G: 3.535785, loss_D: 0.217617\n",
      "[Epoch 129/200] [Batch 720/938] loss_G: 3.045364, loss_D: 0.177317\n",
      "[Epoch 129/200] [Batch 730/938] loss_G: 3.423818, loss_D: 0.138730\n",
      "[Epoch 129/200] [Batch 740/938] loss_G: 3.305248, loss_D: 0.208525\n",
      "[Epoch 129/200] [Batch 750/938] loss_G: 2.982259, loss_D: 0.128053\n",
      "[Epoch 129/200] [Batch 760/938] loss_G: 3.008719, loss_D: 0.168868\n",
      "[Epoch 129/200] [Batch 770/938] loss_G: 3.333083, loss_D: 0.192987\n",
      "[Epoch 129/200] [Batch 780/938] loss_G: 3.271212, loss_D: 0.249989\n",
      "[Epoch 129/200] [Batch 790/938] loss_G: 2.880993, loss_D: 0.254595\n",
      "[Epoch 129/200] [Batch 800/938] loss_G: 3.041306, loss_D: 0.169501\n",
      "[Epoch 129/200] [Batch 810/938] loss_G: 3.103885, loss_D: 0.198538\n",
      "[Epoch 129/200] [Batch 820/938] loss_G: 3.054139, loss_D: 0.148092\n",
      "[Epoch 129/200] [Batch 830/938] loss_G: 3.407131, loss_D: 0.203137\n",
      "[Epoch 129/200] [Batch 840/938] loss_G: 3.462849, loss_D: 0.166492\n",
      "[Epoch 129/200] [Batch 850/938] loss_G: 3.244680, loss_D: 0.263306\n",
      "[Epoch 129/200] [Batch 860/938] loss_G: 3.484984, loss_D: 0.349110\n",
      "[Epoch 129/200] [Batch 870/938] loss_G: 3.476964, loss_D: 0.157881\n",
      "[Epoch 129/200] [Batch 880/938] loss_G: 2.981497, loss_D: 0.170275\n",
      "[Epoch 129/200] [Batch 890/938] loss_G: 3.307281, loss_D: 0.174186\n",
      "[Epoch 129/200] [Batch 900/938] loss_G: 3.741992, loss_D: 0.149936\n",
      "[Epoch 129/200] [Batch 910/938] loss_G: 2.858406, loss_D: 0.195859\n",
      "[Epoch 129/200] [Batch 920/938] loss_G: 3.390649, loss_D: 0.234101\n",
      "[Epoch 129/200] [Batch 930/938] loss_G: 3.305669, loss_D: 0.139283\n",
      "[Epoch 130/200] [Batch 0/938] loss_G: 3.257170, loss_D: 0.184534\n",
      "[Epoch 130/200] [Batch 10/938] loss_G: 3.211122, loss_D: 0.164029\n",
      "[Epoch 130/200] [Batch 20/938] loss_G: 3.339879, loss_D: 0.103365\n",
      "[Epoch 130/200] [Batch 30/938] loss_G: 2.868856, loss_D: 0.124970\n",
      "[Epoch 130/200] [Batch 40/938] loss_G: 3.395337, loss_D: 0.125115\n",
      "[Epoch 130/200] [Batch 50/938] loss_G: 3.249776, loss_D: 0.256178\n",
      "[Epoch 130/200] [Batch 60/938] loss_G: 2.983950, loss_D: 0.190977\n",
      "[Epoch 130/200] [Batch 70/938] loss_G: 3.094009, loss_D: 0.233279\n",
      "[Epoch 130/200] [Batch 80/938] loss_G: 3.198767, loss_D: 0.218070\n",
      "[Epoch 130/200] [Batch 90/938] loss_G: 2.997654, loss_D: 0.299397\n",
      "[Epoch 130/200] [Batch 100/938] loss_G: 3.503029, loss_D: 0.162083\n",
      "[Epoch 130/200] [Batch 110/938] loss_G: 3.131356, loss_D: 0.190983\n",
      "[Epoch 130/200] [Batch 120/938] loss_G: 3.075548, loss_D: 0.175980\n",
      "[Epoch 130/200] [Batch 130/938] loss_G: 3.085896, loss_D: 0.234172\n",
      "[Epoch 130/200] [Batch 140/938] loss_G: 2.858995, loss_D: 0.143086\n",
      "[Epoch 130/200] [Batch 150/938] loss_G: 3.216905, loss_D: 0.143368\n",
      "[Epoch 130/200] [Batch 160/938] loss_G: 3.023763, loss_D: 0.211575\n",
      "[Epoch 130/200] [Batch 170/938] loss_G: 3.343115, loss_D: 0.208479\n",
      "[Epoch 130/200] [Batch 180/938] loss_G: 3.191597, loss_D: 0.180575\n",
      "[Epoch 130/200] [Batch 190/938] loss_G: 3.506007, loss_D: 0.170292\n",
      "[Epoch 130/200] [Batch 200/938] loss_G: 3.131754, loss_D: 0.183845\n",
      "[Epoch 130/200] [Batch 210/938] loss_G: 2.959206, loss_D: 0.276929\n",
      "[Epoch 130/200] [Batch 220/938] loss_G: 2.925988, loss_D: 0.232886\n",
      "[Epoch 130/200] [Batch 230/938] loss_G: 3.173450, loss_D: 0.149947\n",
      "[Epoch 130/200] [Batch 240/938] loss_G: 3.391822, loss_D: 0.151931\n",
      "[Epoch 130/200] [Batch 250/938] loss_G: 3.173457, loss_D: 0.166296\n",
      "[Epoch 130/200] [Batch 260/938] loss_G: 3.153117, loss_D: 0.173610\n",
      "[Epoch 130/200] [Batch 270/938] loss_G: 2.942712, loss_D: 0.244080\n",
      "[Epoch 130/200] [Batch 280/938] loss_G: 3.498055, loss_D: 0.247583\n",
      "[Epoch 130/200] [Batch 290/938] loss_G: 3.278423, loss_D: 0.135377\n",
      "[Epoch 130/200] [Batch 300/938] loss_G: 3.180435, loss_D: 0.256862\n",
      "[Epoch 130/200] [Batch 310/938] loss_G: 3.169681, loss_D: 0.152839\n",
      "[Epoch 130/200] [Batch 320/938] loss_G: 3.159604, loss_D: 0.196829\n",
      "[Epoch 130/200] [Batch 330/938] loss_G: 3.005157, loss_D: 0.160728\n",
      "[Epoch 130/200] [Batch 340/938] loss_G: 3.113066, loss_D: 0.168932\n",
      "[Epoch 130/200] [Batch 350/938] loss_G: 2.875094, loss_D: 0.326023\n",
      "[Epoch 130/200] [Batch 360/938] loss_G: 3.109253, loss_D: 0.210090\n",
      "[Epoch 130/200] [Batch 370/938] loss_G: 3.119297, loss_D: 0.201471\n",
      "[Epoch 130/200] [Batch 380/938] loss_G: 3.229255, loss_D: 0.150852\n",
      "[Epoch 130/200] [Batch 390/938] loss_G: 3.290599, loss_D: 0.220293\n",
      "[Epoch 130/200] [Batch 400/938] loss_G: 3.186751, loss_D: 0.164488\n",
      "[Epoch 130/200] [Batch 410/938] loss_G: 3.049679, loss_D: 0.317830\n",
      "[Epoch 130/200] [Batch 420/938] loss_G: 3.014164, loss_D: 0.128721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 130/200] [Batch 430/938] loss_G: 3.167878, loss_D: 0.147089\n",
      "[Epoch 130/200] [Batch 440/938] loss_G: 3.260677, loss_D: 0.139449\n",
      "[Epoch 130/200] [Batch 450/938] loss_G: 3.223658, loss_D: 0.267761\n",
      "[Epoch 130/200] [Batch 460/938] loss_G: 3.018756, loss_D: 0.128777\n",
      "[Epoch 130/200] [Batch 470/938] loss_G: 3.141274, loss_D: 0.131430\n",
      "[Epoch 130/200] [Batch 480/938] loss_G: 3.236059, loss_D: 0.206479\n",
      "[Epoch 130/200] [Batch 490/938] loss_G: 2.905479, loss_D: 0.246241\n",
      "[Epoch 130/200] [Batch 500/938] loss_G: 3.464987, loss_D: 0.169762\n",
      "[Epoch 130/200] [Batch 510/938] loss_G: 2.508339, loss_D: 0.187099\n",
      "[Epoch 130/200] [Batch 520/938] loss_G: 3.371044, loss_D: 0.184019\n",
      "[Epoch 130/200] [Batch 530/938] loss_G: 3.215519, loss_D: 0.204024\n",
      "[Epoch 130/200] [Batch 540/938] loss_G: 3.089968, loss_D: 0.197327\n",
      "[Epoch 130/200] [Batch 550/938] loss_G: 3.433649, loss_D: 0.209148\n",
      "[Epoch 130/200] [Batch 560/938] loss_G: 3.255686, loss_D: 0.170819\n",
      "[Epoch 130/200] [Batch 570/938] loss_G: 3.026449, loss_D: 0.241627\n",
      "[Epoch 130/200] [Batch 580/938] loss_G: 3.181768, loss_D: 0.199358\n",
      "[Epoch 130/200] [Batch 590/938] loss_G: 3.079885, loss_D: 0.196698\n",
      "[Epoch 130/200] [Batch 600/938] loss_G: 2.947939, loss_D: 0.170977\n",
      "[Epoch 130/200] [Batch 610/938] loss_G: 3.261523, loss_D: 0.171483\n",
      "[Epoch 130/200] [Batch 620/938] loss_G: 3.309758, loss_D: 0.213464\n",
      "[Epoch 130/200] [Batch 630/938] loss_G: 2.945974, loss_D: 0.165184\n",
      "[Epoch 130/200] [Batch 640/938] loss_G: 3.107361, loss_D: 0.226929\n",
      "[Epoch 130/200] [Batch 650/938] loss_G: 3.588998, loss_D: 0.176053\n",
      "[Epoch 130/200] [Batch 660/938] loss_G: 3.173612, loss_D: 0.207359\n",
      "[Epoch 130/200] [Batch 670/938] loss_G: 3.256860, loss_D: 0.183492\n",
      "[Epoch 130/200] [Batch 680/938] loss_G: 2.565531, loss_D: 0.212036\n",
      "[Epoch 130/200] [Batch 690/938] loss_G: 3.156307, loss_D: 0.282741\n",
      "[Epoch 130/200] [Batch 700/938] loss_G: 3.191640, loss_D: 0.105651\n",
      "[Epoch 130/200] [Batch 710/938] loss_G: 3.111265, loss_D: 0.174209\n",
      "[Epoch 130/200] [Batch 720/938] loss_G: 3.408738, loss_D: 0.255531\n",
      "[Epoch 130/200] [Batch 730/938] loss_G: 3.359223, loss_D: 0.140820\n",
      "[Epoch 130/200] [Batch 740/938] loss_G: 2.906033, loss_D: 0.217036\n",
      "[Epoch 130/200] [Batch 750/938] loss_G: 3.275486, loss_D: 0.174941\n",
      "[Epoch 130/200] [Batch 760/938] loss_G: 3.158269, loss_D: 0.197431\n",
      "[Epoch 130/200] [Batch 770/938] loss_G: 3.306295, loss_D: 0.222564\n",
      "[Epoch 130/200] [Batch 780/938] loss_G: 3.408650, loss_D: 0.228997\n",
      "[Epoch 130/200] [Batch 790/938] loss_G: 2.977639, loss_D: 0.303932\n",
      "[Epoch 130/200] [Batch 800/938] loss_G: 3.054808, loss_D: 0.175090\n",
      "[Epoch 130/200] [Batch 810/938] loss_G: 3.186207, loss_D: 0.139377\n",
      "[Epoch 130/200] [Batch 820/938] loss_G: 3.279909, loss_D: 0.237727\n",
      "[Epoch 130/200] [Batch 830/938] loss_G: 3.195756, loss_D: 0.254897\n",
      "[Epoch 130/200] [Batch 840/938] loss_G: 2.856529, loss_D: 0.199818\n",
      "[Epoch 130/200] [Batch 850/938] loss_G: 3.022640, loss_D: 0.308437\n",
      "[Epoch 130/200] [Batch 860/938] loss_G: 3.154729, loss_D: 0.220319\n",
      "[Epoch 130/200] [Batch 870/938] loss_G: 3.389555, loss_D: 0.185138\n",
      "[Epoch 130/200] [Batch 880/938] loss_G: 3.224286, loss_D: 0.239124\n",
      "[Epoch 130/200] [Batch 890/938] loss_G: 3.251705, loss_D: 0.200311\n",
      "[Epoch 130/200] [Batch 900/938] loss_G: 3.377135, loss_D: 0.144824\n",
      "[Epoch 130/200] [Batch 910/938] loss_G: 3.088295, loss_D: 0.248441\n",
      "[Epoch 130/200] [Batch 920/938] loss_G: 3.571560, loss_D: 0.191998\n",
      "[Epoch 130/200] [Batch 930/938] loss_G: 3.156847, loss_D: 0.201267\n",
      "[Epoch 131/200] [Batch 0/938] loss_G: 2.891760, loss_D: 0.255533\n",
      "[Epoch 131/200] [Batch 10/938] loss_G: 3.074990, loss_D: 0.108741\n",
      "[Epoch 131/200] [Batch 20/938] loss_G: 3.532682, loss_D: 0.213846\n",
      "[Epoch 131/200] [Batch 30/938] loss_G: 3.000924, loss_D: 0.221496\n",
      "[Epoch 131/200] [Batch 40/938] loss_G: 3.238331, loss_D: 0.241040\n",
      "[Epoch 131/200] [Batch 50/938] loss_G: 3.426635, loss_D: 0.117442\n",
      "[Epoch 131/200] [Batch 60/938] loss_G: 3.632338, loss_D: 0.283832\n",
      "[Epoch 131/200] [Batch 70/938] loss_G: 3.232650, loss_D: 0.224819\n",
      "[Epoch 131/200] [Batch 80/938] loss_G: 3.041527, loss_D: 0.242629\n",
      "[Epoch 131/200] [Batch 90/938] loss_G: 3.133321, loss_D: 0.190655\n",
      "[Epoch 131/200] [Batch 100/938] loss_G: 3.137475, loss_D: 0.303758\n",
      "[Epoch 131/200] [Batch 110/938] loss_G: 2.995740, loss_D: 0.226625\n",
      "[Epoch 131/200] [Batch 120/938] loss_G: 3.111455, loss_D: 0.221948\n",
      "[Epoch 131/200] [Batch 130/938] loss_G: 3.475068, loss_D: 0.217261\n",
      "[Epoch 131/200] [Batch 140/938] loss_G: 3.019107, loss_D: 0.167393\n",
      "[Epoch 131/200] [Batch 150/938] loss_G: 2.790813, loss_D: 0.219417\n",
      "[Epoch 131/200] [Batch 160/938] loss_G: 3.067678, loss_D: 0.138014\n",
      "[Epoch 131/200] [Batch 170/938] loss_G: 3.088888, loss_D: 0.195812\n",
      "[Epoch 131/200] [Batch 180/938] loss_G: 3.220020, loss_D: 0.223218\n",
      "[Epoch 131/200] [Batch 190/938] loss_G: 2.823281, loss_D: 0.215763\n",
      "[Epoch 131/200] [Batch 200/938] loss_G: 3.267144, loss_D: 0.178497\n",
      "[Epoch 131/200] [Batch 210/938] loss_G: 3.140863, loss_D: 0.208797\n",
      "[Epoch 131/200] [Batch 220/938] loss_G: 3.319813, loss_D: 0.189674\n",
      "[Epoch 131/200] [Batch 230/938] loss_G: 3.487262, loss_D: 0.215850\n",
      "[Epoch 131/200] [Batch 240/938] loss_G: 2.574218, loss_D: 0.204114\n",
      "[Epoch 131/200] [Batch 250/938] loss_G: 3.016690, loss_D: 0.180842\n",
      "[Epoch 131/200] [Batch 260/938] loss_G: 3.262213, loss_D: 0.192981\n",
      "[Epoch 131/200] [Batch 270/938] loss_G: 3.362082, loss_D: 0.185126\n",
      "[Epoch 131/200] [Batch 280/938] loss_G: 3.219339, loss_D: 0.258938\n",
      "[Epoch 131/200] [Batch 290/938] loss_G: 3.106750, loss_D: 0.239894\n",
      "[Epoch 131/200] [Batch 300/938] loss_G: 3.046325, loss_D: 0.160285\n",
      "[Epoch 131/200] [Batch 310/938] loss_G: 3.086782, loss_D: 0.288915\n",
      "[Epoch 131/200] [Batch 320/938] loss_G: 3.372072, loss_D: 0.132843\n",
      "[Epoch 131/200] [Batch 330/938] loss_G: 2.956126, loss_D: 0.146427\n",
      "[Epoch 131/200] [Batch 340/938] loss_G: 2.994763, loss_D: 0.165155\n",
      "[Epoch 131/200] [Batch 350/938] loss_G: 3.266187, loss_D: 0.149339\n",
      "[Epoch 131/200] [Batch 360/938] loss_G: 3.090103, loss_D: 0.179835\n",
      "[Epoch 131/200] [Batch 370/938] loss_G: 3.018246, loss_D: 0.239462\n",
      "[Epoch 131/200] [Batch 380/938] loss_G: 2.981686, loss_D: 0.194643\n",
      "[Epoch 131/200] [Batch 390/938] loss_G: 3.246320, loss_D: 0.206334\n",
      "[Epoch 131/200] [Batch 400/938] loss_G: 2.737513, loss_D: 0.315128\n",
      "[Epoch 131/200] [Batch 410/938] loss_G: 3.135386, loss_D: 0.201308\n",
      "[Epoch 131/200] [Batch 420/938] loss_G: 3.246878, loss_D: 0.169441\n",
      "[Epoch 131/200] [Batch 430/938] loss_G: 2.863980, loss_D: 0.166646\n",
      "[Epoch 131/200] [Batch 440/938] loss_G: 2.886480, loss_D: 0.230630\n",
      "[Epoch 131/200] [Batch 450/938] loss_G: 3.048381, loss_D: 0.198482\n",
      "[Epoch 131/200] [Batch 460/938] loss_G: 3.187146, loss_D: 0.245684\n",
      "[Epoch 131/200] [Batch 470/938] loss_G: 3.083853, loss_D: 0.172645\n",
      "[Epoch 131/200] [Batch 480/938] loss_G: 3.045645, loss_D: 0.280869\n",
      "[Epoch 131/200] [Batch 490/938] loss_G: 3.046075, loss_D: 0.231540\n",
      "[Epoch 131/200] [Batch 500/938] loss_G: 3.454890, loss_D: 0.213115\n",
      "[Epoch 131/200] [Batch 510/938] loss_G: 3.017190, loss_D: 0.169967\n",
      "[Epoch 131/200] [Batch 520/938] loss_G: 2.842754, loss_D: 0.220932\n",
      "[Epoch 131/200] [Batch 530/938] loss_G: 3.548938, loss_D: 0.265002\n",
      "[Epoch 131/200] [Batch 540/938] loss_G: 3.013097, loss_D: 0.173337\n",
      "[Epoch 131/200] [Batch 550/938] loss_G: 2.989304, loss_D: 0.165579\n",
      "[Epoch 131/200] [Batch 560/938] loss_G: 2.950529, loss_D: 0.181567\n",
      "[Epoch 131/200] [Batch 570/938] loss_G: 3.250948, loss_D: 0.206950\n",
      "[Epoch 131/200] [Batch 580/938] loss_G: 3.313798, loss_D: 0.180770\n",
      "[Epoch 131/200] [Batch 590/938] loss_G: 3.409467, loss_D: 0.206753\n",
      "[Epoch 131/200] [Batch 600/938] loss_G: 3.099171, loss_D: 0.267360\n",
      "[Epoch 131/200] [Batch 610/938] loss_G: 3.007092, loss_D: 0.223893\n",
      "[Epoch 131/200] [Batch 620/938] loss_G: 3.220310, loss_D: 0.186549\n",
      "[Epoch 131/200] [Batch 630/938] loss_G: 3.350258, loss_D: 0.179821\n",
      "[Epoch 131/200] [Batch 640/938] loss_G: 3.084181, loss_D: 0.185346\n",
      "[Epoch 131/200] [Batch 650/938] loss_G: 3.190520, loss_D: 0.231486\n",
      "[Epoch 131/200] [Batch 660/938] loss_G: 3.704205, loss_D: 0.155964\n",
      "[Epoch 131/200] [Batch 670/938] loss_G: 2.771331, loss_D: 0.176326\n",
      "[Epoch 131/200] [Batch 680/938] loss_G: 2.951491, loss_D: 0.219198\n",
      "[Epoch 131/200] [Batch 690/938] loss_G: 2.902098, loss_D: 0.229883\n",
      "[Epoch 131/200] [Batch 700/938] loss_G: 3.132885, loss_D: 0.189033\n",
      "[Epoch 131/200] [Batch 710/938] loss_G: 2.989354, loss_D: 0.146637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 131/200] [Batch 720/938] loss_G: 3.020971, loss_D: 0.172199\n",
      "[Epoch 131/200] [Batch 730/938] loss_G: 3.168766, loss_D: 0.218220\n",
      "[Epoch 131/200] [Batch 740/938] loss_G: 3.509933, loss_D: 0.248052\n",
      "[Epoch 131/200] [Batch 750/938] loss_G: 3.303348, loss_D: 0.129220\n",
      "[Epoch 131/200] [Batch 760/938] loss_G: 3.317605, loss_D: 0.162462\n",
      "[Epoch 131/200] [Batch 770/938] loss_G: 3.010580, loss_D: 0.266272\n",
      "[Epoch 131/200] [Batch 780/938] loss_G: 3.102222, loss_D: 0.282276\n",
      "[Epoch 131/200] [Batch 790/938] loss_G: 3.224501, loss_D: 0.229307\n",
      "[Epoch 131/200] [Batch 800/938] loss_G: 3.165149, loss_D: 0.216468\n",
      "[Epoch 131/200] [Batch 810/938] loss_G: 2.979322, loss_D: 0.258851\n",
      "[Epoch 131/200] [Batch 820/938] loss_G: 3.235793, loss_D: 0.218512\n",
      "[Epoch 131/200] [Batch 830/938] loss_G: 3.091469, loss_D: 0.257710\n",
      "[Epoch 131/200] [Batch 840/938] loss_G: 3.035758, loss_D: 0.233040\n",
      "[Epoch 131/200] [Batch 850/938] loss_G: 3.168622, loss_D: 0.162953\n",
      "[Epoch 131/200] [Batch 860/938] loss_G: 2.630213, loss_D: 0.204070\n",
      "[Epoch 131/200] [Batch 870/938] loss_G: 3.204250, loss_D: 0.192043\n",
      "[Epoch 131/200] [Batch 880/938] loss_G: 3.546470, loss_D: 0.167856\n",
      "[Epoch 131/200] [Batch 890/938] loss_G: 2.823718, loss_D: 0.214582\n",
      "[Epoch 131/200] [Batch 900/938] loss_G: 2.926026, loss_D: 0.240671\n",
      "[Epoch 131/200] [Batch 910/938] loss_G: 2.758083, loss_D: 0.251966\n",
      "[Epoch 131/200] [Batch 920/938] loss_G: 3.137649, loss_D: 0.205900\n",
      "[Epoch 131/200] [Batch 930/938] loss_G: 3.260807, loss_D: 0.312159\n",
      "[Epoch 132/200] [Batch 0/938] loss_G: 3.069360, loss_D: 0.179914\n",
      "[Epoch 132/200] [Batch 10/938] loss_G: 3.218248, loss_D: 0.165887\n",
      "[Epoch 132/200] [Batch 20/938] loss_G: 3.217788, loss_D: 0.148207\n",
      "[Epoch 132/200] [Batch 30/938] loss_G: 3.170615, loss_D: 0.170842\n",
      "[Epoch 132/200] [Batch 40/938] loss_G: 3.096956, loss_D: 0.243693\n",
      "[Epoch 132/200] [Batch 50/938] loss_G: 3.220150, loss_D: 0.161484\n",
      "[Epoch 132/200] [Batch 60/938] loss_G: 3.469034, loss_D: 0.156516\n",
      "[Epoch 132/200] [Batch 70/938] loss_G: 3.015888, loss_D: 0.191522\n",
      "[Epoch 132/200] [Batch 80/938] loss_G: 3.125890, loss_D: 0.285086\n",
      "[Epoch 132/200] [Batch 90/938] loss_G: 3.097487, loss_D: 0.210536\n",
      "[Epoch 132/200] [Batch 100/938] loss_G: 3.030296, loss_D: 0.168367\n",
      "[Epoch 132/200] [Batch 110/938] loss_G: 3.016043, loss_D: 0.142393\n",
      "[Epoch 132/200] [Batch 120/938] loss_G: 3.755519, loss_D: 0.152498\n",
      "[Epoch 132/200] [Batch 130/938] loss_G: 2.776276, loss_D: 0.288837\n",
      "[Epoch 132/200] [Batch 140/938] loss_G: 3.446566, loss_D: 0.147253\n",
      "[Epoch 132/200] [Batch 150/938] loss_G: 3.090253, loss_D: 0.123077\n",
      "[Epoch 132/200] [Batch 160/938] loss_G: 2.945007, loss_D: 0.219602\n",
      "[Epoch 132/200] [Batch 170/938] loss_G: 3.004682, loss_D: 0.244496\n",
      "[Epoch 132/200] [Batch 180/938] loss_G: 3.214736, loss_D: 0.193508\n",
      "[Epoch 132/200] [Batch 190/938] loss_G: 3.134506, loss_D: 0.252500\n",
      "[Epoch 132/200] [Batch 200/938] loss_G: 2.576803, loss_D: 0.192836\n",
      "[Epoch 132/200] [Batch 210/938] loss_G: 3.098692, loss_D: 0.213902\n",
      "[Epoch 132/200] [Batch 220/938] loss_G: 3.439746, loss_D: 0.153286\n",
      "[Epoch 132/200] [Batch 230/938] loss_G: 3.054727, loss_D: 0.174820\n",
      "[Epoch 132/200] [Batch 240/938] loss_G: 3.383414, loss_D: 0.294373\n",
      "[Epoch 132/200] [Batch 250/938] loss_G: 3.137964, loss_D: 0.184304\n",
      "[Epoch 132/200] [Batch 260/938] loss_G: 3.414896, loss_D: 0.123655\n",
      "[Epoch 132/200] [Batch 270/938] loss_G: 3.001523, loss_D: 0.207017\n",
      "[Epoch 132/200] [Batch 280/938] loss_G: 2.988517, loss_D: 0.206352\n",
      "[Epoch 132/200] [Batch 290/938] loss_G: 3.298169, loss_D: 0.155708\n",
      "[Epoch 132/200] [Batch 300/938] loss_G: 3.093712, loss_D: 0.243375\n",
      "[Epoch 132/200] [Batch 310/938] loss_G: 3.479912, loss_D: 0.129282\n",
      "[Epoch 132/200] [Batch 320/938] loss_G: 2.528902, loss_D: 0.258265\n",
      "[Epoch 132/200] [Batch 330/938] loss_G: 3.288120, loss_D: 0.239611\n",
      "[Epoch 132/200] [Batch 340/938] loss_G: 3.329814, loss_D: 0.226191\n",
      "[Epoch 132/200] [Batch 350/938] loss_G: 3.322769, loss_D: 0.274866\n",
      "[Epoch 132/200] [Batch 360/938] loss_G: 3.625473, loss_D: 0.159290\n",
      "[Epoch 132/200] [Batch 370/938] loss_G: 3.594857, loss_D: 0.198065\n",
      "[Epoch 132/200] [Batch 380/938] loss_G: 3.055638, loss_D: 0.098930\n",
      "[Epoch 132/200] [Batch 390/938] loss_G: 3.207993, loss_D: 0.197701\n",
      "[Epoch 132/200] [Batch 400/938] loss_G: 3.354720, loss_D: 0.142337\n",
      "[Epoch 132/200] [Batch 410/938] loss_G: 3.719866, loss_D: 0.124710\n",
      "[Epoch 132/200] [Batch 420/938] loss_G: 3.490400, loss_D: 0.195685\n",
      "[Epoch 132/200] [Batch 430/938] loss_G: 3.414503, loss_D: 0.140917\n",
      "[Epoch 132/200] [Batch 440/938] loss_G: 3.192789, loss_D: 0.118812\n",
      "[Epoch 132/200] [Batch 450/938] loss_G: 3.230007, loss_D: 0.143204\n",
      "[Epoch 132/200] [Batch 460/938] loss_G: 3.125947, loss_D: 0.159571\n",
      "[Epoch 132/200] [Batch 470/938] loss_G: 3.627363, loss_D: 0.328595\n",
      "[Epoch 132/200] [Batch 480/938] loss_G: 3.296808, loss_D: 0.180933\n",
      "[Epoch 132/200] [Batch 490/938] loss_G: 3.314792, loss_D: 0.195912\n",
      "[Epoch 132/200] [Batch 500/938] loss_G: 3.022136, loss_D: 0.235558\n",
      "[Epoch 132/200] [Batch 510/938] loss_G: 3.391634, loss_D: 0.211467\n",
      "[Epoch 132/200] [Batch 520/938] loss_G: 2.648012, loss_D: 0.147247\n",
      "[Epoch 132/200] [Batch 530/938] loss_G: 3.415086, loss_D: 0.206512\n",
      "[Epoch 132/200] [Batch 540/938] loss_G: 2.997705, loss_D: 0.310019\n",
      "[Epoch 132/200] [Batch 550/938] loss_G: 3.080931, loss_D: 0.260691\n",
      "[Epoch 132/200] [Batch 560/938] loss_G: 3.321491, loss_D: 0.175568\n",
      "[Epoch 132/200] [Batch 570/938] loss_G: 3.095561, loss_D: 0.148602\n",
      "[Epoch 132/200] [Batch 580/938] loss_G: 3.088764, loss_D: 0.277486\n",
      "[Epoch 132/200] [Batch 590/938] loss_G: 2.982295, loss_D: 0.163619\n",
      "[Epoch 132/200] [Batch 600/938] loss_G: 2.987489, loss_D: 0.200647\n",
      "[Epoch 132/200] [Batch 610/938] loss_G: 3.279171, loss_D: 0.126743\n",
      "[Epoch 132/200] [Batch 620/938] loss_G: 3.419632, loss_D: 0.167112\n",
      "[Epoch 132/200] [Batch 630/938] loss_G: 3.198147, loss_D: 0.153299\n",
      "[Epoch 132/200] [Batch 640/938] loss_G: 3.088460, loss_D: 0.137491\n",
      "[Epoch 132/200] [Batch 650/938] loss_G: 3.043992, loss_D: 0.326996\n",
      "[Epoch 132/200] [Batch 660/938] loss_G: 3.268990, loss_D: 0.196192\n",
      "[Epoch 132/200] [Batch 670/938] loss_G: 2.833467, loss_D: 0.228817\n",
      "[Epoch 132/200] [Batch 680/938] loss_G: 2.984047, loss_D: 0.188368\n",
      "[Epoch 132/200] [Batch 690/938] loss_G: 2.864328, loss_D: 0.181402\n",
      "[Epoch 132/200] [Batch 700/938] loss_G: 3.584692, loss_D: 0.200373\n",
      "[Epoch 132/200] [Batch 710/938] loss_G: 3.288453, loss_D: 0.270490\n",
      "[Epoch 132/200] [Batch 720/938] loss_G: 3.205884, loss_D: 0.208035\n",
      "[Epoch 132/200] [Batch 730/938] loss_G: 2.898807, loss_D: 0.303144\n",
      "[Epoch 132/200] [Batch 740/938] loss_G: 3.248497, loss_D: 0.158744\n",
      "[Epoch 132/200] [Batch 750/938] loss_G: 3.175561, loss_D: 0.210522\n",
      "[Epoch 132/200] [Batch 760/938] loss_G: 3.401963, loss_D: 0.111452\n",
      "[Epoch 132/200] [Batch 770/938] loss_G: 2.978536, loss_D: 0.211444\n",
      "[Epoch 132/200] [Batch 780/938] loss_G: 2.882046, loss_D: 0.201500\n",
      "[Epoch 132/200] [Batch 790/938] loss_G: 2.934118, loss_D: 0.188778\n",
      "[Epoch 132/200] [Batch 800/938] loss_G: 3.337509, loss_D: 0.155343\n",
      "[Epoch 132/200] [Batch 810/938] loss_G: 3.191875, loss_D: 0.184841\n",
      "[Epoch 132/200] [Batch 820/938] loss_G: 2.899177, loss_D: 0.257768\n",
      "[Epoch 132/200] [Batch 830/938] loss_G: 3.287998, loss_D: 0.225614\n",
      "[Epoch 132/200] [Batch 840/938] loss_G: 3.477409, loss_D: 0.197376\n",
      "[Epoch 132/200] [Batch 850/938] loss_G: 3.180767, loss_D: 0.194276\n",
      "[Epoch 132/200] [Batch 860/938] loss_G: 3.047710, loss_D: 0.288820\n",
      "[Epoch 132/200] [Batch 870/938] loss_G: 3.410480, loss_D: 0.226863\n",
      "[Epoch 132/200] [Batch 880/938] loss_G: 3.141047, loss_D: 0.251800\n",
      "[Epoch 132/200] [Batch 890/938] loss_G: 3.249718, loss_D: 0.155991\n",
      "[Epoch 132/200] [Batch 900/938] loss_G: 3.035722, loss_D: 0.313217\n",
      "[Epoch 132/200] [Batch 910/938] loss_G: 2.843775, loss_D: 0.210212\n",
      "[Epoch 132/200] [Batch 920/938] loss_G: 2.973679, loss_D: 0.200946\n",
      "[Epoch 132/200] [Batch 930/938] loss_G: 3.133947, loss_D: 0.329176\n",
      "[Epoch 133/200] [Batch 0/938] loss_G: 3.329331, loss_D: 0.243092\n",
      "[Epoch 133/200] [Batch 10/938] loss_G: 3.099201, loss_D: 0.211552\n",
      "[Epoch 133/200] [Batch 20/938] loss_G: 3.289776, loss_D: 0.136073\n",
      "[Epoch 133/200] [Batch 30/938] loss_G: 3.335604, loss_D: 0.217376\n",
      "[Epoch 133/200] [Batch 40/938] loss_G: 3.182949, loss_D: 0.198739\n",
      "[Epoch 133/200] [Batch 50/938] loss_G: 2.889146, loss_D: 0.264212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 133/200] [Batch 60/938] loss_G: 3.280102, loss_D: 0.216705\n",
      "[Epoch 133/200] [Batch 70/938] loss_G: 3.323452, loss_D: 0.120508\n",
      "[Epoch 133/200] [Batch 80/938] loss_G: 3.336061, loss_D: 0.106150\n",
      "[Epoch 133/200] [Batch 90/938] loss_G: 2.913586, loss_D: 0.186031\n",
      "[Epoch 133/200] [Batch 100/938] loss_G: 3.256474, loss_D: 0.220280\n",
      "[Epoch 133/200] [Batch 110/938] loss_G: 2.773199, loss_D: 0.209722\n",
      "[Epoch 133/200] [Batch 120/938] loss_G: 3.432572, loss_D: 0.228833\n",
      "[Epoch 133/200] [Batch 130/938] loss_G: 3.279644, loss_D: 0.159854\n",
      "[Epoch 133/200] [Batch 140/938] loss_G: 3.199869, loss_D: 0.195529\n",
      "[Epoch 133/200] [Batch 150/938] loss_G: 3.130849, loss_D: 0.160212\n",
      "[Epoch 133/200] [Batch 160/938] loss_G: 2.912503, loss_D: 0.237418\n",
      "[Epoch 133/200] [Batch 170/938] loss_G: 2.966787, loss_D: 0.164424\n",
      "[Epoch 133/200] [Batch 180/938] loss_G: 3.508759, loss_D: 0.195558\n",
      "[Epoch 133/200] [Batch 190/938] loss_G: 3.072297, loss_D: 0.225035\n",
      "[Epoch 133/200] [Batch 200/938] loss_G: 3.150790, loss_D: 0.138357\n",
      "[Epoch 133/200] [Batch 210/938] loss_G: 3.361321, loss_D: 0.129128\n",
      "[Epoch 133/200] [Batch 220/938] loss_G: 3.521220, loss_D: 0.178289\n",
      "[Epoch 133/200] [Batch 230/938] loss_G: 2.986404, loss_D: 0.193392\n",
      "[Epoch 133/200] [Batch 240/938] loss_G: 3.365967, loss_D: 0.149429\n",
      "[Epoch 133/200] [Batch 250/938] loss_G: 2.947271, loss_D: 0.202676\n",
      "[Epoch 133/200] [Batch 260/938] loss_G: 3.008507, loss_D: 0.174283\n",
      "[Epoch 133/200] [Batch 270/938] loss_G: 3.072386, loss_D: 0.253846\n",
      "[Epoch 133/200] [Batch 280/938] loss_G: 3.522815, loss_D: 0.228117\n",
      "[Epoch 133/200] [Batch 290/938] loss_G: 3.135442, loss_D: 0.144140\n",
      "[Epoch 133/200] [Batch 300/938] loss_G: 3.036811, loss_D: 0.175664\n",
      "[Epoch 133/200] [Batch 310/938] loss_G: 3.097252, loss_D: 0.239389\n",
      "[Epoch 133/200] [Batch 320/938] loss_G: 3.010471, loss_D: 0.135630\n",
      "[Epoch 133/200] [Batch 330/938] loss_G: 2.762673, loss_D: 0.174877\n",
      "[Epoch 133/200] [Batch 340/938] loss_G: 3.434612, loss_D: 0.153190\n",
      "[Epoch 133/200] [Batch 350/938] loss_G: 3.460535, loss_D: 0.163520\n",
      "[Epoch 133/200] [Batch 360/938] loss_G: 3.204917, loss_D: 0.165585\n",
      "[Epoch 133/200] [Batch 370/938] loss_G: 3.387967, loss_D: 0.120757\n",
      "[Epoch 133/200] [Batch 380/938] loss_G: 3.222372, loss_D: 0.227966\n",
      "[Epoch 133/200] [Batch 390/938] loss_G: 2.697759, loss_D: 0.216891\n",
      "[Epoch 133/200] [Batch 400/938] loss_G: 3.343108, loss_D: 0.194893\n",
      "[Epoch 133/200] [Batch 410/938] loss_G: 2.994901, loss_D: 0.195851\n",
      "[Epoch 133/200] [Batch 420/938] loss_G: 3.062302, loss_D: 0.218368\n",
      "[Epoch 133/200] [Batch 430/938] loss_G: 3.157060, loss_D: 0.214239\n",
      "[Epoch 133/200] [Batch 440/938] loss_G: 3.126486, loss_D: 0.243177\n",
      "[Epoch 133/200] [Batch 450/938] loss_G: 3.039271, loss_D: 0.243379\n",
      "[Epoch 133/200] [Batch 460/938] loss_G: 2.798717, loss_D: 0.144373\n",
      "[Epoch 133/200] [Batch 470/938] loss_G: 3.229419, loss_D: 0.177184\n",
      "[Epoch 133/200] [Batch 480/938] loss_G: 3.377783, loss_D: 0.268417\n",
      "[Epoch 133/200] [Batch 490/938] loss_G: 3.283493, loss_D: 0.228127\n",
      "[Epoch 133/200] [Batch 500/938] loss_G: 2.932243, loss_D: 0.256225\n",
      "[Epoch 133/200] [Batch 510/938] loss_G: 3.219410, loss_D: 0.141741\n",
      "[Epoch 133/200] [Batch 520/938] loss_G: 3.296663, loss_D: 0.188546\n",
      "[Epoch 133/200] [Batch 530/938] loss_G: 3.167933, loss_D: 0.139049\n",
      "[Epoch 133/200] [Batch 540/938] loss_G: 2.849768, loss_D: 0.209138\n",
      "[Epoch 133/200] [Batch 550/938] loss_G: 3.192197, loss_D: 0.175674\n",
      "[Epoch 133/200] [Batch 560/938] loss_G: 2.979062, loss_D: 0.221875\n",
      "[Epoch 133/200] [Batch 570/938] loss_G: 3.134157, loss_D: 0.146771\n",
      "[Epoch 133/200] [Batch 580/938] loss_G: 3.373217, loss_D: 0.213066\n",
      "[Epoch 133/200] [Batch 590/938] loss_G: 3.166880, loss_D: 0.219614\n",
      "[Epoch 133/200] [Batch 600/938] loss_G: 3.078161, loss_D: 0.182886\n",
      "[Epoch 133/200] [Batch 610/938] loss_G: 2.891397, loss_D: 0.256489\n",
      "[Epoch 133/200] [Batch 620/938] loss_G: 3.052453, loss_D: 0.215034\n",
      "[Epoch 133/200] [Batch 630/938] loss_G: 3.096396, loss_D: 0.280027\n",
      "[Epoch 133/200] [Batch 640/938] loss_G: 2.604758, loss_D: 0.232427\n",
      "[Epoch 133/200] [Batch 650/938] loss_G: 3.303345, loss_D: 0.175375\n",
      "[Epoch 133/200] [Batch 660/938] loss_G: 3.258316, loss_D: 0.258253\n",
      "[Epoch 133/200] [Batch 670/938] loss_G: 2.903169, loss_D: 0.248766\n",
      "[Epoch 133/200] [Batch 680/938] loss_G: 3.607843, loss_D: 0.224741\n",
      "[Epoch 133/200] [Batch 690/938] loss_G: 3.318128, loss_D: 0.148573\n",
      "[Epoch 133/200] [Batch 700/938] loss_G: 3.433120, loss_D: 0.171941\n",
      "[Epoch 133/200] [Batch 710/938] loss_G: 3.182595, loss_D: 0.169556\n",
      "[Epoch 133/200] [Batch 720/938] loss_G: 3.228381, loss_D: 0.124897\n",
      "[Epoch 133/200] [Batch 730/938] loss_G: 3.361073, loss_D: 0.160961\n",
      "[Epoch 133/200] [Batch 740/938] loss_G: 3.372541, loss_D: 0.174035\n",
      "[Epoch 133/200] [Batch 750/938] loss_G: 3.548937, loss_D: 0.190548\n",
      "[Epoch 133/200] [Batch 760/938] loss_G: 3.286667, loss_D: 0.113213\n",
      "[Epoch 133/200] [Batch 770/938] loss_G: 3.162113, loss_D: 0.268040\n",
      "[Epoch 133/200] [Batch 780/938] loss_G: 2.920974, loss_D: 0.163631\n",
      "[Epoch 133/200] [Batch 790/938] loss_G: 3.407720, loss_D: 0.223641\n",
      "[Epoch 133/200] [Batch 800/938] loss_G: 3.128129, loss_D: 0.168535\n",
      "[Epoch 133/200] [Batch 810/938] loss_G: 3.318322, loss_D: 0.180731\n",
      "[Epoch 133/200] [Batch 820/938] loss_G: 3.275118, loss_D: 0.140451\n",
      "[Epoch 133/200] [Batch 830/938] loss_G: 3.374052, loss_D: 0.125826\n",
      "[Epoch 133/200] [Batch 840/938] loss_G: 3.141810, loss_D: 0.217732\n",
      "[Epoch 133/200] [Batch 850/938] loss_G: 3.153637, loss_D: 0.118401\n",
      "[Epoch 133/200] [Batch 860/938] loss_G: 3.588900, loss_D: 0.225393\n",
      "[Epoch 133/200] [Batch 870/938] loss_G: 3.095857, loss_D: 0.135736\n",
      "[Epoch 133/200] [Batch 880/938] loss_G: 3.218369, loss_D: 0.203675\n",
      "[Epoch 133/200] [Batch 890/938] loss_G: 3.281363, loss_D: 0.189510\n",
      "[Epoch 133/200] [Batch 900/938] loss_G: 3.573206, loss_D: 0.131538\n",
      "[Epoch 133/200] [Batch 910/938] loss_G: 2.829759, loss_D: 0.197930\n",
      "[Epoch 133/200] [Batch 920/938] loss_G: 3.092543, loss_D: 0.140646\n",
      "[Epoch 133/200] [Batch 930/938] loss_G: 3.228113, loss_D: 0.248189\n",
      "[Epoch 134/200] [Batch 0/938] loss_G: 3.259046, loss_D: 0.228531\n",
      "[Epoch 134/200] [Batch 10/938] loss_G: 3.251260, loss_D: 0.177602\n",
      "[Epoch 134/200] [Batch 20/938] loss_G: 3.109613, loss_D: 0.258316\n",
      "[Epoch 134/200] [Batch 30/938] loss_G: 3.105239, loss_D: 0.217375\n",
      "[Epoch 134/200] [Batch 40/938] loss_G: 3.476863, loss_D: 0.217274\n",
      "[Epoch 134/200] [Batch 50/938] loss_G: 3.123229, loss_D: 0.220478\n",
      "[Epoch 134/200] [Batch 60/938] loss_G: 3.073521, loss_D: 0.240850\n",
      "[Epoch 134/200] [Batch 70/938] loss_G: 3.394245, loss_D: 0.212295\n",
      "[Epoch 134/200] [Batch 80/938] loss_G: 3.064837, loss_D: 0.188321\n",
      "[Epoch 134/200] [Batch 90/938] loss_G: 3.278972, loss_D: 0.202385\n",
      "[Epoch 134/200] [Batch 100/938] loss_G: 3.039436, loss_D: 0.247971\n",
      "[Epoch 134/200] [Batch 110/938] loss_G: 2.915047, loss_D: 0.198295\n",
      "[Epoch 134/200] [Batch 120/938] loss_G: 3.319333, loss_D: 0.191143\n",
      "[Epoch 134/200] [Batch 130/938] loss_G: 3.302224, loss_D: 0.183543\n",
      "[Epoch 134/200] [Batch 140/938] loss_G: 3.181079, loss_D: 0.249468\n",
      "[Epoch 134/200] [Batch 150/938] loss_G: 3.039087, loss_D: 0.159252\n",
      "[Epoch 134/200] [Batch 160/938] loss_G: 3.178056, loss_D: 0.243968\n",
      "[Epoch 134/200] [Batch 170/938] loss_G: 3.196288, loss_D: 0.184156\n",
      "[Epoch 134/200] [Batch 180/938] loss_G: 3.193412, loss_D: 0.288122\n",
      "[Epoch 134/200] [Batch 190/938] loss_G: 3.038088, loss_D: 0.097640\n",
      "[Epoch 134/200] [Batch 200/938] loss_G: 2.902834, loss_D: 0.224730\n",
      "[Epoch 134/200] [Batch 210/938] loss_G: 3.059220, loss_D: 0.165001\n",
      "[Epoch 134/200] [Batch 220/938] loss_G: 2.927144, loss_D: 0.268062\n",
      "[Epoch 134/200] [Batch 230/938] loss_G: 3.275552, loss_D: 0.196020\n",
      "[Epoch 134/200] [Batch 240/938] loss_G: 3.595198, loss_D: 0.148498\n",
      "[Epoch 134/200] [Batch 250/938] loss_G: 3.296842, loss_D: 0.208627\n",
      "[Epoch 134/200] [Batch 260/938] loss_G: 2.818758, loss_D: 0.237617\n",
      "[Epoch 134/200] [Batch 270/938] loss_G: 2.679665, loss_D: 0.212982\n",
      "[Epoch 134/200] [Batch 280/938] loss_G: 3.102100, loss_D: 0.244997\n",
      "[Epoch 134/200] [Batch 290/938] loss_G: 2.841164, loss_D: 0.187898\n",
      "[Epoch 134/200] [Batch 300/938] loss_G: 3.168074, loss_D: 0.146877\n",
      "[Epoch 134/200] [Batch 310/938] loss_G: 3.107027, loss_D: 0.189574\n",
      "[Epoch 134/200] [Batch 320/938] loss_G: 3.119088, loss_D: 0.265711\n",
      "[Epoch 134/200] [Batch 330/938] loss_G: 3.156819, loss_D: 0.116381\n",
      "[Epoch 134/200] [Batch 340/938] loss_G: 3.185841, loss_D: 0.186365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 134/200] [Batch 350/938] loss_G: 3.095596, loss_D: 0.199178\n",
      "[Epoch 134/200] [Batch 360/938] loss_G: 3.399909, loss_D: 0.188836\n",
      "[Epoch 134/200] [Batch 370/938] loss_G: 2.927199, loss_D: 0.278400\n",
      "[Epoch 134/200] [Batch 380/938] loss_G: 3.005101, loss_D: 0.275372\n",
      "[Epoch 134/200] [Batch 390/938] loss_G: 3.367832, loss_D: 0.182192\n",
      "[Epoch 134/200] [Batch 400/938] loss_G: 3.027349, loss_D: 0.160066\n",
      "[Epoch 134/200] [Batch 410/938] loss_G: 2.901300, loss_D: 0.240468\n",
      "[Epoch 134/200] [Batch 420/938] loss_G: 3.089060, loss_D: 0.158819\n",
      "[Epoch 134/200] [Batch 430/938] loss_G: 2.789884, loss_D: 0.244460\n",
      "[Epoch 134/200] [Batch 440/938] loss_G: 3.216523, loss_D: 0.219330\n",
      "[Epoch 134/200] [Batch 450/938] loss_G: 3.283556, loss_D: 0.202573\n",
      "[Epoch 134/200] [Batch 460/938] loss_G: 3.285031, loss_D: 0.252186\n",
      "[Epoch 134/200] [Batch 470/938] loss_G: 3.676700, loss_D: 0.227349\n",
      "[Epoch 134/200] [Batch 480/938] loss_G: 3.264359, loss_D: 0.232228\n",
      "[Epoch 134/200] [Batch 490/938] loss_G: 3.058763, loss_D: 0.211823\n",
      "[Epoch 134/200] [Batch 500/938] loss_G: 2.840558, loss_D: 0.252459\n",
      "[Epoch 134/200] [Batch 510/938] loss_G: 3.267570, loss_D: 0.176962\n",
      "[Epoch 134/200] [Batch 520/938] loss_G: 3.098355, loss_D: 0.183839\n",
      "[Epoch 134/200] [Batch 530/938] loss_G: 3.156733, loss_D: 0.161350\n",
      "[Epoch 134/200] [Batch 540/938] loss_G: 2.740084, loss_D: 0.217911\n",
      "[Epoch 134/200] [Batch 550/938] loss_G: 2.821360, loss_D: 0.183125\n",
      "[Epoch 134/200] [Batch 560/938] loss_G: 3.174997, loss_D: 0.263750\n",
      "[Epoch 134/200] [Batch 570/938] loss_G: 3.141485, loss_D: 0.167958\n",
      "[Epoch 134/200] [Batch 580/938] loss_G: 2.875319, loss_D: 0.325812\n",
      "[Epoch 134/200] [Batch 590/938] loss_G: 3.107088, loss_D: 0.233479\n",
      "[Epoch 134/200] [Batch 600/938] loss_G: 2.780633, loss_D: 0.176376\n",
      "[Epoch 134/200] [Batch 610/938] loss_G: 3.174909, loss_D: 0.208438\n",
      "[Epoch 134/200] [Batch 620/938] loss_G: 3.291934, loss_D: 0.184822\n",
      "[Epoch 134/200] [Batch 630/938] loss_G: 3.199557, loss_D: 0.244294\n",
      "[Epoch 134/200] [Batch 640/938] loss_G: 2.904755, loss_D: 0.267549\n",
      "[Epoch 134/200] [Batch 650/938] loss_G: 3.152551, loss_D: 0.193735\n",
      "[Epoch 134/200] [Batch 660/938] loss_G: 3.213406, loss_D: 0.228659\n",
      "[Epoch 134/200] [Batch 670/938] loss_G: 3.242258, loss_D: 0.180636\n",
      "[Epoch 134/200] [Batch 680/938] loss_G: 2.996663, loss_D: 0.206236\n",
      "[Epoch 134/200] [Batch 690/938] loss_G: 3.116036, loss_D: 0.177428\n",
      "[Epoch 134/200] [Batch 700/938] loss_G: 2.898067, loss_D: 0.173257\n",
      "[Epoch 134/200] [Batch 710/938] loss_G: 3.427642, loss_D: 0.242473\n",
      "[Epoch 134/200] [Batch 720/938] loss_G: 3.130470, loss_D: 0.207709\n",
      "[Epoch 134/200] [Batch 730/938] loss_G: 3.478298, loss_D: 0.165742\n",
      "[Epoch 134/200] [Batch 740/938] loss_G: 3.423290, loss_D: 0.244487\n",
      "[Epoch 134/200] [Batch 750/938] loss_G: 3.067202, loss_D: 0.173594\n",
      "[Epoch 134/200] [Batch 760/938] loss_G: 3.012063, loss_D: 0.129703\n",
      "[Epoch 134/200] [Batch 770/938] loss_G: 3.371560, loss_D: 0.154119\n",
      "[Epoch 134/200] [Batch 780/938] loss_G: 2.985857, loss_D: 0.230763\n",
      "[Epoch 134/200] [Batch 790/938] loss_G: 3.132530, loss_D: 0.200912\n",
      "[Epoch 134/200] [Batch 800/938] loss_G: 3.185659, loss_D: 0.189591\n",
      "[Epoch 134/200] [Batch 810/938] loss_G: 2.706552, loss_D: 0.234345\n",
      "[Epoch 134/200] [Batch 820/938] loss_G: 2.909311, loss_D: 0.273579\n",
      "[Epoch 134/200] [Batch 830/938] loss_G: 3.097480, loss_D: 0.285965\n",
      "[Epoch 134/200] [Batch 840/938] loss_G: 3.438817, loss_D: 0.205642\n",
      "[Epoch 134/200] [Batch 850/938] loss_G: 3.148327, loss_D: 0.245199\n",
      "[Epoch 134/200] [Batch 860/938] loss_G: 2.918066, loss_D: 0.285826\n",
      "[Epoch 134/200] [Batch 870/938] loss_G: 3.251749, loss_D: 0.220524\n",
      "[Epoch 134/200] [Batch 880/938] loss_G: 3.063400, loss_D: 0.183807\n",
      "[Epoch 134/200] [Batch 890/938] loss_G: 3.232042, loss_D: 0.265280\n",
      "[Epoch 134/200] [Batch 900/938] loss_G: 2.682546, loss_D: 0.239763\n",
      "[Epoch 134/200] [Batch 910/938] loss_G: 2.843512, loss_D: 0.240222\n",
      "[Epoch 134/200] [Batch 920/938] loss_G: 3.168591, loss_D: 0.250515\n",
      "[Epoch 134/200] [Batch 930/938] loss_G: 3.089087, loss_D: 0.150350\n",
      "[Epoch 135/200] [Batch 0/938] loss_G: 3.009438, loss_D: 0.179366\n",
      "[Epoch 135/200] [Batch 10/938] loss_G: 3.289953, loss_D: 0.212976\n",
      "[Epoch 135/200] [Batch 20/938] loss_G: 2.940446, loss_D: 0.179389\n",
      "[Epoch 135/200] [Batch 30/938] loss_G: 2.889810, loss_D: 0.201784\n",
      "[Epoch 135/200] [Batch 40/938] loss_G: 2.878650, loss_D: 0.218993\n",
      "[Epoch 135/200] [Batch 50/938] loss_G: 3.186568, loss_D: 0.217397\n",
      "[Epoch 135/200] [Batch 60/938] loss_G: 2.890682, loss_D: 0.158463\n",
      "[Epoch 135/200] [Batch 70/938] loss_G: 3.217739, loss_D: 0.209095\n",
      "[Epoch 135/200] [Batch 80/938] loss_G: 2.830979, loss_D: 0.213204\n",
      "[Epoch 135/200] [Batch 90/938] loss_G: 3.022429, loss_D: 0.164445\n",
      "[Epoch 135/200] [Batch 100/938] loss_G: 2.848732, loss_D: 0.152624\n",
      "[Epoch 135/200] [Batch 110/938] loss_G: 3.054411, loss_D: 0.237775\n",
      "[Epoch 135/200] [Batch 120/938] loss_G: 3.143056, loss_D: 0.233332\n",
      "[Epoch 135/200] [Batch 130/938] loss_G: 2.702084, loss_D: 0.206486\n",
      "[Epoch 135/200] [Batch 140/938] loss_G: 3.010521, loss_D: 0.250025\n",
      "[Epoch 135/200] [Batch 150/938] loss_G: 2.793223, loss_D: 0.248879\n",
      "[Epoch 135/200] [Batch 160/938] loss_G: 2.929143, loss_D: 0.197554\n",
      "[Epoch 135/200] [Batch 170/938] loss_G: 3.007231, loss_D: 0.120002\n",
      "[Epoch 135/200] [Batch 180/938] loss_G: 3.736108, loss_D: 0.159407\n",
      "[Epoch 135/200] [Batch 190/938] loss_G: 2.747410, loss_D: 0.260317\n",
      "[Epoch 135/200] [Batch 200/938] loss_G: 3.173886, loss_D: 0.117941\n",
      "[Epoch 135/200] [Batch 210/938] loss_G: 3.102497, loss_D: 0.179710\n",
      "[Epoch 135/200] [Batch 220/938] loss_G: 3.349235, loss_D: 0.119229\n",
      "[Epoch 135/200] [Batch 230/938] loss_G: 2.937158, loss_D: 0.234505\n",
      "[Epoch 135/200] [Batch 240/938] loss_G: 3.142559, loss_D: 0.207860\n",
      "[Epoch 135/200] [Batch 250/938] loss_G: 3.344661, loss_D: 0.139960\n",
      "[Epoch 135/200] [Batch 260/938] loss_G: 2.914788, loss_D: 0.146645\n",
      "[Epoch 135/200] [Batch 270/938] loss_G: 3.011883, loss_D: 0.181866\n",
      "[Epoch 135/200] [Batch 280/938] loss_G: 3.191001, loss_D: 0.217679\n",
      "[Epoch 135/200] [Batch 290/938] loss_G: 3.206336, loss_D: 0.258545\n",
      "[Epoch 135/200] [Batch 300/938] loss_G: 3.447106, loss_D: 0.150011\n",
      "[Epoch 135/200] [Batch 310/938] loss_G: 3.114775, loss_D: 0.213063\n",
      "[Epoch 135/200] [Batch 320/938] loss_G: 3.185149, loss_D: 0.176198\n",
      "[Epoch 135/200] [Batch 330/938] loss_G: 2.918115, loss_D: 0.199865\n",
      "[Epoch 135/200] [Batch 340/938] loss_G: 3.321663, loss_D: 0.137215\n",
      "[Epoch 135/200] [Batch 350/938] loss_G: 2.945518, loss_D: 0.188530\n",
      "[Epoch 135/200] [Batch 360/938] loss_G: 2.997632, loss_D: 0.173025\n",
      "[Epoch 135/200] [Batch 370/938] loss_G: 3.292587, loss_D: 0.192394\n",
      "[Epoch 135/200] [Batch 380/938] loss_G: 3.063016, loss_D: 0.198024\n",
      "[Epoch 135/200] [Batch 390/938] loss_G: 3.086837, loss_D: 0.174101\n",
      "[Epoch 135/200] [Batch 400/938] loss_G: 2.806433, loss_D: 0.338533\n",
      "[Epoch 135/200] [Batch 410/938] loss_G: 3.080930, loss_D: 0.206961\n",
      "[Epoch 135/200] [Batch 420/938] loss_G: 3.141710, loss_D: 0.316010\n",
      "[Epoch 135/200] [Batch 430/938] loss_G: 3.194607, loss_D: 0.243135\n",
      "[Epoch 135/200] [Batch 440/938] loss_G: 2.936766, loss_D: 0.165912\n",
      "[Epoch 135/200] [Batch 450/938] loss_G: 3.103851, loss_D: 0.194208\n",
      "[Epoch 135/200] [Batch 460/938] loss_G: 3.010411, loss_D: 0.199926\n",
      "[Epoch 135/200] [Batch 470/938] loss_G: 2.993124, loss_D: 0.158249\n",
      "[Epoch 135/200] [Batch 480/938] loss_G: 3.269680, loss_D: 0.178659\n",
      "[Epoch 135/200] [Batch 490/938] loss_G: 3.066914, loss_D: 0.157465\n",
      "[Epoch 135/200] [Batch 500/938] loss_G: 3.570022, loss_D: 0.155255\n",
      "[Epoch 135/200] [Batch 510/938] loss_G: 2.941798, loss_D: 0.175390\n",
      "[Epoch 135/200] [Batch 520/938] loss_G: 3.074286, loss_D: 0.253176\n",
      "[Epoch 135/200] [Batch 530/938] loss_G: 3.310173, loss_D: 0.195442\n",
      "[Epoch 135/200] [Batch 540/938] loss_G: 2.395546, loss_D: 0.342602\n",
      "[Epoch 135/200] [Batch 550/938] loss_G: 3.252919, loss_D: 0.204658\n",
      "[Epoch 135/200] [Batch 560/938] loss_G: 3.374825, loss_D: 0.327267\n",
      "[Epoch 135/200] [Batch 570/938] loss_G: 3.140026, loss_D: 0.208626\n",
      "[Epoch 135/200] [Batch 580/938] loss_G: 2.876472, loss_D: 0.187174\n",
      "[Epoch 135/200] [Batch 590/938] loss_G: 3.260711, loss_D: 0.235300\n",
      "[Epoch 135/200] [Batch 600/938] loss_G: 2.927163, loss_D: 0.217356\n",
      "[Epoch 135/200] [Batch 610/938] loss_G: 2.928772, loss_D: 0.251577\n",
      "[Epoch 135/200] [Batch 620/938] loss_G: 3.018256, loss_D: 0.204686\n",
      "[Epoch 135/200] [Batch 630/938] loss_G: 3.244667, loss_D: 0.228173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 135/200] [Batch 640/938] loss_G: 2.945073, loss_D: 0.133586\n",
      "[Epoch 135/200] [Batch 650/938] loss_G: 3.026732, loss_D: 0.134264\n",
      "[Epoch 135/200] [Batch 660/938] loss_G: 2.744184, loss_D: 0.240550\n",
      "[Epoch 135/200] [Batch 670/938] loss_G: 2.779643, loss_D: 0.159803\n",
      "[Epoch 135/200] [Batch 680/938] loss_G: 3.156533, loss_D: 0.204510\n",
      "[Epoch 135/200] [Batch 690/938] loss_G: 2.711277, loss_D: 0.167071\n",
      "[Epoch 135/200] [Batch 700/938] loss_G: 3.265251, loss_D: 0.244458\n",
      "[Epoch 135/200] [Batch 710/938] loss_G: 2.643178, loss_D: 0.232953\n",
      "[Epoch 135/200] [Batch 720/938] loss_G: 3.057358, loss_D: 0.178122\n",
      "[Epoch 135/200] [Batch 730/938] loss_G: 3.122345, loss_D: 0.184530\n",
      "[Epoch 135/200] [Batch 740/938] loss_G: 2.808898, loss_D: 0.164650\n",
      "[Epoch 135/200] [Batch 750/938] loss_G: 3.033468, loss_D: 0.191062\n",
      "[Epoch 135/200] [Batch 760/938] loss_G: 3.132182, loss_D: 0.161106\n",
      "[Epoch 135/200] [Batch 770/938] loss_G: 2.797989, loss_D: 0.248738\n",
      "[Epoch 135/200] [Batch 780/938] loss_G: 2.607528, loss_D: 0.231390\n",
      "[Epoch 135/200] [Batch 790/938] loss_G: 3.045476, loss_D: 0.192615\n",
      "[Epoch 135/200] [Batch 800/938] loss_G: 2.830799, loss_D: 0.194048\n",
      "[Epoch 135/200] [Batch 810/938] loss_G: 3.228857, loss_D: 0.223456\n",
      "[Epoch 135/200] [Batch 820/938] loss_G: 3.038737, loss_D: 0.145662\n",
      "[Epoch 135/200] [Batch 830/938] loss_G: 3.161762, loss_D: 0.236023\n",
      "[Epoch 135/200] [Batch 840/938] loss_G: 2.895787, loss_D: 0.187362\n",
      "[Epoch 135/200] [Batch 850/938] loss_G: 3.041536, loss_D: 0.178614\n",
      "[Epoch 135/200] [Batch 860/938] loss_G: 3.120078, loss_D: 0.203678\n",
      "[Epoch 135/200] [Batch 870/938] loss_G: 2.760635, loss_D: 0.131310\n",
      "[Epoch 135/200] [Batch 880/938] loss_G: 3.143056, loss_D: 0.138330\n",
      "[Epoch 135/200] [Batch 890/938] loss_G: 2.862967, loss_D: 0.280987\n",
      "[Epoch 135/200] [Batch 900/938] loss_G: 2.940242, loss_D: 0.309665\n",
      "[Epoch 135/200] [Batch 910/938] loss_G: 3.099111, loss_D: 0.141156\n",
      "[Epoch 135/200] [Batch 920/938] loss_G: 2.758235, loss_D: 0.233296\n",
      "[Epoch 135/200] [Batch 930/938] loss_G: 3.269645, loss_D: 0.215538\n",
      "[Epoch 136/200] [Batch 0/938] loss_G: 3.222507, loss_D: 0.107423\n",
      "[Epoch 136/200] [Batch 10/938] loss_G: 3.132378, loss_D: 0.227489\n",
      "[Epoch 136/200] [Batch 20/938] loss_G: 2.753798, loss_D: 0.217615\n",
      "[Epoch 136/200] [Batch 30/938] loss_G: 2.912858, loss_D: 0.259955\n",
      "[Epoch 136/200] [Batch 40/938] loss_G: 3.098511, loss_D: 0.235646\n",
      "[Epoch 136/200] [Batch 50/938] loss_G: 3.039922, loss_D: 0.118082\n",
      "[Epoch 136/200] [Batch 60/938] loss_G: 3.127178, loss_D: 0.174267\n",
      "[Epoch 136/200] [Batch 70/938] loss_G: 3.086072, loss_D: 0.177488\n",
      "[Epoch 136/200] [Batch 80/938] loss_G: 3.055307, loss_D: 0.196690\n",
      "[Epoch 136/200] [Batch 90/938] loss_G: 3.222590, loss_D: 0.188044\n",
      "[Epoch 136/200] [Batch 100/938] loss_G: 3.197572, loss_D: 0.190557\n",
      "[Epoch 136/200] [Batch 110/938] loss_G: 3.143297, loss_D: 0.103354\n",
      "[Epoch 136/200] [Batch 120/938] loss_G: 3.015445, loss_D: 0.171506\n",
      "[Epoch 136/200] [Batch 130/938] loss_G: 3.075019, loss_D: 0.198637\n",
      "[Epoch 136/200] [Batch 140/938] loss_G: 3.134650, loss_D: 0.292550\n",
      "[Epoch 136/200] [Batch 150/938] loss_G: 3.492991, loss_D: 0.193572\n",
      "[Epoch 136/200] [Batch 160/938] loss_G: 3.223296, loss_D: 0.145893\n",
      "[Epoch 136/200] [Batch 170/938] loss_G: 3.504268, loss_D: 0.171364\n",
      "[Epoch 136/200] [Batch 180/938] loss_G: 3.345228, loss_D: 0.201545\n",
      "[Epoch 136/200] [Batch 190/938] loss_G: 3.144777, loss_D: 0.211758\n",
      "[Epoch 136/200] [Batch 200/938] loss_G: 2.991658, loss_D: 0.236479\n",
      "[Epoch 136/200] [Batch 210/938] loss_G: 2.918737, loss_D: 0.257335\n",
      "[Epoch 136/200] [Batch 220/938] loss_G: 3.418975, loss_D: 0.224961\n",
      "[Epoch 136/200] [Batch 230/938] loss_G: 3.159005, loss_D: 0.228210\n",
      "[Epoch 136/200] [Batch 240/938] loss_G: 3.435486, loss_D: 0.288037\n",
      "[Epoch 136/200] [Batch 250/938] loss_G: 3.275492, loss_D: 0.216529\n",
      "[Epoch 136/200] [Batch 260/938] loss_G: 2.954116, loss_D: 0.237593\n",
      "[Epoch 136/200] [Batch 270/938] loss_G: 3.179023, loss_D: 0.144066\n",
      "[Epoch 136/200] [Batch 280/938] loss_G: 3.301399, loss_D: 0.167319\n",
      "[Epoch 136/200] [Batch 290/938] loss_G: 2.858403, loss_D: 0.201498\n",
      "[Epoch 136/200] [Batch 300/938] loss_G: 3.000703, loss_D: 0.269836\n",
      "[Epoch 136/200] [Batch 310/938] loss_G: 3.190022, loss_D: 0.117699\n",
      "[Epoch 136/200] [Batch 320/938] loss_G: 3.141884, loss_D: 0.165412\n",
      "[Epoch 136/200] [Batch 330/938] loss_G: 3.114271, loss_D: 0.272605\n",
      "[Epoch 136/200] [Batch 340/938] loss_G: 2.760207, loss_D: 0.208328\n",
      "[Epoch 136/200] [Batch 350/938] loss_G: 3.334966, loss_D: 0.288534\n",
      "[Epoch 136/200] [Batch 360/938] loss_G: 3.077673, loss_D: 0.173018\n",
      "[Epoch 136/200] [Batch 370/938] loss_G: 3.198568, loss_D: 0.262649\n",
      "[Epoch 136/200] [Batch 380/938] loss_G: 3.003624, loss_D: 0.293306\n",
      "[Epoch 136/200] [Batch 390/938] loss_G: 3.118050, loss_D: 0.224883\n",
      "[Epoch 136/200] [Batch 400/938] loss_G: 3.212632, loss_D: 0.207412\n",
      "[Epoch 136/200] [Batch 410/938] loss_G: 2.986574, loss_D: 0.216399\n",
      "[Epoch 136/200] [Batch 420/938] loss_G: 3.125891, loss_D: 0.226338\n",
      "[Epoch 136/200] [Batch 430/938] loss_G: 3.257575, loss_D: 0.181836\n",
      "[Epoch 136/200] [Batch 440/938] loss_G: 3.006838, loss_D: 0.186058\n",
      "[Epoch 136/200] [Batch 450/938] loss_G: 3.123020, loss_D: 0.230235\n",
      "[Epoch 136/200] [Batch 460/938] loss_G: 3.006243, loss_D: 0.200129\n",
      "[Epoch 136/200] [Batch 470/938] loss_G: 3.217157, loss_D: 0.087511\n",
      "[Epoch 136/200] [Batch 480/938] loss_G: 3.272733, loss_D: 0.196703\n",
      "[Epoch 136/200] [Batch 490/938] loss_G: 3.170972, loss_D: 0.202952\n",
      "[Epoch 136/200] [Batch 500/938] loss_G: 3.211802, loss_D: 0.223704\n",
      "[Epoch 136/200] [Batch 510/938] loss_G: 2.837742, loss_D: 0.232305\n",
      "[Epoch 136/200] [Batch 520/938] loss_G: 3.148027, loss_D: 0.166233\n",
      "[Epoch 136/200] [Batch 530/938] loss_G: 3.400603, loss_D: 0.217200\n",
      "[Epoch 136/200] [Batch 540/938] loss_G: 3.348353, loss_D: 0.194200\n",
      "[Epoch 136/200] [Batch 550/938] loss_G: 3.395984, loss_D: 0.190074\n",
      "[Epoch 136/200] [Batch 560/938] loss_G: 3.404062, loss_D: 0.163402\n",
      "[Epoch 136/200] [Batch 570/938] loss_G: 3.443431, loss_D: 0.177527\n",
      "[Epoch 136/200] [Batch 580/938] loss_G: 3.073821, loss_D: 0.176018\n",
      "[Epoch 136/200] [Batch 590/938] loss_G: 3.015467, loss_D: 0.134607\n",
      "[Epoch 136/200] [Batch 600/938] loss_G: 2.850887, loss_D: 0.212506\n",
      "[Epoch 136/200] [Batch 610/938] loss_G: 3.391545, loss_D: 0.180576\n",
      "[Epoch 136/200] [Batch 620/938] loss_G: 3.090718, loss_D: 0.173411\n",
      "[Epoch 136/200] [Batch 630/938] loss_G: 3.309471, loss_D: 0.224786\n",
      "[Epoch 136/200] [Batch 640/938] loss_G: 2.963954, loss_D: 0.191414\n",
      "[Epoch 136/200] [Batch 650/938] loss_G: 3.219884, loss_D: 0.286152\n",
      "[Epoch 136/200] [Batch 660/938] loss_G: 3.056750, loss_D: 0.173713\n",
      "[Epoch 136/200] [Batch 670/938] loss_G: 3.064477, loss_D: 0.181723\n",
      "[Epoch 136/200] [Batch 680/938] loss_G: 3.235884, loss_D: 0.137890\n",
      "[Epoch 136/200] [Batch 690/938] loss_G: 3.355771, loss_D: 0.196420\n",
      "[Epoch 136/200] [Batch 700/938] loss_G: 3.201301, loss_D: 0.194124\n",
      "[Epoch 136/200] [Batch 710/938] loss_G: 3.517827, loss_D: 0.272979\n",
      "[Epoch 136/200] [Batch 720/938] loss_G: 2.816527, loss_D: 0.170337\n",
      "[Epoch 136/200] [Batch 730/938] loss_G: 3.122498, loss_D: 0.231124\n",
      "[Epoch 136/200] [Batch 740/938] loss_G: 2.823933, loss_D: 0.254829\n",
      "[Epoch 136/200] [Batch 750/938] loss_G: 3.089691, loss_D: 0.209047\n",
      "[Epoch 136/200] [Batch 760/938] loss_G: 2.950013, loss_D: 0.195869\n",
      "[Epoch 136/200] [Batch 770/938] loss_G: 2.810430, loss_D: 0.245904\n",
      "[Epoch 136/200] [Batch 780/938] loss_G: 3.374252, loss_D: 0.212771\n",
      "[Epoch 136/200] [Batch 790/938] loss_G: 3.297962, loss_D: 0.207057\n",
      "[Epoch 136/200] [Batch 800/938] loss_G: 3.136590, loss_D: 0.153992\n",
      "[Epoch 136/200] [Batch 810/938] loss_G: 2.976953, loss_D: 0.282766\n",
      "[Epoch 136/200] [Batch 820/938] loss_G: 2.868821, loss_D: 0.132683\n",
      "[Epoch 136/200] [Batch 830/938] loss_G: 2.836844, loss_D: 0.201270\n",
      "[Epoch 136/200] [Batch 840/938] loss_G: 3.130698, loss_D: 0.242446\n",
      "[Epoch 136/200] [Batch 850/938] loss_G: 3.446918, loss_D: 0.177650\n",
      "[Epoch 136/200] [Batch 860/938] loss_G: 3.126020, loss_D: 0.125285\n",
      "[Epoch 136/200] [Batch 870/938] loss_G: 3.079613, loss_D: 0.201980\n",
      "[Epoch 136/200] [Batch 880/938] loss_G: 3.096780, loss_D: 0.224373\n",
      "[Epoch 136/200] [Batch 890/938] loss_G: 3.241989, loss_D: 0.145194\n",
      "[Epoch 136/200] [Batch 900/938] loss_G: 3.177627, loss_D: 0.168518\n",
      "[Epoch 136/200] [Batch 910/938] loss_G: 2.955431, loss_D: 0.213556\n",
      "[Epoch 136/200] [Batch 920/938] loss_G: 3.161669, loss_D: 0.180294\n",
      "[Epoch 136/200] [Batch 930/938] loss_G: 3.241617, loss_D: 0.214359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 137/200] [Batch 0/938] loss_G: 3.548158, loss_D: 0.215624\n",
      "[Epoch 137/200] [Batch 10/938] loss_G: 3.377291, loss_D: 0.175862\n",
      "[Epoch 137/200] [Batch 20/938] loss_G: 2.818913, loss_D: 0.188288\n",
      "[Epoch 137/200] [Batch 30/938] loss_G: 3.036869, loss_D: 0.149000\n",
      "[Epoch 137/200] [Batch 40/938] loss_G: 2.958354, loss_D: 0.209001\n",
      "[Epoch 137/200] [Batch 50/938] loss_G: 2.988313, loss_D: 0.219996\n",
      "[Epoch 137/200] [Batch 60/938] loss_G: 2.963191, loss_D: 0.248063\n",
      "[Epoch 137/200] [Batch 70/938] loss_G: 3.353286, loss_D: 0.173541\n",
      "[Epoch 137/200] [Batch 80/938] loss_G: 3.180367, loss_D: 0.256868\n",
      "[Epoch 137/200] [Batch 90/938] loss_G: 2.907391, loss_D: 0.221421\n",
      "[Epoch 137/200] [Batch 100/938] loss_G: 3.503985, loss_D: 0.142512\n",
      "[Epoch 137/200] [Batch 110/938] loss_G: 3.095747, loss_D: 0.239986\n",
      "[Epoch 137/200] [Batch 120/938] loss_G: 3.178027, loss_D: 0.136707\n",
      "[Epoch 137/200] [Batch 130/938] loss_G: 3.005504, loss_D: 0.171066\n",
      "[Epoch 137/200] [Batch 140/938] loss_G: 3.215504, loss_D: 0.194325\n",
      "[Epoch 137/200] [Batch 150/938] loss_G: 3.153027, loss_D: 0.271403\n",
      "[Epoch 137/200] [Batch 160/938] loss_G: 2.879680, loss_D: 0.239707\n",
      "[Epoch 137/200] [Batch 170/938] loss_G: 3.288839, loss_D: 0.194444\n",
      "[Epoch 137/200] [Batch 180/938] loss_G: 3.285559, loss_D: 0.217198\n",
      "[Epoch 137/200] [Batch 190/938] loss_G: 2.847723, loss_D: 0.177109\n",
      "[Epoch 137/200] [Batch 200/938] loss_G: 3.165222, loss_D: 0.234930\n",
      "[Epoch 137/200] [Batch 210/938] loss_G: 2.871404, loss_D: 0.299699\n",
      "[Epoch 137/200] [Batch 220/938] loss_G: 2.935710, loss_D: 0.154793\n",
      "[Epoch 137/200] [Batch 230/938] loss_G: 2.931697, loss_D: 0.215789\n",
      "[Epoch 137/200] [Batch 240/938] loss_G: 2.971458, loss_D: 0.284673\n",
      "[Epoch 137/200] [Batch 250/938] loss_G: 3.362687, loss_D: 0.239258\n",
      "[Epoch 137/200] [Batch 260/938] loss_G: 2.993578, loss_D: 0.322233\n",
      "[Epoch 137/200] [Batch 270/938] loss_G: 3.389893, loss_D: 0.185151\n",
      "[Epoch 137/200] [Batch 280/938] loss_G: 3.408965, loss_D: 0.198052\n",
      "[Epoch 137/200] [Batch 290/938] loss_G: 3.283529, loss_D: 0.181702\n",
      "[Epoch 137/200] [Batch 300/938] loss_G: 2.852631, loss_D: 0.259454\n",
      "[Epoch 137/200] [Batch 310/938] loss_G: 3.417305, loss_D: 0.202415\n",
      "[Epoch 137/200] [Batch 320/938] loss_G: 3.139160, loss_D: 0.187461\n",
      "[Epoch 137/200] [Batch 330/938] loss_G: 3.055055, loss_D: 0.200375\n",
      "[Epoch 137/200] [Batch 340/938] loss_G: 3.270775, loss_D: 0.215802\n",
      "[Epoch 137/200] [Batch 350/938] loss_G: 3.463027, loss_D: 0.224409\n",
      "[Epoch 137/200] [Batch 360/938] loss_G: 3.326664, loss_D: 0.253264\n",
      "[Epoch 137/200] [Batch 370/938] loss_G: 3.420036, loss_D: 0.176650\n",
      "[Epoch 137/200] [Batch 380/938] loss_G: 3.167625, loss_D: 0.161476\n",
      "[Epoch 137/200] [Batch 390/938] loss_G: 3.111429, loss_D: 0.166220\n",
      "[Epoch 137/200] [Batch 400/938] loss_G: 3.664073, loss_D: 0.251418\n",
      "[Epoch 137/200] [Batch 410/938] loss_G: 3.174222, loss_D: 0.165075\n",
      "[Epoch 137/200] [Batch 420/938] loss_G: 3.102389, loss_D: 0.195343\n",
      "[Epoch 137/200] [Batch 430/938] loss_G: 3.295722, loss_D: 0.164126\n",
      "[Epoch 137/200] [Batch 440/938] loss_G: 3.109579, loss_D: 0.174551\n",
      "[Epoch 137/200] [Batch 450/938] loss_G: 2.955521, loss_D: 0.172753\n",
      "[Epoch 137/200] [Batch 460/938] loss_G: 3.213684, loss_D: 0.147077\n",
      "[Epoch 137/200] [Batch 470/938] loss_G: 3.064021, loss_D: 0.261731\n",
      "[Epoch 137/200] [Batch 480/938] loss_G: 3.154406, loss_D: 0.181943\n",
      "[Epoch 137/200] [Batch 490/938] loss_G: 3.231406, loss_D: 0.181899\n",
      "[Epoch 137/200] [Batch 500/938] loss_G: 3.316093, loss_D: 0.257867\n",
      "[Epoch 137/200] [Batch 510/938] loss_G: 3.099765, loss_D: 0.225273\n",
      "[Epoch 137/200] [Batch 520/938] loss_G: 3.161328, loss_D: 0.248322\n",
      "[Epoch 137/200] [Batch 530/938] loss_G: 3.472481, loss_D: 0.195582\n",
      "[Epoch 137/200] [Batch 540/938] loss_G: 3.247573, loss_D: 0.335263\n",
      "[Epoch 137/200] [Batch 550/938] loss_G: 3.084841, loss_D: 0.151298\n",
      "[Epoch 137/200] [Batch 560/938] loss_G: 2.984451, loss_D: 0.198009\n",
      "[Epoch 137/200] [Batch 570/938] loss_G: 3.228549, loss_D: 0.168609\n",
      "[Epoch 137/200] [Batch 580/938] loss_G: 3.211699, loss_D: 0.211588\n",
      "[Epoch 137/200] [Batch 590/938] loss_G: 3.314356, loss_D: 0.121552\n",
      "[Epoch 137/200] [Batch 600/938] loss_G: 3.023712, loss_D: 0.159853\n",
      "[Epoch 137/200] [Batch 610/938] loss_G: 3.022233, loss_D: 0.163496\n",
      "[Epoch 137/200] [Batch 620/938] loss_G: 3.200249, loss_D: 0.222270\n",
      "[Epoch 137/200] [Batch 630/938] loss_G: 3.218896, loss_D: 0.237916\n",
      "[Epoch 137/200] [Batch 640/938] loss_G: 3.262682, loss_D: 0.220954\n",
      "[Epoch 137/200] [Batch 650/938] loss_G: 3.070190, loss_D: 0.190081\n",
      "[Epoch 137/200] [Batch 660/938] loss_G: 2.895809, loss_D: 0.212707\n",
      "[Epoch 137/200] [Batch 670/938] loss_G: 3.096394, loss_D: 0.167584\n",
      "[Epoch 137/200] [Batch 680/938] loss_G: 3.051914, loss_D: 0.197658\n",
      "[Epoch 137/200] [Batch 690/938] loss_G: 3.404670, loss_D: 0.230357\n",
      "[Epoch 137/200] [Batch 700/938] loss_G: 3.034267, loss_D: 0.125468\n",
      "[Epoch 137/200] [Batch 710/938] loss_G: 3.305054, loss_D: 0.134488\n",
      "[Epoch 137/200] [Batch 720/938] loss_G: 3.500959, loss_D: 0.125332\n",
      "[Epoch 137/200] [Batch 730/938] loss_G: 3.087677, loss_D: 0.174757\n",
      "[Epoch 137/200] [Batch 740/938] loss_G: 2.710750, loss_D: 0.216554\n",
      "[Epoch 137/200] [Batch 750/938] loss_G: 3.374497, loss_D: 0.194883\n",
      "[Epoch 137/200] [Batch 760/938] loss_G: 3.133581, loss_D: 0.145857\n",
      "[Epoch 137/200] [Batch 770/938] loss_G: 2.885906, loss_D: 0.120208\n",
      "[Epoch 137/200] [Batch 780/938] loss_G: 3.200904, loss_D: 0.133706\n",
      "[Epoch 137/200] [Batch 790/938] loss_G: 3.119820, loss_D: 0.136750\n",
      "[Epoch 137/200] [Batch 800/938] loss_G: 3.189251, loss_D: 0.139233\n",
      "[Epoch 137/200] [Batch 810/938] loss_G: 3.052147, loss_D: 0.163262\n",
      "[Epoch 137/200] [Batch 820/938] loss_G: 3.622311, loss_D: 0.111676\n",
      "[Epoch 137/200] [Batch 830/938] loss_G: 2.866847, loss_D: 0.250304\n",
      "[Epoch 137/200] [Batch 840/938] loss_G: 3.000366, loss_D: 0.270397\n",
      "[Epoch 137/200] [Batch 850/938] loss_G: 3.346846, loss_D: 0.225872\n",
      "[Epoch 137/200] [Batch 860/938] loss_G: 3.138813, loss_D: 0.250359\n",
      "[Epoch 137/200] [Batch 870/938] loss_G: 3.307422, loss_D: 0.206541\n",
      "[Epoch 137/200] [Batch 880/938] loss_G: 3.554252, loss_D: 0.143970\n",
      "[Epoch 137/200] [Batch 890/938] loss_G: 3.244001, loss_D: 0.167443\n",
      "[Epoch 137/200] [Batch 900/938] loss_G: 3.176706, loss_D: 0.183880\n",
      "[Epoch 137/200] [Batch 910/938] loss_G: 3.126953, loss_D: 0.205816\n",
      "[Epoch 137/200] [Batch 920/938] loss_G: 3.180223, loss_D: 0.177017\n",
      "[Epoch 137/200] [Batch 930/938] loss_G: 2.921630, loss_D: 0.248845\n",
      "[Epoch 138/200] [Batch 0/938] loss_G: 3.060728, loss_D: 0.133577\n",
      "[Epoch 138/200] [Batch 10/938] loss_G: 3.334471, loss_D: 0.303743\n",
      "[Epoch 138/200] [Batch 20/938] loss_G: 3.179997, loss_D: 0.176145\n",
      "[Epoch 138/200] [Batch 30/938] loss_G: 2.911794, loss_D: 0.238490\n",
      "[Epoch 138/200] [Batch 40/938] loss_G: 3.022034, loss_D: 0.220663\n",
      "[Epoch 138/200] [Batch 50/938] loss_G: 3.015705, loss_D: 0.137985\n",
      "[Epoch 138/200] [Batch 60/938] loss_G: 2.866367, loss_D: 0.242136\n",
      "[Epoch 138/200] [Batch 70/938] loss_G: 3.796378, loss_D: 0.167981\n",
      "[Epoch 138/200] [Batch 80/938] loss_G: 2.762085, loss_D: 0.203475\n",
      "[Epoch 138/200] [Batch 90/938] loss_G: 3.093340, loss_D: 0.188108\n",
      "[Epoch 138/200] [Batch 100/938] loss_G: 3.050523, loss_D: 0.240144\n",
      "[Epoch 138/200] [Batch 110/938] loss_G: 3.011260, loss_D: 0.159662\n",
      "[Epoch 138/200] [Batch 120/938] loss_G: 2.874650, loss_D: 0.111681\n",
      "[Epoch 138/200] [Batch 130/938] loss_G: 2.711495, loss_D: 0.255242\n",
      "[Epoch 138/200] [Batch 140/938] loss_G: 2.792694, loss_D: 0.237050\n",
      "[Epoch 138/200] [Batch 150/938] loss_G: 3.002021, loss_D: 0.263705\n",
      "[Epoch 138/200] [Batch 160/938] loss_G: 2.969944, loss_D: 0.158134\n",
      "[Epoch 138/200] [Batch 170/938] loss_G: 2.854742, loss_D: 0.232134\n",
      "[Epoch 138/200] [Batch 180/938] loss_G: 3.059860, loss_D: 0.229575\n",
      "[Epoch 138/200] [Batch 190/938] loss_G: 2.789852, loss_D: 0.250524\n",
      "[Epoch 138/200] [Batch 200/938] loss_G: 3.080025, loss_D: 0.219436\n",
      "[Epoch 138/200] [Batch 210/938] loss_G: 3.283816, loss_D: 0.162496\n",
      "[Epoch 138/200] [Batch 220/938] loss_G: 3.250357, loss_D: 0.202940\n",
      "[Epoch 138/200] [Batch 230/938] loss_G: 3.361519, loss_D: 0.175686\n",
      "[Epoch 138/200] [Batch 240/938] loss_G: 2.974112, loss_D: 0.248181\n",
      "[Epoch 138/200] [Batch 250/938] loss_G: 3.225250, loss_D: 0.191309\n",
      "[Epoch 138/200] [Batch 260/938] loss_G: 2.981278, loss_D: 0.243575\n",
      "[Epoch 138/200] [Batch 270/938] loss_G: 3.365029, loss_D: 0.266799\n",
      "[Epoch 138/200] [Batch 280/938] loss_G: 3.296387, loss_D: 0.137481\n",
      "[Epoch 138/200] [Batch 290/938] loss_G: 3.433241, loss_D: 0.191004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 138/200] [Batch 300/938] loss_G: 2.794202, loss_D: 0.207145\n",
      "[Epoch 138/200] [Batch 310/938] loss_G: 2.886976, loss_D: 0.210609\n",
      "[Epoch 138/200] [Batch 320/938] loss_G: 3.169789, loss_D: 0.198964\n",
      "[Epoch 138/200] [Batch 330/938] loss_G: 3.281281, loss_D: 0.169076\n",
      "[Epoch 138/200] [Batch 340/938] loss_G: 3.110226, loss_D: 0.244014\n",
      "[Epoch 138/200] [Batch 350/938] loss_G: 3.341899, loss_D: 0.193466\n",
      "[Epoch 138/200] [Batch 360/938] loss_G: 3.167204, loss_D: 0.150890\n",
      "[Epoch 138/200] [Batch 370/938] loss_G: 3.255883, loss_D: 0.181648\n",
      "[Epoch 138/200] [Batch 380/938] loss_G: 3.054449, loss_D: 0.193662\n",
      "[Epoch 138/200] [Batch 390/938] loss_G: 3.531458, loss_D: 0.197359\n",
      "[Epoch 138/200] [Batch 400/938] loss_G: 2.966454, loss_D: 0.208762\n",
      "[Epoch 138/200] [Batch 410/938] loss_G: 3.149048, loss_D: 0.167147\n",
      "[Epoch 138/200] [Batch 420/938] loss_G: 3.628800, loss_D: 0.159470\n",
      "[Epoch 138/200] [Batch 430/938] loss_G: 2.929671, loss_D: 0.267966\n",
      "[Epoch 138/200] [Batch 440/938] loss_G: 2.975513, loss_D: 0.250930\n",
      "[Epoch 138/200] [Batch 450/938] loss_G: 2.803900, loss_D: 0.259772\n",
      "[Epoch 138/200] [Batch 460/938] loss_G: 3.533538, loss_D: 0.242224\n",
      "[Epoch 138/200] [Batch 470/938] loss_G: 3.146202, loss_D: 0.182180\n",
      "[Epoch 138/200] [Batch 480/938] loss_G: 3.322254, loss_D: 0.204460\n",
      "[Epoch 138/200] [Batch 490/938] loss_G: 3.504011, loss_D: 0.171764\n",
      "[Epoch 138/200] [Batch 500/938] loss_G: 3.674370, loss_D: 0.247653\n",
      "[Epoch 138/200] [Batch 510/938] loss_G: 3.191621, loss_D: 0.145772\n",
      "[Epoch 138/200] [Batch 520/938] loss_G: 3.232410, loss_D: 0.160093\n",
      "[Epoch 138/200] [Batch 530/938] loss_G: 3.620515, loss_D: 0.171238\n",
      "[Epoch 138/200] [Batch 540/938] loss_G: 3.040292, loss_D: 0.264888\n",
      "[Epoch 138/200] [Batch 550/938] loss_G: 3.710935, loss_D: 0.183568\n",
      "[Epoch 138/200] [Batch 560/938] loss_G: 3.759985, loss_D: 0.151635\n",
      "[Epoch 138/200] [Batch 570/938] loss_G: 3.095545, loss_D: 0.177825\n",
      "[Epoch 138/200] [Batch 580/938] loss_G: 3.436960, loss_D: 0.145765\n",
      "[Epoch 138/200] [Batch 590/938] loss_G: 3.313062, loss_D: 0.201458\n",
      "[Epoch 138/200] [Batch 600/938] loss_G: 3.088006, loss_D: 0.146853\n",
      "[Epoch 138/200] [Batch 610/938] loss_G: 3.212935, loss_D: 0.272365\n",
      "[Epoch 138/200] [Batch 620/938] loss_G: 2.937204, loss_D: 0.216015\n",
      "[Epoch 138/200] [Batch 630/938] loss_G: 3.028233, loss_D: 0.238777\n",
      "[Epoch 138/200] [Batch 640/938] loss_G: 3.703062, loss_D: 0.240599\n",
      "[Epoch 138/200] [Batch 650/938] loss_G: 2.969992, loss_D: 0.206666\n",
      "[Epoch 138/200] [Batch 660/938] loss_G: 3.795137, loss_D: 0.146801\n",
      "[Epoch 138/200] [Batch 670/938] loss_G: 3.124351, loss_D: 0.309168\n",
      "[Epoch 138/200] [Batch 680/938] loss_G: 3.163522, loss_D: 0.214269\n",
      "[Epoch 138/200] [Batch 690/938] loss_G: 3.435253, loss_D: 0.213411\n",
      "[Epoch 138/200] [Batch 700/938] loss_G: 3.063696, loss_D: 0.203577\n",
      "[Epoch 138/200] [Batch 710/938] loss_G: 2.924093, loss_D: 0.308395\n",
      "[Epoch 138/200] [Batch 720/938] loss_G: 3.367150, loss_D: 0.217359\n",
      "[Epoch 138/200] [Batch 730/938] loss_G: 3.456972, loss_D: 0.185076\n",
      "[Epoch 138/200] [Batch 740/938] loss_G: 2.889582, loss_D: 0.167401\n",
      "[Epoch 138/200] [Batch 750/938] loss_G: 3.318441, loss_D: 0.219383\n",
      "[Epoch 138/200] [Batch 760/938] loss_G: 2.931799, loss_D: 0.196062\n",
      "[Epoch 138/200] [Batch 770/938] loss_G: 3.296891, loss_D: 0.173719\n",
      "[Epoch 138/200] [Batch 780/938] loss_G: 3.310863, loss_D: 0.331368\n",
      "[Epoch 138/200] [Batch 790/938] loss_G: 2.792418, loss_D: 0.176718\n",
      "[Epoch 138/200] [Batch 800/938] loss_G: 2.994170, loss_D: 0.120228\n",
      "[Epoch 138/200] [Batch 810/938] loss_G: 3.205904, loss_D: 0.210610\n",
      "[Epoch 138/200] [Batch 820/938] loss_G: 3.042986, loss_D: 0.270370\n",
      "[Epoch 138/200] [Batch 830/938] loss_G: 3.006902, loss_D: 0.280546\n",
      "[Epoch 138/200] [Batch 840/938] loss_G: 2.975435, loss_D: 0.170311\n",
      "[Epoch 138/200] [Batch 850/938] loss_G: 3.159046, loss_D: 0.227307\n",
      "[Epoch 138/200] [Batch 860/938] loss_G: 3.213502, loss_D: 0.189697\n",
      "[Epoch 138/200] [Batch 870/938] loss_G: 3.044385, loss_D: 0.237372\n",
      "[Epoch 138/200] [Batch 880/938] loss_G: 3.128309, loss_D: 0.185325\n",
      "[Epoch 138/200] [Batch 890/938] loss_G: 3.426565, loss_D: 0.129599\n",
      "[Epoch 138/200] [Batch 900/938] loss_G: 3.478915, loss_D: 0.148285\n",
      "[Epoch 138/200] [Batch 910/938] loss_G: 3.263222, loss_D: 0.227046\n",
      "[Epoch 138/200] [Batch 920/938] loss_G: 3.165105, loss_D: 0.228291\n",
      "[Epoch 138/200] [Batch 930/938] loss_G: 3.329719, loss_D: 0.161163\n",
      "[Epoch 139/200] [Batch 0/938] loss_G: 3.002517, loss_D: 0.262327\n",
      "[Epoch 139/200] [Batch 10/938] loss_G: 3.536403, loss_D: 0.153016\n",
      "[Epoch 139/200] [Batch 20/938] loss_G: 3.088048, loss_D: 0.264763\n",
      "[Epoch 139/200] [Batch 30/938] loss_G: 3.202267, loss_D: 0.215433\n",
      "[Epoch 139/200] [Batch 40/938] loss_G: 3.322138, loss_D: 0.186812\n",
      "[Epoch 139/200] [Batch 50/938] loss_G: 3.031010, loss_D: 0.184639\n",
      "[Epoch 139/200] [Batch 60/938] loss_G: 3.254746, loss_D: 0.238181\n",
      "[Epoch 139/200] [Batch 70/938] loss_G: 3.278963, loss_D: 0.161288\n",
      "[Epoch 139/200] [Batch 80/938] loss_G: 2.909773, loss_D: 0.170450\n",
      "[Epoch 139/200] [Batch 90/938] loss_G: 3.102175, loss_D: 0.158905\n",
      "[Epoch 139/200] [Batch 100/938] loss_G: 3.262500, loss_D: 0.222503\n",
      "[Epoch 139/200] [Batch 110/938] loss_G: 3.176513, loss_D: 0.227784\n",
      "[Epoch 139/200] [Batch 120/938] loss_G: 3.192566, loss_D: 0.157282\n",
      "[Epoch 139/200] [Batch 130/938] loss_G: 3.319166, loss_D: 0.210940\n",
      "[Epoch 139/200] [Batch 140/938] loss_G: 3.051443, loss_D: 0.218863\n",
      "[Epoch 139/200] [Batch 150/938] loss_G: 3.111264, loss_D: 0.234496\n",
      "[Epoch 139/200] [Batch 160/938] loss_G: 3.455458, loss_D: 0.280948\n",
      "[Epoch 139/200] [Batch 170/938] loss_G: 3.220646, loss_D: 0.320082\n",
      "[Epoch 139/200] [Batch 180/938] loss_G: 3.175542, loss_D: 0.140652\n",
      "[Epoch 139/200] [Batch 190/938] loss_G: 3.041131, loss_D: 0.231150\n",
      "[Epoch 139/200] [Batch 200/938] loss_G: 2.552406, loss_D: 0.171840\n",
      "[Epoch 139/200] [Batch 210/938] loss_G: 2.919903, loss_D: 0.175585\n",
      "[Epoch 139/200] [Batch 220/938] loss_G: 3.133393, loss_D: 0.243092\n",
      "[Epoch 139/200] [Batch 230/938] loss_G: 2.904291, loss_D: 0.259451\n",
      "[Epoch 139/200] [Batch 240/938] loss_G: 3.121101, loss_D: 0.165543\n",
      "[Epoch 139/200] [Batch 250/938] loss_G: 3.306083, loss_D: 0.200380\n",
      "[Epoch 139/200] [Batch 260/938] loss_G: 3.232166, loss_D: 0.128383\n",
      "[Epoch 139/200] [Batch 270/938] loss_G: 3.270147, loss_D: 0.200515\n",
      "[Epoch 139/200] [Batch 280/938] loss_G: 3.036537, loss_D: 0.298297\n",
      "[Epoch 139/200] [Batch 290/938] loss_G: 3.002962, loss_D: 0.302174\n",
      "[Epoch 139/200] [Batch 300/938] loss_G: 3.542686, loss_D: 0.240211\n",
      "[Epoch 139/200] [Batch 310/938] loss_G: 3.210441, loss_D: 0.222958\n",
      "[Epoch 139/200] [Batch 320/938] loss_G: 3.154242, loss_D: 0.238434\n",
      "[Epoch 139/200] [Batch 330/938] loss_G: 3.347656, loss_D: 0.174275\n",
      "[Epoch 139/200] [Batch 340/938] loss_G: 2.967138, loss_D: 0.157553\n",
      "[Epoch 139/200] [Batch 350/938] loss_G: 3.482501, loss_D: 0.233864\n",
      "[Epoch 139/200] [Batch 360/938] loss_G: 3.537058, loss_D: 0.154092\n",
      "[Epoch 139/200] [Batch 370/938] loss_G: 2.716386, loss_D: 0.231736\n",
      "[Epoch 139/200] [Batch 380/938] loss_G: 3.054929, loss_D: 0.189987\n",
      "[Epoch 139/200] [Batch 390/938] loss_G: 2.690968, loss_D: 0.282783\n",
      "[Epoch 139/200] [Batch 400/938] loss_G: 2.771019, loss_D: 0.241066\n",
      "[Epoch 139/200] [Batch 410/938] loss_G: 3.048207, loss_D: 0.238026\n",
      "[Epoch 139/200] [Batch 420/938] loss_G: 3.091031, loss_D: 0.198464\n",
      "[Epoch 139/200] [Batch 430/938] loss_G: 2.980080, loss_D: 0.173043\n",
      "[Epoch 139/200] [Batch 440/938] loss_G: 2.998111, loss_D: 0.164041\n",
      "[Epoch 139/200] [Batch 450/938] loss_G: 3.001404, loss_D: 0.244810\n",
      "[Epoch 139/200] [Batch 460/938] loss_G: 3.278930, loss_D: 0.172788\n",
      "[Epoch 139/200] [Batch 470/938] loss_G: 2.857912, loss_D: 0.222724\n",
      "[Epoch 139/200] [Batch 480/938] loss_G: 2.895911, loss_D: 0.238475\n",
      "[Epoch 139/200] [Batch 490/938] loss_G: 3.117392, loss_D: 0.233692\n",
      "[Epoch 139/200] [Batch 500/938] loss_G: 2.991007, loss_D: 0.214234\n",
      "[Epoch 139/200] [Batch 510/938] loss_G: 3.277968, loss_D: 0.186010\n",
      "[Epoch 139/200] [Batch 520/938] loss_G: 2.958678, loss_D: 0.200840\n",
      "[Epoch 139/200] [Batch 530/938] loss_G: 3.570362, loss_D: 0.195966\n",
      "[Epoch 139/200] [Batch 540/938] loss_G: 3.264965, loss_D: 0.219990\n",
      "[Epoch 139/200] [Batch 550/938] loss_G: 3.312326, loss_D: 0.149074\n",
      "[Epoch 139/200] [Batch 560/938] loss_G: 2.998499, loss_D: 0.194739\n",
      "[Epoch 139/200] [Batch 570/938] loss_G: 2.931740, loss_D: 0.229661\n",
      "[Epoch 139/200] [Batch 580/938] loss_G: 3.106825, loss_D: 0.289033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 139/200] [Batch 590/938] loss_G: 3.063914, loss_D: 0.249667\n",
      "[Epoch 139/200] [Batch 600/938] loss_G: 3.249149, loss_D: 0.208498\n",
      "[Epoch 139/200] [Batch 610/938] loss_G: 2.834829, loss_D: 0.181032\n",
      "[Epoch 139/200] [Batch 620/938] loss_G: 2.963772, loss_D: 0.267536\n",
      "[Epoch 139/200] [Batch 630/938] loss_G: 2.969948, loss_D: 0.163737\n",
      "[Epoch 139/200] [Batch 640/938] loss_G: 3.113624, loss_D: 0.152872\n",
      "[Epoch 139/200] [Batch 650/938] loss_G: 3.484740, loss_D: 0.204157\n",
      "[Epoch 139/200] [Batch 660/938] loss_G: 3.618356, loss_D: 0.283493\n",
      "[Epoch 139/200] [Batch 670/938] loss_G: 3.451543, loss_D: 0.194014\n",
      "[Epoch 139/200] [Batch 680/938] loss_G: 3.082866, loss_D: 0.168976\n",
      "[Epoch 139/200] [Batch 690/938] loss_G: 3.051186, loss_D: 0.223037\n",
      "[Epoch 139/200] [Batch 700/938] loss_G: 3.248391, loss_D: 0.165860\n",
      "[Epoch 139/200] [Batch 710/938] loss_G: 3.012799, loss_D: 0.239284\n",
      "[Epoch 139/200] [Batch 720/938] loss_G: 3.192854, loss_D: 0.201572\n",
      "[Epoch 139/200] [Batch 730/938] loss_G: 3.059058, loss_D: 0.228576\n",
      "[Epoch 139/200] [Batch 740/938] loss_G: 3.213316, loss_D: 0.147510\n",
      "[Epoch 139/200] [Batch 750/938] loss_G: 3.040887, loss_D: 0.195758\n",
      "[Epoch 139/200] [Batch 760/938] loss_G: 3.418865, loss_D: 0.234765\n",
      "[Epoch 139/200] [Batch 770/938] loss_G: 3.159293, loss_D: 0.157725\n",
      "[Epoch 139/200] [Batch 780/938] loss_G: 3.183300, loss_D: 0.172547\n",
      "[Epoch 139/200] [Batch 790/938] loss_G: 3.079533, loss_D: 0.172368\n",
      "[Epoch 139/200] [Batch 800/938] loss_G: 3.030982, loss_D: 0.214626\n",
      "[Epoch 139/200] [Batch 810/938] loss_G: 3.431122, loss_D: 0.196171\n",
      "[Epoch 139/200] [Batch 820/938] loss_G: 3.047312, loss_D: 0.163897\n",
      "[Epoch 139/200] [Batch 830/938] loss_G: 3.034608, loss_D: 0.197188\n",
      "[Epoch 139/200] [Batch 840/938] loss_G: 3.430094, loss_D: 0.163125\n",
      "[Epoch 139/200] [Batch 850/938] loss_G: 3.584748, loss_D: 0.193408\n",
      "[Epoch 139/200] [Batch 860/938] loss_G: 3.195105, loss_D: 0.229318\n",
      "[Epoch 139/200] [Batch 870/938] loss_G: 2.608274, loss_D: 0.191079\n",
      "[Epoch 139/200] [Batch 880/938] loss_G: 3.201200, loss_D: 0.260817\n",
      "[Epoch 139/200] [Batch 890/938] loss_G: 2.973255, loss_D: 0.134379\n",
      "[Epoch 139/200] [Batch 900/938] loss_G: 2.861094, loss_D: 0.214254\n",
      "[Epoch 139/200] [Batch 910/938] loss_G: 3.211918, loss_D: 0.259089\n",
      "[Epoch 139/200] [Batch 920/938] loss_G: 3.377453, loss_D: 0.140416\n",
      "[Epoch 139/200] [Batch 930/938] loss_G: 3.037958, loss_D: 0.210347\n",
      "[Epoch 140/200] [Batch 0/938] loss_G: 2.895793, loss_D: 0.212056\n",
      "[Epoch 140/200] [Batch 10/938] loss_G: 3.197118, loss_D: 0.172502\n",
      "[Epoch 140/200] [Batch 20/938] loss_G: 3.476923, loss_D: 0.195279\n",
      "[Epoch 140/200] [Batch 30/938] loss_G: 3.020303, loss_D: 0.177415\n",
      "[Epoch 140/200] [Batch 40/938] loss_G: 3.128887, loss_D: 0.155226\n",
      "[Epoch 140/200] [Batch 50/938] loss_G: 2.849802, loss_D: 0.259020\n",
      "[Epoch 140/200] [Batch 60/938] loss_G: 2.793329, loss_D: 0.225120\n",
      "[Epoch 140/200] [Batch 70/938] loss_G: 2.972080, loss_D: 0.192077\n",
      "[Epoch 140/200] [Batch 80/938] loss_G: 3.314232, loss_D: 0.229080\n",
      "[Epoch 140/200] [Batch 90/938] loss_G: 3.227986, loss_D: 0.331720\n",
      "[Epoch 140/200] [Batch 100/938] loss_G: 3.274577, loss_D: 0.220440\n",
      "[Epoch 140/200] [Batch 110/938] loss_G: 3.123534, loss_D: 0.190027\n",
      "[Epoch 140/200] [Batch 120/938] loss_G: 3.194579, loss_D: 0.219314\n",
      "[Epoch 140/200] [Batch 130/938] loss_G: 3.392470, loss_D: 0.266972\n",
      "[Epoch 140/200] [Batch 140/938] loss_G: 3.293528, loss_D: 0.210893\n",
      "[Epoch 140/200] [Batch 150/938] loss_G: 2.886395, loss_D: 0.164615\n",
      "[Epoch 140/200] [Batch 160/938] loss_G: 2.779612, loss_D: 0.143433\n",
      "[Epoch 140/200] [Batch 170/938] loss_G: 3.048602, loss_D: 0.148318\n",
      "[Epoch 140/200] [Batch 180/938] loss_G: 3.213071, loss_D: 0.173811\n",
      "[Epoch 140/200] [Batch 190/938] loss_G: 3.399173, loss_D: 0.192781\n",
      "[Epoch 140/200] [Batch 200/938] loss_G: 2.921253, loss_D: 0.264443\n",
      "[Epoch 140/200] [Batch 210/938] loss_G: 3.444656, loss_D: 0.166578\n",
      "[Epoch 140/200] [Batch 220/938] loss_G: 2.932568, loss_D: 0.264107\n",
      "[Epoch 140/200] [Batch 230/938] loss_G: 3.107272, loss_D: 0.215038\n",
      "[Epoch 140/200] [Batch 240/938] loss_G: 3.280256, loss_D: 0.228342\n",
      "[Epoch 140/200] [Batch 250/938] loss_G: 3.208578, loss_D: 0.104632\n",
      "[Epoch 140/200] [Batch 260/938] loss_G: 3.130611, loss_D: 0.267605\n",
      "[Epoch 140/200] [Batch 270/938] loss_G: 3.038762, loss_D: 0.214788\n",
      "[Epoch 140/200] [Batch 280/938] loss_G: 3.450652, loss_D: 0.096464\n",
      "[Epoch 140/200] [Batch 290/938] loss_G: 2.991684, loss_D: 0.173414\n",
      "[Epoch 140/200] [Batch 300/938] loss_G: 3.516753, loss_D: 0.226713\n",
      "[Epoch 140/200] [Batch 310/938] loss_G: 3.060634, loss_D: 0.170313\n",
      "[Epoch 140/200] [Batch 320/938] loss_G: 3.404348, loss_D: 0.172846\n",
      "[Epoch 140/200] [Batch 330/938] loss_G: 3.010847, loss_D: 0.221145\n",
      "[Epoch 140/200] [Batch 340/938] loss_G: 3.280515, loss_D: 0.193371\n",
      "[Epoch 140/200] [Batch 350/938] loss_G: 3.041562, loss_D: 0.227454\n",
      "[Epoch 140/200] [Batch 360/938] loss_G: 3.213975, loss_D: 0.237622\n",
      "[Epoch 140/200] [Batch 370/938] loss_G: 2.725757, loss_D: 0.250846\n",
      "[Epoch 140/200] [Batch 380/938] loss_G: 3.136973, loss_D: 0.159001\n",
      "[Epoch 140/200] [Batch 390/938] loss_G: 2.938503, loss_D: 0.187829\n",
      "[Epoch 140/200] [Batch 400/938] loss_G: 3.072807, loss_D: 0.235943\n",
      "[Epoch 140/200] [Batch 410/938] loss_G: 3.174519, loss_D: 0.161174\n",
      "[Epoch 140/200] [Batch 420/938] loss_G: 3.054725, loss_D: 0.268633\n",
      "[Epoch 140/200] [Batch 430/938] loss_G: 3.157910, loss_D: 0.147628\n",
      "[Epoch 140/200] [Batch 440/938] loss_G: 3.087053, loss_D: 0.219381\n",
      "[Epoch 140/200] [Batch 450/938] loss_G: 3.174082, loss_D: 0.187230\n",
      "[Epoch 140/200] [Batch 460/938] loss_G: 3.337992, loss_D: 0.174888\n",
      "[Epoch 140/200] [Batch 470/938] loss_G: 3.154704, loss_D: 0.221221\n",
      "[Epoch 140/200] [Batch 480/938] loss_G: 2.984473, loss_D: 0.382666\n",
      "[Epoch 140/200] [Batch 490/938] loss_G: 3.179815, loss_D: 0.227375\n",
      "[Epoch 140/200] [Batch 500/938] loss_G: 3.271423, loss_D: 0.209256\n",
      "[Epoch 140/200] [Batch 510/938] loss_G: 3.163749, loss_D: 0.220421\n",
      "[Epoch 140/200] [Batch 520/938] loss_G: 3.189592, loss_D: 0.286113\n",
      "[Epoch 140/200] [Batch 530/938] loss_G: 3.220226, loss_D: 0.199142\n",
      "[Epoch 140/200] [Batch 540/938] loss_G: 3.076568, loss_D: 0.212955\n",
      "[Epoch 140/200] [Batch 550/938] loss_G: 2.893502, loss_D: 0.206481\n",
      "[Epoch 140/200] [Batch 560/938] loss_G: 2.777051, loss_D: 0.174328\n",
      "[Epoch 140/200] [Batch 570/938] loss_G: 2.720948, loss_D: 0.126534\n",
      "[Epoch 140/200] [Batch 580/938] loss_G: 3.190531, loss_D: 0.128198\n",
      "[Epoch 140/200] [Batch 590/938] loss_G: 3.409385, loss_D: 0.155225\n",
      "[Epoch 140/200] [Batch 600/938] loss_G: 3.123099, loss_D: 0.211096\n",
      "[Epoch 140/200] [Batch 610/938] loss_G: 3.262277, loss_D: 0.208718\n",
      "[Epoch 140/200] [Batch 620/938] loss_G: 2.850126, loss_D: 0.264435\n",
      "[Epoch 140/200] [Batch 630/938] loss_G: 3.052970, loss_D: 0.212799\n",
      "[Epoch 140/200] [Batch 640/938] loss_G: 2.925767, loss_D: 0.200227\n",
      "[Epoch 140/200] [Batch 650/938] loss_G: 2.684148, loss_D: 0.179857\n",
      "[Epoch 140/200] [Batch 660/938] loss_G: 3.113776, loss_D: 0.190256\n",
      "[Epoch 140/200] [Batch 670/938] loss_G: 2.921863, loss_D: 0.215179\n",
      "[Epoch 140/200] [Batch 680/938] loss_G: 3.310057, loss_D: 0.155574\n",
      "[Epoch 140/200] [Batch 690/938] loss_G: 2.944798, loss_D: 0.177824\n",
      "[Epoch 140/200] [Batch 700/938] loss_G: 3.188430, loss_D: 0.240412\n",
      "[Epoch 140/200] [Batch 710/938] loss_G: 3.125885, loss_D: 0.213563\n",
      "[Epoch 140/200] [Batch 720/938] loss_G: 3.288450, loss_D: 0.157801\n",
      "[Epoch 140/200] [Batch 730/938] loss_G: 3.344630, loss_D: 0.179519\n",
      "[Epoch 140/200] [Batch 740/938] loss_G: 2.939361, loss_D: 0.146753\n",
      "[Epoch 140/200] [Batch 750/938] loss_G: 3.161159, loss_D: 0.113099\n",
      "[Epoch 140/200] [Batch 760/938] loss_G: 3.019763, loss_D: 0.271511\n",
      "[Epoch 140/200] [Batch 770/938] loss_G: 3.073434, loss_D: 0.225465\n",
      "[Epoch 140/200] [Batch 780/938] loss_G: 3.309555, loss_D: 0.147375\n",
      "[Epoch 140/200] [Batch 790/938] loss_G: 3.160240, loss_D: 0.251528\n",
      "[Epoch 140/200] [Batch 800/938] loss_G: 3.185146, loss_D: 0.234475\n",
      "[Epoch 140/200] [Batch 810/938] loss_G: 2.855314, loss_D: 0.156778\n",
      "[Epoch 140/200] [Batch 820/938] loss_G: 3.218749, loss_D: 0.147264\n",
      "[Epoch 140/200] [Batch 830/938] loss_G: 2.911413, loss_D: 0.181319\n",
      "[Epoch 140/200] [Batch 840/938] loss_G: 3.137736, loss_D: 0.228035\n",
      "[Epoch 140/200] [Batch 850/938] loss_G: 2.945993, loss_D: 0.200473\n",
      "[Epoch 140/200] [Batch 860/938] loss_G: 2.945570, loss_D: 0.216734\n",
      "[Epoch 140/200] [Batch 870/938] loss_G: 3.103960, loss_D: 0.298158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 140/200] [Batch 880/938] loss_G: 3.113947, loss_D: 0.191030\n",
      "[Epoch 140/200] [Batch 890/938] loss_G: 3.433782, loss_D: 0.155320\n",
      "[Epoch 140/200] [Batch 900/938] loss_G: 3.028058, loss_D: 0.208425\n",
      "[Epoch 140/200] [Batch 910/938] loss_G: 2.837174, loss_D: 0.167411\n",
      "[Epoch 140/200] [Batch 920/938] loss_G: 3.192044, loss_D: 0.171089\n",
      "[Epoch 140/200] [Batch 930/938] loss_G: 2.951788, loss_D: 0.252431\n",
      "[Epoch 141/200] [Batch 0/938] loss_G: 3.220702, loss_D: 0.266653\n",
      "[Epoch 141/200] [Batch 10/938] loss_G: 2.805571, loss_D: 0.173897\n",
      "[Epoch 141/200] [Batch 20/938] loss_G: 3.071912, loss_D: 0.198087\n",
      "[Epoch 141/200] [Batch 30/938] loss_G: 3.466045, loss_D: 0.123079\n",
      "[Epoch 141/200] [Batch 40/938] loss_G: 3.242657, loss_D: 0.136064\n",
      "[Epoch 141/200] [Batch 50/938] loss_G: 3.464341, loss_D: 0.124745\n",
      "[Epoch 141/200] [Batch 60/938] loss_G: 3.541300, loss_D: 0.149588\n",
      "[Epoch 141/200] [Batch 70/938] loss_G: 3.056230, loss_D: 0.191044\n",
      "[Epoch 141/200] [Batch 80/938] loss_G: 3.577194, loss_D: 0.163585\n",
      "[Epoch 141/200] [Batch 90/938] loss_G: 3.234878, loss_D: 0.231439\n",
      "[Epoch 141/200] [Batch 100/938] loss_G: 3.051708, loss_D: 0.234020\n",
      "[Epoch 141/200] [Batch 110/938] loss_G: 3.188462, loss_D: 0.194838\n",
      "[Epoch 141/200] [Batch 120/938] loss_G: 3.276104, loss_D: 0.164805\n",
      "[Epoch 141/200] [Batch 130/938] loss_G: 3.079810, loss_D: 0.278084\n",
      "[Epoch 141/200] [Batch 140/938] loss_G: 3.183172, loss_D: 0.239773\n",
      "[Epoch 141/200] [Batch 150/938] loss_G: 3.377883, loss_D: 0.155678\n",
      "[Epoch 141/200] [Batch 160/938] loss_G: 3.007738, loss_D: 0.284703\n",
      "[Epoch 141/200] [Batch 170/938] loss_G: 3.125500, loss_D: 0.183015\n",
      "[Epoch 141/200] [Batch 180/938] loss_G: 3.429982, loss_D: 0.201988\n",
      "[Epoch 141/200] [Batch 190/938] loss_G: 2.952913, loss_D: 0.240490\n",
      "[Epoch 141/200] [Batch 200/938] loss_G: 3.097859, loss_D: 0.187380\n",
      "[Epoch 141/200] [Batch 210/938] loss_G: 3.178674, loss_D: 0.214807\n",
      "[Epoch 141/200] [Batch 220/938] loss_G: 3.032389, loss_D: 0.263356\n",
      "[Epoch 141/200] [Batch 230/938] loss_G: 2.885269, loss_D: 0.195326\n",
      "[Epoch 141/200] [Batch 240/938] loss_G: 3.340654, loss_D: 0.153399\n",
      "[Epoch 141/200] [Batch 250/938] loss_G: 3.354368, loss_D: 0.235476\n",
      "[Epoch 141/200] [Batch 260/938] loss_G: 3.135353, loss_D: 0.222971\n",
      "[Epoch 141/200] [Batch 270/938] loss_G: 3.064545, loss_D: 0.161640\n",
      "[Epoch 141/200] [Batch 280/938] loss_G: 2.694051, loss_D: 0.147140\n",
      "[Epoch 141/200] [Batch 290/938] loss_G: 3.072648, loss_D: 0.205186\n",
      "[Epoch 141/200] [Batch 300/938] loss_G: 3.525849, loss_D: 0.194134\n",
      "[Epoch 141/200] [Batch 310/938] loss_G: 3.051442, loss_D: 0.202388\n",
      "[Epoch 141/200] [Batch 320/938] loss_G: 3.424988, loss_D: 0.175628\n",
      "[Epoch 141/200] [Batch 330/938] loss_G: 3.273703, loss_D: 0.167056\n",
      "[Epoch 141/200] [Batch 340/938] loss_G: 3.093544, loss_D: 0.215249\n",
      "[Epoch 141/200] [Batch 350/938] loss_G: 3.034600, loss_D: 0.197177\n",
      "[Epoch 141/200] [Batch 360/938] loss_G: 3.172780, loss_D: 0.193739\n",
      "[Epoch 141/200] [Batch 370/938] loss_G: 2.602921, loss_D: 0.216872\n",
      "[Epoch 141/200] [Batch 380/938] loss_G: 3.224288, loss_D: 0.173491\n",
      "[Epoch 141/200] [Batch 390/938] loss_G: 3.036670, loss_D: 0.206729\n",
      "[Epoch 141/200] [Batch 400/938] loss_G: 3.007529, loss_D: 0.192875\n",
      "[Epoch 141/200] [Batch 410/938] loss_G: 3.099757, loss_D: 0.201766\n",
      "[Epoch 141/200] [Batch 420/938] loss_G: 2.920178, loss_D: 0.210096\n",
      "[Epoch 141/200] [Batch 430/938] loss_G: 3.579902, loss_D: 0.209316\n",
      "[Epoch 141/200] [Batch 440/938] loss_G: 3.126860, loss_D: 0.146274\n",
      "[Epoch 141/200] [Batch 450/938] loss_G: 3.336159, loss_D: 0.193164\n",
      "[Epoch 141/200] [Batch 460/938] loss_G: 2.814352, loss_D: 0.219397\n",
      "[Epoch 141/200] [Batch 470/938] loss_G: 3.230994, loss_D: 0.210854\n",
      "[Epoch 141/200] [Batch 480/938] loss_G: 3.678480, loss_D: 0.182469\n",
      "[Epoch 141/200] [Batch 490/938] loss_G: 3.563361, loss_D: 0.193550\n",
      "[Epoch 141/200] [Batch 500/938] loss_G: 3.369148, loss_D: 0.120003\n",
      "[Epoch 141/200] [Batch 510/938] loss_G: 3.014194, loss_D: 0.191254\n",
      "[Epoch 141/200] [Batch 520/938] loss_G: 3.367785, loss_D: 0.097001\n",
      "[Epoch 141/200] [Batch 530/938] loss_G: 3.209662, loss_D: 0.202562\n",
      "[Epoch 141/200] [Batch 540/938] loss_G: 3.354393, loss_D: 0.117278\n",
      "[Epoch 141/200] [Batch 550/938] loss_G: 3.452545, loss_D: 0.091906\n",
      "[Epoch 141/200] [Batch 560/938] loss_G: 3.627607, loss_D: 0.154677\n",
      "[Epoch 141/200] [Batch 570/938] loss_G: 3.236668, loss_D: 0.195466\n",
      "[Epoch 141/200] [Batch 580/938] loss_G: 3.444919, loss_D: 0.122281\n",
      "[Epoch 141/200] [Batch 590/938] loss_G: 3.723490, loss_D: 0.267226\n",
      "[Epoch 141/200] [Batch 600/938] loss_G: 3.463245, loss_D: 0.293105\n",
      "[Epoch 141/200] [Batch 610/938] loss_G: 3.230834, loss_D: 0.271844\n",
      "[Epoch 141/200] [Batch 620/938] loss_G: 3.410827, loss_D: 0.199635\n",
      "[Epoch 141/200] [Batch 630/938] loss_G: 3.378245, loss_D: 0.213981\n",
      "[Epoch 141/200] [Batch 640/938] loss_G: 3.237037, loss_D: 0.247974\n",
      "[Epoch 141/200] [Batch 650/938] loss_G: 3.017369, loss_D: 0.162622\n",
      "[Epoch 141/200] [Batch 660/938] loss_G: 3.254848, loss_D: 0.215339\n",
      "[Epoch 141/200] [Batch 670/938] loss_G: 3.518434, loss_D: 0.254925\n",
      "[Epoch 141/200] [Batch 680/938] loss_G: 3.342914, loss_D: 0.162015\n",
      "[Epoch 141/200] [Batch 690/938] loss_G: 3.316514, loss_D: 0.111304\n",
      "[Epoch 141/200] [Batch 700/938] loss_G: 3.276688, loss_D: 0.161613\n",
      "[Epoch 141/200] [Batch 710/938] loss_G: 3.249730, loss_D: 0.196120\n",
      "[Epoch 141/200] [Batch 720/938] loss_G: 3.581958, loss_D: 0.230596\n",
      "[Epoch 141/200] [Batch 730/938] loss_G: 3.372778, loss_D: 0.237976\n",
      "[Epoch 141/200] [Batch 740/938] loss_G: 3.301423, loss_D: 0.142776\n",
      "[Epoch 141/200] [Batch 750/938] loss_G: 3.075750, loss_D: 0.187482\n",
      "[Epoch 141/200] [Batch 760/938] loss_G: 2.796619, loss_D: 0.293192\n",
      "[Epoch 141/200] [Batch 770/938] loss_G: 3.309639, loss_D: 0.311044\n",
      "[Epoch 141/200] [Batch 780/938] loss_G: 3.062891, loss_D: 0.174662\n",
      "[Epoch 141/200] [Batch 790/938] loss_G: 3.274209, loss_D: 0.191379\n",
      "[Epoch 141/200] [Batch 800/938] loss_G: 3.426583, loss_D: 0.174186\n",
      "[Epoch 141/200] [Batch 810/938] loss_G: 3.177633, loss_D: 0.112371\n",
      "[Epoch 141/200] [Batch 820/938] loss_G: 3.140783, loss_D: 0.143027\n",
      "[Epoch 141/200] [Batch 830/938] loss_G: 3.757708, loss_D: 0.194916\n",
      "[Epoch 141/200] [Batch 840/938] loss_G: 3.353829, loss_D: 0.186464\n",
      "[Epoch 141/200] [Batch 850/938] loss_G: 2.970691, loss_D: 0.244006\n",
      "[Epoch 141/200] [Batch 860/938] loss_G: 3.510058, loss_D: 0.255098\n",
      "[Epoch 141/200] [Batch 870/938] loss_G: 3.422792, loss_D: 0.196678\n",
      "[Epoch 141/200] [Batch 880/938] loss_G: 3.186701, loss_D: 0.232906\n",
      "[Epoch 141/200] [Batch 890/938] loss_G: 3.607984, loss_D: 0.229513\n",
      "[Epoch 141/200] [Batch 900/938] loss_G: 3.242084, loss_D: 0.199997\n",
      "[Epoch 141/200] [Batch 910/938] loss_G: 3.253744, loss_D: 0.260779\n",
      "[Epoch 141/200] [Batch 920/938] loss_G: 3.299438, loss_D: 0.215244\n",
      "[Epoch 141/200] [Batch 930/938] loss_G: 3.148241, loss_D: 0.194978\n",
      "[Epoch 142/200] [Batch 0/938] loss_G: 3.340434, loss_D: 0.224381\n",
      "[Epoch 142/200] [Batch 10/938] loss_G: 3.089844, loss_D: 0.162033\n",
      "[Epoch 142/200] [Batch 20/938] loss_G: 2.980589, loss_D: 0.144216\n",
      "[Epoch 142/200] [Batch 30/938] loss_G: 3.198644, loss_D: 0.241082\n",
      "[Epoch 142/200] [Batch 40/938] loss_G: 3.148621, loss_D: 0.176935\n",
      "[Epoch 142/200] [Batch 50/938] loss_G: 3.222755, loss_D: 0.192470\n",
      "[Epoch 142/200] [Batch 60/938] loss_G: 3.162936, loss_D: 0.182267\n",
      "[Epoch 142/200] [Batch 70/938] loss_G: 3.616762, loss_D: 0.205841\n",
      "[Epoch 142/200] [Batch 80/938] loss_G: 3.232179, loss_D: 0.161449\n",
      "[Epoch 142/200] [Batch 90/938] loss_G: 3.083432, loss_D: 0.246287\n",
      "[Epoch 142/200] [Batch 100/938] loss_G: 3.448668, loss_D: 0.175411\n",
      "[Epoch 142/200] [Batch 110/938] loss_G: 3.250401, loss_D: 0.147999\n",
      "[Epoch 142/200] [Batch 120/938] loss_G: 3.102372, loss_D: 0.189933\n",
      "[Epoch 142/200] [Batch 130/938] loss_G: 3.216384, loss_D: 0.220145\n",
      "[Epoch 142/200] [Batch 140/938] loss_G: 3.310113, loss_D: 0.178359\n",
      "[Epoch 142/200] [Batch 150/938] loss_G: 3.016561, loss_D: 0.142601\n",
      "[Epoch 142/200] [Batch 160/938] loss_G: 3.282568, loss_D: 0.200390\n",
      "[Epoch 142/200] [Batch 170/938] loss_G: 2.988830, loss_D: 0.261253\n",
      "[Epoch 142/200] [Batch 180/938] loss_G: 2.932003, loss_D: 0.189348\n",
      "[Epoch 142/200] [Batch 190/938] loss_G: 3.240489, loss_D: 0.187492\n",
      "[Epoch 142/200] [Batch 200/938] loss_G: 3.144646, loss_D: 0.217653\n",
      "[Epoch 142/200] [Batch 210/938] loss_G: 3.313865, loss_D: 0.197525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 142/200] [Batch 220/938] loss_G: 3.531460, loss_D: 0.139895\n",
      "[Epoch 142/200] [Batch 230/938] loss_G: 3.054352, loss_D: 0.211759\n",
      "[Epoch 142/200] [Batch 240/938] loss_G: 2.730304, loss_D: 0.174880\n",
      "[Epoch 142/200] [Batch 250/938] loss_G: 3.195133, loss_D: 0.215597\n",
      "[Epoch 142/200] [Batch 260/938] loss_G: 3.470633, loss_D: 0.127992\n",
      "[Epoch 142/200] [Batch 270/938] loss_G: 2.764864, loss_D: 0.123706\n",
      "[Epoch 142/200] [Batch 280/938] loss_G: 2.968766, loss_D: 0.152124\n",
      "[Epoch 142/200] [Batch 290/938] loss_G: 3.143310, loss_D: 0.228522\n",
      "[Epoch 142/200] [Batch 300/938] loss_G: 3.087248, loss_D: 0.150921\n",
      "[Epoch 142/200] [Batch 310/938] loss_G: 3.593627, loss_D: 0.167411\n",
      "[Epoch 142/200] [Batch 320/938] loss_G: 3.460055, loss_D: 0.202518\n",
      "[Epoch 142/200] [Batch 330/938] loss_G: 3.411733, loss_D: 0.176857\n",
      "[Epoch 142/200] [Batch 340/938] loss_G: 3.309531, loss_D: 0.111843\n",
      "[Epoch 142/200] [Batch 350/938] loss_G: 3.273902, loss_D: 0.175606\n",
      "[Epoch 142/200] [Batch 360/938] loss_G: 3.346286, loss_D: 0.180119\n",
      "[Epoch 142/200] [Batch 370/938] loss_G: 3.117276, loss_D: 0.235447\n",
      "[Epoch 142/200] [Batch 380/938] loss_G: 3.136382, loss_D: 0.206495\n",
      "[Epoch 142/200] [Batch 390/938] loss_G: 3.034726, loss_D: 0.274112\n",
      "[Epoch 142/200] [Batch 400/938] loss_G: 3.692742, loss_D: 0.157138\n",
      "[Epoch 142/200] [Batch 410/938] loss_G: 3.505356, loss_D: 0.204523\n",
      "[Epoch 142/200] [Batch 420/938] loss_G: 3.728214, loss_D: 0.148829\n",
      "[Epoch 142/200] [Batch 430/938] loss_G: 3.111201, loss_D: 0.270970\n",
      "[Epoch 142/200] [Batch 440/938] loss_G: 3.351251, loss_D: 0.207616\n",
      "[Epoch 142/200] [Batch 450/938] loss_G: 3.171988, loss_D: 0.242212\n",
      "[Epoch 142/200] [Batch 460/938] loss_G: 2.918533, loss_D: 0.227374\n",
      "[Epoch 142/200] [Batch 470/938] loss_G: 3.294631, loss_D: 0.192421\n",
      "[Epoch 142/200] [Batch 480/938] loss_G: 2.617102, loss_D: 0.288351\n",
      "[Epoch 142/200] [Batch 490/938] loss_G: 3.485617, loss_D: 0.170494\n",
      "[Epoch 142/200] [Batch 500/938] loss_G: 3.406686, loss_D: 0.228806\n",
      "[Epoch 142/200] [Batch 510/938] loss_G: 3.217529, loss_D: 0.169505\n",
      "[Epoch 142/200] [Batch 520/938] loss_G: 3.114667, loss_D: 0.206983\n",
      "[Epoch 142/200] [Batch 530/938] loss_G: 3.025111, loss_D: 0.242085\n",
      "[Epoch 142/200] [Batch 540/938] loss_G: 3.125741, loss_D: 0.186862\n",
      "[Epoch 142/200] [Batch 550/938] loss_G: 3.150708, loss_D: 0.140293\n",
      "[Epoch 142/200] [Batch 560/938] loss_G: 3.249504, loss_D: 0.213519\n",
      "[Epoch 142/200] [Batch 570/938] loss_G: 3.115492, loss_D: 0.181363\n",
      "[Epoch 142/200] [Batch 580/938] loss_G: 3.195471, loss_D: 0.176459\n",
      "[Epoch 142/200] [Batch 590/938] loss_G: 3.505593, loss_D: 0.166845\n",
      "[Epoch 142/200] [Batch 600/938] loss_G: 3.347890, loss_D: 0.179857\n",
      "[Epoch 142/200] [Batch 610/938] loss_G: 3.156345, loss_D: 0.108973\n",
      "[Epoch 142/200] [Batch 620/938] loss_G: 3.238341, loss_D: 0.213727\n",
      "[Epoch 142/200] [Batch 630/938] loss_G: 3.165794, loss_D: 0.191950\n",
      "[Epoch 142/200] [Batch 640/938] loss_G: 3.425601, loss_D: 0.177422\n",
      "[Epoch 142/200] [Batch 650/938] loss_G: 3.269929, loss_D: 0.191525\n",
      "[Epoch 142/200] [Batch 660/938] loss_G: 3.014583, loss_D: 0.226291\n",
      "[Epoch 142/200] [Batch 670/938] loss_G: 3.320110, loss_D: 0.194459\n",
      "[Epoch 142/200] [Batch 680/938] loss_G: 3.650370, loss_D: 0.201774\n",
      "[Epoch 142/200] [Batch 690/938] loss_G: 3.636843, loss_D: 0.140440\n",
      "[Epoch 142/200] [Batch 700/938] loss_G: 2.966065, loss_D: 0.274292\n",
      "[Epoch 142/200] [Batch 710/938] loss_G: 3.775439, loss_D: 0.206408\n",
      "[Epoch 142/200] [Batch 720/938] loss_G: 3.239513, loss_D: 0.211310\n",
      "[Epoch 142/200] [Batch 730/938] loss_G: 2.830891, loss_D: 0.228377\n",
      "[Epoch 142/200] [Batch 740/938] loss_G: 3.127983, loss_D: 0.248767\n",
      "[Epoch 142/200] [Batch 750/938] loss_G: 2.989341, loss_D: 0.237628\n",
      "[Epoch 142/200] [Batch 760/938] loss_G: 3.192595, loss_D: 0.264804\n",
      "[Epoch 142/200] [Batch 770/938] loss_G: 3.115861, loss_D: 0.237575\n",
      "[Epoch 142/200] [Batch 780/938] loss_G: 3.076309, loss_D: 0.170131\n",
      "[Epoch 142/200] [Batch 790/938] loss_G: 3.033819, loss_D: 0.149590\n",
      "[Epoch 142/200] [Batch 800/938] loss_G: 2.958391, loss_D: 0.215117\n",
      "[Epoch 142/200] [Batch 810/938] loss_G: 3.242337, loss_D: 0.181622\n",
      "[Epoch 142/200] [Batch 820/938] loss_G: 3.505563, loss_D: 0.169243\n",
      "[Epoch 142/200] [Batch 830/938] loss_G: 2.741469, loss_D: 0.244512\n",
      "[Epoch 142/200] [Batch 840/938] loss_G: 3.280259, loss_D: 0.300756\n",
      "[Epoch 142/200] [Batch 850/938] loss_G: 3.164247, loss_D: 0.163122\n",
      "[Epoch 142/200] [Batch 860/938] loss_G: 3.033836, loss_D: 0.274976\n",
      "[Epoch 142/200] [Batch 870/938] loss_G: 3.050356, loss_D: 0.196875\n",
      "[Epoch 142/200] [Batch 880/938] loss_G: 3.286396, loss_D: 0.125784\n",
      "[Epoch 142/200] [Batch 890/938] loss_G: 3.195273, loss_D: 0.177303\n",
      "[Epoch 142/200] [Batch 900/938] loss_G: 3.290646, loss_D: 0.225855\n",
      "[Epoch 142/200] [Batch 910/938] loss_G: 3.489756, loss_D: 0.223262\n",
      "[Epoch 142/200] [Batch 920/938] loss_G: 3.310287, loss_D: 0.149125\n",
      "[Epoch 142/200] [Batch 930/938] loss_G: 3.392052, loss_D: 0.148119\n",
      "[Epoch 143/200] [Batch 0/938] loss_G: 3.322118, loss_D: 0.261961\n",
      "[Epoch 143/200] [Batch 10/938] loss_G: 3.486826, loss_D: 0.214564\n",
      "[Epoch 143/200] [Batch 20/938] loss_G: 3.178667, loss_D: 0.188174\n",
      "[Epoch 143/200] [Batch 30/938] loss_G: 3.021821, loss_D: 0.130750\n",
      "[Epoch 143/200] [Batch 40/938] loss_G: 3.279258, loss_D: 0.197042\n",
      "[Epoch 143/200] [Batch 50/938] loss_G: 3.333719, loss_D: 0.181271\n",
      "[Epoch 143/200] [Batch 60/938] loss_G: 3.141230, loss_D: 0.255297\n",
      "[Epoch 143/200] [Batch 70/938] loss_G: 3.495350, loss_D: 0.222299\n",
      "[Epoch 143/200] [Batch 80/938] loss_G: 3.339125, loss_D: 0.266504\n",
      "[Epoch 143/200] [Batch 90/938] loss_G: 3.448949, loss_D: 0.202248\n",
      "[Epoch 143/200] [Batch 100/938] loss_G: 2.870676, loss_D: 0.169748\n",
      "[Epoch 143/200] [Batch 110/938] loss_G: 3.456311, loss_D: 0.234643\n",
      "[Epoch 143/200] [Batch 120/938] loss_G: 3.369321, loss_D: 0.103936\n",
      "[Epoch 143/200] [Batch 130/938] loss_G: 3.180511, loss_D: 0.123667\n",
      "[Epoch 143/200] [Batch 140/938] loss_G: 3.272617, loss_D: 0.161063\n",
      "[Epoch 143/200] [Batch 150/938] loss_G: 2.879806, loss_D: 0.233893\n",
      "[Epoch 143/200] [Batch 160/938] loss_G: 3.319760, loss_D: 0.145613\n",
      "[Epoch 143/200] [Batch 170/938] loss_G: 3.007504, loss_D: 0.298366\n",
      "[Epoch 143/200] [Batch 180/938] loss_G: 2.801304, loss_D: 0.261525\n",
      "[Epoch 143/200] [Batch 190/938] loss_G: 3.232381, loss_D: 0.169664\n",
      "[Epoch 143/200] [Batch 200/938] loss_G: 3.225272, loss_D: 0.130636\n",
      "[Epoch 143/200] [Batch 210/938] loss_G: 3.164209, loss_D: 0.220493\n",
      "[Epoch 143/200] [Batch 220/938] loss_G: 3.272889, loss_D: 0.211211\n",
      "[Epoch 143/200] [Batch 230/938] loss_G: 2.956043, loss_D: 0.269729\n",
      "[Epoch 143/200] [Batch 240/938] loss_G: 3.433463, loss_D: 0.156849\n",
      "[Epoch 143/200] [Batch 250/938] loss_G: 3.006846, loss_D: 0.219847\n",
      "[Epoch 143/200] [Batch 260/938] loss_G: 3.208769, loss_D: 0.194235\n",
      "[Epoch 143/200] [Batch 270/938] loss_G: 3.337771, loss_D: 0.207626\n",
      "[Epoch 143/200] [Batch 280/938] loss_G: 3.123142, loss_D: 0.160823\n",
      "[Epoch 143/200] [Batch 290/938] loss_G: 2.499929, loss_D: 0.217232\n",
      "[Epoch 143/200] [Batch 300/938] loss_G: 3.298711, loss_D: 0.242237\n",
      "[Epoch 143/200] [Batch 310/938] loss_G: 2.992178, loss_D: 0.203129\n",
      "[Epoch 143/200] [Batch 320/938] loss_G: 3.052578, loss_D: 0.200694\n",
      "[Epoch 143/200] [Batch 330/938] loss_G: 3.126712, loss_D: 0.174944\n",
      "[Epoch 143/200] [Batch 340/938] loss_G: 3.229299, loss_D: 0.133556\n",
      "[Epoch 143/200] [Batch 350/938] loss_G: 2.947931, loss_D: 0.189290\n",
      "[Epoch 143/200] [Batch 360/938] loss_G: 3.260156, loss_D: 0.186192\n",
      "[Epoch 143/200] [Batch 370/938] loss_G: 3.168638, loss_D: 0.123747\n",
      "[Epoch 143/200] [Batch 380/938] loss_G: 3.381781, loss_D: 0.163077\n",
      "[Epoch 143/200] [Batch 390/938] loss_G: 3.344784, loss_D: 0.226747\n",
      "[Epoch 143/200] [Batch 400/938] loss_G: 3.214675, loss_D: 0.124700\n",
      "[Epoch 143/200] [Batch 410/938] loss_G: 2.793046, loss_D: 0.156366\n",
      "[Epoch 143/200] [Batch 420/938] loss_G: 3.467834, loss_D: 0.218458\n",
      "[Epoch 143/200] [Batch 430/938] loss_G: 3.469216, loss_D: 0.133755\n",
      "[Epoch 143/200] [Batch 440/938] loss_G: 3.475292, loss_D: 0.247856\n",
      "[Epoch 143/200] [Batch 450/938] loss_G: 3.227564, loss_D: 0.225734\n",
      "[Epoch 143/200] [Batch 460/938] loss_G: 3.125709, loss_D: 0.195998\n",
      "[Epoch 143/200] [Batch 470/938] loss_G: 3.044782, loss_D: 0.229410\n",
      "[Epoch 143/200] [Batch 480/938] loss_G: 3.004401, loss_D: 0.166607\n",
      "[Epoch 143/200] [Batch 490/938] loss_G: 2.976067, loss_D: 0.133086\n",
      "[Epoch 143/200] [Batch 500/938] loss_G: 2.899599, loss_D: 0.202772\n",
      "[Epoch 143/200] [Batch 510/938] loss_G: 3.210639, loss_D: 0.150648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 143/200] [Batch 520/938] loss_G: 3.423242, loss_D: 0.199573\n",
      "[Epoch 143/200] [Batch 530/938] loss_G: 3.217780, loss_D: 0.222140\n",
      "[Epoch 143/200] [Batch 540/938] loss_G: 3.329358, loss_D: 0.125763\n",
      "[Epoch 143/200] [Batch 550/938] loss_G: 3.383292, loss_D: 0.188859\n",
      "[Epoch 143/200] [Batch 560/938] loss_G: 2.915765, loss_D: 0.205615\n",
      "[Epoch 143/200] [Batch 570/938] loss_G: 2.832279, loss_D: 0.236597\n",
      "[Epoch 143/200] [Batch 580/938] loss_G: 2.890003, loss_D: 0.200248\n",
      "[Epoch 143/200] [Batch 590/938] loss_G: 3.168936, loss_D: 0.170124\n",
      "[Epoch 143/200] [Batch 600/938] loss_G: 3.249413, loss_D: 0.113261\n",
      "[Epoch 143/200] [Batch 610/938] loss_G: 3.405111, loss_D: 0.127948\n",
      "[Epoch 143/200] [Batch 620/938] loss_G: 3.368593, loss_D: 0.216654\n",
      "[Epoch 143/200] [Batch 630/938] loss_G: 3.042456, loss_D: 0.198521\n",
      "[Epoch 143/200] [Batch 640/938] loss_G: 3.083029, loss_D: 0.231957\n",
      "[Epoch 143/200] [Batch 650/938] loss_G: 2.632725, loss_D: 0.274096\n",
      "[Epoch 143/200] [Batch 660/938] loss_G: 2.935288, loss_D: 0.226207\n",
      "[Epoch 143/200] [Batch 670/938] loss_G: 3.247751, loss_D: 0.111231\n",
      "[Epoch 143/200] [Batch 680/938] loss_G: 3.284670, loss_D: 0.154969\n",
      "[Epoch 143/200] [Batch 690/938] loss_G: 2.829616, loss_D: 0.236861\n",
      "[Epoch 143/200] [Batch 700/938] loss_G: 3.107189, loss_D: 0.165937\n",
      "[Epoch 143/200] [Batch 710/938] loss_G: 3.043583, loss_D: 0.186251\n",
      "[Epoch 143/200] [Batch 720/938] loss_G: 3.064465, loss_D: 0.230124\n",
      "[Epoch 143/200] [Batch 730/938] loss_G: 3.480250, loss_D: 0.184186\n",
      "[Epoch 143/200] [Batch 740/938] loss_G: 3.024958, loss_D: 0.189388\n",
      "[Epoch 143/200] [Batch 750/938] loss_G: 3.162411, loss_D: 0.158916\n",
      "[Epoch 143/200] [Batch 760/938] loss_G: 3.106040, loss_D: 0.151535\n",
      "[Epoch 143/200] [Batch 770/938] loss_G: 3.199536, loss_D: 0.367237\n",
      "[Epoch 143/200] [Batch 780/938] loss_G: 2.775243, loss_D: 0.320240\n",
      "[Epoch 143/200] [Batch 790/938] loss_G: 2.745219, loss_D: 0.208733\n",
      "[Epoch 143/200] [Batch 800/938] loss_G: 3.281684, loss_D: 0.152047\n",
      "[Epoch 143/200] [Batch 810/938] loss_G: 3.312419, loss_D: 0.228134\n",
      "[Epoch 143/200] [Batch 820/938] loss_G: 2.960859, loss_D: 0.184323\n",
      "[Epoch 143/200] [Batch 830/938] loss_G: 3.433385, loss_D: 0.211336\n",
      "[Epoch 143/200] [Batch 840/938] loss_G: 3.095122, loss_D: 0.174221\n",
      "[Epoch 143/200] [Batch 850/938] loss_G: 3.448336, loss_D: 0.250975\n",
      "[Epoch 143/200] [Batch 860/938] loss_G: 3.302108, loss_D: 0.172117\n",
      "[Epoch 143/200] [Batch 870/938] loss_G: 2.791163, loss_D: 0.196289\n",
      "[Epoch 143/200] [Batch 880/938] loss_G: 3.224028, loss_D: 0.189577\n",
      "[Epoch 143/200] [Batch 890/938] loss_G: 3.206622, loss_D: 0.135161\n",
      "[Epoch 143/200] [Batch 900/938] loss_G: 3.223459, loss_D: 0.272260\n",
      "[Epoch 143/200] [Batch 910/938] loss_G: 3.446647, loss_D: 0.163749\n",
      "[Epoch 143/200] [Batch 920/938] loss_G: 3.136694, loss_D: 0.206742\n",
      "[Epoch 143/200] [Batch 930/938] loss_G: 3.627517, loss_D: 0.177210\n",
      "[Epoch 144/200] [Batch 0/938] loss_G: 3.187196, loss_D: 0.162771\n",
      "[Epoch 144/200] [Batch 10/938] loss_G: 3.172036, loss_D: 0.274640\n",
      "[Epoch 144/200] [Batch 20/938] loss_G: 2.995548, loss_D: 0.223168\n",
      "[Epoch 144/200] [Batch 30/938] loss_G: 3.422519, loss_D: 0.105534\n",
      "[Epoch 144/200] [Batch 40/938] loss_G: 3.160366, loss_D: 0.189355\n",
      "[Epoch 144/200] [Batch 50/938] loss_G: 3.342220, loss_D: 0.182876\n",
      "[Epoch 144/200] [Batch 60/938] loss_G: 3.596990, loss_D: 0.182503\n",
      "[Epoch 144/200] [Batch 70/938] loss_G: 2.935409, loss_D: 0.208780\n",
      "[Epoch 144/200] [Batch 80/938] loss_G: 2.921881, loss_D: 0.271730\n",
      "[Epoch 144/200] [Batch 90/938] loss_G: 3.349526, loss_D: 0.192236\n",
      "[Epoch 144/200] [Batch 100/938] loss_G: 3.144584, loss_D: 0.180830\n",
      "[Epoch 144/200] [Batch 110/938] loss_G: 3.050782, loss_D: 0.234459\n",
      "[Epoch 144/200] [Batch 120/938] loss_G: 3.185030, loss_D: 0.282044\n",
      "[Epoch 144/200] [Batch 130/938] loss_G: 3.050859, loss_D: 0.182649\n",
      "[Epoch 144/200] [Batch 140/938] loss_G: 3.274770, loss_D: 0.178889\n",
      "[Epoch 144/200] [Batch 150/938] loss_G: 3.281800, loss_D: 0.183359\n",
      "[Epoch 144/200] [Batch 160/938] loss_G: 3.255135, loss_D: 0.276734\n",
      "[Epoch 144/200] [Batch 170/938] loss_G: 3.170042, loss_D: 0.244102\n",
      "[Epoch 144/200] [Batch 180/938] loss_G: 2.891306, loss_D: 0.167982\n",
      "[Epoch 144/200] [Batch 190/938] loss_G: 3.752682, loss_D: 0.155342\n",
      "[Epoch 144/200] [Batch 200/938] loss_G: 2.981380, loss_D: 0.233776\n",
      "[Epoch 144/200] [Batch 210/938] loss_G: 3.301465, loss_D: 0.202928\n",
      "[Epoch 144/200] [Batch 220/938] loss_G: 3.344322, loss_D: 0.168523\n",
      "[Epoch 144/200] [Batch 230/938] loss_G: 2.933715, loss_D: 0.147250\n",
      "[Epoch 144/200] [Batch 240/938] loss_G: 3.372711, loss_D: 0.180702\n",
      "[Epoch 144/200] [Batch 250/938] loss_G: 3.140420, loss_D: 0.236869\n",
      "[Epoch 144/200] [Batch 260/938] loss_G: 2.777925, loss_D: 0.238474\n",
      "[Epoch 144/200] [Batch 270/938] loss_G: 3.386528, loss_D: 0.182531\n",
      "[Epoch 144/200] [Batch 280/938] loss_G: 3.345756, loss_D: 0.154536\n",
      "[Epoch 144/200] [Batch 290/938] loss_G: 3.068593, loss_D: 0.177177\n",
      "[Epoch 144/200] [Batch 300/938] loss_G: 3.152319, loss_D: 0.296751\n",
      "[Epoch 144/200] [Batch 310/938] loss_G: 3.057461, loss_D: 0.260813\n",
      "[Epoch 144/200] [Batch 320/938] loss_G: 3.081498, loss_D: 0.225640\n",
      "[Epoch 144/200] [Batch 330/938] loss_G: 2.821214, loss_D: 0.155205\n",
      "[Epoch 144/200] [Batch 340/938] loss_G: 3.382650, loss_D: 0.163059\n",
      "[Epoch 144/200] [Batch 350/938] loss_G: 3.239271, loss_D: 0.212372\n",
      "[Epoch 144/200] [Batch 360/938] loss_G: 3.370825, loss_D: 0.219676\n",
      "[Epoch 144/200] [Batch 370/938] loss_G: 3.329447, loss_D: 0.253928\n",
      "[Epoch 144/200] [Batch 380/938] loss_G: 3.218737, loss_D: 0.274273\n",
      "[Epoch 144/200] [Batch 390/938] loss_G: 3.243095, loss_D: 0.176292\n",
      "[Epoch 144/200] [Batch 400/938] loss_G: 3.361985, loss_D: 0.203562\n",
      "[Epoch 144/200] [Batch 410/938] loss_G: 3.207271, loss_D: 0.287647\n",
      "[Epoch 144/200] [Batch 420/938] loss_G: 3.151606, loss_D: 0.220364\n",
      "[Epoch 144/200] [Batch 430/938] loss_G: 3.559883, loss_D: 0.171945\n",
      "[Epoch 144/200] [Batch 440/938] loss_G: 3.535680, loss_D: 0.197192\n",
      "[Epoch 144/200] [Batch 450/938] loss_G: 3.019197, loss_D: 0.179082\n",
      "[Epoch 144/200] [Batch 460/938] loss_G: 2.936509, loss_D: 0.252803\n",
      "[Epoch 144/200] [Batch 470/938] loss_G: 3.062085, loss_D: 0.239266\n",
      "[Epoch 144/200] [Batch 480/938] loss_G: 3.482371, loss_D: 0.223129\n",
      "[Epoch 144/200] [Batch 490/938] loss_G: 3.198957, loss_D: 0.252869\n",
      "[Epoch 144/200] [Batch 500/938] loss_G: 2.832084, loss_D: 0.202394\n",
      "[Epoch 144/200] [Batch 510/938] loss_G: 3.426835, loss_D: 0.138671\n",
      "[Epoch 144/200] [Batch 520/938] loss_G: 2.971893, loss_D: 0.212894\n",
      "[Epoch 144/200] [Batch 530/938] loss_G: 3.302030, loss_D: 0.244171\n",
      "[Epoch 144/200] [Batch 540/938] loss_G: 3.098515, loss_D: 0.280259\n",
      "[Epoch 144/200] [Batch 550/938] loss_G: 3.232957, loss_D: 0.178102\n",
      "[Epoch 144/200] [Batch 560/938] loss_G: 3.360872, loss_D: 0.145263\n",
      "[Epoch 144/200] [Batch 570/938] loss_G: 3.413704, loss_D: 0.181960\n",
      "[Epoch 144/200] [Batch 580/938] loss_G: 3.279817, loss_D: 0.205545\n",
      "[Epoch 144/200] [Batch 590/938] loss_G: 3.108249, loss_D: 0.264359\n",
      "[Epoch 144/200] [Batch 600/938] loss_G: 3.531121, loss_D: 0.156494\n",
      "[Epoch 144/200] [Batch 610/938] loss_G: 3.072393, loss_D: 0.235298\n",
      "[Epoch 144/200] [Batch 620/938] loss_G: 3.275845, loss_D: 0.283196\n",
      "[Epoch 144/200] [Batch 630/938] loss_G: 3.026409, loss_D: 0.224087\n",
      "[Epoch 144/200] [Batch 640/938] loss_G: 3.058584, loss_D: 0.118765\n",
      "[Epoch 144/200] [Batch 650/938] loss_G: 3.117522, loss_D: 0.129350\n",
      "[Epoch 144/200] [Batch 660/938] loss_G: 3.278425, loss_D: 0.158520\n",
      "[Epoch 144/200] [Batch 670/938] loss_G: 3.391479, loss_D: 0.131471\n",
      "[Epoch 144/200] [Batch 680/938] loss_G: 3.016430, loss_D: 0.161581\n",
      "[Epoch 144/200] [Batch 690/938] loss_G: 3.530496, loss_D: 0.267124\n",
      "[Epoch 144/200] [Batch 700/938] loss_G: 3.215969, loss_D: 0.172282\n",
      "[Epoch 144/200] [Batch 710/938] loss_G: 3.205734, loss_D: 0.204605\n",
      "[Epoch 144/200] [Batch 720/938] loss_G: 3.218402, loss_D: 0.211484\n",
      "[Epoch 144/200] [Batch 730/938] loss_G: 3.338453, loss_D: 0.198314\n",
      "[Epoch 144/200] [Batch 740/938] loss_G: 3.165954, loss_D: 0.205430\n",
      "[Epoch 144/200] [Batch 750/938] loss_G: 3.180370, loss_D: 0.157817\n",
      "[Epoch 144/200] [Batch 760/938] loss_G: 3.561646, loss_D: 0.184053\n",
      "[Epoch 144/200] [Batch 770/938] loss_G: 2.896368, loss_D: 0.239387\n",
      "[Epoch 144/200] [Batch 780/938] loss_G: 3.179344, loss_D: 0.201982\n",
      "[Epoch 144/200] [Batch 790/938] loss_G: 2.703967, loss_D: 0.228658\n",
      "[Epoch 144/200] [Batch 800/938] loss_G: 2.938738, loss_D: 0.290623\n",
      "[Epoch 144/200] [Batch 810/938] loss_G: 3.090693, loss_D: 0.158351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 144/200] [Batch 820/938] loss_G: 3.474535, loss_D: 0.190589\n",
      "[Epoch 144/200] [Batch 830/938] loss_G: 3.423313, loss_D: 0.154922\n",
      "[Epoch 144/200] [Batch 840/938] loss_G: 3.615049, loss_D: 0.149986\n",
      "[Epoch 144/200] [Batch 850/938] loss_G: 3.458585, loss_D: 0.152306\n",
      "[Epoch 144/200] [Batch 860/938] loss_G: 2.986506, loss_D: 0.199279\n",
      "[Epoch 144/200] [Batch 870/938] loss_G: 3.566112, loss_D: 0.203509\n",
      "[Epoch 144/200] [Batch 880/938] loss_G: 2.873665, loss_D: 0.310880\n",
      "[Epoch 144/200] [Batch 890/938] loss_G: 2.690983, loss_D: 0.180921\n",
      "[Epoch 144/200] [Batch 900/938] loss_G: 3.690256, loss_D: 0.251947\n",
      "[Epoch 144/200] [Batch 910/938] loss_G: 2.998394, loss_D: 0.142447\n",
      "[Epoch 144/200] [Batch 920/938] loss_G: 3.581375, loss_D: 0.128133\n",
      "[Epoch 144/200] [Batch 930/938] loss_G: 2.819240, loss_D: 0.199271\n",
      "[Epoch 145/200] [Batch 0/938] loss_G: 2.912381, loss_D: 0.206874\n",
      "[Epoch 145/200] [Batch 10/938] loss_G: 3.206901, loss_D: 0.284484\n",
      "[Epoch 145/200] [Batch 20/938] loss_G: 3.443999, loss_D: 0.128502\n",
      "[Epoch 145/200] [Batch 30/938] loss_G: 2.860563, loss_D: 0.233963\n",
      "[Epoch 145/200] [Batch 40/938] loss_G: 3.424741, loss_D: 0.176770\n",
      "[Epoch 145/200] [Batch 50/938] loss_G: 3.215401, loss_D: 0.194677\n",
      "[Epoch 145/200] [Batch 60/938] loss_G: 3.120637, loss_D: 0.207072\n",
      "[Epoch 145/200] [Batch 70/938] loss_G: 3.204965, loss_D: 0.173862\n",
      "[Epoch 145/200] [Batch 80/938] loss_G: 3.273803, loss_D: 0.139627\n",
      "[Epoch 145/200] [Batch 90/938] loss_G: 3.438735, loss_D: 0.144590\n",
      "[Epoch 145/200] [Batch 100/938] loss_G: 3.658556, loss_D: 0.224484\n",
      "[Epoch 145/200] [Batch 110/938] loss_G: 3.071477, loss_D: 0.214711\n",
      "[Epoch 145/200] [Batch 120/938] loss_G: 3.394844, loss_D: 0.160970\n",
      "[Epoch 145/200] [Batch 130/938] loss_G: 3.440678, loss_D: 0.151624\n",
      "[Epoch 145/200] [Batch 140/938] loss_G: 2.987246, loss_D: 0.181769\n",
      "[Epoch 145/200] [Batch 150/938] loss_G: 3.206305, loss_D: 0.194930\n",
      "[Epoch 145/200] [Batch 160/938] loss_G: 3.406393, loss_D: 0.151110\n",
      "[Epoch 145/200] [Batch 170/938] loss_G: 3.219094, loss_D: 0.212535\n",
      "[Epoch 145/200] [Batch 180/938] loss_G: 3.010926, loss_D: 0.287585\n",
      "[Epoch 145/200] [Batch 190/938] loss_G: 3.198707, loss_D: 0.188425\n",
      "[Epoch 145/200] [Batch 200/938] loss_G: 3.250432, loss_D: 0.237016\n",
      "[Epoch 145/200] [Batch 210/938] loss_G: 3.277668, loss_D: 0.157226\n",
      "[Epoch 145/200] [Batch 220/938] loss_G: 3.126744, loss_D: 0.184563\n",
      "[Epoch 145/200] [Batch 230/938] loss_G: 3.308982, loss_D: 0.183846\n",
      "[Epoch 145/200] [Batch 240/938] loss_G: 3.310348, loss_D: 0.269338\n",
      "[Epoch 145/200] [Batch 250/938] loss_G: 3.445250, loss_D: 0.325773\n",
      "[Epoch 145/200] [Batch 260/938] loss_G: 3.601157, loss_D: 0.215075\n",
      "[Epoch 145/200] [Batch 270/938] loss_G: 3.535757, loss_D: 0.142522\n",
      "[Epoch 145/200] [Batch 280/938] loss_G: 3.616886, loss_D: 0.177224\n",
      "[Epoch 145/200] [Batch 290/938] loss_G: 3.154166, loss_D: 0.228560\n",
      "[Epoch 145/200] [Batch 300/938] loss_G: 3.082095, loss_D: 0.175372\n",
      "[Epoch 145/200] [Batch 310/938] loss_G: 3.232644, loss_D: 0.202002\n",
      "[Epoch 145/200] [Batch 320/938] loss_G: 3.203583, loss_D: 0.184571\n",
      "[Epoch 145/200] [Batch 330/938] loss_G: 2.888351, loss_D: 0.214534\n",
      "[Epoch 145/200] [Batch 340/938] loss_G: 3.331933, loss_D: 0.141315\n",
      "[Epoch 145/200] [Batch 350/938] loss_G: 3.274564, loss_D: 0.177249\n",
      "[Epoch 145/200] [Batch 360/938] loss_G: 3.043717, loss_D: 0.141322\n",
      "[Epoch 145/200] [Batch 370/938] loss_G: 3.151957, loss_D: 0.164575\n",
      "[Epoch 145/200] [Batch 380/938] loss_G: 3.257171, loss_D: 0.231291\n",
      "[Epoch 145/200] [Batch 390/938] loss_G: 3.285618, loss_D: 0.208441\n",
      "[Epoch 145/200] [Batch 400/938] loss_G: 3.645040, loss_D: 0.216327\n",
      "[Epoch 145/200] [Batch 410/938] loss_G: 3.347269, loss_D: 0.280602\n",
      "[Epoch 145/200] [Batch 420/938] loss_G: 3.334832, loss_D: 0.178146\n",
      "[Epoch 145/200] [Batch 430/938] loss_G: 3.071541, loss_D: 0.158988\n",
      "[Epoch 145/200] [Batch 440/938] loss_G: 3.186567, loss_D: 0.210772\n",
      "[Epoch 145/200] [Batch 450/938] loss_G: 3.206701, loss_D: 0.122374\n",
      "[Epoch 145/200] [Batch 460/938] loss_G: 3.430635, loss_D: 0.174566\n",
      "[Epoch 145/200] [Batch 470/938] loss_G: 3.557058, loss_D: 0.206103\n",
      "[Epoch 145/200] [Batch 480/938] loss_G: 3.388196, loss_D: 0.217762\n",
      "[Epoch 145/200] [Batch 490/938] loss_G: 3.441737, loss_D: 0.167442\n",
      "[Epoch 145/200] [Batch 500/938] loss_G: 2.944903, loss_D: 0.245551\n",
      "[Epoch 145/200] [Batch 510/938] loss_G: 3.514486, loss_D: 0.323883\n",
      "[Epoch 145/200] [Batch 520/938] loss_G: 3.125281, loss_D: 0.224802\n",
      "[Epoch 145/200] [Batch 530/938] loss_G: 3.299337, loss_D: 0.201381\n",
      "[Epoch 145/200] [Batch 540/938] loss_G: 3.129600, loss_D: 0.133988\n",
      "[Epoch 145/200] [Batch 550/938] loss_G: 3.369225, loss_D: 0.162547\n",
      "[Epoch 145/200] [Batch 560/938] loss_G: 3.228152, loss_D: 0.195723\n",
      "[Epoch 145/200] [Batch 570/938] loss_G: 3.074933, loss_D: 0.168343\n",
      "[Epoch 145/200] [Batch 580/938] loss_G: 3.591180, loss_D: 0.240803\n",
      "[Epoch 145/200] [Batch 590/938] loss_G: 3.579669, loss_D: 0.202900\n",
      "[Epoch 145/200] [Batch 600/938] loss_G: 3.287035, loss_D: 0.123455\n",
      "[Epoch 145/200] [Batch 610/938] loss_G: 2.950587, loss_D: 0.181235\n",
      "[Epoch 145/200] [Batch 620/938] loss_G: 3.366193, loss_D: 0.166513\n",
      "[Epoch 145/200] [Batch 630/938] loss_G: 3.376088, loss_D: 0.200758\n",
      "[Epoch 145/200] [Batch 640/938] loss_G: 3.069922, loss_D: 0.228748\n",
      "[Epoch 145/200] [Batch 650/938] loss_G: 3.218865, loss_D: 0.200491\n",
      "[Epoch 145/200] [Batch 660/938] loss_G: 3.213650, loss_D: 0.158493\n",
      "[Epoch 145/200] [Batch 670/938] loss_G: 3.326405, loss_D: 0.182959\n",
      "[Epoch 145/200] [Batch 680/938] loss_G: 3.271966, loss_D: 0.280465\n",
      "[Epoch 145/200] [Batch 690/938] loss_G: 3.525879, loss_D: 0.149573\n",
      "[Epoch 145/200] [Batch 700/938] loss_G: 3.322437, loss_D: 0.178212\n",
      "[Epoch 145/200] [Batch 710/938] loss_G: 3.074188, loss_D: 0.251603\n",
      "[Epoch 145/200] [Batch 720/938] loss_G: 3.503849, loss_D: 0.179478\n",
      "[Epoch 145/200] [Batch 730/938] loss_G: 2.888769, loss_D: 0.266502\n",
      "[Epoch 145/200] [Batch 740/938] loss_G: 3.338293, loss_D: 0.177438\n",
      "[Epoch 145/200] [Batch 750/938] loss_G: 2.879323, loss_D: 0.229176\n",
      "[Epoch 145/200] [Batch 760/938] loss_G: 3.258177, loss_D: 0.138021\n",
      "[Epoch 145/200] [Batch 770/938] loss_G: 3.013099, loss_D: 0.362463\n",
      "[Epoch 145/200] [Batch 780/938] loss_G: 3.042963, loss_D: 0.140906\n",
      "[Epoch 145/200] [Batch 790/938] loss_G: 3.286624, loss_D: 0.241838\n",
      "[Epoch 145/200] [Batch 800/938] loss_G: 3.267888, loss_D: 0.223423\n",
      "[Epoch 145/200] [Batch 810/938] loss_G: 3.280236, loss_D: 0.200052\n",
      "[Epoch 145/200] [Batch 820/938] loss_G: 3.137041, loss_D: 0.200053\n",
      "[Epoch 145/200] [Batch 830/938] loss_G: 3.205979, loss_D: 0.159625\n",
      "[Epoch 145/200] [Batch 840/938] loss_G: 3.444405, loss_D: 0.134182\n",
      "[Epoch 145/200] [Batch 850/938] loss_G: 3.202355, loss_D: 0.285205\n",
      "[Epoch 145/200] [Batch 860/938] loss_G: 3.293358, loss_D: 0.184043\n",
      "[Epoch 145/200] [Batch 870/938] loss_G: 3.316539, loss_D: 0.167819\n",
      "[Epoch 145/200] [Batch 880/938] loss_G: 3.488423, loss_D: 0.224971\n",
      "[Epoch 145/200] [Batch 890/938] loss_G: 3.509098, loss_D: 0.280007\n",
      "[Epoch 145/200] [Batch 900/938] loss_G: 3.631204, loss_D: 0.148798\n",
      "[Epoch 145/200] [Batch 910/938] loss_G: 3.530309, loss_D: 0.157646\n",
      "[Epoch 145/200] [Batch 920/938] loss_G: 3.367950, loss_D: 0.216801\n",
      "[Epoch 145/200] [Batch 930/938] loss_G: 3.254990, loss_D: 0.172147\n",
      "[Epoch 146/200] [Batch 0/938] loss_G: 3.467378, loss_D: 0.180886\n",
      "[Epoch 146/200] [Batch 10/938] loss_G: 3.208089, loss_D: 0.134720\n",
      "[Epoch 146/200] [Batch 20/938] loss_G: 3.155676, loss_D: 0.113596\n",
      "[Epoch 146/200] [Batch 30/938] loss_G: 3.020060, loss_D: 0.166862\n",
      "[Epoch 146/200] [Batch 40/938] loss_G: 3.643859, loss_D: 0.299828\n",
      "[Epoch 146/200] [Batch 50/938] loss_G: 3.052783, loss_D: 0.211788\n",
      "[Epoch 146/200] [Batch 60/938] loss_G: 3.230273, loss_D: 0.140122\n",
      "[Epoch 146/200] [Batch 70/938] loss_G: 2.776674, loss_D: 0.224083\n",
      "[Epoch 146/200] [Batch 80/938] loss_G: 3.387062, loss_D: 0.233900\n",
      "[Epoch 146/200] [Batch 90/938] loss_G: 3.409818, loss_D: 0.139680\n",
      "[Epoch 146/200] [Batch 100/938] loss_G: 3.091101, loss_D: 0.191009\n",
      "[Epoch 146/200] [Batch 110/938] loss_G: 3.098919, loss_D: 0.329308\n",
      "[Epoch 146/200] [Batch 120/938] loss_G: 3.210603, loss_D: 0.166927\n",
      "[Epoch 146/200] [Batch 130/938] loss_G: 3.461829, loss_D: 0.239520\n",
      "[Epoch 146/200] [Batch 140/938] loss_G: 3.315671, loss_D: 0.244897\n",
      "[Epoch 146/200] [Batch 150/938] loss_G: 2.845128, loss_D: 0.305076\n",
      "[Epoch 146/200] [Batch 160/938] loss_G: 3.030426, loss_D: 0.277804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 146/200] [Batch 170/938] loss_G: 3.307955, loss_D: 0.187075\n",
      "[Epoch 146/200] [Batch 180/938] loss_G: 3.228904, loss_D: 0.183860\n",
      "[Epoch 146/200] [Batch 190/938] loss_G: 3.185931, loss_D: 0.135877\n",
      "[Epoch 146/200] [Batch 200/938] loss_G: 3.058158, loss_D: 0.159119\n",
      "[Epoch 146/200] [Batch 210/938] loss_G: 3.419305, loss_D: 0.177625\n",
      "[Epoch 146/200] [Batch 220/938] loss_G: 3.408309, loss_D: 0.153111\n",
      "[Epoch 146/200] [Batch 230/938] loss_G: 2.857419, loss_D: 0.138367\n",
      "[Epoch 146/200] [Batch 240/938] loss_G: 2.658689, loss_D: 0.285367\n",
      "[Epoch 146/200] [Batch 250/938] loss_G: 3.334211, loss_D: 0.179151\n",
      "[Epoch 146/200] [Batch 260/938] loss_G: 3.024951, loss_D: 0.279575\n",
      "[Epoch 146/200] [Batch 270/938] loss_G: 3.393626, loss_D: 0.167075\n",
      "[Epoch 146/200] [Batch 280/938] loss_G: 3.083938, loss_D: 0.172544\n",
      "[Epoch 146/200] [Batch 290/938] loss_G: 3.096907, loss_D: 0.202068\n",
      "[Epoch 146/200] [Batch 300/938] loss_G: 3.411157, loss_D: 0.195606\n",
      "[Epoch 146/200] [Batch 310/938] loss_G: 3.219110, loss_D: 0.165837\n",
      "[Epoch 146/200] [Batch 320/938] loss_G: 3.233634, loss_D: 0.210084\n",
      "[Epoch 146/200] [Batch 330/938] loss_G: 3.315912, loss_D: 0.217755\n",
      "[Epoch 146/200] [Batch 340/938] loss_G: 3.079484, loss_D: 0.216738\n",
      "[Epoch 146/200] [Batch 350/938] loss_G: 3.220952, loss_D: 0.183395\n",
      "[Epoch 146/200] [Batch 360/938] loss_G: 3.101495, loss_D: 0.157618\n",
      "[Epoch 146/200] [Batch 370/938] loss_G: 2.968125, loss_D: 0.178449\n",
      "[Epoch 146/200] [Batch 380/938] loss_G: 3.259560, loss_D: 0.179961\n",
      "[Epoch 146/200] [Batch 390/938] loss_G: 2.888619, loss_D: 0.119758\n",
      "[Epoch 146/200] [Batch 400/938] loss_G: 3.349033, loss_D: 0.269576\n",
      "[Epoch 146/200] [Batch 410/938] loss_G: 3.315310, loss_D: 0.145020\n",
      "[Epoch 146/200] [Batch 420/938] loss_G: 3.296755, loss_D: 0.163438\n",
      "[Epoch 146/200] [Batch 430/938] loss_G: 3.525374, loss_D: 0.089248\n",
      "[Epoch 146/200] [Batch 440/938] loss_G: 3.325626, loss_D: 0.203683\n",
      "[Epoch 146/200] [Batch 450/938] loss_G: 3.351731, loss_D: 0.223882\n",
      "[Epoch 146/200] [Batch 460/938] loss_G: 3.215510, loss_D: 0.150860\n",
      "[Epoch 146/200] [Batch 470/938] loss_G: 3.606158, loss_D: 0.234536\n",
      "[Epoch 146/200] [Batch 480/938] loss_G: 2.977150, loss_D: 0.168848\n",
      "[Epoch 146/200] [Batch 490/938] loss_G: 3.561256, loss_D: 0.163559\n",
      "[Epoch 146/200] [Batch 500/938] loss_G: 3.154113, loss_D: 0.153077\n",
      "[Epoch 146/200] [Batch 510/938] loss_G: 3.459349, loss_D: 0.140382\n",
      "[Epoch 146/200] [Batch 520/938] loss_G: 3.071688, loss_D: 0.191841\n",
      "[Epoch 146/200] [Batch 530/938] loss_G: 3.151260, loss_D: 0.191319\n",
      "[Epoch 146/200] [Batch 540/938] loss_G: 3.063348, loss_D: 0.273098\n",
      "[Epoch 146/200] [Batch 550/938] loss_G: 3.441237, loss_D: 0.122530\n",
      "[Epoch 146/200] [Batch 560/938] loss_G: 3.374267, loss_D: 0.197633\n",
      "[Epoch 146/200] [Batch 570/938] loss_G: 3.466084, loss_D: 0.116938\n",
      "[Epoch 146/200] [Batch 580/938] loss_G: 3.652960, loss_D: 0.188441\n",
      "[Epoch 146/200] [Batch 590/938] loss_G: 3.100020, loss_D: 0.189753\n",
      "[Epoch 146/200] [Batch 600/938] loss_G: 3.231224, loss_D: 0.166661\n",
      "[Epoch 146/200] [Batch 610/938] loss_G: 2.858782, loss_D: 0.174622\n",
      "[Epoch 146/200] [Batch 620/938] loss_G: 2.995239, loss_D: 0.181868\n",
      "[Epoch 146/200] [Batch 630/938] loss_G: 3.627252, loss_D: 0.230915\n",
      "[Epoch 146/200] [Batch 640/938] loss_G: 3.559325, loss_D: 0.198002\n",
      "[Epoch 146/200] [Batch 650/938] loss_G: 3.408421, loss_D: 0.192124\n",
      "[Epoch 146/200] [Batch 660/938] loss_G: 3.490934, loss_D: 0.219718\n",
      "[Epoch 146/200] [Batch 670/938] loss_G: 3.426382, loss_D: 0.215293\n",
      "[Epoch 146/200] [Batch 680/938] loss_G: 3.628485, loss_D: 0.211577\n",
      "[Epoch 146/200] [Batch 690/938] loss_G: 3.327282, loss_D: 0.153935\n",
      "[Epoch 146/200] [Batch 700/938] loss_G: 3.631948, loss_D: 0.126811\n",
      "[Epoch 146/200] [Batch 710/938] loss_G: 3.220985, loss_D: 0.205920\n",
      "[Epoch 146/200] [Batch 720/938] loss_G: 3.341579, loss_D: 0.172558\n",
      "[Epoch 146/200] [Batch 730/938] loss_G: 3.128870, loss_D: 0.213884\n",
      "[Epoch 146/200] [Batch 740/938] loss_G: 3.630297, loss_D: 0.228892\n",
      "[Epoch 146/200] [Batch 750/938] loss_G: 3.450616, loss_D: 0.174135\n",
      "[Epoch 146/200] [Batch 760/938] loss_G: 3.384002, loss_D: 0.201894\n",
      "[Epoch 146/200] [Batch 770/938] loss_G: 3.371931, loss_D: 0.154605\n",
      "[Epoch 146/200] [Batch 780/938] loss_G: 3.009749, loss_D: 0.144244\n",
      "[Epoch 146/200] [Batch 790/938] loss_G: 3.316177, loss_D: 0.266638\n",
      "[Epoch 146/200] [Batch 800/938] loss_G: 3.316906, loss_D: 0.230955\n",
      "[Epoch 146/200] [Batch 810/938] loss_G: 3.565567, loss_D: 0.156381\n",
      "[Epoch 146/200] [Batch 820/938] loss_G: 3.148764, loss_D: 0.188118\n",
      "[Epoch 146/200] [Batch 830/938] loss_G: 3.439924, loss_D: 0.205869\n",
      "[Epoch 146/200] [Batch 840/938] loss_G: 3.501444, loss_D: 0.172172\n",
      "[Epoch 146/200] [Batch 850/938] loss_G: 2.917746, loss_D: 0.292073\n",
      "[Epoch 146/200] [Batch 860/938] loss_G: 3.394691, loss_D: 0.146508\n",
      "[Epoch 146/200] [Batch 870/938] loss_G: 3.756783, loss_D: 0.165116\n",
      "[Epoch 146/200] [Batch 880/938] loss_G: 3.084950, loss_D: 0.214309\n",
      "[Epoch 146/200] [Batch 890/938] loss_G: 3.288242, loss_D: 0.183794\n",
      "[Epoch 146/200] [Batch 900/938] loss_G: 3.344476, loss_D: 0.260460\n",
      "[Epoch 146/200] [Batch 910/938] loss_G: 2.819400, loss_D: 0.193911\n",
      "[Epoch 146/200] [Batch 920/938] loss_G: 3.568970, loss_D: 0.191052\n",
      "[Epoch 146/200] [Batch 930/938] loss_G: 3.853926, loss_D: 0.139226\n",
      "[Epoch 147/200] [Batch 0/938] loss_G: 3.375111, loss_D: 0.149141\n",
      "[Epoch 147/200] [Batch 10/938] loss_G: 3.286137, loss_D: 0.144105\n",
      "[Epoch 147/200] [Batch 20/938] loss_G: 3.263391, loss_D: 0.176396\n",
      "[Epoch 147/200] [Batch 30/938] loss_G: 3.432525, loss_D: 0.243116\n",
      "[Epoch 147/200] [Batch 40/938] loss_G: 3.086665, loss_D: 0.227860\n",
      "[Epoch 147/200] [Batch 50/938] loss_G: 3.189356, loss_D: 0.220385\n",
      "[Epoch 147/200] [Batch 60/938] loss_G: 3.423089, loss_D: 0.147562\n",
      "[Epoch 147/200] [Batch 70/938] loss_G: 3.290602, loss_D: 0.175451\n",
      "[Epoch 147/200] [Batch 80/938] loss_G: 3.171108, loss_D: 0.153514\n",
      "[Epoch 147/200] [Batch 90/938] loss_G: 3.495694, loss_D: 0.128827\n",
      "[Epoch 147/200] [Batch 100/938] loss_G: 3.165277, loss_D: 0.245366\n",
      "[Epoch 147/200] [Batch 110/938] loss_G: 3.081214, loss_D: 0.194446\n",
      "[Epoch 147/200] [Batch 120/938] loss_G: 3.416297, loss_D: 0.177136\n",
      "[Epoch 147/200] [Batch 130/938] loss_G: 3.445004, loss_D: 0.188536\n",
      "[Epoch 147/200] [Batch 140/938] loss_G: 2.900017, loss_D: 0.263394\n",
      "[Epoch 147/200] [Batch 150/938] loss_G: 3.197751, loss_D: 0.204098\n",
      "[Epoch 147/200] [Batch 160/938] loss_G: 3.366907, loss_D: 0.158317\n",
      "[Epoch 147/200] [Batch 170/938] loss_G: 3.083870, loss_D: 0.127106\n",
      "[Epoch 147/200] [Batch 180/938] loss_G: 3.239902, loss_D: 0.160198\n",
      "[Epoch 147/200] [Batch 190/938] loss_G: 3.839989, loss_D: 0.228552\n",
      "[Epoch 147/200] [Batch 200/938] loss_G: 3.542490, loss_D: 0.205802\n",
      "[Epoch 147/200] [Batch 210/938] loss_G: 3.279041, loss_D: 0.213309\n",
      "[Epoch 147/200] [Batch 220/938] loss_G: 3.509170, loss_D: 0.148580\n",
      "[Epoch 147/200] [Batch 230/938] loss_G: 3.015783, loss_D: 0.263967\n",
      "[Epoch 147/200] [Batch 240/938] loss_G: 3.106981, loss_D: 0.255644\n",
      "[Epoch 147/200] [Batch 250/938] loss_G: 2.819076, loss_D: 0.157935\n",
      "[Epoch 147/200] [Batch 260/938] loss_G: 2.755311, loss_D: 0.228938\n",
      "[Epoch 147/200] [Batch 270/938] loss_G: 3.350909, loss_D: 0.197633\n",
      "[Epoch 147/200] [Batch 280/938] loss_G: 3.210498, loss_D: 0.180165\n",
      "[Epoch 147/200] [Batch 290/938] loss_G: 3.373609, loss_D: 0.199687\n",
      "[Epoch 147/200] [Batch 300/938] loss_G: 3.877840, loss_D: 0.171769\n",
      "[Epoch 147/200] [Batch 310/938] loss_G: 3.076471, loss_D: 0.229311\n",
      "[Epoch 147/200] [Batch 320/938] loss_G: 3.519502, loss_D: 0.191676\n",
      "[Epoch 147/200] [Batch 330/938] loss_G: 3.006528, loss_D: 0.191049\n",
      "[Epoch 147/200] [Batch 340/938] loss_G: 3.266664, loss_D: 0.171651\n",
      "[Epoch 147/200] [Batch 350/938] loss_G: 3.055756, loss_D: 0.186856\n",
      "[Epoch 147/200] [Batch 360/938] loss_G: 3.478966, loss_D: 0.190255\n",
      "[Epoch 147/200] [Batch 370/938] loss_G: 3.434930, loss_D: 0.145625\n",
      "[Epoch 147/200] [Batch 380/938] loss_G: 3.345233, loss_D: 0.218933\n",
      "[Epoch 147/200] [Batch 390/938] loss_G: 3.093586, loss_D: 0.249395\n",
      "[Epoch 147/200] [Batch 400/938] loss_G: 3.766016, loss_D: 0.170864\n",
      "[Epoch 147/200] [Batch 410/938] loss_G: 3.277975, loss_D: 0.099844\n",
      "[Epoch 147/200] [Batch 420/938] loss_G: 3.182807, loss_D: 0.207372\n",
      "[Epoch 147/200] [Batch 430/938] loss_G: 3.265101, loss_D: 0.210992\n",
      "[Epoch 147/200] [Batch 440/938] loss_G: 3.239496, loss_D: 0.258980\n",
      "[Epoch 147/200] [Batch 450/938] loss_G: 3.329123, loss_D: 0.210176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 147/200] [Batch 460/938] loss_G: 3.569699, loss_D: 0.140778\n",
      "[Epoch 147/200] [Batch 470/938] loss_G: 3.159849, loss_D: 0.201544\n",
      "[Epoch 147/200] [Batch 480/938] loss_G: 3.286731, loss_D: 0.247380\n",
      "[Epoch 147/200] [Batch 490/938] loss_G: 3.360007, loss_D: 0.243242\n",
      "[Epoch 147/200] [Batch 500/938] loss_G: 3.392672, loss_D: 0.214748\n",
      "[Epoch 147/200] [Batch 510/938] loss_G: 3.493433, loss_D: 0.184793\n",
      "[Epoch 147/200] [Batch 520/938] loss_G: 3.598098, loss_D: 0.100541\n",
      "[Epoch 147/200] [Batch 530/938] loss_G: 3.399350, loss_D: 0.193093\n",
      "[Epoch 147/200] [Batch 540/938] loss_G: 3.463321, loss_D: 0.138315\n",
      "[Epoch 147/200] [Batch 550/938] loss_G: 3.262938, loss_D: 0.234495\n",
      "[Epoch 147/200] [Batch 560/938] loss_G: 3.415271, loss_D: 0.198568\n",
      "[Epoch 147/200] [Batch 570/938] loss_G: 3.271799, loss_D: 0.172198\n",
      "[Epoch 147/200] [Batch 580/938] loss_G: 3.870839, loss_D: 0.168008\n",
      "[Epoch 147/200] [Batch 590/938] loss_G: 3.245065, loss_D: 0.153045\n",
      "[Epoch 147/200] [Batch 600/938] loss_G: 2.933750, loss_D: 0.280628\n",
      "[Epoch 147/200] [Batch 610/938] loss_G: 3.209609, loss_D: 0.129665\n",
      "[Epoch 147/200] [Batch 620/938] loss_G: 3.325592, loss_D: 0.175409\n",
      "[Epoch 147/200] [Batch 630/938] loss_G: 3.083056, loss_D: 0.209291\n",
      "[Epoch 147/200] [Batch 640/938] loss_G: 3.394924, loss_D: 0.224376\n",
      "[Epoch 147/200] [Batch 650/938] loss_G: 3.753900, loss_D: 0.141783\n",
      "[Epoch 147/200] [Batch 660/938] loss_G: 3.147727, loss_D: 0.227426\n",
      "[Epoch 147/200] [Batch 670/938] loss_G: 3.220541, loss_D: 0.137165\n",
      "[Epoch 147/200] [Batch 680/938] loss_G: 3.166761, loss_D: 0.191478\n",
      "[Epoch 147/200] [Batch 690/938] loss_G: 3.361050, loss_D: 0.144054\n",
      "[Epoch 147/200] [Batch 700/938] loss_G: 3.274295, loss_D: 0.148961\n",
      "[Epoch 147/200] [Batch 710/938] loss_G: 3.090535, loss_D: 0.248302\n",
      "[Epoch 147/200] [Batch 720/938] loss_G: 3.172657, loss_D: 0.206461\n",
      "[Epoch 147/200] [Batch 730/938] loss_G: 3.419630, loss_D: 0.203178\n",
      "[Epoch 147/200] [Batch 740/938] loss_G: 2.783887, loss_D: 0.200068\n",
      "[Epoch 147/200] [Batch 750/938] loss_G: 3.139219, loss_D: 0.220857\n",
      "[Epoch 147/200] [Batch 760/938] loss_G: 3.180146, loss_D: 0.217913\n",
      "[Epoch 147/200] [Batch 770/938] loss_G: 3.304768, loss_D: 0.217895\n",
      "[Epoch 147/200] [Batch 780/938] loss_G: 3.128315, loss_D: 0.208516\n",
      "[Epoch 147/200] [Batch 790/938] loss_G: 3.033527, loss_D: 0.152420\n",
      "[Epoch 147/200] [Batch 800/938] loss_G: 3.285401, loss_D: 0.167108\n",
      "[Epoch 147/200] [Batch 810/938] loss_G: 3.536223, loss_D: 0.154886\n",
      "[Epoch 147/200] [Batch 820/938] loss_G: 2.810565, loss_D: 0.245752\n",
      "[Epoch 147/200] [Batch 830/938] loss_G: 2.922997, loss_D: 0.260742\n",
      "[Epoch 147/200] [Batch 840/938] loss_G: 3.362611, loss_D: 0.163175\n",
      "[Epoch 147/200] [Batch 850/938] loss_G: 3.568449, loss_D: 0.125407\n",
      "[Epoch 147/200] [Batch 860/938] loss_G: 3.090368, loss_D: 0.150496\n",
      "[Epoch 147/200] [Batch 870/938] loss_G: 3.372308, loss_D: 0.205546\n",
      "[Epoch 147/200] [Batch 880/938] loss_G: 3.394038, loss_D: 0.247005\n",
      "[Epoch 147/200] [Batch 890/938] loss_G: 3.048585, loss_D: 0.157685\n",
      "[Epoch 147/200] [Batch 900/938] loss_G: 3.121696, loss_D: 0.256805\n",
      "[Epoch 147/200] [Batch 910/938] loss_G: 3.386312, loss_D: 0.244336\n",
      "[Epoch 147/200] [Batch 920/938] loss_G: 3.277974, loss_D: 0.236778\n",
      "[Epoch 147/200] [Batch 930/938] loss_G: 3.314830, loss_D: 0.242694\n",
      "[Epoch 148/200] [Batch 0/938] loss_G: 3.120565, loss_D: 0.143176\n",
      "[Epoch 148/200] [Batch 10/938] loss_G: 2.954226, loss_D: 0.216772\n",
      "[Epoch 148/200] [Batch 20/938] loss_G: 3.392457, loss_D: 0.200499\n",
      "[Epoch 148/200] [Batch 30/938] loss_G: 2.989914, loss_D: 0.152510\n",
      "[Epoch 148/200] [Batch 40/938] loss_G: 3.575305, loss_D: 0.206915\n",
      "[Epoch 148/200] [Batch 50/938] loss_G: 3.174695, loss_D: 0.331622\n",
      "[Epoch 148/200] [Batch 60/938] loss_G: 3.034842, loss_D: 0.184806\n",
      "[Epoch 148/200] [Batch 70/938] loss_G: 3.208757, loss_D: 0.211890\n",
      "[Epoch 148/200] [Batch 80/938] loss_G: 3.265448, loss_D: 0.166901\n",
      "[Epoch 148/200] [Batch 90/938] loss_G: 3.078191, loss_D: 0.242807\n",
      "[Epoch 148/200] [Batch 100/938] loss_G: 3.061345, loss_D: 0.218825\n",
      "[Epoch 148/200] [Batch 110/938] loss_G: 3.431507, loss_D: 0.172464\n",
      "[Epoch 148/200] [Batch 120/938] loss_G: 3.041807, loss_D: 0.327450\n",
      "[Epoch 148/200] [Batch 130/938] loss_G: 3.108552, loss_D: 0.120468\n",
      "[Epoch 148/200] [Batch 140/938] loss_G: 3.445754, loss_D: 0.159206\n",
      "[Epoch 148/200] [Batch 150/938] loss_G: 3.539189, loss_D: 0.219858\n",
      "[Epoch 148/200] [Batch 160/938] loss_G: 3.222281, loss_D: 0.235367\n",
      "[Epoch 148/200] [Batch 170/938] loss_G: 3.322982, loss_D: 0.239222\n",
      "[Epoch 148/200] [Batch 180/938] loss_G: 3.496660, loss_D: 0.191229\n",
      "[Epoch 148/200] [Batch 190/938] loss_G: 3.354382, loss_D: 0.262203\n",
      "[Epoch 148/200] [Batch 200/938] loss_G: 3.091236, loss_D: 0.169181\n",
      "[Epoch 148/200] [Batch 210/938] loss_G: 3.404314, loss_D: 0.241331\n",
      "[Epoch 148/200] [Batch 220/938] loss_G: 3.339903, loss_D: 0.177289\n",
      "[Epoch 148/200] [Batch 230/938] loss_G: 3.622321, loss_D: 0.153268\n",
      "[Epoch 148/200] [Batch 240/938] loss_G: 3.244419, loss_D: 0.195293\n",
      "[Epoch 148/200] [Batch 250/938] loss_G: 3.672490, loss_D: 0.165307\n",
      "[Epoch 148/200] [Batch 260/938] loss_G: 3.161504, loss_D: 0.203865\n",
      "[Epoch 148/200] [Batch 270/938] loss_G: 3.034051, loss_D: 0.172928\n",
      "[Epoch 148/200] [Batch 280/938] loss_G: 3.715550, loss_D: 0.331313\n",
      "[Epoch 148/200] [Batch 290/938] loss_G: 3.428226, loss_D: 0.215202\n",
      "[Epoch 148/200] [Batch 300/938] loss_G: 3.273170, loss_D: 0.213239\n",
      "[Epoch 148/200] [Batch 310/938] loss_G: 3.432602, loss_D: 0.273676\n",
      "[Epoch 148/200] [Batch 320/938] loss_G: 3.074602, loss_D: 0.155901\n",
      "[Epoch 148/200] [Batch 330/938] loss_G: 2.999393, loss_D: 0.149187\n",
      "[Epoch 148/200] [Batch 340/938] loss_G: 3.272723, loss_D: 0.105531\n",
      "[Epoch 148/200] [Batch 350/938] loss_G: 3.210187, loss_D: 0.240511\n",
      "[Epoch 148/200] [Batch 360/938] loss_G: 2.961021, loss_D: 0.169953\n",
      "[Epoch 148/200] [Batch 370/938] loss_G: 3.394801, loss_D: 0.208321\n",
      "[Epoch 148/200] [Batch 380/938] loss_G: 3.025691, loss_D: 0.189150\n",
      "[Epoch 148/200] [Batch 390/938] loss_G: 2.943738, loss_D: 0.178106\n",
      "[Epoch 148/200] [Batch 400/938] loss_G: 3.459434, loss_D: 0.243162\n",
      "[Epoch 148/200] [Batch 410/938] loss_G: 3.630185, loss_D: 0.160377\n",
      "[Epoch 148/200] [Batch 420/938] loss_G: 3.352052, loss_D: 0.212662\n",
      "[Epoch 148/200] [Batch 430/938] loss_G: 3.216249, loss_D: 0.183648\n",
      "[Epoch 148/200] [Batch 440/938] loss_G: 3.378436, loss_D: 0.183082\n",
      "[Epoch 148/200] [Batch 450/938] loss_G: 2.852199, loss_D: 0.254638\n",
      "[Epoch 148/200] [Batch 460/938] loss_G: 3.106071, loss_D: 0.208375\n",
      "[Epoch 148/200] [Batch 470/938] loss_G: 3.389048, loss_D: 0.145687\n",
      "[Epoch 148/200] [Batch 480/938] loss_G: 3.668379, loss_D: 0.153959\n",
      "[Epoch 148/200] [Batch 490/938] loss_G: 3.338472, loss_D: 0.191983\n",
      "[Epoch 148/200] [Batch 500/938] loss_G: 3.209422, loss_D: 0.247213\n",
      "[Epoch 148/200] [Batch 510/938] loss_G: 3.579918, loss_D: 0.157247\n",
      "[Epoch 148/200] [Batch 520/938] loss_G: 3.090413, loss_D: 0.192809\n",
      "[Epoch 148/200] [Batch 530/938] loss_G: 3.610715, loss_D: 0.115573\n",
      "[Epoch 148/200] [Batch 540/938] loss_G: 2.789476, loss_D: 0.201988\n",
      "[Epoch 148/200] [Batch 550/938] loss_G: 2.939854, loss_D: 0.177633\n",
      "[Epoch 148/200] [Batch 560/938] loss_G: 3.236299, loss_D: 0.244345\n",
      "[Epoch 148/200] [Batch 570/938] loss_G: 2.885464, loss_D: 0.182798\n",
      "[Epoch 148/200] [Batch 580/938] loss_G: 3.358550, loss_D: 0.196772\n",
      "[Epoch 148/200] [Batch 590/938] loss_G: 3.203017, loss_D: 0.145959\n",
      "[Epoch 148/200] [Batch 600/938] loss_G: 3.316589, loss_D: 0.179412\n",
      "[Epoch 148/200] [Batch 610/938] loss_G: 3.246295, loss_D: 0.175411\n",
      "[Epoch 148/200] [Batch 620/938] loss_G: 2.815401, loss_D: 0.221627\n",
      "[Epoch 148/200] [Batch 630/938] loss_G: 3.424072, loss_D: 0.190512\n",
      "[Epoch 148/200] [Batch 640/938] loss_G: 3.451279, loss_D: 0.179166\n",
      "[Epoch 148/200] [Batch 650/938] loss_G: 3.247370, loss_D: 0.180048\n",
      "[Epoch 148/200] [Batch 660/938] loss_G: 2.674089, loss_D: 0.279307\n",
      "[Epoch 148/200] [Batch 670/938] loss_G: 3.189085, loss_D: 0.223243\n",
      "[Epoch 148/200] [Batch 680/938] loss_G: 3.056667, loss_D: 0.186983\n",
      "[Epoch 148/200] [Batch 690/938] loss_G: 3.080374, loss_D: 0.178271\n",
      "[Epoch 148/200] [Batch 700/938] loss_G: 3.358305, loss_D: 0.198833\n",
      "[Epoch 148/200] [Batch 710/938] loss_G: 3.524027, loss_D: 0.192646\n",
      "[Epoch 148/200] [Batch 720/938] loss_G: 3.527283, loss_D: 0.215968\n",
      "[Epoch 148/200] [Batch 730/938] loss_G: 3.232665, loss_D: 0.180564\n",
      "[Epoch 148/200] [Batch 740/938] loss_G: 2.961726, loss_D: 0.244355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 148/200] [Batch 750/938] loss_G: 3.615944, loss_D: 0.110821\n",
      "[Epoch 148/200] [Batch 760/938] loss_G: 3.307097, loss_D: 0.211782\n",
      "[Epoch 148/200] [Batch 770/938] loss_G: 3.075247, loss_D: 0.265620\n",
      "[Epoch 148/200] [Batch 780/938] loss_G: 3.174213, loss_D: 0.182096\n",
      "[Epoch 148/200] [Batch 790/938] loss_G: 2.802660, loss_D: 0.241276\n",
      "[Epoch 148/200] [Batch 800/938] loss_G: 2.479004, loss_D: 0.231510\n",
      "[Epoch 148/200] [Batch 810/938] loss_G: 3.921988, loss_D: 0.232741\n",
      "[Epoch 148/200] [Batch 820/938] loss_G: 3.064399, loss_D: 0.157869\n",
      "[Epoch 148/200] [Batch 830/938] loss_G: 3.397548, loss_D: 0.141189\n",
      "[Epoch 148/200] [Batch 840/938] loss_G: 3.368903, loss_D: 0.197900\n",
      "[Epoch 148/200] [Batch 850/938] loss_G: 3.294746, loss_D: 0.209509\n",
      "[Epoch 148/200] [Batch 860/938] loss_G: 3.465546, loss_D: 0.268342\n",
      "[Epoch 148/200] [Batch 870/938] loss_G: 3.481864, loss_D: 0.161057\n",
      "[Epoch 148/200] [Batch 880/938] loss_G: 3.107202, loss_D: 0.171008\n",
      "[Epoch 148/200] [Batch 890/938] loss_G: 3.385302, loss_D: 0.185698\n",
      "[Epoch 148/200] [Batch 900/938] loss_G: 3.666862, loss_D: 0.194330\n",
      "[Epoch 148/200] [Batch 910/938] loss_G: 3.124385, loss_D: 0.204966\n",
      "[Epoch 148/200] [Batch 920/938] loss_G: 3.197441, loss_D: 0.184871\n",
      "[Epoch 148/200] [Batch 930/938] loss_G: 3.552385, loss_D: 0.174950\n",
      "[Epoch 149/200] [Batch 0/938] loss_G: 3.393306, loss_D: 0.166688\n",
      "[Epoch 149/200] [Batch 10/938] loss_G: 2.919177, loss_D: 0.271402\n",
      "[Epoch 149/200] [Batch 20/938] loss_G: 3.776520, loss_D: 0.157872\n",
      "[Epoch 149/200] [Batch 30/938] loss_G: 3.260715, loss_D: 0.220799\n",
      "[Epoch 149/200] [Batch 40/938] loss_G: 3.561742, loss_D: 0.238523\n",
      "[Epoch 149/200] [Batch 50/938] loss_G: 3.015316, loss_D: 0.148269\n",
      "[Epoch 149/200] [Batch 60/938] loss_G: 3.212085, loss_D: 0.174206\n",
      "[Epoch 149/200] [Batch 70/938] loss_G: 3.345036, loss_D: 0.210859\n",
      "[Epoch 149/200] [Batch 80/938] loss_G: 3.182896, loss_D: 0.319272\n",
      "[Epoch 149/200] [Batch 90/938] loss_G: 3.152648, loss_D: 0.142033\n",
      "[Epoch 149/200] [Batch 100/938] loss_G: 3.326586, loss_D: 0.178088\n",
      "[Epoch 149/200] [Batch 110/938] loss_G: 3.299294, loss_D: 0.231313\n",
      "[Epoch 149/200] [Batch 120/938] loss_G: 3.385687, loss_D: 0.220169\n",
      "[Epoch 149/200] [Batch 130/938] loss_G: 3.166366, loss_D: 0.289958\n",
      "[Epoch 149/200] [Batch 140/938] loss_G: 3.031546, loss_D: 0.248596\n",
      "[Epoch 149/200] [Batch 150/938] loss_G: 3.518475, loss_D: 0.194636\n",
      "[Epoch 149/200] [Batch 160/938] loss_G: 3.258694, loss_D: 0.252875\n",
      "[Epoch 149/200] [Batch 170/938] loss_G: 3.375740, loss_D: 0.241295\n",
      "[Epoch 149/200] [Batch 180/938] loss_G: 3.670514, loss_D: 0.195747\n",
      "[Epoch 149/200] [Batch 190/938] loss_G: 2.993216, loss_D: 0.181984\n",
      "[Epoch 149/200] [Batch 200/938] loss_G: 3.827597, loss_D: 0.154920\n",
      "[Epoch 149/200] [Batch 210/938] loss_G: 2.986283, loss_D: 0.145113\n",
      "[Epoch 149/200] [Batch 220/938] loss_G: 3.408481, loss_D: 0.165496\n",
      "[Epoch 149/200] [Batch 230/938] loss_G: 3.758264, loss_D: 0.144882\n",
      "[Epoch 149/200] [Batch 240/938] loss_G: 3.088031, loss_D: 0.184396\n",
      "[Epoch 149/200] [Batch 250/938] loss_G: 3.179956, loss_D: 0.167546\n",
      "[Epoch 149/200] [Batch 260/938] loss_G: 3.270864, loss_D: 0.259619\n",
      "[Epoch 149/200] [Batch 270/938] loss_G: 3.032463, loss_D: 0.161742\n",
      "[Epoch 149/200] [Batch 280/938] loss_G: 3.305769, loss_D: 0.185708\n",
      "[Epoch 149/200] [Batch 290/938] loss_G: 2.992417, loss_D: 0.280338\n",
      "[Epoch 149/200] [Batch 300/938] loss_G: 2.960650, loss_D: 0.178811\n",
      "[Epoch 149/200] [Batch 310/938] loss_G: 3.387277, loss_D: 0.208424\n",
      "[Epoch 149/200] [Batch 320/938] loss_G: 3.335678, loss_D: 0.210614\n",
      "[Epoch 149/200] [Batch 330/938] loss_G: 3.138786, loss_D: 0.149405\n",
      "[Epoch 149/200] [Batch 340/938] loss_G: 3.198988, loss_D: 0.184479\n",
      "[Epoch 149/200] [Batch 350/938] loss_G: 3.346872, loss_D: 0.268380\n",
      "[Epoch 149/200] [Batch 360/938] loss_G: 3.195238, loss_D: 0.180131\n",
      "[Epoch 149/200] [Batch 370/938] loss_G: 3.162597, loss_D: 0.146747\n",
      "[Epoch 149/200] [Batch 380/938] loss_G: 3.130856, loss_D: 0.186698\n",
      "[Epoch 149/200] [Batch 390/938] loss_G: 3.601406, loss_D: 0.160676\n",
      "[Epoch 149/200] [Batch 400/938] loss_G: 3.441454, loss_D: 0.247561\n",
      "[Epoch 149/200] [Batch 410/938] loss_G: 2.901522, loss_D: 0.165677\n",
      "[Epoch 149/200] [Batch 420/938] loss_G: 3.141752, loss_D: 0.187308\n",
      "[Epoch 149/200] [Batch 430/938] loss_G: 3.588995, loss_D: 0.163008\n",
      "[Epoch 149/200] [Batch 440/938] loss_G: 3.497643, loss_D: 0.120403\n",
      "[Epoch 149/200] [Batch 450/938] loss_G: 3.354264, loss_D: 0.232151\n",
      "[Epoch 149/200] [Batch 460/938] loss_G: 3.351335, loss_D: 0.157512\n",
      "[Epoch 149/200] [Batch 470/938] loss_G: 3.468234, loss_D: 0.204387\n",
      "[Epoch 149/200] [Batch 480/938] loss_G: 3.197727, loss_D: 0.227261\n",
      "[Epoch 149/200] [Batch 490/938] loss_G: 3.153386, loss_D: 0.244739\n",
      "[Epoch 149/200] [Batch 500/938] loss_G: 3.426402, loss_D: 0.184555\n",
      "[Epoch 149/200] [Batch 510/938] loss_G: 3.100586, loss_D: 0.233601\n",
      "[Epoch 149/200] [Batch 520/938] loss_G: 3.343938, loss_D: 0.144661\n",
      "[Epoch 149/200] [Batch 530/938] loss_G: 2.894238, loss_D: 0.183836\n",
      "[Epoch 149/200] [Batch 540/938] loss_G: 3.275690, loss_D: 0.194224\n",
      "[Epoch 149/200] [Batch 550/938] loss_G: 3.459713, loss_D: 0.158924\n",
      "[Epoch 149/200] [Batch 560/938] loss_G: 3.257286, loss_D: 0.148101\n",
      "[Epoch 149/200] [Batch 570/938] loss_G: 3.299162, loss_D: 0.185229\n",
      "[Epoch 149/200] [Batch 580/938] loss_G: 3.190602, loss_D: 0.195596\n",
      "[Epoch 149/200] [Batch 590/938] loss_G: 3.170268, loss_D: 0.162707\n",
      "[Epoch 149/200] [Batch 600/938] loss_G: 3.104229, loss_D: 0.242615\n",
      "[Epoch 149/200] [Batch 610/938] loss_G: 3.040663, loss_D: 0.182676\n",
      "[Epoch 149/200] [Batch 620/938] loss_G: 3.210836, loss_D: 0.200364\n",
      "[Epoch 149/200] [Batch 630/938] loss_G: 3.746638, loss_D: 0.132148\n",
      "[Epoch 149/200] [Batch 640/938] loss_G: 2.791246, loss_D: 0.175654\n",
      "[Epoch 149/200] [Batch 650/938] loss_G: 3.247002, loss_D: 0.218677\n",
      "[Epoch 149/200] [Batch 660/938] loss_G: 3.740852, loss_D: 0.134477\n",
      "[Epoch 149/200] [Batch 670/938] loss_G: 3.079833, loss_D: 0.286776\n",
      "[Epoch 149/200] [Batch 680/938] loss_G: 3.611368, loss_D: 0.198094\n",
      "[Epoch 149/200] [Batch 690/938] loss_G: 3.066283, loss_D: 0.156334\n",
      "[Epoch 149/200] [Batch 700/938] loss_G: 3.150406, loss_D: 0.185761\n",
      "[Epoch 149/200] [Batch 710/938] loss_G: 3.254456, loss_D: 0.229755\n",
      "[Epoch 149/200] [Batch 720/938] loss_G: 3.381146, loss_D: 0.246891\n",
      "[Epoch 149/200] [Batch 730/938] loss_G: 3.441465, loss_D: 0.164990\n",
      "[Epoch 149/200] [Batch 740/938] loss_G: 3.103668, loss_D: 0.185357\n",
      "[Epoch 149/200] [Batch 750/938] loss_G: 3.635516, loss_D: 0.257404\n",
      "[Epoch 149/200] [Batch 760/938] loss_G: 3.326926, loss_D: 0.155594\n",
      "[Epoch 149/200] [Batch 770/938] loss_G: 3.402442, loss_D: 0.188701\n",
      "[Epoch 149/200] [Batch 780/938] loss_G: 3.422479, loss_D: 0.181707\n",
      "[Epoch 149/200] [Batch 790/938] loss_G: 3.042445, loss_D: 0.171665\n",
      "[Epoch 149/200] [Batch 800/938] loss_G: 3.285630, loss_D: 0.197507\n",
      "[Epoch 149/200] [Batch 810/938] loss_G: 3.742517, loss_D: 0.167419\n",
      "[Epoch 149/200] [Batch 820/938] loss_G: 3.242505, loss_D: 0.179882\n",
      "[Epoch 149/200] [Batch 830/938] loss_G: 3.092407, loss_D: 0.214467\n",
      "[Epoch 149/200] [Batch 840/938] loss_G: 3.179027, loss_D: 0.237889\n",
      "[Epoch 149/200] [Batch 850/938] loss_G: 3.160871, loss_D: 0.242076\n",
      "[Epoch 149/200] [Batch 860/938] loss_G: 3.111443, loss_D: 0.314048\n",
      "[Epoch 149/200] [Batch 870/938] loss_G: 2.879986, loss_D: 0.169386\n",
      "[Epoch 149/200] [Batch 880/938] loss_G: 3.041127, loss_D: 0.149945\n",
      "[Epoch 149/200] [Batch 890/938] loss_G: 3.648741, loss_D: 0.146139\n",
      "[Epoch 149/200] [Batch 900/938] loss_G: 3.205531, loss_D: 0.205781\n",
      "[Epoch 149/200] [Batch 910/938] loss_G: 3.042508, loss_D: 0.273526\n",
      "[Epoch 149/200] [Batch 920/938] loss_G: 3.170904, loss_D: 0.188240\n",
      "[Epoch 149/200] [Batch 930/938] loss_G: 3.262243, loss_D: 0.177075\n",
      "[Epoch 150/200] [Batch 0/938] loss_G: 3.052602, loss_D: 0.243557\n",
      "[Epoch 150/200] [Batch 10/938] loss_G: 3.195706, loss_D: 0.203803\n",
      "[Epoch 150/200] [Batch 20/938] loss_G: 3.062922, loss_D: 0.279773\n",
      "[Epoch 150/200] [Batch 30/938] loss_G: 3.316451, loss_D: 0.205613\n",
      "[Epoch 150/200] [Batch 40/938] loss_G: 3.309732, loss_D: 0.228415\n",
      "[Epoch 150/200] [Batch 50/938] loss_G: 3.526656, loss_D: 0.197653\n",
      "[Epoch 150/200] [Batch 60/938] loss_G: 3.295504, loss_D: 0.167704\n",
      "[Epoch 150/200] [Batch 70/938] loss_G: 3.276296, loss_D: 0.237534\n",
      "[Epoch 150/200] [Batch 80/938] loss_G: 3.298434, loss_D: 0.164380\n",
      "[Epoch 150/200] [Batch 90/938] loss_G: 3.206808, loss_D: 0.164594\n",
      "[Epoch 150/200] [Batch 100/938] loss_G: 3.178257, loss_D: 0.159968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 150/200] [Batch 110/938] loss_G: 3.164742, loss_D: 0.188675\n",
      "[Epoch 150/200] [Batch 120/938] loss_G: 2.887241, loss_D: 0.181009\n",
      "[Epoch 150/200] [Batch 130/938] loss_G: 3.546631, loss_D: 0.189085\n",
      "[Epoch 150/200] [Batch 140/938] loss_G: 3.247756, loss_D: 0.159236\n",
      "[Epoch 150/200] [Batch 150/938] loss_G: 3.069894, loss_D: 0.187001\n",
      "[Epoch 150/200] [Batch 160/938] loss_G: 3.196628, loss_D: 0.161675\n",
      "[Epoch 150/200] [Batch 170/938] loss_G: 3.010950, loss_D: 0.188897\n",
      "[Epoch 150/200] [Batch 180/938] loss_G: 3.565197, loss_D: 0.193189\n",
      "[Epoch 150/200] [Batch 190/938] loss_G: 3.024933, loss_D: 0.206529\n",
      "[Epoch 150/200] [Batch 200/938] loss_G: 3.355879, loss_D: 0.165656\n",
      "[Epoch 150/200] [Batch 210/938] loss_G: 3.396036, loss_D: 0.141389\n",
      "[Epoch 150/200] [Batch 220/938] loss_G: 2.956901, loss_D: 0.155183\n",
      "[Epoch 150/200] [Batch 230/938] loss_G: 3.398771, loss_D: 0.106066\n",
      "[Epoch 150/200] [Batch 240/938] loss_G: 3.284241, loss_D: 0.187372\n",
      "[Epoch 150/200] [Batch 250/938] loss_G: 3.418420, loss_D: 0.251089\n",
      "[Epoch 150/200] [Batch 260/938] loss_G: 3.493521, loss_D: 0.167203\n",
      "[Epoch 150/200] [Batch 270/938] loss_G: 3.256040, loss_D: 0.172665\n",
      "[Epoch 150/200] [Batch 280/938] loss_G: 3.255159, loss_D: 0.178709\n",
      "[Epoch 150/200] [Batch 290/938] loss_G: 3.093825, loss_D: 0.325768\n",
      "[Epoch 150/200] [Batch 300/938] loss_G: 3.509541, loss_D: 0.253292\n",
      "[Epoch 150/200] [Batch 310/938] loss_G: 3.140993, loss_D: 0.223057\n",
      "[Epoch 150/200] [Batch 320/938] loss_G: 3.275321, loss_D: 0.215465\n",
      "[Epoch 150/200] [Batch 330/938] loss_G: 2.989059, loss_D: 0.127341\n",
      "[Epoch 150/200] [Batch 340/938] loss_G: 3.413673, loss_D: 0.158245\n",
      "[Epoch 150/200] [Batch 350/938] loss_G: 3.180770, loss_D: 0.265207\n",
      "[Epoch 150/200] [Batch 360/938] loss_G: 3.343767, loss_D: 0.184074\n",
      "[Epoch 150/200] [Batch 370/938] loss_G: 3.254507, loss_D: 0.222118\n",
      "[Epoch 150/200] [Batch 380/938] loss_G: 3.572384, loss_D: 0.249087\n",
      "[Epoch 150/200] [Batch 390/938] loss_G: 3.151666, loss_D: 0.162526\n",
      "[Epoch 150/200] [Batch 400/938] loss_G: 3.347971, loss_D: 0.184805\n",
      "[Epoch 150/200] [Batch 410/938] loss_G: 3.092381, loss_D: 0.147150\n",
      "[Epoch 150/200] [Batch 420/938] loss_G: 3.385202, loss_D: 0.160967\n",
      "[Epoch 150/200] [Batch 430/938] loss_G: 3.380276, loss_D: 0.217089\n",
      "[Epoch 150/200] [Batch 440/938] loss_G: 3.159541, loss_D: 0.237002\n",
      "[Epoch 150/200] [Batch 450/938] loss_G: 3.145997, loss_D: 0.203986\n",
      "[Epoch 150/200] [Batch 460/938] loss_G: 3.232350, loss_D: 0.146336\n",
      "[Epoch 150/200] [Batch 470/938] loss_G: 3.287803, loss_D: 0.185195\n",
      "[Epoch 150/200] [Batch 480/938] loss_G: 3.309428, loss_D: 0.247995\n",
      "[Epoch 150/200] [Batch 490/938] loss_G: 3.223208, loss_D: 0.247665\n",
      "[Epoch 150/200] [Batch 500/938] loss_G: 3.078913, loss_D: 0.198992\n",
      "[Epoch 150/200] [Batch 510/938] loss_G: 2.942463, loss_D: 0.268421\n",
      "[Epoch 150/200] [Batch 520/938] loss_G: 3.307798, loss_D: 0.174234\n",
      "[Epoch 150/200] [Batch 530/938] loss_G: 3.162967, loss_D: 0.135701\n",
      "[Epoch 150/200] [Batch 540/938] loss_G: 2.906061, loss_D: 0.203519\n",
      "[Epoch 150/200] [Batch 550/938] loss_G: 3.537870, loss_D: 0.368539\n",
      "[Epoch 150/200] [Batch 560/938] loss_G: 3.510962, loss_D: 0.143825\n",
      "[Epoch 150/200] [Batch 570/938] loss_G: 3.449218, loss_D: 0.203815\n",
      "[Epoch 150/200] [Batch 580/938] loss_G: 3.916195, loss_D: 0.183938\n",
      "[Epoch 150/200] [Batch 590/938] loss_G: 3.131913, loss_D: 0.151451\n",
      "[Epoch 150/200] [Batch 600/938] loss_G: 3.102215, loss_D: 0.181063\n",
      "[Epoch 150/200] [Batch 610/938] loss_G: 3.268805, loss_D: 0.240197\n",
      "[Epoch 150/200] [Batch 620/938] loss_G: 3.157275, loss_D: 0.247582\n",
      "[Epoch 150/200] [Batch 630/938] loss_G: 3.036458, loss_D: 0.223309\n",
      "[Epoch 150/200] [Batch 640/938] loss_G: 3.336297, loss_D: 0.213223\n",
      "[Epoch 150/200] [Batch 650/938] loss_G: 2.977369, loss_D: 0.208878\n",
      "[Epoch 150/200] [Batch 660/938] loss_G: 3.183411, loss_D: 0.145909\n",
      "[Epoch 150/200] [Batch 670/938] loss_G: 3.757354, loss_D: 0.170264\n",
      "[Epoch 150/200] [Batch 680/938] loss_G: 3.066330, loss_D: 0.218579\n",
      "[Epoch 150/200] [Batch 690/938] loss_G: 2.800227, loss_D: 0.203562\n",
      "[Epoch 150/200] [Batch 700/938] loss_G: 3.385748, loss_D: 0.144013\n",
      "[Epoch 150/200] [Batch 710/938] loss_G: 3.245296, loss_D: 0.258978\n",
      "[Epoch 150/200] [Batch 720/938] loss_G: 3.032390, loss_D: 0.141982\n",
      "[Epoch 150/200] [Batch 730/938] loss_G: 2.916671, loss_D: 0.166938\n",
      "[Epoch 150/200] [Batch 740/938] loss_G: 3.231013, loss_D: 0.189870\n",
      "[Epoch 150/200] [Batch 750/938] loss_G: 3.121167, loss_D: 0.183867\n",
      "[Epoch 150/200] [Batch 760/938] loss_G: 3.084818, loss_D: 0.198611\n",
      "[Epoch 150/200] [Batch 770/938] loss_G: 3.580858, loss_D: 0.177163\n",
      "[Epoch 150/200] [Batch 780/938] loss_G: 3.094483, loss_D: 0.201713\n",
      "[Epoch 150/200] [Batch 790/938] loss_G: 3.004278, loss_D: 0.187310\n",
      "[Epoch 150/200] [Batch 800/938] loss_G: 3.375973, loss_D: 0.116359\n",
      "[Epoch 150/200] [Batch 810/938] loss_G: 3.054801, loss_D: 0.210423\n",
      "[Epoch 150/200] [Batch 820/938] loss_G: 3.227137, loss_D: 0.185723\n",
      "[Epoch 150/200] [Batch 830/938] loss_G: 3.273569, loss_D: 0.172608\n",
      "[Epoch 150/200] [Batch 840/938] loss_G: 3.375636, loss_D: 0.281659\n",
      "[Epoch 150/200] [Batch 850/938] loss_G: 3.465198, loss_D: 0.181610\n",
      "[Epoch 150/200] [Batch 860/938] loss_G: 3.406512, loss_D: 0.150717\n",
      "[Epoch 150/200] [Batch 870/938] loss_G: 3.571565, loss_D: 0.176581\n",
      "[Epoch 150/200] [Batch 880/938] loss_G: 2.951958, loss_D: 0.186572\n",
      "[Epoch 150/200] [Batch 890/938] loss_G: 3.163812, loss_D: 0.154606\n",
      "[Epoch 150/200] [Batch 900/938] loss_G: 2.993150, loss_D: 0.131422\n",
      "[Epoch 150/200] [Batch 910/938] loss_G: 3.022293, loss_D: 0.181430\n",
      "[Epoch 150/200] [Batch 920/938] loss_G: 3.390183, loss_D: 0.164241\n",
      "[Epoch 150/200] [Batch 930/938] loss_G: 3.450701, loss_D: 0.125750\n",
      "[Epoch 151/200] [Batch 0/938] loss_G: 3.250650, loss_D: 0.257958\n",
      "[Epoch 151/200] [Batch 10/938] loss_G: 3.229692, loss_D: 0.171585\n",
      "[Epoch 151/200] [Batch 20/938] loss_G: 3.140195, loss_D: 0.262650\n",
      "[Epoch 151/200] [Batch 30/938] loss_G: 3.545037, loss_D: 0.124314\n",
      "[Epoch 151/200] [Batch 40/938] loss_G: 3.350926, loss_D: 0.208230\n",
      "[Epoch 151/200] [Batch 50/938] loss_G: 3.412298, loss_D: 0.240415\n",
      "[Epoch 151/200] [Batch 60/938] loss_G: 3.475252, loss_D: 0.147645\n",
      "[Epoch 151/200] [Batch 70/938] loss_G: 3.066552, loss_D: 0.207071\n",
      "[Epoch 151/200] [Batch 80/938] loss_G: 3.245001, loss_D: 0.270357\n",
      "[Epoch 151/200] [Batch 90/938] loss_G: 2.914989, loss_D: 0.220260\n",
      "[Epoch 151/200] [Batch 100/938] loss_G: 2.935531, loss_D: 0.202861\n",
      "[Epoch 151/200] [Batch 110/938] loss_G: 3.033864, loss_D: 0.259153\n",
      "[Epoch 151/200] [Batch 120/938] loss_G: 3.160907, loss_D: 0.250270\n",
      "[Epoch 151/200] [Batch 130/938] loss_G: 3.055059, loss_D: 0.118491\n",
      "[Epoch 151/200] [Batch 140/938] loss_G: 3.605254, loss_D: 0.166867\n",
      "[Epoch 151/200] [Batch 150/938] loss_G: 2.595038, loss_D: 0.201195\n",
      "[Epoch 151/200] [Batch 160/938] loss_G: 3.140725, loss_D: 0.272457\n",
      "[Epoch 151/200] [Batch 170/938] loss_G: 3.654070, loss_D: 0.196175\n",
      "[Epoch 151/200] [Batch 180/938] loss_G: 2.745811, loss_D: 0.232390\n",
      "[Epoch 151/200] [Batch 190/938] loss_G: 3.465541, loss_D: 0.204316\n",
      "[Epoch 151/200] [Batch 200/938] loss_G: 3.067374, loss_D: 0.103640\n",
      "[Epoch 151/200] [Batch 210/938] loss_G: 3.387613, loss_D: 0.248699\n",
      "[Epoch 151/200] [Batch 220/938] loss_G: 2.878533, loss_D: 0.257662\n",
      "[Epoch 151/200] [Batch 230/938] loss_G: 3.173949, loss_D: 0.166571\n",
      "[Epoch 151/200] [Batch 240/938] loss_G: 3.454433, loss_D: 0.224594\n",
      "[Epoch 151/200] [Batch 250/938] loss_G: 3.383996, loss_D: 0.176263\n",
      "[Epoch 151/200] [Batch 260/938] loss_G: 3.448766, loss_D: 0.162023\n",
      "[Epoch 151/200] [Batch 270/938] loss_G: 2.645854, loss_D: 0.214435\n",
      "[Epoch 151/200] [Batch 280/938] loss_G: 3.147144, loss_D: 0.198864\n",
      "[Epoch 151/200] [Batch 290/938] loss_G: 2.727474, loss_D: 0.165902\n",
      "[Epoch 151/200] [Batch 300/938] loss_G: 3.171741, loss_D: 0.215298\n",
      "[Epoch 151/200] [Batch 310/938] loss_G: 3.467969, loss_D: 0.174558\n",
      "[Epoch 151/200] [Batch 320/938] loss_G: 2.963233, loss_D: 0.170835\n",
      "[Epoch 151/200] [Batch 330/938] loss_G: 3.300699, loss_D: 0.190984\n",
      "[Epoch 151/200] [Batch 340/938] loss_G: 3.287057, loss_D: 0.218109\n",
      "[Epoch 151/200] [Batch 350/938] loss_G: 3.355822, loss_D: 0.168242\n",
      "[Epoch 151/200] [Batch 360/938] loss_G: 3.522385, loss_D: 0.125812\n",
      "[Epoch 151/200] [Batch 370/938] loss_G: 3.595067, loss_D: 0.185368\n",
      "[Epoch 151/200] [Batch 380/938] loss_G: 3.408194, loss_D: 0.197282\n",
      "[Epoch 151/200] [Batch 390/938] loss_G: 3.591576, loss_D: 0.197128\n",
      "[Epoch 151/200] [Batch 400/938] loss_G: 3.109496, loss_D: 0.224551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 151/200] [Batch 410/938] loss_G: 2.790872, loss_D: 0.255540\n",
      "[Epoch 151/200] [Batch 420/938] loss_G: 3.165999, loss_D: 0.111207\n",
      "[Epoch 151/200] [Batch 430/938] loss_G: 3.331071, loss_D: 0.211903\n",
      "[Epoch 151/200] [Batch 440/938] loss_G: 3.416433, loss_D: 0.228750\n",
      "[Epoch 151/200] [Batch 450/938] loss_G: 3.480546, loss_D: 0.217228\n",
      "[Epoch 151/200] [Batch 460/938] loss_G: 2.968280, loss_D: 0.163702\n",
      "[Epoch 151/200] [Batch 470/938] loss_G: 3.064372, loss_D: 0.132229\n",
      "[Epoch 151/200] [Batch 480/938] loss_G: 3.351685, loss_D: 0.184060\n",
      "[Epoch 151/200] [Batch 490/938] loss_G: 3.081749, loss_D: 0.116678\n",
      "[Epoch 151/200] [Batch 500/938] loss_G: 3.624506, loss_D: 0.204197\n",
      "[Epoch 151/200] [Batch 510/938] loss_G: 3.075504, loss_D: 0.198010\n",
      "[Epoch 151/200] [Batch 520/938] loss_G: 2.814407, loss_D: 0.209892\n",
      "[Epoch 151/200] [Batch 530/938] loss_G: 3.420705, loss_D: 0.187582\n",
      "[Epoch 151/200] [Batch 540/938] loss_G: 3.398415, loss_D: 0.120720\n",
      "[Epoch 151/200] [Batch 550/938] loss_G: 3.440968, loss_D: 0.187848\n",
      "[Epoch 151/200] [Batch 560/938] loss_G: 3.184307, loss_D: 0.271220\n",
      "[Epoch 151/200] [Batch 570/938] loss_G: 3.370121, loss_D: 0.188771\n",
      "[Epoch 151/200] [Batch 580/938] loss_G: 2.927416, loss_D: 0.120153\n",
      "[Epoch 151/200] [Batch 590/938] loss_G: 3.234057, loss_D: 0.229606\n",
      "[Epoch 151/200] [Batch 600/938] loss_G: 3.163890, loss_D: 0.187711\n",
      "[Epoch 151/200] [Batch 610/938] loss_G: 2.845895, loss_D: 0.141217\n",
      "[Epoch 151/200] [Batch 620/938] loss_G: 3.501689, loss_D: 0.161524\n",
      "[Epoch 151/200] [Batch 630/938] loss_G: 3.050135, loss_D: 0.151800\n",
      "[Epoch 151/200] [Batch 640/938] loss_G: 3.106291, loss_D: 0.206718\n",
      "[Epoch 151/200] [Batch 650/938] loss_G: 3.570450, loss_D: 0.200581\n",
      "[Epoch 151/200] [Batch 660/938] loss_G: 3.393576, loss_D: 0.171225\n",
      "[Epoch 151/200] [Batch 670/938] loss_G: 2.600667, loss_D: 0.199752\n",
      "[Epoch 151/200] [Batch 680/938] loss_G: 3.363995, loss_D: 0.187502\n",
      "[Epoch 151/200] [Batch 690/938] loss_G: 3.194610, loss_D: 0.211942\n",
      "[Epoch 151/200] [Batch 700/938] loss_G: 3.453162, loss_D: 0.242369\n",
      "[Epoch 151/200] [Batch 710/938] loss_G: 3.248076, loss_D: 0.105638\n",
      "[Epoch 151/200] [Batch 720/938] loss_G: 2.979305, loss_D: 0.124499\n",
      "[Epoch 151/200] [Batch 730/938] loss_G: 3.090430, loss_D: 0.172410\n",
      "[Epoch 151/200] [Batch 740/938] loss_G: 2.958905, loss_D: 0.191155\n",
      "[Epoch 151/200] [Batch 750/938] loss_G: 3.376633, loss_D: 0.231039\n",
      "[Epoch 151/200] [Batch 760/938] loss_G: 3.096178, loss_D: 0.161916\n",
      "[Epoch 151/200] [Batch 770/938] loss_G: 3.093215, loss_D: 0.255076\n",
      "[Epoch 151/200] [Batch 780/938] loss_G: 3.168163, loss_D: 0.167018\n",
      "[Epoch 151/200] [Batch 790/938] loss_G: 3.060830, loss_D: 0.242231\n",
      "[Epoch 151/200] [Batch 800/938] loss_G: 3.677083, loss_D: 0.143990\n",
      "[Epoch 151/200] [Batch 810/938] loss_G: 3.198669, loss_D: 0.285599\n",
      "[Epoch 151/200] [Batch 820/938] loss_G: 3.496499, loss_D: 0.189797\n",
      "[Epoch 151/200] [Batch 830/938] loss_G: 3.452079, loss_D: 0.278189\n",
      "[Epoch 151/200] [Batch 840/938] loss_G: 3.823226, loss_D: 0.191909\n",
      "[Epoch 151/200] [Batch 850/938] loss_G: 3.420316, loss_D: 0.174979\n",
      "[Epoch 151/200] [Batch 860/938] loss_G: 3.394861, loss_D: 0.126026\n",
      "[Epoch 151/200] [Batch 870/938] loss_G: 3.492729, loss_D: 0.164828\n",
      "[Epoch 151/200] [Batch 880/938] loss_G: 3.436077, loss_D: 0.182141\n",
      "[Epoch 151/200] [Batch 890/938] loss_G: 3.474233, loss_D: 0.187262\n",
      "[Epoch 151/200] [Batch 900/938] loss_G: 3.196930, loss_D: 0.185671\n",
      "[Epoch 151/200] [Batch 910/938] loss_G: 3.268206, loss_D: 0.306321\n",
      "[Epoch 151/200] [Batch 920/938] loss_G: 3.437503, loss_D: 0.192768\n",
      "[Epoch 151/200] [Batch 930/938] loss_G: 3.460963, loss_D: 0.193270\n",
      "[Epoch 152/200] [Batch 0/938] loss_G: 3.096353, loss_D: 0.251756\n",
      "[Epoch 152/200] [Batch 10/938] loss_G: 3.071109, loss_D: 0.194136\n",
      "[Epoch 152/200] [Batch 20/938] loss_G: 3.590904, loss_D: 0.205323\n",
      "[Epoch 152/200] [Batch 30/938] loss_G: 3.396438, loss_D: 0.141746\n",
      "[Epoch 152/200] [Batch 40/938] loss_G: 3.523310, loss_D: 0.207625\n",
      "[Epoch 152/200] [Batch 50/938] loss_G: 3.077673, loss_D: 0.210165\n",
      "[Epoch 152/200] [Batch 60/938] loss_G: 3.396365, loss_D: 0.125435\n",
      "[Epoch 152/200] [Batch 70/938] loss_G: 3.463191, loss_D: 0.234931\n",
      "[Epoch 152/200] [Batch 80/938] loss_G: 3.193461, loss_D: 0.211789\n",
      "[Epoch 152/200] [Batch 90/938] loss_G: 3.194619, loss_D: 0.162100\n",
      "[Epoch 152/200] [Batch 100/938] loss_G: 3.380555, loss_D: 0.130206\n",
      "[Epoch 152/200] [Batch 110/938] loss_G: 3.206184, loss_D: 0.186359\n",
      "[Epoch 152/200] [Batch 120/938] loss_G: 3.069576, loss_D: 0.185552\n",
      "[Epoch 152/200] [Batch 130/938] loss_G: 3.224704, loss_D: 0.212554\n",
      "[Epoch 152/200] [Batch 140/938] loss_G: 3.307208, loss_D: 0.242204\n",
      "[Epoch 152/200] [Batch 150/938] loss_G: 3.379344, loss_D: 0.127197\n",
      "[Epoch 152/200] [Batch 160/938] loss_G: 3.486818, loss_D: 0.179589\n",
      "[Epoch 152/200] [Batch 170/938] loss_G: 3.432352, loss_D: 0.166020\n",
      "[Epoch 152/200] [Batch 180/938] loss_G: 2.910163, loss_D: 0.333726\n",
      "[Epoch 152/200] [Batch 190/938] loss_G: 3.180377, loss_D: 0.316746\n",
      "[Epoch 152/200] [Batch 200/938] loss_G: 3.261756, loss_D: 0.210591\n",
      "[Epoch 152/200] [Batch 210/938] loss_G: 3.262356, loss_D: 0.179626\n",
      "[Epoch 152/200] [Batch 220/938] loss_G: 3.147336, loss_D: 0.148651\n",
      "[Epoch 152/200] [Batch 230/938] loss_G: 3.004655, loss_D: 0.195203\n",
      "[Epoch 152/200] [Batch 240/938] loss_G: 3.118402, loss_D: 0.129380\n",
      "[Epoch 152/200] [Batch 250/938] loss_G: 3.000725, loss_D: 0.212332\n",
      "[Epoch 152/200] [Batch 260/938] loss_G: 3.736616, loss_D: 0.153126\n",
      "[Epoch 152/200] [Batch 270/938] loss_G: 2.987348, loss_D: 0.149792\n",
      "[Epoch 152/200] [Batch 280/938] loss_G: 3.152272, loss_D: 0.175547\n",
      "[Epoch 152/200] [Batch 290/938] loss_G: 3.238696, loss_D: 0.168916\n",
      "[Epoch 152/200] [Batch 300/938] loss_G: 3.475174, loss_D: 0.232442\n",
      "[Epoch 152/200] [Batch 310/938] loss_G: 2.834627, loss_D: 0.293021\n",
      "[Epoch 152/200] [Batch 320/938] loss_G: 3.554272, loss_D: 0.226049\n",
      "[Epoch 152/200] [Batch 330/938] loss_G: 3.049047, loss_D: 0.328444\n",
      "[Epoch 152/200] [Batch 340/938] loss_G: 3.220300, loss_D: 0.298527\n",
      "[Epoch 152/200] [Batch 350/938] loss_G: 3.563704, loss_D: 0.195312\n",
      "[Epoch 152/200] [Batch 360/938] loss_G: 3.157274, loss_D: 0.228039\n",
      "[Epoch 152/200] [Batch 370/938] loss_G: 3.264777, loss_D: 0.178889\n",
      "[Epoch 152/200] [Batch 380/938] loss_G: 3.473581, loss_D: 0.234314\n",
      "[Epoch 152/200] [Batch 390/938] loss_G: 3.178546, loss_D: 0.231330\n",
      "[Epoch 152/200] [Batch 400/938] loss_G: 3.554037, loss_D: 0.195024\n",
      "[Epoch 152/200] [Batch 410/938] loss_G: 3.018815, loss_D: 0.206698\n",
      "[Epoch 152/200] [Batch 420/938] loss_G: 3.406322, loss_D: 0.216215\n",
      "[Epoch 152/200] [Batch 430/938] loss_G: 3.233241, loss_D: 0.167916\n",
      "[Epoch 152/200] [Batch 440/938] loss_G: 3.375357, loss_D: 0.226297\n",
      "[Epoch 152/200] [Batch 450/938] loss_G: 3.446091, loss_D: 0.308658\n",
      "[Epoch 152/200] [Batch 460/938] loss_G: 3.320991, loss_D: 0.412673\n",
      "[Epoch 152/200] [Batch 470/938] loss_G: 3.383410, loss_D: 0.191517\n",
      "[Epoch 152/200] [Batch 480/938] loss_G: 3.151193, loss_D: 0.275318\n",
      "[Epoch 152/200] [Batch 490/938] loss_G: 3.159338, loss_D: 0.213629\n",
      "[Epoch 152/200] [Batch 500/938] loss_G: 3.402643, loss_D: 0.237956\n",
      "[Epoch 152/200] [Batch 510/938] loss_G: 2.880927, loss_D: 0.209658\n",
      "[Epoch 152/200] [Batch 520/938] loss_G: 3.100971, loss_D: 0.183568\n",
      "[Epoch 152/200] [Batch 530/938] loss_G: 3.343383, loss_D: 0.219065\n",
      "[Epoch 152/200] [Batch 540/938] loss_G: 3.387699, loss_D: 0.125213\n",
      "[Epoch 152/200] [Batch 550/938] loss_G: 3.001506, loss_D: 0.194293\n",
      "[Epoch 152/200] [Batch 560/938] loss_G: 3.302933, loss_D: 0.219814\n",
      "[Epoch 152/200] [Batch 570/938] loss_G: 3.192448, loss_D: 0.221257\n",
      "[Epoch 152/200] [Batch 580/938] loss_G: 3.021009, loss_D: 0.287954\n",
      "[Epoch 152/200] [Batch 590/938] loss_G: 2.991809, loss_D: 0.195453\n",
      "[Epoch 152/200] [Batch 600/938] loss_G: 3.374071, loss_D: 0.189766\n",
      "[Epoch 152/200] [Batch 610/938] loss_G: 3.398934, loss_D: 0.200172\n",
      "[Epoch 152/200] [Batch 620/938] loss_G: 3.332564, loss_D: 0.163575\n",
      "[Epoch 152/200] [Batch 630/938] loss_G: 3.173637, loss_D: 0.214383\n",
      "[Epoch 152/200] [Batch 640/938] loss_G: 3.304574, loss_D: 0.218658\n",
      "[Epoch 152/200] [Batch 650/938] loss_G: 3.327685, loss_D: 0.178510\n",
      "[Epoch 152/200] [Batch 660/938] loss_G: 3.966288, loss_D: 0.157000\n",
      "[Epoch 152/200] [Batch 670/938] loss_G: 3.128935, loss_D: 0.208595\n",
      "[Epoch 152/200] [Batch 680/938] loss_G: 2.751259, loss_D: 0.320726\n",
      "[Epoch 152/200] [Batch 690/938] loss_G: 3.219155, loss_D: 0.198140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 152/200] [Batch 700/938] loss_G: 3.142956, loss_D: 0.237162\n",
      "[Epoch 152/200] [Batch 710/938] loss_G: 2.830324, loss_D: 0.231269\n",
      "[Epoch 152/200] [Batch 720/938] loss_G: 3.079512, loss_D: 0.235456\n",
      "[Epoch 152/200] [Batch 730/938] loss_G: 3.467331, loss_D: 0.184805\n",
      "[Epoch 152/200] [Batch 740/938] loss_G: 3.314079, loss_D: 0.166803\n",
      "[Epoch 152/200] [Batch 750/938] loss_G: 3.104172, loss_D: 0.173188\n",
      "[Epoch 152/200] [Batch 760/938] loss_G: 3.261822, loss_D: 0.140933\n",
      "[Epoch 152/200] [Batch 770/938] loss_G: 3.248907, loss_D: 0.104333\n",
      "[Epoch 152/200] [Batch 780/938] loss_G: 3.149548, loss_D: 0.209398\n",
      "[Epoch 152/200] [Batch 790/938] loss_G: 3.482063, loss_D: 0.220239\n",
      "[Epoch 152/200] [Batch 800/938] loss_G: 3.202119, loss_D: 0.134032\n",
      "[Epoch 152/200] [Batch 810/938] loss_G: 3.318294, loss_D: 0.115684\n",
      "[Epoch 152/200] [Batch 820/938] loss_G: 3.041950, loss_D: 0.235879\n",
      "[Epoch 152/200] [Batch 830/938] loss_G: 3.250667, loss_D: 0.181143\n",
      "[Epoch 152/200] [Batch 840/938] loss_G: 2.943208, loss_D: 0.210238\n",
      "[Epoch 152/200] [Batch 850/938] loss_G: 3.372637, loss_D: 0.213266\n",
      "[Epoch 152/200] [Batch 860/938] loss_G: 3.442154, loss_D: 0.214042\n",
      "[Epoch 152/200] [Batch 870/938] loss_G: 3.022989, loss_D: 0.163251\n",
      "[Epoch 152/200] [Batch 880/938] loss_G: 3.307273, loss_D: 0.186147\n",
      "[Epoch 152/200] [Batch 890/938] loss_G: 3.235773, loss_D: 0.141665\n",
      "[Epoch 152/200] [Batch 900/938] loss_G: 2.788206, loss_D: 0.227183\n",
      "[Epoch 152/200] [Batch 910/938] loss_G: 3.435930, loss_D: 0.189988\n",
      "[Epoch 152/200] [Batch 920/938] loss_G: 3.220951, loss_D: 0.166172\n",
      "[Epoch 152/200] [Batch 930/938] loss_G: 3.204465, loss_D: 0.149749\n",
      "[Epoch 153/200] [Batch 0/938] loss_G: 2.907832, loss_D: 0.220010\n",
      "[Epoch 153/200] [Batch 10/938] loss_G: 3.351697, loss_D: 0.121297\n",
      "[Epoch 153/200] [Batch 20/938] loss_G: 3.519195, loss_D: 0.134016\n",
      "[Epoch 153/200] [Batch 30/938] loss_G: 3.142086, loss_D: 0.180401\n",
      "[Epoch 153/200] [Batch 40/938] loss_G: 3.275637, loss_D: 0.252815\n",
      "[Epoch 153/200] [Batch 50/938] loss_G: 3.603850, loss_D: 0.263611\n",
      "[Epoch 153/200] [Batch 60/938] loss_G: 3.019691, loss_D: 0.144243\n",
      "[Epoch 153/200] [Batch 70/938] loss_G: 3.328243, loss_D: 0.181821\n",
      "[Epoch 153/200] [Batch 80/938] loss_G: 2.985116, loss_D: 0.219701\n",
      "[Epoch 153/200] [Batch 90/938] loss_G: 3.352721, loss_D: 0.115515\n",
      "[Epoch 153/200] [Batch 100/938] loss_G: 3.124680, loss_D: 0.182116\n",
      "[Epoch 153/200] [Batch 110/938] loss_G: 3.738099, loss_D: 0.192196\n",
      "[Epoch 153/200] [Batch 120/938] loss_G: 3.315138, loss_D: 0.189768\n",
      "[Epoch 153/200] [Batch 130/938] loss_G: 3.370536, loss_D: 0.160519\n",
      "[Epoch 153/200] [Batch 140/938] loss_G: 3.008863, loss_D: 0.130545\n",
      "[Epoch 153/200] [Batch 150/938] loss_G: 3.509599, loss_D: 0.190125\n",
      "[Epoch 153/200] [Batch 160/938] loss_G: 3.573531, loss_D: 0.152207\n",
      "[Epoch 153/200] [Batch 170/938] loss_G: 3.349731, loss_D: 0.178395\n",
      "[Epoch 153/200] [Batch 180/938] loss_G: 3.649828, loss_D: 0.142103\n",
      "[Epoch 153/200] [Batch 190/938] loss_G: 2.719117, loss_D: 0.170909\n",
      "[Epoch 153/200] [Batch 200/938] loss_G: 3.172158, loss_D: 0.187243\n",
      "[Epoch 153/200] [Batch 210/938] loss_G: 3.393280, loss_D: 0.181061\n",
      "[Epoch 153/200] [Batch 220/938] loss_G: 3.137047, loss_D: 0.175215\n",
      "[Epoch 153/200] [Batch 230/938] loss_G: 3.349764, loss_D: 0.181711\n",
      "[Epoch 153/200] [Batch 240/938] loss_G: 3.108420, loss_D: 0.236635\n",
      "[Epoch 153/200] [Batch 250/938] loss_G: 3.112058, loss_D: 0.166642\n",
      "[Epoch 153/200] [Batch 260/938] loss_G: 3.352543, loss_D: 0.229417\n",
      "[Epoch 153/200] [Batch 270/938] loss_G: 3.200131, loss_D: 0.199168\n",
      "[Epoch 153/200] [Batch 280/938] loss_G: 2.972080, loss_D: 0.203914\n",
      "[Epoch 153/200] [Batch 290/938] loss_G: 3.509105, loss_D: 0.182830\n",
      "[Epoch 153/200] [Batch 300/938] loss_G: 2.880441, loss_D: 0.155947\n",
      "[Epoch 153/200] [Batch 310/938] loss_G: 3.737900, loss_D: 0.185166\n",
      "[Epoch 153/200] [Batch 320/938] loss_G: 3.588370, loss_D: 0.187861\n",
      "[Epoch 153/200] [Batch 330/938] loss_G: 3.175882, loss_D: 0.209615\n",
      "[Epoch 153/200] [Batch 340/938] loss_G: 3.141511, loss_D: 0.148581\n",
      "[Epoch 153/200] [Batch 350/938] loss_G: 3.080048, loss_D: 0.200940\n",
      "[Epoch 153/200] [Batch 360/938] loss_G: 3.343989, loss_D: 0.177986\n",
      "[Epoch 153/200] [Batch 370/938] loss_G: 3.218534, loss_D: 0.164788\n",
      "[Epoch 153/200] [Batch 380/938] loss_G: 3.459076, loss_D: 0.261675\n",
      "[Epoch 153/200] [Batch 390/938] loss_G: 3.362444, loss_D: 0.204531\n",
      "[Epoch 153/200] [Batch 400/938] loss_G: 3.151781, loss_D: 0.210428\n",
      "[Epoch 153/200] [Batch 410/938] loss_G: 3.280296, loss_D: 0.239329\n",
      "[Epoch 153/200] [Batch 420/938] loss_G: 3.102168, loss_D: 0.189399\n",
      "[Epoch 153/200] [Batch 430/938] loss_G: 3.334157, loss_D: 0.240709\n",
      "[Epoch 153/200] [Batch 440/938] loss_G: 3.353941, loss_D: 0.255532\n",
      "[Epoch 153/200] [Batch 450/938] loss_G: 3.117994, loss_D: 0.175462\n",
      "[Epoch 153/200] [Batch 460/938] loss_G: 3.229869, loss_D: 0.227150\n",
      "[Epoch 153/200] [Batch 470/938] loss_G: 3.370231, loss_D: 0.225857\n",
      "[Epoch 153/200] [Batch 480/938] loss_G: 3.089632, loss_D: 0.176832\n",
      "[Epoch 153/200] [Batch 490/938] loss_G: 3.148549, loss_D: 0.184653\n",
      "[Epoch 153/200] [Batch 500/938] loss_G: 3.196897, loss_D: 0.199383\n",
      "[Epoch 153/200] [Batch 510/938] loss_G: 3.226486, loss_D: 0.120013\n",
      "[Epoch 153/200] [Batch 520/938] loss_G: 3.317652, loss_D: 0.270550\n",
      "[Epoch 153/200] [Batch 530/938] loss_G: 3.188051, loss_D: 0.202601\n",
      "[Epoch 153/200] [Batch 540/938] loss_G: 3.165468, loss_D: 0.211320\n",
      "[Epoch 153/200] [Batch 550/938] loss_G: 3.151854, loss_D: 0.171305\n",
      "[Epoch 153/200] [Batch 560/938] loss_G: 3.220351, loss_D: 0.193353\n",
      "[Epoch 153/200] [Batch 570/938] loss_G: 3.167054, loss_D: 0.162163\n",
      "[Epoch 153/200] [Batch 580/938] loss_G: 2.741648, loss_D: 0.191378\n",
      "[Epoch 153/200] [Batch 590/938] loss_G: 2.943455, loss_D: 0.186148\n",
      "[Epoch 153/200] [Batch 600/938] loss_G: 3.517356, loss_D: 0.206119\n",
      "[Epoch 153/200] [Batch 610/938] loss_G: 3.309470, loss_D: 0.207146\n",
      "[Epoch 153/200] [Batch 620/938] loss_G: 2.877517, loss_D: 0.248317\n",
      "[Epoch 153/200] [Batch 630/938] loss_G: 2.932805, loss_D: 0.212061\n",
      "[Epoch 153/200] [Batch 640/938] loss_G: 3.355182, loss_D: 0.245978\n",
      "[Epoch 153/200] [Batch 650/938] loss_G: 3.459434, loss_D: 0.205879\n",
      "[Epoch 153/200] [Batch 660/938] loss_G: 3.262913, loss_D: 0.193430\n",
      "[Epoch 153/200] [Batch 670/938] loss_G: 3.351881, loss_D: 0.188964\n",
      "[Epoch 153/200] [Batch 680/938] loss_G: 3.214971, loss_D: 0.233278\n",
      "[Epoch 153/200] [Batch 690/938] loss_G: 3.054146, loss_D: 0.185269\n",
      "[Epoch 153/200] [Batch 700/938] loss_G: 2.955704, loss_D: 0.145493\n",
      "[Epoch 153/200] [Batch 710/938] loss_G: 3.152251, loss_D: 0.198291\n",
      "[Epoch 153/200] [Batch 720/938] loss_G: 3.163139, loss_D: 0.234053\n",
      "[Epoch 153/200] [Batch 730/938] loss_G: 3.025156, loss_D: 0.194492\n",
      "[Epoch 153/200] [Batch 740/938] loss_G: 3.308376, loss_D: 0.155164\n",
      "[Epoch 153/200] [Batch 750/938] loss_G: 3.087976, loss_D: 0.220568\n",
      "[Epoch 153/200] [Batch 760/938] loss_G: 3.047039, loss_D: 0.323114\n",
      "[Epoch 153/200] [Batch 770/938] loss_G: 3.536420, loss_D: 0.207510\n",
      "[Epoch 153/200] [Batch 780/938] loss_G: 3.274035, loss_D: 0.202058\n",
      "[Epoch 153/200] [Batch 790/938] loss_G: 2.978144, loss_D: 0.147201\n",
      "[Epoch 153/200] [Batch 800/938] loss_G: 3.089718, loss_D: 0.289649\n",
      "[Epoch 153/200] [Batch 810/938] loss_G: 3.569670, loss_D: 0.231311\n",
      "[Epoch 153/200] [Batch 820/938] loss_G: 2.781610, loss_D: 0.189334\n",
      "[Epoch 153/200] [Batch 830/938] loss_G: 3.585702, loss_D: 0.133703\n",
      "[Epoch 153/200] [Batch 840/938] loss_G: 2.964635, loss_D: 0.163704\n",
      "[Epoch 153/200] [Batch 850/938] loss_G: 3.152209, loss_D: 0.159919\n",
      "[Epoch 153/200] [Batch 860/938] loss_G: 3.557615, loss_D: 0.191985\n",
      "[Epoch 153/200] [Batch 870/938] loss_G: 3.160301, loss_D: 0.212142\n",
      "[Epoch 153/200] [Batch 880/938] loss_G: 3.082824, loss_D: 0.225069\n",
      "[Epoch 153/200] [Batch 890/938] loss_G: 3.444795, loss_D: 0.166940\n",
      "[Epoch 153/200] [Batch 900/938] loss_G: 3.020772, loss_D: 0.177912\n",
      "[Epoch 153/200] [Batch 910/938] loss_G: 3.477555, loss_D: 0.218878\n",
      "[Epoch 153/200] [Batch 920/938] loss_G: 3.227486, loss_D: 0.268738\n",
      "[Epoch 153/200] [Batch 930/938] loss_G: 3.104331, loss_D: 0.203498\n",
      "[Epoch 154/200] [Batch 0/938] loss_G: 3.078929, loss_D: 0.199211\n",
      "[Epoch 154/200] [Batch 10/938] loss_G: 3.291586, loss_D: 0.250196\n",
      "[Epoch 154/200] [Batch 20/938] loss_G: 3.582768, loss_D: 0.168599\n",
      "[Epoch 154/200] [Batch 30/938] loss_G: 3.786885, loss_D: 0.169505\n",
      "[Epoch 154/200] [Batch 40/938] loss_G: 2.921834, loss_D: 0.274920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 154/200] [Batch 50/938] loss_G: 3.301811, loss_D: 0.166300\n",
      "[Epoch 154/200] [Batch 60/938] loss_G: 3.319743, loss_D: 0.177155\n",
      "[Epoch 154/200] [Batch 70/938] loss_G: 2.895926, loss_D: 0.266006\n",
      "[Epoch 154/200] [Batch 80/938] loss_G: 3.344568, loss_D: 0.195746\n",
      "[Epoch 154/200] [Batch 90/938] loss_G: 3.173858, loss_D: 0.159018\n",
      "[Epoch 154/200] [Batch 100/938] loss_G: 3.445463, loss_D: 0.167297\n",
      "[Epoch 154/200] [Batch 110/938] loss_G: 3.257867, loss_D: 0.154626\n",
      "[Epoch 154/200] [Batch 120/938] loss_G: 3.203829, loss_D: 0.237209\n",
      "[Epoch 154/200] [Batch 130/938] loss_G: 3.119861, loss_D: 0.201642\n",
      "[Epoch 154/200] [Batch 140/938] loss_G: 3.103447, loss_D: 0.149924\n",
      "[Epoch 154/200] [Batch 150/938] loss_G: 3.393758, loss_D: 0.118867\n",
      "[Epoch 154/200] [Batch 160/938] loss_G: 2.791051, loss_D: 0.313500\n",
      "[Epoch 154/200] [Batch 170/938] loss_G: 2.801625, loss_D: 0.173070\n",
      "[Epoch 154/200] [Batch 180/938] loss_G: 3.496874, loss_D: 0.136782\n",
      "[Epoch 154/200] [Batch 190/938] loss_G: 3.157135, loss_D: 0.142816\n",
      "[Epoch 154/200] [Batch 200/938] loss_G: 3.073255, loss_D: 0.350478\n",
      "[Epoch 154/200] [Batch 210/938] loss_G: 3.170784, loss_D: 0.182258\n",
      "[Epoch 154/200] [Batch 220/938] loss_G: 3.012333, loss_D: 0.240383\n",
      "[Epoch 154/200] [Batch 230/938] loss_G: 3.137251, loss_D: 0.255892\n",
      "[Epoch 154/200] [Batch 240/938] loss_G: 3.144774, loss_D: 0.161620\n",
      "[Epoch 154/200] [Batch 250/938] loss_G: 3.597975, loss_D: 0.164077\n",
      "[Epoch 154/200] [Batch 260/938] loss_G: 2.998618, loss_D: 0.229415\n",
      "[Epoch 154/200] [Batch 270/938] loss_G: 3.292181, loss_D: 0.223943\n",
      "[Epoch 154/200] [Batch 280/938] loss_G: 3.647679, loss_D: 0.182654\n",
      "[Epoch 154/200] [Batch 290/938] loss_G: 3.130221, loss_D: 0.153943\n",
      "[Epoch 154/200] [Batch 300/938] loss_G: 3.058836, loss_D: 0.185443\n",
      "[Epoch 154/200] [Batch 310/938] loss_G: 3.223086, loss_D: 0.179381\n",
      "[Epoch 154/200] [Batch 320/938] loss_G: 3.063196, loss_D: 0.131440\n",
      "[Epoch 154/200] [Batch 330/938] loss_G: 3.328422, loss_D: 0.158240\n",
      "[Epoch 154/200] [Batch 340/938] loss_G: 3.431084, loss_D: 0.163342\n",
      "[Epoch 154/200] [Batch 350/938] loss_G: 3.076834, loss_D: 0.197102\n",
      "[Epoch 154/200] [Batch 360/938] loss_G: 3.068989, loss_D: 0.149202\n",
      "[Epoch 154/200] [Batch 370/938] loss_G: 3.376626, loss_D: 0.226925\n",
      "[Epoch 154/200] [Batch 380/938] loss_G: 3.121977, loss_D: 0.200810\n",
      "[Epoch 154/200] [Batch 390/938] loss_G: 3.264577, loss_D: 0.192861\n",
      "[Epoch 154/200] [Batch 400/938] loss_G: 3.617666, loss_D: 0.217998\n",
      "[Epoch 154/200] [Batch 410/938] loss_G: 3.020836, loss_D: 0.169270\n",
      "[Epoch 154/200] [Batch 420/938] loss_G: 2.775306, loss_D: 0.150434\n",
      "[Epoch 154/200] [Batch 430/938] loss_G: 4.062949, loss_D: 0.125378\n",
      "[Epoch 154/200] [Batch 440/938] loss_G: 3.130528, loss_D: 0.191733\n",
      "[Epoch 154/200] [Batch 450/938] loss_G: 3.350937, loss_D: 0.139940\n",
      "[Epoch 154/200] [Batch 460/938] loss_G: 3.684159, loss_D: 0.215688\n",
      "[Epoch 154/200] [Batch 470/938] loss_G: 3.309116, loss_D: 0.312706\n",
      "[Epoch 154/200] [Batch 480/938] loss_G: 3.081998, loss_D: 0.215497\n",
      "[Epoch 154/200] [Batch 490/938] loss_G: 3.307546, loss_D: 0.237364\n",
      "[Epoch 154/200] [Batch 500/938] loss_G: 3.066165, loss_D: 0.216340\n",
      "[Epoch 154/200] [Batch 510/938] loss_G: 3.388141, loss_D: 0.204225\n",
      "[Epoch 154/200] [Batch 520/938] loss_G: 3.051390, loss_D: 0.220601\n",
      "[Epoch 154/200] [Batch 530/938] loss_G: 3.244667, loss_D: 0.269340\n",
      "[Epoch 154/200] [Batch 540/938] loss_G: 2.931746, loss_D: 0.169106\n",
      "[Epoch 154/200] [Batch 550/938] loss_G: 3.221915, loss_D: 0.164436\n",
      "[Epoch 154/200] [Batch 560/938] loss_G: 3.091920, loss_D: 0.182507\n",
      "[Epoch 154/200] [Batch 570/938] loss_G: 2.754740, loss_D: 0.204626\n",
      "[Epoch 154/200] [Batch 580/938] loss_G: 2.813389, loss_D: 0.162048\n",
      "[Epoch 154/200] [Batch 590/938] loss_G: 3.245788, loss_D: 0.215802\n",
      "[Epoch 154/200] [Batch 600/938] loss_G: 3.343552, loss_D: 0.180966\n",
      "[Epoch 154/200] [Batch 610/938] loss_G: 3.450240, loss_D: 0.108622\n",
      "[Epoch 154/200] [Batch 620/938] loss_G: 3.030805, loss_D: 0.208191\n",
      "[Epoch 154/200] [Batch 630/938] loss_G: 3.323292, loss_D: 0.136745\n",
      "[Epoch 154/200] [Batch 640/938] loss_G: 3.123550, loss_D: 0.110458\n",
      "[Epoch 154/200] [Batch 650/938] loss_G: 2.991125, loss_D: 0.282414\n",
      "[Epoch 154/200] [Batch 660/938] loss_G: 2.946036, loss_D: 0.218806\n",
      "[Epoch 154/200] [Batch 670/938] loss_G: 3.700162, loss_D: 0.128319\n",
      "[Epoch 154/200] [Batch 680/938] loss_G: 3.760104, loss_D: 0.173265\n",
      "[Epoch 154/200] [Batch 690/938] loss_G: 3.291004, loss_D: 0.154673\n",
      "[Epoch 154/200] [Batch 700/938] loss_G: 3.331826, loss_D: 0.100732\n",
      "[Epoch 154/200] [Batch 710/938] loss_G: 3.520452, loss_D: 0.169354\n",
      "[Epoch 154/200] [Batch 720/938] loss_G: 3.191850, loss_D: 0.140606\n",
      "[Epoch 154/200] [Batch 730/938] loss_G: 3.700540, loss_D: 0.200759\n",
      "[Epoch 154/200] [Batch 740/938] loss_G: 3.695224, loss_D: 0.166238\n",
      "[Epoch 154/200] [Batch 750/938] loss_G: 3.148171, loss_D: 0.223404\n",
      "[Epoch 154/200] [Batch 760/938] loss_G: 2.933137, loss_D: 0.256418\n",
      "[Epoch 154/200] [Batch 770/938] loss_G: 3.053029, loss_D: 0.252045\n",
      "[Epoch 154/200] [Batch 780/938] loss_G: 3.373102, loss_D: 0.196304\n",
      "[Epoch 154/200] [Batch 790/938] loss_G: 3.069246, loss_D: 0.202433\n",
      "[Epoch 154/200] [Batch 800/938] loss_G: 3.439089, loss_D: 0.280100\n",
      "[Epoch 154/200] [Batch 810/938] loss_G: 3.157859, loss_D: 0.267607\n",
      "[Epoch 154/200] [Batch 820/938] loss_G: 3.073875, loss_D: 0.183298\n",
      "[Epoch 154/200] [Batch 830/938] loss_G: 3.329060, loss_D: 0.211504\n",
      "[Epoch 154/200] [Batch 840/938] loss_G: 3.420042, loss_D: 0.175179\n",
      "[Epoch 154/200] [Batch 850/938] loss_G: 3.490804, loss_D: 0.296906\n",
      "[Epoch 154/200] [Batch 860/938] loss_G: 3.025748, loss_D: 0.211033\n",
      "[Epoch 154/200] [Batch 870/938] loss_G: 3.022990, loss_D: 0.228162\n",
      "[Epoch 154/200] [Batch 880/938] loss_G: 3.416986, loss_D: 0.209606\n",
      "[Epoch 154/200] [Batch 890/938] loss_G: 2.961040, loss_D: 0.191391\n",
      "[Epoch 154/200] [Batch 900/938] loss_G: 3.530866, loss_D: 0.275917\n",
      "[Epoch 154/200] [Batch 910/938] loss_G: 3.112473, loss_D: 0.218434\n",
      "[Epoch 154/200] [Batch 920/938] loss_G: 2.894770, loss_D: 0.182534\n",
      "[Epoch 154/200] [Batch 930/938] loss_G: 3.199570, loss_D: 0.179867\n",
      "[Epoch 155/200] [Batch 0/938] loss_G: 3.517022, loss_D: 0.132502\n",
      "[Epoch 155/200] [Batch 10/938] loss_G: 3.063611, loss_D: 0.176812\n",
      "[Epoch 155/200] [Batch 20/938] loss_G: 3.445193, loss_D: 0.208300\n",
      "[Epoch 155/200] [Batch 30/938] loss_G: 3.515435, loss_D: 0.274733\n",
      "[Epoch 155/200] [Batch 40/938] loss_G: 3.384331, loss_D: 0.275389\n",
      "[Epoch 155/200] [Batch 50/938] loss_G: 3.107516, loss_D: 0.204377\n",
      "[Epoch 155/200] [Batch 60/938] loss_G: 3.274624, loss_D: 0.183172\n",
      "[Epoch 155/200] [Batch 70/938] loss_G: 3.312867, loss_D: 0.210918\n",
      "[Epoch 155/200] [Batch 80/938] loss_G: 3.224294, loss_D: 0.254229\n",
      "[Epoch 155/200] [Batch 90/938] loss_G: 3.543752, loss_D: 0.153181\n",
      "[Epoch 155/200] [Batch 100/938] loss_G: 3.254492, loss_D: 0.225334\n",
      "[Epoch 155/200] [Batch 110/938] loss_G: 3.415698, loss_D: 0.228591\n",
      "[Epoch 155/200] [Batch 120/938] loss_G: 3.485628, loss_D: 0.205916\n",
      "[Epoch 155/200] [Batch 130/938] loss_G: 2.917909, loss_D: 0.209115\n",
      "[Epoch 155/200] [Batch 140/938] loss_G: 3.155920, loss_D: 0.133286\n",
      "[Epoch 155/200] [Batch 150/938] loss_G: 3.212615, loss_D: 0.188876\n",
      "[Epoch 155/200] [Batch 160/938] loss_G: 3.276385, loss_D: 0.155610\n",
      "[Epoch 155/200] [Batch 170/938] loss_G: 3.298311, loss_D: 0.128227\n",
      "[Epoch 155/200] [Batch 180/938] loss_G: 3.476252, loss_D: 0.233099\n",
      "[Epoch 155/200] [Batch 190/938] loss_G: 3.496595, loss_D: 0.168613\n",
      "[Epoch 155/200] [Batch 200/938] loss_G: 3.571324, loss_D: 0.147821\n",
      "[Epoch 155/200] [Batch 210/938] loss_G: 3.254225, loss_D: 0.244783\n",
      "[Epoch 155/200] [Batch 220/938] loss_G: 3.352803, loss_D: 0.184085\n",
      "[Epoch 155/200] [Batch 230/938] loss_G: 3.201039, loss_D: 0.224765\n",
      "[Epoch 155/200] [Batch 240/938] loss_G: 3.131113, loss_D: 0.176950\n",
      "[Epoch 155/200] [Batch 250/938] loss_G: 3.085417, loss_D: 0.157574\n",
      "[Epoch 155/200] [Batch 260/938] loss_G: 3.197561, loss_D: 0.271791\n",
      "[Epoch 155/200] [Batch 270/938] loss_G: 3.319468, loss_D: 0.200722\n",
      "[Epoch 155/200] [Batch 280/938] loss_G: 3.423785, loss_D: 0.207899\n",
      "[Epoch 155/200] [Batch 290/938] loss_G: 3.102216, loss_D: 0.175987\n",
      "[Epoch 155/200] [Batch 300/938] loss_G: 3.448460, loss_D: 0.252776\n",
      "[Epoch 155/200] [Batch 310/938] loss_G: 3.133837, loss_D: 0.198392\n",
      "[Epoch 155/200] [Batch 320/938] loss_G: 3.514280, loss_D: 0.164853\n",
      "[Epoch 155/200] [Batch 330/938] loss_G: 3.271520, loss_D: 0.173103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 155/200] [Batch 340/938] loss_G: 3.267597, loss_D: 0.218774\n",
      "[Epoch 155/200] [Batch 350/938] loss_G: 3.239060, loss_D: 0.180936\n",
      "[Epoch 155/200] [Batch 360/938] loss_G: 3.246698, loss_D: 0.211105\n",
      "[Epoch 155/200] [Batch 370/938] loss_G: 3.344128, loss_D: 0.257263\n",
      "[Epoch 155/200] [Batch 380/938] loss_G: 3.345052, loss_D: 0.094319\n",
      "[Epoch 155/200] [Batch 390/938] loss_G: 3.527093, loss_D: 0.124829\n",
      "[Epoch 155/200] [Batch 400/938] loss_G: 3.030420, loss_D: 0.178248\n",
      "[Epoch 155/200] [Batch 410/938] loss_G: 3.273017, loss_D: 0.158314\n",
      "[Epoch 155/200] [Batch 420/938] loss_G: 3.076977, loss_D: 0.190260\n",
      "[Epoch 155/200] [Batch 430/938] loss_G: 3.885529, loss_D: 0.194347\n",
      "[Epoch 155/200] [Batch 440/938] loss_G: 3.014969, loss_D: 0.180231\n",
      "[Epoch 155/200] [Batch 450/938] loss_G: 3.631220, loss_D: 0.179065\n",
      "[Epoch 155/200] [Batch 460/938] loss_G: 3.230747, loss_D: 0.196155\n",
      "[Epoch 155/200] [Batch 470/938] loss_G: 3.255747, loss_D: 0.243743\n",
      "[Epoch 155/200] [Batch 480/938] loss_G: 2.955195, loss_D: 0.265711\n",
      "[Epoch 155/200] [Batch 490/938] loss_G: 3.063399, loss_D: 0.228443\n",
      "[Epoch 155/200] [Batch 500/938] loss_G: 3.172721, loss_D: 0.192758\n",
      "[Epoch 155/200] [Batch 510/938] loss_G: 3.563470, loss_D: 0.165924\n",
      "[Epoch 155/200] [Batch 520/938] loss_G: 3.370188, loss_D: 0.120110\n",
      "[Epoch 155/200] [Batch 530/938] loss_G: 2.928102, loss_D: 0.209992\n",
      "[Epoch 155/200] [Batch 540/938] loss_G: 3.331879, loss_D: 0.295737\n",
      "[Epoch 155/200] [Batch 550/938] loss_G: 3.052491, loss_D: 0.270635\n",
      "[Epoch 155/200] [Batch 560/938] loss_G: 3.333156, loss_D: 0.123180\n",
      "[Epoch 155/200] [Batch 570/938] loss_G: 3.226394, loss_D: 0.196953\n",
      "[Epoch 155/200] [Batch 580/938] loss_G: 3.010626, loss_D: 0.227858\n",
      "[Epoch 155/200] [Batch 590/938] loss_G: 3.312777, loss_D: 0.203573\n",
      "[Epoch 155/200] [Batch 600/938] loss_G: 3.217422, loss_D: 0.206112\n",
      "[Epoch 155/200] [Batch 610/938] loss_G: 3.417186, loss_D: 0.229664\n",
      "[Epoch 155/200] [Batch 620/938] loss_G: 3.089574, loss_D: 0.211209\n",
      "[Epoch 155/200] [Batch 630/938] loss_G: 3.524878, loss_D: 0.127663\n",
      "[Epoch 155/200] [Batch 640/938] loss_G: 3.630386, loss_D: 0.206633\n",
      "[Epoch 155/200] [Batch 650/938] loss_G: 3.463128, loss_D: 0.241952\n",
      "[Epoch 155/200] [Batch 660/938] loss_G: 3.555850, loss_D: 0.235143\n",
      "[Epoch 155/200] [Batch 670/938] loss_G: 3.382126, loss_D: 0.151029\n",
      "[Epoch 155/200] [Batch 680/938] loss_G: 3.067362, loss_D: 0.168042\n",
      "[Epoch 155/200] [Batch 690/938] loss_G: 3.464483, loss_D: 0.189649\n",
      "[Epoch 155/200] [Batch 700/938] loss_G: 3.941644, loss_D: 0.214636\n",
      "[Epoch 155/200] [Batch 710/938] loss_G: 3.616785, loss_D: 0.094158\n",
      "[Epoch 155/200] [Batch 720/938] loss_G: 3.559569, loss_D: 0.149318\n",
      "[Epoch 155/200] [Batch 730/938] loss_G: 3.537315, loss_D: 0.168366\n",
      "[Epoch 155/200] [Batch 740/938] loss_G: 3.217197, loss_D: 0.271643\n",
      "[Epoch 155/200] [Batch 750/938] loss_G: 3.736475, loss_D: 0.094609\n",
      "[Epoch 155/200] [Batch 760/938] loss_G: 3.658354, loss_D: 0.270682\n",
      "[Epoch 155/200] [Batch 770/938] loss_G: 3.176863, loss_D: 0.116148\n",
      "[Epoch 155/200] [Batch 780/938] loss_G: 3.079344, loss_D: 0.241667\n",
      "[Epoch 155/200] [Batch 790/938] loss_G: 3.786520, loss_D: 0.212375\n",
      "[Epoch 155/200] [Batch 800/938] loss_G: 3.464359, loss_D: 0.260135\n",
      "[Epoch 155/200] [Batch 810/938] loss_G: 3.386065, loss_D: 0.153327\n",
      "[Epoch 155/200] [Batch 820/938] loss_G: 3.227902, loss_D: 0.180765\n",
      "[Epoch 155/200] [Batch 830/938] loss_G: 3.821412, loss_D: 0.150695\n",
      "[Epoch 155/200] [Batch 840/938] loss_G: 2.942657, loss_D: 0.167395\n",
      "[Epoch 155/200] [Batch 850/938] loss_G: 3.396917, loss_D: 0.241759\n",
      "[Epoch 155/200] [Batch 860/938] loss_G: 3.284044, loss_D: 0.129839\n",
      "[Epoch 155/200] [Batch 870/938] loss_G: 2.990767, loss_D: 0.127876\n",
      "[Epoch 155/200] [Batch 880/938] loss_G: 3.673638, loss_D: 0.123687\n",
      "[Epoch 155/200] [Batch 890/938] loss_G: 2.998305, loss_D: 0.203602\n",
      "[Epoch 155/200] [Batch 900/938] loss_G: 3.649405, loss_D: 0.217505\n",
      "[Epoch 155/200] [Batch 910/938] loss_G: 3.290319, loss_D: 0.192984\n",
      "[Epoch 155/200] [Batch 920/938] loss_G: 3.527511, loss_D: 0.110951\n",
      "[Epoch 155/200] [Batch 930/938] loss_G: 3.290102, loss_D: 0.127216\n",
      "[Epoch 156/200] [Batch 0/938] loss_G: 2.977314, loss_D: 0.138412\n",
      "[Epoch 156/200] [Batch 10/938] loss_G: 3.508508, loss_D: 0.133978\n",
      "[Epoch 156/200] [Batch 20/938] loss_G: 2.956829, loss_D: 0.235621\n",
      "[Epoch 156/200] [Batch 30/938] loss_G: 3.463515, loss_D: 0.183040\n",
      "[Epoch 156/200] [Batch 40/938] loss_G: 3.273764, loss_D: 0.202567\n",
      "[Epoch 156/200] [Batch 50/938] loss_G: 3.305868, loss_D: 0.265373\n",
      "[Epoch 156/200] [Batch 60/938] loss_G: 3.241728, loss_D: 0.198340\n",
      "[Epoch 156/200] [Batch 70/938] loss_G: 3.648326, loss_D: 0.174856\n",
      "[Epoch 156/200] [Batch 80/938] loss_G: 3.292746, loss_D: 0.123376\n",
      "[Epoch 156/200] [Batch 90/938] loss_G: 2.873058, loss_D: 0.172016\n",
      "[Epoch 156/200] [Batch 100/938] loss_G: 3.253633, loss_D: 0.122851\n",
      "[Epoch 156/200] [Batch 110/938] loss_G: 3.674758, loss_D: 0.178272\n",
      "[Epoch 156/200] [Batch 120/938] loss_G: 3.435798, loss_D: 0.150585\n",
      "[Epoch 156/200] [Batch 130/938] loss_G: 3.279695, loss_D: 0.212541\n",
      "[Epoch 156/200] [Batch 140/938] loss_G: 3.177428, loss_D: 0.195439\n",
      "[Epoch 156/200] [Batch 150/938] loss_G: 3.478739, loss_D: 0.189476\n",
      "[Epoch 156/200] [Batch 160/938] loss_G: 3.414491, loss_D: 0.185037\n",
      "[Epoch 156/200] [Batch 170/938] loss_G: 3.187745, loss_D: 0.152419\n",
      "[Epoch 156/200] [Batch 180/938] loss_G: 3.502736, loss_D: 0.173825\n",
      "[Epoch 156/200] [Batch 190/938] loss_G: 3.100189, loss_D: 0.153999\n",
      "[Epoch 156/200] [Batch 200/938] loss_G: 2.893758, loss_D: 0.248599\n",
      "[Epoch 156/200] [Batch 210/938] loss_G: 3.357917, loss_D: 0.211279\n",
      "[Epoch 156/200] [Batch 220/938] loss_G: 2.884775, loss_D: 0.191144\n",
      "[Epoch 156/200] [Batch 230/938] loss_G: 3.410496, loss_D: 0.192778\n",
      "[Epoch 156/200] [Batch 240/938] loss_G: 3.352959, loss_D: 0.194443\n",
      "[Epoch 156/200] [Batch 250/938] loss_G: 3.150891, loss_D: 0.171143\n",
      "[Epoch 156/200] [Batch 260/938] loss_G: 3.021115, loss_D: 0.229969\n",
      "[Epoch 156/200] [Batch 270/938] loss_G: 3.228504, loss_D: 0.181519\n",
      "[Epoch 156/200] [Batch 280/938] loss_G: 3.354672, loss_D: 0.149413\n",
      "[Epoch 156/200] [Batch 290/938] loss_G: 3.163847, loss_D: 0.283846\n",
      "[Epoch 156/200] [Batch 300/938] loss_G: 3.238392, loss_D: 0.194002\n",
      "[Epoch 156/200] [Batch 310/938] loss_G: 3.366289, loss_D: 0.237048\n",
      "[Epoch 156/200] [Batch 320/938] loss_G: 3.118601, loss_D: 0.221156\n",
      "[Epoch 156/200] [Batch 330/938] loss_G: 3.501950, loss_D: 0.208679\n",
      "[Epoch 156/200] [Batch 340/938] loss_G: 3.122872, loss_D: 0.242608\n",
      "[Epoch 156/200] [Batch 350/938] loss_G: 3.240320, loss_D: 0.199651\n",
      "[Epoch 156/200] [Batch 360/938] loss_G: 2.863896, loss_D: 0.227790\n",
      "[Epoch 156/200] [Batch 370/938] loss_G: 3.341984, loss_D: 0.174441\n",
      "[Epoch 156/200] [Batch 380/938] loss_G: 3.082352, loss_D: 0.277545\n",
      "[Epoch 156/200] [Batch 390/938] loss_G: 3.210098, loss_D: 0.195875\n",
      "[Epoch 156/200] [Batch 400/938] loss_G: 3.134592, loss_D: 0.237721\n",
      "[Epoch 156/200] [Batch 410/938] loss_G: 3.640397, loss_D: 0.169940\n",
      "[Epoch 156/200] [Batch 420/938] loss_G: 3.163350, loss_D: 0.175501\n",
      "[Epoch 156/200] [Batch 430/938] loss_G: 3.389140, loss_D: 0.252324\n",
      "[Epoch 156/200] [Batch 440/938] loss_G: 3.342266, loss_D: 0.205807\n",
      "[Epoch 156/200] [Batch 450/938] loss_G: 3.109417, loss_D: 0.171697\n",
      "[Epoch 156/200] [Batch 460/938] loss_G: 3.302612, loss_D: 0.110723\n",
      "[Epoch 156/200] [Batch 470/938] loss_G: 3.509258, loss_D: 0.140850\n",
      "[Epoch 156/200] [Batch 480/938] loss_G: 3.390608, loss_D: 0.128266\n",
      "[Epoch 156/200] [Batch 490/938] loss_G: 3.132983, loss_D: 0.135784\n",
      "[Epoch 156/200] [Batch 500/938] loss_G: 2.969624, loss_D: 0.185095\n",
      "[Epoch 156/200] [Batch 510/938] loss_G: 3.190669, loss_D: 0.164820\n",
      "[Epoch 156/200] [Batch 520/938] loss_G: 3.384494, loss_D: 0.127137\n",
      "[Epoch 156/200] [Batch 530/938] loss_G: 3.073847, loss_D: 0.188466\n",
      "[Epoch 156/200] [Batch 540/938] loss_G: 3.115201, loss_D: 0.135338\n",
      "[Epoch 156/200] [Batch 550/938] loss_G: 3.299745, loss_D: 0.178615\n",
      "[Epoch 156/200] [Batch 560/938] loss_G: 3.392333, loss_D: 0.178888\n",
      "[Epoch 156/200] [Batch 570/938] loss_G: 3.038948, loss_D: 0.160099\n",
      "[Epoch 156/200] [Batch 580/938] loss_G: 2.971342, loss_D: 0.206574\n",
      "[Epoch 156/200] [Batch 590/938] loss_G: 3.252872, loss_D: 0.222592\n",
      "[Epoch 156/200] [Batch 600/938] loss_G: 2.879356, loss_D: 0.085214\n",
      "[Epoch 156/200] [Batch 610/938] loss_G: 3.205238, loss_D: 0.275026\n",
      "[Epoch 156/200] [Batch 620/938] loss_G: 3.560671, loss_D: 0.143148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 156/200] [Batch 630/938] loss_G: 3.054048, loss_D: 0.219127\n",
      "[Epoch 156/200] [Batch 640/938] loss_G: 3.199940, loss_D: 0.271269\n",
      "[Epoch 156/200] [Batch 650/938] loss_G: 3.500125, loss_D: 0.200773\n",
      "[Epoch 156/200] [Batch 660/938] loss_G: 3.416397, loss_D: 0.224089\n",
      "[Epoch 156/200] [Batch 670/938] loss_G: 3.184098, loss_D: 0.273417\n",
      "[Epoch 156/200] [Batch 680/938] loss_G: 3.628818, loss_D: 0.128838\n",
      "[Epoch 156/200] [Batch 690/938] loss_G: 3.430768, loss_D: 0.228355\n",
      "[Epoch 156/200] [Batch 700/938] loss_G: 3.523631, loss_D: 0.186178\n",
      "[Epoch 156/200] [Batch 710/938] loss_G: 3.129493, loss_D: 0.176205\n",
      "[Epoch 156/200] [Batch 720/938] loss_G: 3.466131, loss_D: 0.198465\n",
      "[Epoch 156/200] [Batch 730/938] loss_G: 3.070194, loss_D: 0.206606\n",
      "[Epoch 156/200] [Batch 740/938] loss_G: 3.655039, loss_D: 0.225965\n",
      "[Epoch 156/200] [Batch 750/938] loss_G: 3.339392, loss_D: 0.174416\n",
      "[Epoch 156/200] [Batch 760/938] loss_G: 2.731176, loss_D: 0.166234\n",
      "[Epoch 156/200] [Batch 770/938] loss_G: 3.248230, loss_D: 0.183026\n",
      "[Epoch 156/200] [Batch 780/938] loss_G: 3.382702, loss_D: 0.203471\n",
      "[Epoch 156/200] [Batch 790/938] loss_G: 3.009272, loss_D: 0.266248\n",
      "[Epoch 156/200] [Batch 800/938] loss_G: 3.231387, loss_D: 0.141898\n",
      "[Epoch 156/200] [Batch 810/938] loss_G: 3.068717, loss_D: 0.223207\n",
      "[Epoch 156/200] [Batch 820/938] loss_G: 3.186420, loss_D: 0.179397\n",
      "[Epoch 156/200] [Batch 830/938] loss_G: 3.348001, loss_D: 0.150938\n",
      "[Epoch 156/200] [Batch 840/938] loss_G: 3.211191, loss_D: 0.161087\n",
      "[Epoch 156/200] [Batch 850/938] loss_G: 3.154755, loss_D: 0.293338\n",
      "[Epoch 156/200] [Batch 860/938] loss_G: 3.230838, loss_D: 0.120943\n",
      "[Epoch 156/200] [Batch 870/938] loss_G: 3.560232, loss_D: 0.256929\n",
      "[Epoch 156/200] [Batch 880/938] loss_G: 3.294873, loss_D: 0.216921\n",
      "[Epoch 156/200] [Batch 890/938] loss_G: 2.902420, loss_D: 0.221094\n",
      "[Epoch 156/200] [Batch 900/938] loss_G: 3.196021, loss_D: 0.151043\n",
      "[Epoch 156/200] [Batch 910/938] loss_G: 3.184162, loss_D: 0.119458\n",
      "[Epoch 156/200] [Batch 920/938] loss_G: 3.239727, loss_D: 0.235127\n",
      "[Epoch 156/200] [Batch 930/938] loss_G: 3.286772, loss_D: 0.199562\n",
      "[Epoch 157/200] [Batch 0/938] loss_G: 3.007883, loss_D: 0.208335\n",
      "[Epoch 157/200] [Batch 10/938] loss_G: 3.038020, loss_D: 0.178370\n",
      "[Epoch 157/200] [Batch 20/938] loss_G: 3.258440, loss_D: 0.197464\n",
      "[Epoch 157/200] [Batch 30/938] loss_G: 3.414322, loss_D: 0.205434\n",
      "[Epoch 157/200] [Batch 40/938] loss_G: 3.404995, loss_D: 0.193209\n",
      "[Epoch 157/200] [Batch 50/938] loss_G: 3.288468, loss_D: 0.165693\n",
      "[Epoch 157/200] [Batch 60/938] loss_G: 3.283370, loss_D: 0.197515\n",
      "[Epoch 157/200] [Batch 70/938] loss_G: 3.342648, loss_D: 0.136081\n",
      "[Epoch 157/200] [Batch 80/938] loss_G: 2.935781, loss_D: 0.209906\n",
      "[Epoch 157/200] [Batch 90/938] loss_G: 3.318893, loss_D: 0.146909\n",
      "[Epoch 157/200] [Batch 100/938] loss_G: 3.313079, loss_D: 0.124234\n",
      "[Epoch 157/200] [Batch 110/938] loss_G: 2.935081, loss_D: 0.174072\n",
      "[Epoch 157/200] [Batch 120/938] loss_G: 2.950733, loss_D: 0.140605\n",
      "[Epoch 157/200] [Batch 130/938] loss_G: 3.626801, loss_D: 0.167782\n",
      "[Epoch 157/200] [Batch 140/938] loss_G: 3.322522, loss_D: 0.278120\n",
      "[Epoch 157/200] [Batch 150/938] loss_G: 3.079336, loss_D: 0.162388\n",
      "[Epoch 157/200] [Batch 160/938] loss_G: 3.201509, loss_D: 0.133421\n",
      "[Epoch 157/200] [Batch 170/938] loss_G: 3.125462, loss_D: 0.192104\n",
      "[Epoch 157/200] [Batch 180/938] loss_G: 2.954387, loss_D: 0.190319\n",
      "[Epoch 157/200] [Batch 190/938] loss_G: 3.269706, loss_D: 0.129929\n",
      "[Epoch 157/200] [Batch 200/938] loss_G: 3.595975, loss_D: 0.194621\n",
      "[Epoch 157/200] [Batch 210/938] loss_G: 3.145564, loss_D: 0.136455\n",
      "[Epoch 157/200] [Batch 220/938] loss_G: 3.279126, loss_D: 0.185866\n",
      "[Epoch 157/200] [Batch 230/938] loss_G: 3.566164, loss_D: 0.164348\n",
      "[Epoch 157/200] [Batch 240/938] loss_G: 2.961576, loss_D: 0.165932\n",
      "[Epoch 157/200] [Batch 250/938] loss_G: 3.126070, loss_D: 0.216208\n",
      "[Epoch 157/200] [Batch 260/938] loss_G: 3.226064, loss_D: 0.182631\n",
      "[Epoch 157/200] [Batch 270/938] loss_G: 3.325716, loss_D: 0.230673\n",
      "[Epoch 157/200] [Batch 280/938] loss_G: 3.787894, loss_D: 0.154990\n",
      "[Epoch 157/200] [Batch 290/938] loss_G: 3.434858, loss_D: 0.239015\n",
      "[Epoch 157/200] [Batch 300/938] loss_G: 3.475874, loss_D: 0.195912\n",
      "[Epoch 157/200] [Batch 310/938] loss_G: 3.257212, loss_D: 0.292883\n",
      "[Epoch 157/200] [Batch 320/938] loss_G: 3.442122, loss_D: 0.230220\n",
      "[Epoch 157/200] [Batch 330/938] loss_G: 3.389138, loss_D: 0.228776\n",
      "[Epoch 157/200] [Batch 340/938] loss_G: 3.000453, loss_D: 0.193447\n",
      "[Epoch 157/200] [Batch 350/938] loss_G: 3.334563, loss_D: 0.159460\n",
      "[Epoch 157/200] [Batch 360/938] loss_G: 3.243888, loss_D: 0.335939\n",
      "[Epoch 157/200] [Batch 370/938] loss_G: 3.368827, loss_D: 0.262154\n",
      "[Epoch 157/200] [Batch 380/938] loss_G: 3.262892, loss_D: 0.158488\n",
      "[Epoch 157/200] [Batch 390/938] loss_G: 3.462240, loss_D: 0.308085\n",
      "[Epoch 157/200] [Batch 400/938] loss_G: 2.907986, loss_D: 0.308066\n",
      "[Epoch 157/200] [Batch 410/938] loss_G: 3.523843, loss_D: 0.161362\n",
      "[Epoch 157/200] [Batch 420/938] loss_G: 3.522657, loss_D: 0.163534\n",
      "[Epoch 157/200] [Batch 430/938] loss_G: 3.059948, loss_D: 0.211499\n",
      "[Epoch 157/200] [Batch 440/938] loss_G: 3.144876, loss_D: 0.200139\n",
      "[Epoch 157/200] [Batch 450/938] loss_G: 3.246860, loss_D: 0.093346\n",
      "[Epoch 157/200] [Batch 460/938] loss_G: 3.488501, loss_D: 0.148257\n",
      "[Epoch 157/200] [Batch 470/938] loss_G: 3.355948, loss_D: 0.211558\n",
      "[Epoch 157/200] [Batch 480/938] loss_G: 3.616910, loss_D: 0.266292\n",
      "[Epoch 157/200] [Batch 490/938] loss_G: 3.143420, loss_D: 0.157825\n",
      "[Epoch 157/200] [Batch 500/938] loss_G: 3.444629, loss_D: 0.232133\n",
      "[Epoch 157/200] [Batch 510/938] loss_G: 3.229549, loss_D: 0.202108\n",
      "[Epoch 157/200] [Batch 520/938] loss_G: 3.082880, loss_D: 0.199318\n",
      "[Epoch 157/200] [Batch 530/938] loss_G: 3.423618, loss_D: 0.161419\n",
      "[Epoch 157/200] [Batch 540/938] loss_G: 3.215240, loss_D: 0.216594\n",
      "[Epoch 157/200] [Batch 550/938] loss_G: 3.003108, loss_D: 0.234778\n",
      "[Epoch 157/200] [Batch 560/938] loss_G: 3.160224, loss_D: 0.237430\n",
      "[Epoch 157/200] [Batch 570/938] loss_G: 3.181290, loss_D: 0.237465\n",
      "[Epoch 157/200] [Batch 580/938] loss_G: 3.565051, loss_D: 0.185737\n",
      "[Epoch 157/200] [Batch 590/938] loss_G: 3.644230, loss_D: 0.178593\n",
      "[Epoch 157/200] [Batch 600/938] loss_G: 3.130221, loss_D: 0.212990\n",
      "[Epoch 157/200] [Batch 610/938] loss_G: 3.336792, loss_D: 0.245964\n",
      "[Epoch 157/200] [Batch 620/938] loss_G: 3.781760, loss_D: 0.152453\n",
      "[Epoch 157/200] [Batch 630/938] loss_G: 3.113214, loss_D: 0.234088\n",
      "[Epoch 157/200] [Batch 640/938] loss_G: 2.987499, loss_D: 0.242098\n",
      "[Epoch 157/200] [Batch 650/938] loss_G: 3.392968, loss_D: 0.247579\n",
      "[Epoch 157/200] [Batch 660/938] loss_G: 3.643734, loss_D: 0.205766\n",
      "[Epoch 157/200] [Batch 670/938] loss_G: 3.397180, loss_D: 0.165600\n",
      "[Epoch 157/200] [Batch 680/938] loss_G: 3.524897, loss_D: 0.144388\n",
      "[Epoch 157/200] [Batch 690/938] loss_G: 3.387690, loss_D: 0.208772\n",
      "[Epoch 157/200] [Batch 700/938] loss_G: 3.370077, loss_D: 0.276992\n",
      "[Epoch 157/200] [Batch 710/938] loss_G: 3.048278, loss_D: 0.279512\n",
      "[Epoch 157/200] [Batch 720/938] loss_G: 3.245571, loss_D: 0.187116\n",
      "[Epoch 157/200] [Batch 730/938] loss_G: 2.983634, loss_D: 0.172859\n",
      "[Epoch 157/200] [Batch 740/938] loss_G: 3.257697, loss_D: 0.202645\n",
      "[Epoch 157/200] [Batch 750/938] loss_G: 3.552031, loss_D: 0.211987\n",
      "[Epoch 157/200] [Batch 760/938] loss_G: 3.527755, loss_D: 0.200771\n",
      "[Epoch 157/200] [Batch 770/938] loss_G: 2.733737, loss_D: 0.181659\n",
      "[Epoch 157/200] [Batch 780/938] loss_G: 3.485094, loss_D: 0.201589\n",
      "[Epoch 157/200] [Batch 790/938] loss_G: 3.311382, loss_D: 0.184801\n",
      "[Epoch 157/200] [Batch 800/938] loss_G: 3.284167, loss_D: 0.263504\n",
      "[Epoch 157/200] [Batch 810/938] loss_G: 3.148450, loss_D: 0.274155\n",
      "[Epoch 157/200] [Batch 820/938] loss_G: 3.527013, loss_D: 0.170117\n",
      "[Epoch 157/200] [Batch 830/938] loss_G: 3.888493, loss_D: 0.173636\n",
      "[Epoch 157/200] [Batch 840/938] loss_G: 3.566649, loss_D: 0.271661\n",
      "[Epoch 157/200] [Batch 850/938] loss_G: 3.168736, loss_D: 0.266118\n",
      "[Epoch 157/200] [Batch 860/938] loss_G: 3.183249, loss_D: 0.150163\n",
      "[Epoch 157/200] [Batch 870/938] loss_G: 3.000117, loss_D: 0.240272\n",
      "[Epoch 157/200] [Batch 880/938] loss_G: 3.499600, loss_D: 0.158691\n",
      "[Epoch 157/200] [Batch 890/938] loss_G: 3.261642, loss_D: 0.300747\n",
      "[Epoch 157/200] [Batch 900/938] loss_G: 3.500226, loss_D: 0.193789\n",
      "[Epoch 157/200] [Batch 910/938] loss_G: 3.188635, loss_D: 0.285116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 157/200] [Batch 920/938] loss_G: 2.987245, loss_D: 0.161242\n",
      "[Epoch 157/200] [Batch 930/938] loss_G: 3.509102, loss_D: 0.108390\n",
      "[Epoch 158/200] [Batch 0/938] loss_G: 3.780637, loss_D: 0.263979\n",
      "[Epoch 158/200] [Batch 10/938] loss_G: 3.047365, loss_D: 0.161292\n",
      "[Epoch 158/200] [Batch 20/938] loss_G: 2.989430, loss_D: 0.152119\n",
      "[Epoch 158/200] [Batch 30/938] loss_G: 3.691398, loss_D: 0.152450\n",
      "[Epoch 158/200] [Batch 40/938] loss_G: 3.303614, loss_D: 0.168320\n",
      "[Epoch 158/200] [Batch 50/938] loss_G: 3.069915, loss_D: 0.194470\n",
      "[Epoch 158/200] [Batch 60/938] loss_G: 3.194512, loss_D: 0.220270\n",
      "[Epoch 158/200] [Batch 70/938] loss_G: 3.277020, loss_D: 0.186059\n",
      "[Epoch 158/200] [Batch 80/938] loss_G: 3.461752, loss_D: 0.296596\n",
      "[Epoch 158/200] [Batch 90/938] loss_G: 3.228145, loss_D: 0.174085\n",
      "[Epoch 158/200] [Batch 100/938] loss_G: 3.852461, loss_D: 0.149686\n",
      "[Epoch 158/200] [Batch 110/938] loss_G: 3.306381, loss_D: 0.255627\n",
      "[Epoch 158/200] [Batch 120/938] loss_G: 3.278662, loss_D: 0.098007\n",
      "[Epoch 158/200] [Batch 130/938] loss_G: 3.193828, loss_D: 0.173818\n",
      "[Epoch 158/200] [Batch 140/938] loss_G: 3.309957, loss_D: 0.168006\n",
      "[Epoch 158/200] [Batch 150/938] loss_G: 3.121779, loss_D: 0.158997\n",
      "[Epoch 158/200] [Batch 160/938] loss_G: 3.232049, loss_D: 0.152440\n",
      "[Epoch 158/200] [Batch 170/938] loss_G: 3.183908, loss_D: 0.150334\n",
      "[Epoch 158/200] [Batch 180/938] loss_G: 3.228411, loss_D: 0.112608\n",
      "[Epoch 158/200] [Batch 190/938] loss_G: 3.121080, loss_D: 0.162653\n",
      "[Epoch 158/200] [Batch 200/938] loss_G: 3.042105, loss_D: 0.210102\n",
      "[Epoch 158/200] [Batch 210/938] loss_G: 3.100398, loss_D: 0.168055\n",
      "[Epoch 158/200] [Batch 220/938] loss_G: 3.095561, loss_D: 0.160341\n",
      "[Epoch 158/200] [Batch 230/938] loss_G: 3.196476, loss_D: 0.134344\n",
      "[Epoch 158/200] [Batch 240/938] loss_G: 3.730283, loss_D: 0.196530\n",
      "[Epoch 158/200] [Batch 250/938] loss_G: 3.345650, loss_D: 0.233614\n",
      "[Epoch 158/200] [Batch 260/938] loss_G: 3.196462, loss_D: 0.125428\n",
      "[Epoch 158/200] [Batch 270/938] loss_G: 3.122652, loss_D: 0.175277\n",
      "[Epoch 158/200] [Batch 280/938] loss_G: 3.142845, loss_D: 0.167447\n",
      "[Epoch 158/200] [Batch 290/938] loss_G: 3.131299, loss_D: 0.216487\n",
      "[Epoch 158/200] [Batch 300/938] loss_G: 3.559243, loss_D: 0.135817\n",
      "[Epoch 158/200] [Batch 310/938] loss_G: 3.734631, loss_D: 0.169617\n",
      "[Epoch 158/200] [Batch 320/938] loss_G: 3.268424, loss_D: 0.151695\n",
      "[Epoch 158/200] [Batch 330/938] loss_G: 3.456613, loss_D: 0.232326\n",
      "[Epoch 158/200] [Batch 340/938] loss_G: 3.606575, loss_D: 0.120756\n",
      "[Epoch 158/200] [Batch 350/938] loss_G: 3.120278, loss_D: 0.178102\n",
      "[Epoch 158/200] [Batch 360/938] loss_G: 3.736560, loss_D: 0.205248\n",
      "[Epoch 158/200] [Batch 370/938] loss_G: 3.484506, loss_D: 0.147895\n",
      "[Epoch 158/200] [Batch 380/938] loss_G: 3.110890, loss_D: 0.168665\n",
      "[Epoch 158/200] [Batch 390/938] loss_G: 3.363926, loss_D: 0.156851\n",
      "[Epoch 158/200] [Batch 400/938] loss_G: 3.223359, loss_D: 0.223677\n",
      "[Epoch 158/200] [Batch 410/938] loss_G: 3.492625, loss_D: 0.220088\n",
      "[Epoch 158/200] [Batch 420/938] loss_G: 3.375054, loss_D: 0.159149\n",
      "[Epoch 158/200] [Batch 430/938] loss_G: 3.184110, loss_D: 0.210223\n",
      "[Epoch 158/200] [Batch 440/938] loss_G: 3.036882, loss_D: 0.207077\n",
      "[Epoch 158/200] [Batch 450/938] loss_G: 3.491151, loss_D: 0.146133\n",
      "[Epoch 158/200] [Batch 460/938] loss_G: 3.496315, loss_D: 0.126398\n",
      "[Epoch 158/200] [Batch 470/938] loss_G: 3.649532, loss_D: 0.170954\n",
      "[Epoch 158/200] [Batch 480/938] loss_G: 3.077693, loss_D: 0.308236\n",
      "[Epoch 158/200] [Batch 490/938] loss_G: 3.606703, loss_D: 0.156390\n",
      "[Epoch 158/200] [Batch 500/938] loss_G: 3.610033, loss_D: 0.108813\n",
      "[Epoch 158/200] [Batch 510/938] loss_G: 3.056948, loss_D: 0.196523\n",
      "[Epoch 158/200] [Batch 520/938] loss_G: 3.444042, loss_D: 0.097271\n",
      "[Epoch 158/200] [Batch 530/938] loss_G: 3.194945, loss_D: 0.251060\n",
      "[Epoch 158/200] [Batch 540/938] loss_G: 2.932310, loss_D: 0.171357\n",
      "[Epoch 158/200] [Batch 550/938] loss_G: 2.901033, loss_D: 0.175406\n",
      "[Epoch 158/200] [Batch 560/938] loss_G: 3.490059, loss_D: 0.222242\n",
      "[Epoch 158/200] [Batch 570/938] loss_G: 3.409993, loss_D: 0.222079\n",
      "[Epoch 158/200] [Batch 580/938] loss_G: 3.041350, loss_D: 0.234659\n",
      "[Epoch 158/200] [Batch 590/938] loss_G: 3.492394, loss_D: 0.213225\n",
      "[Epoch 158/200] [Batch 600/938] loss_G: 3.004107, loss_D: 0.258305\n",
      "[Epoch 158/200] [Batch 610/938] loss_G: 3.316877, loss_D: 0.248161\n",
      "[Epoch 158/200] [Batch 620/938] loss_G: 3.334542, loss_D: 0.162077\n",
      "[Epoch 158/200] [Batch 630/938] loss_G: 3.214544, loss_D: 0.248725\n",
      "[Epoch 158/200] [Batch 640/938] loss_G: 3.026213, loss_D: 0.229732\n",
      "[Epoch 158/200] [Batch 650/938] loss_G: 3.403984, loss_D: 0.149426\n",
      "[Epoch 158/200] [Batch 660/938] loss_G: 3.066788, loss_D: 0.203527\n",
      "[Epoch 158/200] [Batch 670/938] loss_G: 3.404145, loss_D: 0.144079\n",
      "[Epoch 158/200] [Batch 680/938] loss_G: 3.562351, loss_D: 0.179185\n",
      "[Epoch 158/200] [Batch 690/938] loss_G: 3.527063, loss_D: 0.187331\n",
      "[Epoch 158/200] [Batch 700/938] loss_G: 2.842799, loss_D: 0.231489\n",
      "[Epoch 158/200] [Batch 710/938] loss_G: 3.457839, loss_D: 0.175382\n",
      "[Epoch 158/200] [Batch 720/938] loss_G: 3.087763, loss_D: 0.248159\n",
      "[Epoch 158/200] [Batch 730/938] loss_G: 3.322929, loss_D: 0.176168\n",
      "[Epoch 158/200] [Batch 740/938] loss_G: 2.668300, loss_D: 0.181792\n",
      "[Epoch 158/200] [Batch 750/938] loss_G: 3.257500, loss_D: 0.161014\n",
      "[Epoch 158/200] [Batch 760/938] loss_G: 3.292653, loss_D: 0.313322\n",
      "[Epoch 158/200] [Batch 770/938] loss_G: 3.385825, loss_D: 0.153434\n",
      "[Epoch 158/200] [Batch 780/938] loss_G: 3.149189, loss_D: 0.164256\n",
      "[Epoch 158/200] [Batch 790/938] loss_G: 3.361918, loss_D: 0.214168\n",
      "[Epoch 158/200] [Batch 800/938] loss_G: 3.537593, loss_D: 0.256971\n",
      "[Epoch 158/200] [Batch 810/938] loss_G: 3.252652, loss_D: 0.173059\n",
      "[Epoch 158/200] [Batch 820/938] loss_G: 3.239678, loss_D: 0.181124\n",
      "[Epoch 158/200] [Batch 830/938] loss_G: 3.075374, loss_D: 0.282850\n",
      "[Epoch 158/200] [Batch 840/938] loss_G: 3.489843, loss_D: 0.196610\n",
      "[Epoch 158/200] [Batch 850/938] loss_G: 3.444074, loss_D: 0.127007\n",
      "[Epoch 158/200] [Batch 860/938] loss_G: 2.808032, loss_D: 0.154808\n",
      "[Epoch 158/200] [Batch 870/938] loss_G: 3.121882, loss_D: 0.227591\n",
      "[Epoch 158/200] [Batch 880/938] loss_G: 3.185098, loss_D: 0.208425\n",
      "[Epoch 158/200] [Batch 890/938] loss_G: 3.237281, loss_D: 0.236857\n",
      "[Epoch 158/200] [Batch 900/938] loss_G: 3.266981, loss_D: 0.251963\n",
      "[Epoch 158/200] [Batch 910/938] loss_G: 3.270000, loss_D: 0.219498\n",
      "[Epoch 158/200] [Batch 920/938] loss_G: 2.806385, loss_D: 0.163235\n",
      "[Epoch 158/200] [Batch 930/938] loss_G: 3.624314, loss_D: 0.225124\n",
      "[Epoch 159/200] [Batch 0/938] loss_G: 3.177139, loss_D: 0.219499\n",
      "[Epoch 159/200] [Batch 10/938] loss_G: 3.182059, loss_D: 0.205358\n",
      "[Epoch 159/200] [Batch 20/938] loss_G: 3.023091, loss_D: 0.239899\n",
      "[Epoch 159/200] [Batch 30/938] loss_G: 3.383513, loss_D: 0.186210\n",
      "[Epoch 159/200] [Batch 40/938] loss_G: 3.396173, loss_D: 0.132447\n",
      "[Epoch 159/200] [Batch 50/938] loss_G: 3.039433, loss_D: 0.227535\n",
      "[Epoch 159/200] [Batch 60/938] loss_G: 3.347978, loss_D: 0.203535\n",
      "[Epoch 159/200] [Batch 70/938] loss_G: 2.783069, loss_D: 0.154489\n",
      "[Epoch 159/200] [Batch 80/938] loss_G: 3.100119, loss_D: 0.225050\n",
      "[Epoch 159/200] [Batch 90/938] loss_G: 3.457255, loss_D: 0.169851\n",
      "[Epoch 159/200] [Batch 100/938] loss_G: 3.181307, loss_D: 0.185290\n",
      "[Epoch 159/200] [Batch 110/938] loss_G: 3.508665, loss_D: 0.149411\n",
      "[Epoch 159/200] [Batch 120/938] loss_G: 3.519871, loss_D: 0.212486\n",
      "[Epoch 159/200] [Batch 130/938] loss_G: 3.448359, loss_D: 0.191589\n",
      "[Epoch 159/200] [Batch 140/938] loss_G: 2.622283, loss_D: 0.216458\n",
      "[Epoch 159/200] [Batch 150/938] loss_G: 3.235534, loss_D: 0.171447\n",
      "[Epoch 159/200] [Batch 160/938] loss_G: 3.652513, loss_D: 0.216227\n",
      "[Epoch 159/200] [Batch 170/938] loss_G: 3.395617, loss_D: 0.193335\n",
      "[Epoch 159/200] [Batch 180/938] loss_G: 3.453825, loss_D: 0.154230\n",
      "[Epoch 159/200] [Batch 190/938] loss_G: 3.318109, loss_D: 0.314204\n",
      "[Epoch 159/200] [Batch 200/938] loss_G: 3.156878, loss_D: 0.280428\n",
      "[Epoch 159/200] [Batch 210/938] loss_G: 3.444738, loss_D: 0.260410\n",
      "[Epoch 159/200] [Batch 220/938] loss_G: 2.829831, loss_D: 0.292700\n",
      "[Epoch 159/200] [Batch 230/938] loss_G: 3.224417, loss_D: 0.224214\n",
      "[Epoch 159/200] [Batch 240/938] loss_G: 3.164454, loss_D: 0.133930\n",
      "[Epoch 159/200] [Batch 250/938] loss_G: 3.429444, loss_D: 0.118244\n",
      "[Epoch 159/200] [Batch 260/938] loss_G: 3.553399, loss_D: 0.236741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 159/200] [Batch 270/938] loss_G: 3.014005, loss_D: 0.211717\n",
      "[Epoch 159/200] [Batch 280/938] loss_G: 3.595977, loss_D: 0.180759\n",
      "[Epoch 159/200] [Batch 290/938] loss_G: 2.876120, loss_D: 0.204773\n",
      "[Epoch 159/200] [Batch 300/938] loss_G: 2.682101, loss_D: 0.237990\n",
      "[Epoch 159/200] [Batch 310/938] loss_G: 3.304016, loss_D: 0.200872\n",
      "[Epoch 159/200] [Batch 320/938] loss_G: 3.381070, loss_D: 0.184997\n",
      "[Epoch 159/200] [Batch 330/938] loss_G: 3.347272, loss_D: 0.104669\n",
      "[Epoch 159/200] [Batch 340/938] loss_G: 3.181380, loss_D: 0.231016\n",
      "[Epoch 159/200] [Batch 350/938] loss_G: 3.805662, loss_D: 0.241425\n",
      "[Epoch 159/200] [Batch 360/938] loss_G: 3.034143, loss_D: 0.153911\n",
      "[Epoch 159/200] [Batch 370/938] loss_G: 3.587185, loss_D: 0.155801\n",
      "[Epoch 159/200] [Batch 380/938] loss_G: 3.450410, loss_D: 0.279783\n",
      "[Epoch 159/200] [Batch 390/938] loss_G: 2.963085, loss_D: 0.189374\n",
      "[Epoch 159/200] [Batch 400/938] loss_G: 3.315257, loss_D: 0.169381\n",
      "[Epoch 159/200] [Batch 410/938] loss_G: 3.486511, loss_D: 0.174582\n",
      "[Epoch 159/200] [Batch 420/938] loss_G: 2.912827, loss_D: 0.218528\n",
      "[Epoch 159/200] [Batch 430/938] loss_G: 3.643907, loss_D: 0.135998\n",
      "[Epoch 159/200] [Batch 440/938] loss_G: 3.285548, loss_D: 0.181026\n",
      "[Epoch 159/200] [Batch 450/938] loss_G: 3.294528, loss_D: 0.200610\n",
      "[Epoch 159/200] [Batch 460/938] loss_G: 3.385556, loss_D: 0.211067\n",
      "[Epoch 159/200] [Batch 470/938] loss_G: 3.340882, loss_D: 0.221048\n",
      "[Epoch 159/200] [Batch 480/938] loss_G: 3.383565, loss_D: 0.137869\n",
      "[Epoch 159/200] [Batch 490/938] loss_G: 3.327315, loss_D: 0.252584\n",
      "[Epoch 159/200] [Batch 500/938] loss_G: 3.340382, loss_D: 0.125067\n",
      "[Epoch 159/200] [Batch 510/938] loss_G: 3.285992, loss_D: 0.247787\n",
      "[Epoch 159/200] [Batch 520/938] loss_G: 3.508806, loss_D: 0.157098\n",
      "[Epoch 159/200] [Batch 530/938] loss_G: 3.212204, loss_D: 0.202898\n",
      "[Epoch 159/200] [Batch 540/938] loss_G: 3.369901, loss_D: 0.255029\n",
      "[Epoch 159/200] [Batch 550/938] loss_G: 3.011539, loss_D: 0.212721\n",
      "[Epoch 159/200] [Batch 560/938] loss_G: 3.220940, loss_D: 0.179068\n",
      "[Epoch 159/200] [Batch 570/938] loss_G: 3.510623, loss_D: 0.114194\n",
      "[Epoch 159/200] [Batch 580/938] loss_G: 3.599472, loss_D: 0.202316\n",
      "[Epoch 159/200] [Batch 590/938] loss_G: 3.404543, loss_D: 0.201911\n",
      "[Epoch 159/200] [Batch 600/938] loss_G: 3.257558, loss_D: 0.252920\n",
      "[Epoch 159/200] [Batch 610/938] loss_G: 3.428483, loss_D: 0.143875\n",
      "[Epoch 159/200] [Batch 620/938] loss_G: 3.306697, loss_D: 0.185884\n",
      "[Epoch 159/200] [Batch 630/938] loss_G: 3.273485, loss_D: 0.161394\n",
      "[Epoch 159/200] [Batch 640/938] loss_G: 3.389887, loss_D: 0.104048\n",
      "[Epoch 159/200] [Batch 650/938] loss_G: 3.643679, loss_D: 0.142082\n",
      "[Epoch 159/200] [Batch 660/938] loss_G: 3.397474, loss_D: 0.244417\n",
      "[Epoch 159/200] [Batch 670/938] loss_G: 2.990701, loss_D: 0.138179\n",
      "[Epoch 159/200] [Batch 680/938] loss_G: 3.582127, loss_D: 0.166326\n",
      "[Epoch 159/200] [Batch 690/938] loss_G: 3.485277, loss_D: 0.164365\n",
      "[Epoch 159/200] [Batch 700/938] loss_G: 3.376336, loss_D: 0.130520\n",
      "[Epoch 159/200] [Batch 710/938] loss_G: 3.847895, loss_D: 0.142349\n",
      "[Epoch 159/200] [Batch 720/938] loss_G: 3.591834, loss_D: 0.219829\n",
      "[Epoch 159/200] [Batch 730/938] loss_G: 3.369663, loss_D: 0.233282\n",
      "[Epoch 159/200] [Batch 740/938] loss_G: 3.620057, loss_D: 0.180095\n",
      "[Epoch 159/200] [Batch 750/938] loss_G: 3.258143, loss_D: 0.175660\n",
      "[Epoch 159/200] [Batch 760/938] loss_G: 3.466948, loss_D: 0.162396\n",
      "[Epoch 159/200] [Batch 770/938] loss_G: 3.042493, loss_D: 0.159208\n",
      "[Epoch 159/200] [Batch 780/938] loss_G: 3.355275, loss_D: 0.294828\n",
      "[Epoch 159/200] [Batch 790/938] loss_G: 3.287223, loss_D: 0.182254\n",
      "[Epoch 159/200] [Batch 800/938] loss_G: 3.501734, loss_D: 0.198172\n",
      "[Epoch 159/200] [Batch 810/938] loss_G: 3.279768, loss_D: 0.162976\n",
      "[Epoch 159/200] [Batch 820/938] loss_G: 3.352872, loss_D: 0.127616\n",
      "[Epoch 159/200] [Batch 830/938] loss_G: 3.227360, loss_D: 0.211095\n",
      "[Epoch 159/200] [Batch 840/938] loss_G: 3.173643, loss_D: 0.170457\n",
      "[Epoch 159/200] [Batch 850/938] loss_G: 3.215095, loss_D: 0.170911\n",
      "[Epoch 159/200] [Batch 860/938] loss_G: 2.942688, loss_D: 0.223059\n",
      "[Epoch 159/200] [Batch 870/938] loss_G: 3.354980, loss_D: 0.153663\n",
      "[Epoch 159/200] [Batch 880/938] loss_G: 3.304038, loss_D: 0.181081\n",
      "[Epoch 159/200] [Batch 890/938] loss_G: 3.528171, loss_D: 0.145891\n",
      "[Epoch 159/200] [Batch 900/938] loss_G: 3.558114, loss_D: 0.109563\n",
      "[Epoch 159/200] [Batch 910/938] loss_G: 3.499051, loss_D: 0.209619\n",
      "[Epoch 159/200] [Batch 920/938] loss_G: 3.310636, loss_D: 0.190997\n",
      "[Epoch 159/200] [Batch 930/938] loss_G: 3.099616, loss_D: 0.253555\n",
      "[Epoch 160/200] [Batch 0/938] loss_G: 3.257691, loss_D: 0.353142\n",
      "[Epoch 160/200] [Batch 10/938] loss_G: 3.399435, loss_D: 0.159045\n",
      "[Epoch 160/200] [Batch 20/938] loss_G: 3.762232, loss_D: 0.179563\n",
      "[Epoch 160/200] [Batch 30/938] loss_G: 3.190161, loss_D: 0.225949\n",
      "[Epoch 160/200] [Batch 40/938] loss_G: 3.433603, loss_D: 0.187570\n",
      "[Epoch 160/200] [Batch 50/938] loss_G: 3.313721, loss_D: 0.228531\n",
      "[Epoch 160/200] [Batch 60/938] loss_G: 3.204533, loss_D: 0.177826\n",
      "[Epoch 160/200] [Batch 70/938] loss_G: 3.215607, loss_D: 0.191323\n",
      "[Epoch 160/200] [Batch 80/938] loss_G: 3.369503, loss_D: 0.122317\n",
      "[Epoch 160/200] [Batch 90/938] loss_G: 3.333507, loss_D: 0.179613\n",
      "[Epoch 160/200] [Batch 100/938] loss_G: 3.576812, loss_D: 0.106999\n",
      "[Epoch 160/200] [Batch 110/938] loss_G: 3.580532, loss_D: 0.243715\n",
      "[Epoch 160/200] [Batch 120/938] loss_G: 3.118617, loss_D: 0.157518\n",
      "[Epoch 160/200] [Batch 130/938] loss_G: 3.365971, loss_D: 0.206463\n",
      "[Epoch 160/200] [Batch 140/938] loss_G: 3.302284, loss_D: 0.117117\n",
      "[Epoch 160/200] [Batch 150/938] loss_G: 2.810086, loss_D: 0.231446\n",
      "[Epoch 160/200] [Batch 160/938] loss_G: 3.719132, loss_D: 0.215504\n",
      "[Epoch 160/200] [Batch 170/938] loss_G: 3.352094, loss_D: 0.218502\n",
      "[Epoch 160/200] [Batch 180/938] loss_G: 3.127597, loss_D: 0.210217\n",
      "[Epoch 160/200] [Batch 190/938] loss_G: 3.796098, loss_D: 0.196201\n",
      "[Epoch 160/200] [Batch 200/938] loss_G: 3.068361, loss_D: 0.227513\n",
      "[Epoch 160/200] [Batch 210/938] loss_G: 3.494389, loss_D: 0.204529\n",
      "[Epoch 160/200] [Batch 220/938] loss_G: 3.376379, loss_D: 0.166739\n",
      "[Epoch 160/200] [Batch 230/938] loss_G: 3.555253, loss_D: 0.160679\n",
      "[Epoch 160/200] [Batch 240/938] loss_G: 3.850066, loss_D: 0.187620\n",
      "[Epoch 160/200] [Batch 250/938] loss_G: 3.072505, loss_D: 0.178563\n",
      "[Epoch 160/200] [Batch 260/938] loss_G: 3.584410, loss_D: 0.165782\n",
      "[Epoch 160/200] [Batch 270/938] loss_G: 3.998311, loss_D: 0.147208\n",
      "[Epoch 160/200] [Batch 280/938] loss_G: 3.400624, loss_D: 0.150711\n",
      "[Epoch 160/200] [Batch 290/938] loss_G: 3.544837, loss_D: 0.156478\n",
      "[Epoch 160/200] [Batch 300/938] loss_G: 3.058699, loss_D: 0.170825\n",
      "[Epoch 160/200] [Batch 310/938] loss_G: 3.294011, loss_D: 0.167719\n",
      "[Epoch 160/200] [Batch 320/938] loss_G: 3.219254, loss_D: 0.287474\n",
      "[Epoch 160/200] [Batch 330/938] loss_G: 3.065445, loss_D: 0.293949\n",
      "[Epoch 160/200] [Batch 340/938] loss_G: 3.541198, loss_D: 0.186029\n",
      "[Epoch 160/200] [Batch 350/938] loss_G: 3.688398, loss_D: 0.169329\n",
      "[Epoch 160/200] [Batch 360/938] loss_G: 3.732075, loss_D: 0.201804\n",
      "[Epoch 160/200] [Batch 370/938] loss_G: 3.376560, loss_D: 0.166270\n",
      "[Epoch 160/200] [Batch 380/938] loss_G: 3.297530, loss_D: 0.181271\n",
      "[Epoch 160/200] [Batch 390/938] loss_G: 3.394908, loss_D: 0.146846\n",
      "[Epoch 160/200] [Batch 400/938] loss_G: 3.613026, loss_D: 0.154200\n",
      "[Epoch 160/200] [Batch 410/938] loss_G: 3.623128, loss_D: 0.164060\n",
      "[Epoch 160/200] [Batch 420/938] loss_G: 3.491477, loss_D: 0.198117\n",
      "[Epoch 160/200] [Batch 430/938] loss_G: 3.805636, loss_D: 0.232507\n",
      "[Epoch 160/200] [Batch 440/938] loss_G: 3.527575, loss_D: 0.204245\n",
      "[Epoch 160/200] [Batch 450/938] loss_G: 3.098451, loss_D: 0.277234\n",
      "[Epoch 160/200] [Batch 460/938] loss_G: 3.396423, loss_D: 0.151474\n",
      "[Epoch 160/200] [Batch 470/938] loss_G: 3.298051, loss_D: 0.176178\n",
      "[Epoch 160/200] [Batch 480/938] loss_G: 3.132532, loss_D: 0.123772\n",
      "[Epoch 160/200] [Batch 490/938] loss_G: 3.272870, loss_D: 0.196679\n",
      "[Epoch 160/200] [Batch 500/938] loss_G: 3.371624, loss_D: 0.201473\n",
      "[Epoch 160/200] [Batch 510/938] loss_G: 3.107313, loss_D: 0.228965\n",
      "[Epoch 160/200] [Batch 520/938] loss_G: 3.786328, loss_D: 0.225807\n",
      "[Epoch 160/200] [Batch 530/938] loss_G: 2.997368, loss_D: 0.243762\n",
      "[Epoch 160/200] [Batch 540/938] loss_G: 3.346441, loss_D: 0.100849\n",
      "[Epoch 160/200] [Batch 550/938] loss_G: 3.479144, loss_D: 0.164389\n",
      "[Epoch 160/200] [Batch 560/938] loss_G: 3.094356, loss_D: 0.270477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 160/200] [Batch 570/938] loss_G: 3.610186, loss_D: 0.133541\n",
      "[Epoch 160/200] [Batch 580/938] loss_G: 3.432235, loss_D: 0.192949\n",
      "[Epoch 160/200] [Batch 590/938] loss_G: 3.700398, loss_D: 0.196741\n",
      "[Epoch 160/200] [Batch 600/938] loss_G: 3.104383, loss_D: 0.297179\n",
      "[Epoch 160/200] [Batch 610/938] loss_G: 3.314574, loss_D: 0.195841\n",
      "[Epoch 160/200] [Batch 620/938] loss_G: 3.343075, loss_D: 0.130469\n",
      "[Epoch 160/200] [Batch 630/938] loss_G: 3.219514, loss_D: 0.195069\n",
      "[Epoch 160/200] [Batch 640/938] loss_G: 3.115425, loss_D: 0.192034\n",
      "[Epoch 160/200] [Batch 650/938] loss_G: 3.359722, loss_D: 0.217510\n",
      "[Epoch 160/200] [Batch 660/938] loss_G: 3.508440, loss_D: 0.169900\n",
      "[Epoch 160/200] [Batch 670/938] loss_G: 3.107572, loss_D: 0.177268\n",
      "[Epoch 160/200] [Batch 680/938] loss_G: 3.385964, loss_D: 0.198337\n",
      "[Epoch 160/200] [Batch 690/938] loss_G: 3.154290, loss_D: 0.213727\n",
      "[Epoch 160/200] [Batch 700/938] loss_G: 3.590971, loss_D: 0.134637\n",
      "[Epoch 160/200] [Batch 710/938] loss_G: 3.232884, loss_D: 0.119077\n",
      "[Epoch 160/200] [Batch 720/938] loss_G: 3.587580, loss_D: 0.097887\n",
      "[Epoch 160/200] [Batch 730/938] loss_G: 3.108557, loss_D: 0.201782\n",
      "[Epoch 160/200] [Batch 740/938] loss_G: 3.533003, loss_D: 0.250897\n",
      "[Epoch 160/200] [Batch 750/938] loss_G: 3.289864, loss_D: 0.161141\n",
      "[Epoch 160/200] [Batch 760/938] loss_G: 3.140088, loss_D: 0.204140\n",
      "[Epoch 160/200] [Batch 770/938] loss_G: 2.798943, loss_D: 0.216888\n",
      "[Epoch 160/200] [Batch 780/938] loss_G: 3.317184, loss_D: 0.255448\n",
      "[Epoch 160/200] [Batch 790/938] loss_G: 3.280756, loss_D: 0.324841\n",
      "[Epoch 160/200] [Batch 800/938] loss_G: 2.900602, loss_D: 0.112792\n",
      "[Epoch 160/200] [Batch 810/938] loss_G: 3.268222, loss_D: 0.209238\n",
      "[Epoch 160/200] [Batch 820/938] loss_G: 3.626191, loss_D: 0.219077\n",
      "[Epoch 160/200] [Batch 830/938] loss_G: 2.749854, loss_D: 0.285937\n",
      "[Epoch 160/200] [Batch 840/938] loss_G: 3.048891, loss_D: 0.318269\n",
      "[Epoch 160/200] [Batch 850/938] loss_G: 3.438308, loss_D: 0.159250\n",
      "[Epoch 160/200] [Batch 860/938] loss_G: 3.099606, loss_D: 0.184550\n",
      "[Epoch 160/200] [Batch 870/938] loss_G: 3.427619, loss_D: 0.178052\n",
      "[Epoch 160/200] [Batch 880/938] loss_G: 3.790434, loss_D: 0.235704\n",
      "[Epoch 160/200] [Batch 890/938] loss_G: 3.115449, loss_D: 0.182736\n",
      "[Epoch 160/200] [Batch 900/938] loss_G: 3.528803, loss_D: 0.164569\n",
      "[Epoch 160/200] [Batch 910/938] loss_G: 3.288887, loss_D: 0.195933\n",
      "[Epoch 160/200] [Batch 920/938] loss_G: 3.315827, loss_D: 0.180027\n",
      "[Epoch 160/200] [Batch 930/938] loss_G: 3.455603, loss_D: 0.183552\n",
      "[Epoch 161/200] [Batch 0/938] loss_G: 3.321149, loss_D: 0.175160\n",
      "[Epoch 161/200] [Batch 10/938] loss_G: 3.404621, loss_D: 0.214461\n",
      "[Epoch 161/200] [Batch 20/938] loss_G: 3.513211, loss_D: 0.162305\n",
      "[Epoch 161/200] [Batch 30/938] loss_G: 2.839999, loss_D: 0.188563\n",
      "[Epoch 161/200] [Batch 40/938] loss_G: 3.310230, loss_D: 0.220735\n",
      "[Epoch 161/200] [Batch 50/938] loss_G: 3.572779, loss_D: 0.136391\n",
      "[Epoch 161/200] [Batch 60/938] loss_G: 3.790164, loss_D: 0.115645\n",
      "[Epoch 161/200] [Batch 70/938] loss_G: 3.460640, loss_D: 0.177548\n",
      "[Epoch 161/200] [Batch 80/938] loss_G: 2.840951, loss_D: 0.215039\n",
      "[Epoch 161/200] [Batch 90/938] loss_G: 3.889268, loss_D: 0.156506\n",
      "[Epoch 161/200] [Batch 100/938] loss_G: 3.599259, loss_D: 0.149314\n",
      "[Epoch 161/200] [Batch 110/938] loss_G: 3.681993, loss_D: 0.114472\n",
      "[Epoch 161/200] [Batch 120/938] loss_G: 3.655773, loss_D: 0.131245\n",
      "[Epoch 161/200] [Batch 130/938] loss_G: 2.919981, loss_D: 0.205248\n",
      "[Epoch 161/200] [Batch 140/938] loss_G: 3.240461, loss_D: 0.208639\n",
      "[Epoch 161/200] [Batch 150/938] loss_G: 3.423889, loss_D: 0.238942\n",
      "[Epoch 161/200] [Batch 160/938] loss_G: 3.265818, loss_D: 0.174460\n",
      "[Epoch 161/200] [Batch 170/938] loss_G: 3.339416, loss_D: 0.191133\n",
      "[Epoch 161/200] [Batch 180/938] loss_G: 2.928162, loss_D: 0.163832\n",
      "[Epoch 161/200] [Batch 190/938] loss_G: 3.141223, loss_D: 0.182701\n",
      "[Epoch 161/200] [Batch 200/938] loss_G: 3.306317, loss_D: 0.158649\n",
      "[Epoch 161/200] [Batch 210/938] loss_G: 3.066750, loss_D: 0.190876\n",
      "[Epoch 161/200] [Batch 220/938] loss_G: 3.291080, loss_D: 0.200274\n",
      "[Epoch 161/200] [Batch 230/938] loss_G: 3.486103, loss_D: 0.210855\n",
      "[Epoch 161/200] [Batch 240/938] loss_G: 3.712951, loss_D: 0.165767\n",
      "[Epoch 161/200] [Batch 250/938] loss_G: 3.570286, loss_D: 0.154893\n",
      "[Epoch 161/200] [Batch 260/938] loss_G: 3.098870, loss_D: 0.126787\n",
      "[Epoch 161/200] [Batch 270/938] loss_G: 3.931690, loss_D: 0.124140\n",
      "[Epoch 161/200] [Batch 280/938] loss_G: 3.137543, loss_D: 0.231601\n",
      "[Epoch 161/200] [Batch 290/938] loss_G: 3.262539, loss_D: 0.185205\n",
      "[Epoch 161/200] [Batch 300/938] loss_G: 3.510697, loss_D: 0.111384\n",
      "[Epoch 161/200] [Batch 310/938] loss_G: 3.580978, loss_D: 0.154070\n",
      "[Epoch 161/200] [Batch 320/938] loss_G: 3.177669, loss_D: 0.164305\n",
      "[Epoch 161/200] [Batch 330/938] loss_G: 3.319317, loss_D: 0.181964\n",
      "[Epoch 161/200] [Batch 340/938] loss_G: 3.858731, loss_D: 0.162426\n",
      "[Epoch 161/200] [Batch 350/938] loss_G: 3.390022, loss_D: 0.146120\n",
      "[Epoch 161/200] [Batch 360/938] loss_G: 3.184900, loss_D: 0.159687\n",
      "[Epoch 161/200] [Batch 370/938] loss_G: 2.793911, loss_D: 0.175188\n",
      "[Epoch 161/200] [Batch 380/938] loss_G: 3.025982, loss_D: 0.206444\n",
      "[Epoch 161/200] [Batch 390/938] loss_G: 3.193629, loss_D: 0.176222\n",
      "[Epoch 161/200] [Batch 400/938] loss_G: 3.748214, loss_D: 0.196816\n",
      "[Epoch 161/200] [Batch 410/938] loss_G: 3.413006, loss_D: 0.288937\n",
      "[Epoch 161/200] [Batch 420/938] loss_G: 3.671880, loss_D: 0.160654\n",
      "[Epoch 161/200] [Batch 430/938] loss_G: 3.490229, loss_D: 0.151817\n",
      "[Epoch 161/200] [Batch 440/938] loss_G: 3.468863, loss_D: 0.183774\n",
      "[Epoch 161/200] [Batch 450/938] loss_G: 3.246857, loss_D: 0.122861\n",
      "[Epoch 161/200] [Batch 460/938] loss_G: 2.996109, loss_D: 0.238441\n",
      "[Epoch 161/200] [Batch 470/938] loss_G: 3.538022, loss_D: 0.224570\n",
      "[Epoch 161/200] [Batch 480/938] loss_G: 3.396976, loss_D: 0.121006\n",
      "[Epoch 161/200] [Batch 490/938] loss_G: 3.536610, loss_D: 0.234467\n",
      "[Epoch 161/200] [Batch 500/938] loss_G: 3.419172, loss_D: 0.189671\n",
      "[Epoch 161/200] [Batch 510/938] loss_G: 3.226455, loss_D: 0.125709\n",
      "[Epoch 161/200] [Batch 520/938] loss_G: 3.182560, loss_D: 0.147706\n",
      "[Epoch 161/200] [Batch 530/938] loss_G: 3.440391, loss_D: 0.184185\n",
      "[Epoch 161/200] [Batch 540/938] loss_G: 3.034134, loss_D: 0.157884\n",
      "[Epoch 161/200] [Batch 550/938] loss_G: 3.352343, loss_D: 0.189476\n",
      "[Epoch 161/200] [Batch 560/938] loss_G: 3.081765, loss_D: 0.218552\n",
      "[Epoch 161/200] [Batch 570/938] loss_G: 3.160969, loss_D: 0.201205\n",
      "[Epoch 161/200] [Batch 580/938] loss_G: 3.384856, loss_D: 0.195484\n",
      "[Epoch 161/200] [Batch 590/938] loss_G: 3.133096, loss_D: 0.212184\n",
      "[Epoch 161/200] [Batch 600/938] loss_G: 3.361959, loss_D: 0.196803\n",
      "[Epoch 161/200] [Batch 610/938] loss_G: 3.425435, loss_D: 0.272059\n",
      "[Epoch 161/200] [Batch 620/938] loss_G: 3.585355, loss_D: 0.208722\n",
      "[Epoch 161/200] [Batch 630/938] loss_G: 3.318564, loss_D: 0.210264\n",
      "[Epoch 161/200] [Batch 640/938] loss_G: 3.483088, loss_D: 0.145126\n",
      "[Epoch 161/200] [Batch 650/938] loss_G: 3.314111, loss_D: 0.176201\n",
      "[Epoch 161/200] [Batch 660/938] loss_G: 3.050722, loss_D: 0.180291\n",
      "[Epoch 161/200] [Batch 670/938] loss_G: 3.364822, loss_D: 0.178481\n",
      "[Epoch 161/200] [Batch 680/938] loss_G: 3.641768, loss_D: 0.246583\n",
      "[Epoch 161/200] [Batch 690/938] loss_G: 3.684175, loss_D: 0.168095\n",
      "[Epoch 161/200] [Batch 700/938] loss_G: 3.358392, loss_D: 0.205492\n",
      "[Epoch 161/200] [Batch 710/938] loss_G: 3.282522, loss_D: 0.265140\n",
      "[Epoch 161/200] [Batch 720/938] loss_G: 3.234655, loss_D: 0.275330\n",
      "[Epoch 161/200] [Batch 730/938] loss_G: 3.359022, loss_D: 0.133626\n",
      "[Epoch 161/200] [Batch 740/938] loss_G: 3.361004, loss_D: 0.152120\n",
      "[Epoch 161/200] [Batch 750/938] loss_G: 3.326400, loss_D: 0.168576\n",
      "[Epoch 161/200] [Batch 760/938] loss_G: 3.110654, loss_D: 0.174812\n",
      "[Epoch 161/200] [Batch 770/938] loss_G: 3.443545, loss_D: 0.258281\n",
      "[Epoch 161/200] [Batch 780/938] loss_G: 3.293733, loss_D: 0.196799\n",
      "[Epoch 161/200] [Batch 790/938] loss_G: 3.018776, loss_D: 0.202693\n",
      "[Epoch 161/200] [Batch 800/938] loss_G: 3.282828, loss_D: 0.110355\n",
      "[Epoch 161/200] [Batch 810/938] loss_G: 3.279896, loss_D: 0.131919\n",
      "[Epoch 161/200] [Batch 820/938] loss_G: 3.682273, loss_D: 0.158796\n",
      "[Epoch 161/200] [Batch 830/938] loss_G: 2.910617, loss_D: 0.180307\n",
      "[Epoch 161/200] [Batch 840/938] loss_G: 3.491155, loss_D: 0.167645\n",
      "[Epoch 161/200] [Batch 850/938] loss_G: 3.177521, loss_D: 0.140598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 161/200] [Batch 860/938] loss_G: 3.045532, loss_D: 0.167685\n",
      "[Epoch 161/200] [Batch 870/938] loss_G: 3.518236, loss_D: 0.171784\n",
      "[Epoch 161/200] [Batch 880/938] loss_G: 3.557941, loss_D: 0.223326\n",
      "[Epoch 161/200] [Batch 890/938] loss_G: 3.726959, loss_D: 0.113830\n",
      "[Epoch 161/200] [Batch 900/938] loss_G: 3.245835, loss_D: 0.227151\n",
      "[Epoch 161/200] [Batch 910/938] loss_G: 3.398510, loss_D: 0.210693\n",
      "[Epoch 161/200] [Batch 920/938] loss_G: 3.023192, loss_D: 0.168982\n",
      "[Epoch 161/200] [Batch 930/938] loss_G: 3.170789, loss_D: 0.217051\n",
      "[Epoch 162/200] [Batch 0/938] loss_G: 3.274454, loss_D: 0.168786\n",
      "[Epoch 162/200] [Batch 10/938] loss_G: 3.733440, loss_D: 0.179983\n",
      "[Epoch 162/200] [Batch 20/938] loss_G: 3.160903, loss_D: 0.163344\n",
      "[Epoch 162/200] [Batch 30/938] loss_G: 3.389105, loss_D: 0.289358\n",
      "[Epoch 162/200] [Batch 40/938] loss_G: 3.288891, loss_D: 0.238634\n",
      "[Epoch 162/200] [Batch 50/938] loss_G: 3.052563, loss_D: 0.163353\n",
      "[Epoch 162/200] [Batch 60/938] loss_G: 3.263529, loss_D: 0.091898\n",
      "[Epoch 162/200] [Batch 70/938] loss_G: 3.100051, loss_D: 0.100696\n",
      "[Epoch 162/200] [Batch 80/938] loss_G: 3.431234, loss_D: 0.188398\n",
      "[Epoch 162/200] [Batch 90/938] loss_G: 3.589788, loss_D: 0.245837\n",
      "[Epoch 162/200] [Batch 100/938] loss_G: 3.460418, loss_D: 0.211397\n",
      "[Epoch 162/200] [Batch 110/938] loss_G: 3.087937, loss_D: 0.223746\n",
      "[Epoch 162/200] [Batch 120/938] loss_G: 3.407626, loss_D: 0.178328\n",
      "[Epoch 162/200] [Batch 130/938] loss_G: 2.913042, loss_D: 0.276594\n",
      "[Epoch 162/200] [Batch 140/938] loss_G: 3.185972, loss_D: 0.195779\n",
      "[Epoch 162/200] [Batch 150/938] loss_G: 3.485975, loss_D: 0.129655\n",
      "[Epoch 162/200] [Batch 160/938] loss_G: 3.376663, loss_D: 0.155683\n",
      "[Epoch 162/200] [Batch 170/938] loss_G: 3.564500, loss_D: 0.136200\n",
      "[Epoch 162/200] [Batch 180/938] loss_G: 3.455546, loss_D: 0.142512\n",
      "[Epoch 162/200] [Batch 190/938] loss_G: 3.549202, loss_D: 0.300591\n",
      "[Epoch 162/200] [Batch 200/938] loss_G: 3.348720, loss_D: 0.172162\n",
      "[Epoch 162/200] [Batch 210/938] loss_G: 3.434693, loss_D: 0.199696\n",
      "[Epoch 162/200] [Batch 220/938] loss_G: 3.361746, loss_D: 0.194757\n",
      "[Epoch 162/200] [Batch 230/938] loss_G: 3.332118, loss_D: 0.181682\n",
      "[Epoch 162/200] [Batch 240/938] loss_G: 3.417321, loss_D: 0.195126\n",
      "[Epoch 162/200] [Batch 250/938] loss_G: 3.295033, loss_D: 0.242283\n",
      "[Epoch 162/200] [Batch 260/938] loss_G: 2.851694, loss_D: 0.178336\n",
      "[Epoch 162/200] [Batch 270/938] loss_G: 3.643878, loss_D: 0.251202\n",
      "[Epoch 162/200] [Batch 280/938] loss_G: 3.226541, loss_D: 0.201677\n",
      "[Epoch 162/200] [Batch 290/938] loss_G: 3.825146, loss_D: 0.191270\n",
      "[Epoch 162/200] [Batch 300/938] loss_G: 3.433558, loss_D: 0.152383\n",
      "[Epoch 162/200] [Batch 310/938] loss_G: 3.402191, loss_D: 0.229719\n",
      "[Epoch 162/200] [Batch 320/938] loss_G: 3.623882, loss_D: 0.099998\n",
      "[Epoch 162/200] [Batch 330/938] loss_G: 3.299479, loss_D: 0.169047\n",
      "[Epoch 162/200] [Batch 340/938] loss_G: 3.540736, loss_D: 0.221377\n",
      "[Epoch 162/200] [Batch 350/938] loss_G: 3.177822, loss_D: 0.183529\n",
      "[Epoch 162/200] [Batch 360/938] loss_G: 3.173755, loss_D: 0.181975\n",
      "[Epoch 162/200] [Batch 370/938] loss_G: 3.254973, loss_D: 0.137676\n",
      "[Epoch 162/200] [Batch 380/938] loss_G: 3.383002, loss_D: 0.141094\n",
      "[Epoch 162/200] [Batch 390/938] loss_G: 3.650798, loss_D: 0.170019\n",
      "[Epoch 162/200] [Batch 400/938] loss_G: 3.494092, loss_D: 0.208658\n",
      "[Epoch 162/200] [Batch 410/938] loss_G: 3.111331, loss_D: 0.194308\n",
      "[Epoch 162/200] [Batch 420/938] loss_G: 3.200095, loss_D: 0.220412\n",
      "[Epoch 162/200] [Batch 430/938] loss_G: 2.683490, loss_D: 0.260874\n",
      "[Epoch 162/200] [Batch 440/938] loss_G: 3.338447, loss_D: 0.240985\n",
      "[Epoch 162/200] [Batch 450/938] loss_G: 3.253004, loss_D: 0.246942\n",
      "[Epoch 162/200] [Batch 460/938] loss_G: 3.543737, loss_D: 0.187075\n",
      "[Epoch 162/200] [Batch 470/938] loss_G: 3.116384, loss_D: 0.253431\n",
      "[Epoch 162/200] [Batch 480/938] loss_G: 3.181145, loss_D: 0.219520\n",
      "[Epoch 162/200] [Batch 490/938] loss_G: 2.765239, loss_D: 0.206178\n",
      "[Epoch 162/200] [Batch 500/938] loss_G: 3.469633, loss_D: 0.141376\n",
      "[Epoch 162/200] [Batch 510/938] loss_G: 3.785333, loss_D: 0.223915\n",
      "[Epoch 162/200] [Batch 520/938] loss_G: 2.956464, loss_D: 0.274870\n",
      "[Epoch 162/200] [Batch 530/938] loss_G: 3.301525, loss_D: 0.193108\n",
      "[Epoch 162/200] [Batch 540/938] loss_G: 3.531020, loss_D: 0.206466\n",
      "[Epoch 162/200] [Batch 550/938] loss_G: 3.229607, loss_D: 0.277126\n",
      "[Epoch 162/200] [Batch 560/938] loss_G: 3.704185, loss_D: 0.235524\n",
      "[Epoch 162/200] [Batch 570/938] loss_G: 3.629510, loss_D: 0.216229\n",
      "[Epoch 162/200] [Batch 580/938] loss_G: 3.423295, loss_D: 0.120004\n",
      "[Epoch 162/200] [Batch 590/938] loss_G: 3.258309, loss_D: 0.186563\n",
      "[Epoch 162/200] [Batch 600/938] loss_G: 3.368272, loss_D: 0.166534\n",
      "[Epoch 162/200] [Batch 610/938] loss_G: 3.506551, loss_D: 0.168373\n",
      "[Epoch 162/200] [Batch 620/938] loss_G: 3.380056, loss_D: 0.199019\n",
      "[Epoch 162/200] [Batch 630/938] loss_G: 3.529237, loss_D: 0.261767\n",
      "[Epoch 162/200] [Batch 640/938] loss_G: 3.048244, loss_D: 0.184536\n",
      "[Epoch 162/200] [Batch 650/938] loss_G: 3.023367, loss_D: 0.209031\n",
      "[Epoch 162/200] [Batch 660/938] loss_G: 3.346625, loss_D: 0.208194\n",
      "[Epoch 162/200] [Batch 670/938] loss_G: 3.120685, loss_D: 0.183713\n",
      "[Epoch 162/200] [Batch 680/938] loss_G: 3.121198, loss_D: 0.217288\n",
      "[Epoch 162/200] [Batch 690/938] loss_G: 3.073442, loss_D: 0.165682\n",
      "[Epoch 162/200] [Batch 700/938] loss_G: 3.111404, loss_D: 0.240658\n",
      "[Epoch 162/200] [Batch 710/938] loss_G: 2.842336, loss_D: 0.202949\n",
      "[Epoch 162/200] [Batch 720/938] loss_G: 3.453067, loss_D: 0.207229\n",
      "[Epoch 162/200] [Batch 730/938] loss_G: 3.737286, loss_D: 0.149149\n",
      "[Epoch 162/200] [Batch 740/938] loss_G: 3.353507, loss_D: 0.172916\n",
      "[Epoch 162/200] [Batch 750/938] loss_G: 3.232010, loss_D: 0.238183\n",
      "[Epoch 162/200] [Batch 760/938] loss_G: 3.339140, loss_D: 0.245170\n",
      "[Epoch 162/200] [Batch 770/938] loss_G: 2.929658, loss_D: 0.366093\n",
      "[Epoch 162/200] [Batch 780/938] loss_G: 3.351842, loss_D: 0.192006\n",
      "[Epoch 162/200] [Batch 790/938] loss_G: 3.520983, loss_D: 0.212841\n",
      "[Epoch 162/200] [Batch 800/938] loss_G: 3.850601, loss_D: 0.277354\n",
      "[Epoch 162/200] [Batch 810/938] loss_G: 3.375044, loss_D: 0.189648\n",
      "[Epoch 162/200] [Batch 820/938] loss_G: 3.177480, loss_D: 0.192322\n",
      "[Epoch 162/200] [Batch 830/938] loss_G: 3.165932, loss_D: 0.128731\n",
      "[Epoch 162/200] [Batch 840/938] loss_G: 3.179402, loss_D: 0.213368\n",
      "[Epoch 162/200] [Batch 850/938] loss_G: 3.137891, loss_D: 0.159920\n",
      "[Epoch 162/200] [Batch 860/938] loss_G: 3.201599, loss_D: 0.232855\n",
      "[Epoch 162/200] [Batch 870/938] loss_G: 3.129516, loss_D: 0.207200\n",
      "[Epoch 162/200] [Batch 880/938] loss_G: 3.156505, loss_D: 0.223160\n",
      "[Epoch 162/200] [Batch 890/938] loss_G: 2.894839, loss_D: 0.222298\n",
      "[Epoch 162/200] [Batch 900/938] loss_G: 3.406527, loss_D: 0.153475\n",
      "[Epoch 162/200] [Batch 910/938] loss_G: 3.018147, loss_D: 0.223062\n",
      "[Epoch 162/200] [Batch 920/938] loss_G: 3.257021, loss_D: 0.111953\n",
      "[Epoch 162/200] [Batch 930/938] loss_G: 3.181363, loss_D: 0.170824\n",
      "[Epoch 163/200] [Batch 0/938] loss_G: 3.331956, loss_D: 0.203233\n",
      "[Epoch 163/200] [Batch 10/938] loss_G: 3.563248, loss_D: 0.189154\n",
      "[Epoch 163/200] [Batch 20/938] loss_G: 3.762297, loss_D: 0.157839\n",
      "[Epoch 163/200] [Batch 30/938] loss_G: 3.785595, loss_D: 0.177946\n",
      "[Epoch 163/200] [Batch 40/938] loss_G: 2.980816, loss_D: 0.239764\n",
      "[Epoch 163/200] [Batch 50/938] loss_G: 3.796201, loss_D: 0.192525\n",
      "[Epoch 163/200] [Batch 60/938] loss_G: 3.367038, loss_D: 0.174748\n",
      "[Epoch 163/200] [Batch 70/938] loss_G: 3.008365, loss_D: 0.194667\n",
      "[Epoch 163/200] [Batch 80/938] loss_G: 3.541775, loss_D: 0.251649\n",
      "[Epoch 163/200] [Batch 90/938] loss_G: 3.433477, loss_D: 0.194468\n",
      "[Epoch 163/200] [Batch 100/938] loss_G: 3.541592, loss_D: 0.117987\n",
      "[Epoch 163/200] [Batch 110/938] loss_G: 3.236847, loss_D: 0.172316\n",
      "[Epoch 163/200] [Batch 120/938] loss_G: 3.281969, loss_D: 0.165599\n",
      "[Epoch 163/200] [Batch 130/938] loss_G: 3.698245, loss_D: 0.191878\n",
      "[Epoch 163/200] [Batch 140/938] loss_G: 3.117858, loss_D: 0.180025\n",
      "[Epoch 163/200] [Batch 150/938] loss_G: 3.711309, loss_D: 0.173503\n",
      "[Epoch 163/200] [Batch 160/938] loss_G: 2.861730, loss_D: 0.316884\n",
      "[Epoch 163/200] [Batch 170/938] loss_G: 3.261782, loss_D: 0.147392\n",
      "[Epoch 163/200] [Batch 180/938] loss_G: 3.610094, loss_D: 0.243915\n",
      "[Epoch 163/200] [Batch 190/938] loss_G: 2.668435, loss_D: 0.198973\n",
      "[Epoch 163/200] [Batch 200/938] loss_G: 3.538417, loss_D: 0.154473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 163/200] [Batch 210/938] loss_G: 3.589269, loss_D: 0.196981\n",
      "[Epoch 163/200] [Batch 220/938] loss_G: 3.268844, loss_D: 0.163423\n",
      "[Epoch 163/200] [Batch 230/938] loss_G: 3.144790, loss_D: 0.191117\n",
      "[Epoch 163/200] [Batch 240/938] loss_G: 3.416066, loss_D: 0.144996\n",
      "[Epoch 163/200] [Batch 250/938] loss_G: 3.737904, loss_D: 0.219160\n",
      "[Epoch 163/200] [Batch 260/938] loss_G: 3.558043, loss_D: 0.198314\n",
      "[Epoch 163/200] [Batch 270/938] loss_G: 3.464437, loss_D: 0.259861\n",
      "[Epoch 163/200] [Batch 280/938] loss_G: 3.644203, loss_D: 0.170416\n",
      "[Epoch 163/200] [Batch 290/938] loss_G: 3.439274, loss_D: 0.165563\n",
      "[Epoch 163/200] [Batch 300/938] loss_G: 3.427668, loss_D: 0.195527\n",
      "[Epoch 163/200] [Batch 310/938] loss_G: 3.124211, loss_D: 0.274740\n",
      "[Epoch 163/200] [Batch 320/938] loss_G: 3.276784, loss_D: 0.254802\n",
      "[Epoch 163/200] [Batch 330/938] loss_G: 3.236789, loss_D: 0.177627\n",
      "[Epoch 163/200] [Batch 340/938] loss_G: 3.382180, loss_D: 0.150256\n",
      "[Epoch 163/200] [Batch 350/938] loss_G: 3.415677, loss_D: 0.162358\n",
      "[Epoch 163/200] [Batch 360/938] loss_G: 2.758976, loss_D: 0.168185\n",
      "[Epoch 163/200] [Batch 370/938] loss_G: 3.450101, loss_D: 0.199462\n",
      "[Epoch 163/200] [Batch 380/938] loss_G: 3.329447, loss_D: 0.138660\n",
      "[Epoch 163/200] [Batch 390/938] loss_G: 3.640423, loss_D: 0.249825\n",
      "[Epoch 163/200] [Batch 400/938] loss_G: 3.409375, loss_D: 0.256836\n",
      "[Epoch 163/200] [Batch 410/938] loss_G: 3.416060, loss_D: 0.155611\n",
      "[Epoch 163/200] [Batch 420/938] loss_G: 4.082490, loss_D: 0.173797\n",
      "[Epoch 163/200] [Batch 430/938] loss_G: 3.151615, loss_D: 0.187739\n",
      "[Epoch 163/200] [Batch 440/938] loss_G: 3.498008, loss_D: 0.180082\n",
      "[Epoch 163/200] [Batch 450/938] loss_G: 3.115133, loss_D: 0.147799\n",
      "[Epoch 163/200] [Batch 460/938] loss_G: 3.190235, loss_D: 0.270054\n",
      "[Epoch 163/200] [Batch 470/938] loss_G: 3.149039, loss_D: 0.122944\n",
      "[Epoch 163/200] [Batch 480/938] loss_G: 3.466568, loss_D: 0.180749\n",
      "[Epoch 163/200] [Batch 490/938] loss_G: 3.280623, loss_D: 0.185967\n",
      "[Epoch 163/200] [Batch 500/938] loss_G: 3.331621, loss_D: 0.140188\n",
      "[Epoch 163/200] [Batch 510/938] loss_G: 3.563398, loss_D: 0.163118\n",
      "[Epoch 163/200] [Batch 520/938] loss_G: 3.034614, loss_D: 0.158650\n",
      "[Epoch 163/200] [Batch 530/938] loss_G: 3.464336, loss_D: 0.253639\n",
      "[Epoch 163/200] [Batch 540/938] loss_G: 3.394935, loss_D: 0.131860\n",
      "[Epoch 163/200] [Batch 550/938] loss_G: 3.222699, loss_D: 0.129913\n",
      "[Epoch 163/200] [Batch 560/938] loss_G: 3.588840, loss_D: 0.144716\n",
      "[Epoch 163/200] [Batch 570/938] loss_G: 3.258084, loss_D: 0.188752\n",
      "[Epoch 163/200] [Batch 580/938] loss_G: 3.117126, loss_D: 0.211891\n",
      "[Epoch 163/200] [Batch 590/938] loss_G: 3.449125, loss_D: 0.133595\n",
      "[Epoch 163/200] [Batch 600/938] loss_G: 2.911858, loss_D: 0.212512\n",
      "[Epoch 163/200] [Batch 610/938] loss_G: 3.365255, loss_D: 0.200921\n",
      "[Epoch 163/200] [Batch 620/938] loss_G: 3.691601, loss_D: 0.185669\n",
      "[Epoch 163/200] [Batch 630/938] loss_G: 3.272251, loss_D: 0.150324\n",
      "[Epoch 163/200] [Batch 640/938] loss_G: 2.739954, loss_D: 0.170601\n",
      "[Epoch 163/200] [Batch 650/938] loss_G: 3.541937, loss_D: 0.194058\n",
      "[Epoch 163/200] [Batch 660/938] loss_G: 3.517260, loss_D: 0.200245\n",
      "[Epoch 163/200] [Batch 670/938] loss_G: 3.313785, loss_D: 0.180617\n",
      "[Epoch 163/200] [Batch 680/938] loss_G: 3.592199, loss_D: 0.153124\n",
      "[Epoch 163/200] [Batch 690/938] loss_G: 3.417319, loss_D: 0.186611\n",
      "[Epoch 163/200] [Batch 700/938] loss_G: 3.513278, loss_D: 0.176280\n",
      "[Epoch 163/200] [Batch 710/938] loss_G: 3.185451, loss_D: 0.165214\n",
      "[Epoch 163/200] [Batch 720/938] loss_G: 3.031043, loss_D: 0.217486\n",
      "[Epoch 163/200] [Batch 730/938] loss_G: 3.336374, loss_D: 0.218713\n",
      "[Epoch 163/200] [Batch 740/938] loss_G: 3.076378, loss_D: 0.287743\n",
      "[Epoch 163/200] [Batch 750/938] loss_G: 3.652752, loss_D: 0.220128\n",
      "[Epoch 163/200] [Batch 760/938] loss_G: 3.605063, loss_D: 0.191864\n",
      "[Epoch 163/200] [Batch 770/938] loss_G: 3.179983, loss_D: 0.187042\n",
      "[Epoch 163/200] [Batch 780/938] loss_G: 3.117594, loss_D: 0.189372\n",
      "[Epoch 163/200] [Batch 790/938] loss_G: 3.301109, loss_D: 0.205567\n",
      "[Epoch 163/200] [Batch 800/938] loss_G: 3.824576, loss_D: 0.132836\n",
      "[Epoch 163/200] [Batch 810/938] loss_G: 2.938081, loss_D: 0.237457\n",
      "[Epoch 163/200] [Batch 820/938] loss_G: 3.014511, loss_D: 0.304474\n",
      "[Epoch 163/200] [Batch 830/938] loss_G: 3.357162, loss_D: 0.190421\n",
      "[Epoch 163/200] [Batch 840/938] loss_G: 2.919263, loss_D: 0.209841\n",
      "[Epoch 163/200] [Batch 850/938] loss_G: 3.391311, loss_D: 0.207081\n",
      "[Epoch 163/200] [Batch 860/938] loss_G: 3.519737, loss_D: 0.178865\n",
      "[Epoch 163/200] [Batch 870/938] loss_G: 3.388832, loss_D: 0.168472\n",
      "[Epoch 163/200] [Batch 880/938] loss_G: 3.329624, loss_D: 0.250444\n",
      "[Epoch 163/200] [Batch 890/938] loss_G: 3.733040, loss_D: 0.154929\n",
      "[Epoch 163/200] [Batch 900/938] loss_G: 2.950832, loss_D: 0.251649\n",
      "[Epoch 163/200] [Batch 910/938] loss_G: 3.138645, loss_D: 0.192023\n",
      "[Epoch 163/200] [Batch 920/938] loss_G: 3.464145, loss_D: 0.240278\n",
      "[Epoch 163/200] [Batch 930/938] loss_G: 3.488288, loss_D: 0.232252\n",
      "[Epoch 164/200] [Batch 0/938] loss_G: 3.409026, loss_D: 0.229425\n",
      "[Epoch 164/200] [Batch 10/938] loss_G: 3.226558, loss_D: 0.160016\n",
      "[Epoch 164/200] [Batch 20/938] loss_G: 3.455346, loss_D: 0.144402\n",
      "[Epoch 164/200] [Batch 30/938] loss_G: 3.367878, loss_D: 0.123354\n",
      "[Epoch 164/200] [Batch 40/938] loss_G: 3.080324, loss_D: 0.241720\n",
      "[Epoch 164/200] [Batch 50/938] loss_G: 3.184447, loss_D: 0.177695\n",
      "[Epoch 164/200] [Batch 60/938] loss_G: 3.188714, loss_D: 0.144296\n",
      "[Epoch 164/200] [Batch 70/938] loss_G: 3.405387, loss_D: 0.252551\n",
      "[Epoch 164/200] [Batch 80/938] loss_G: 3.356068, loss_D: 0.095000\n",
      "[Epoch 164/200] [Batch 90/938] loss_G: 3.494308, loss_D: 0.178880\n",
      "[Epoch 164/200] [Batch 100/938] loss_G: 3.084634, loss_D: 0.276977\n",
      "[Epoch 164/200] [Batch 110/938] loss_G: 3.134962, loss_D: 0.144061\n",
      "[Epoch 164/200] [Batch 120/938] loss_G: 3.152270, loss_D: 0.224854\n",
      "[Epoch 164/200] [Batch 130/938] loss_G: 3.776936, loss_D: 0.199115\n",
      "[Epoch 164/200] [Batch 140/938] loss_G: 3.240773, loss_D: 0.139239\n",
      "[Epoch 164/200] [Batch 150/938] loss_G: 4.156623, loss_D: 0.116854\n",
      "[Epoch 164/200] [Batch 160/938] loss_G: 2.701266, loss_D: 0.227859\n",
      "[Epoch 164/200] [Batch 170/938] loss_G: 3.201900, loss_D: 0.155825\n",
      "[Epoch 164/200] [Batch 180/938] loss_G: 3.064692, loss_D: 0.182334\n",
      "[Epoch 164/200] [Batch 190/938] loss_G: 3.489815, loss_D: 0.209200\n",
      "[Epoch 164/200] [Batch 200/938] loss_G: 3.469901, loss_D: 0.198193\n",
      "[Epoch 164/200] [Batch 210/938] loss_G: 3.338866, loss_D: 0.165885\n",
      "[Epoch 164/200] [Batch 220/938] loss_G: 3.078030, loss_D: 0.210235\n",
      "[Epoch 164/200] [Batch 230/938] loss_G: 3.511201, loss_D: 0.178288\n",
      "[Epoch 164/200] [Batch 240/938] loss_G: 3.522644, loss_D: 0.259456\n",
      "[Epoch 164/200] [Batch 250/938] loss_G: 2.780651, loss_D: 0.196671\n",
      "[Epoch 164/200] [Batch 260/938] loss_G: 3.351609, loss_D: 0.150150\n",
      "[Epoch 164/200] [Batch 270/938] loss_G: 3.419060, loss_D: 0.168288\n",
      "[Epoch 164/200] [Batch 280/938] loss_G: 3.052118, loss_D: 0.176087\n",
      "[Epoch 164/200] [Batch 290/938] loss_G: 3.374872, loss_D: 0.152629\n",
      "[Epoch 164/200] [Batch 300/938] loss_G: 3.199434, loss_D: 0.151092\n",
      "[Epoch 164/200] [Batch 310/938] loss_G: 3.398396, loss_D: 0.116613\n",
      "[Epoch 164/200] [Batch 320/938] loss_G: 3.257030, loss_D: 0.158586\n",
      "[Epoch 164/200] [Batch 330/938] loss_G: 3.333227, loss_D: 0.182708\n",
      "[Epoch 164/200] [Batch 340/938] loss_G: 3.038642, loss_D: 0.184339\n",
      "[Epoch 164/200] [Batch 350/938] loss_G: 3.512985, loss_D: 0.155943\n",
      "[Epoch 164/200] [Batch 360/938] loss_G: 3.461196, loss_D: 0.177122\n",
      "[Epoch 164/200] [Batch 370/938] loss_G: 3.530829, loss_D: 0.156412\n",
      "[Epoch 164/200] [Batch 380/938] loss_G: 3.632881, loss_D: 0.198160\n",
      "[Epoch 164/200] [Batch 390/938] loss_G: 3.429461, loss_D: 0.098930\n",
      "[Epoch 164/200] [Batch 400/938] loss_G: 3.142017, loss_D: 0.151400\n",
      "[Epoch 164/200] [Batch 410/938] loss_G: 3.053845, loss_D: 0.236112\n",
      "[Epoch 164/200] [Batch 420/938] loss_G: 3.423312, loss_D: 0.189221\n",
      "[Epoch 164/200] [Batch 430/938] loss_G: 3.479357, loss_D: 0.209769\n",
      "[Epoch 164/200] [Batch 440/938] loss_G: 3.450151, loss_D: 0.225608\n",
      "[Epoch 164/200] [Batch 450/938] loss_G: 3.357987, loss_D: 0.171163\n",
      "[Epoch 164/200] [Batch 460/938] loss_G: 3.417293, loss_D: 0.260216\n",
      "[Epoch 164/200] [Batch 470/938] loss_G: 3.326607, loss_D: 0.267623\n",
      "[Epoch 164/200] [Batch 480/938] loss_G: 3.711186, loss_D: 0.191537\n",
      "[Epoch 164/200] [Batch 490/938] loss_G: 3.544121, loss_D: 0.197058\n",
      "[Epoch 164/200] [Batch 500/938] loss_G: 3.170722, loss_D: 0.148880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 164/200] [Batch 510/938] loss_G: 3.627898, loss_D: 0.205777\n",
      "[Epoch 164/200] [Batch 520/938] loss_G: 3.102813, loss_D: 0.204698\n",
      "[Epoch 164/200] [Batch 530/938] loss_G: 3.328737, loss_D: 0.124889\n",
      "[Epoch 164/200] [Batch 540/938] loss_G: 2.950020, loss_D: 0.242068\n",
      "[Epoch 164/200] [Batch 550/938] loss_G: 3.553200, loss_D: 0.166800\n",
      "[Epoch 164/200] [Batch 560/938] loss_G: 3.045325, loss_D: 0.167678\n",
      "[Epoch 164/200] [Batch 570/938] loss_G: 3.385765, loss_D: 0.160755\n",
      "[Epoch 164/200] [Batch 580/938] loss_G: 3.253275, loss_D: 0.248376\n",
      "[Epoch 164/200] [Batch 590/938] loss_G: 3.712244, loss_D: 0.184923\n",
      "[Epoch 164/200] [Batch 600/938] loss_G: 3.187513, loss_D: 0.171544\n",
      "[Epoch 164/200] [Batch 610/938] loss_G: 3.081429, loss_D: 0.207256\n",
      "[Epoch 164/200] [Batch 620/938] loss_G: 3.579388, loss_D: 0.241312\n",
      "[Epoch 164/200] [Batch 630/938] loss_G: 3.014605, loss_D: 0.191255\n",
      "[Epoch 164/200] [Batch 640/938] loss_G: 3.106392, loss_D: 0.134241\n",
      "[Epoch 164/200] [Batch 650/938] loss_G: 3.412150, loss_D: 0.107558\n",
      "[Epoch 164/200] [Batch 660/938] loss_G: 3.407602, loss_D: 0.148825\n",
      "[Epoch 164/200] [Batch 670/938] loss_G: 3.444287, loss_D: 0.222818\n",
      "[Epoch 164/200] [Batch 680/938] loss_G: 3.395800, loss_D: 0.189803\n",
      "[Epoch 164/200] [Batch 690/938] loss_G: 3.527682, loss_D: 0.170776\n",
      "[Epoch 164/200] [Batch 700/938] loss_G: 3.245649, loss_D: 0.156091\n",
      "[Epoch 164/200] [Batch 710/938] loss_G: 3.392881, loss_D: 0.132853\n",
      "[Epoch 164/200] [Batch 720/938] loss_G: 3.799735, loss_D: 0.168631\n",
      "[Epoch 164/200] [Batch 730/938] loss_G: 3.240856, loss_D: 0.297727\n",
      "[Epoch 164/200] [Batch 740/938] loss_G: 3.520232, loss_D: 0.181765\n",
      "[Epoch 164/200] [Batch 750/938] loss_G: 3.591179, loss_D: 0.161247\n",
      "[Epoch 164/200] [Batch 760/938] loss_G: 3.207250, loss_D: 0.108889\n",
      "[Epoch 164/200] [Batch 770/938] loss_G: 3.253948, loss_D: 0.192239\n",
      "[Epoch 164/200] [Batch 780/938] loss_G: 2.659087, loss_D: 0.225379\n",
      "[Epoch 164/200] [Batch 790/938] loss_G: 3.372620, loss_D: 0.158393\n",
      "[Epoch 164/200] [Batch 800/938] loss_G: 3.561929, loss_D: 0.132299\n",
      "[Epoch 164/200] [Batch 810/938] loss_G: 3.392984, loss_D: 0.227868\n",
      "[Epoch 164/200] [Batch 820/938] loss_G: 3.249684, loss_D: 0.181482\n",
      "[Epoch 164/200] [Batch 830/938] loss_G: 3.076453, loss_D: 0.247393\n",
      "[Epoch 164/200] [Batch 840/938] loss_G: 3.534188, loss_D: 0.136891\n",
      "[Epoch 164/200] [Batch 850/938] loss_G: 3.152689, loss_D: 0.186703\n",
      "[Epoch 164/200] [Batch 860/938] loss_G: 3.176921, loss_D: 0.224797\n",
      "[Epoch 164/200] [Batch 870/938] loss_G: 3.287859, loss_D: 0.199364\n",
      "[Epoch 164/200] [Batch 880/938] loss_G: 3.527701, loss_D: 0.197301\n",
      "[Epoch 164/200] [Batch 890/938] loss_G: 3.217907, loss_D: 0.128351\n",
      "[Epoch 164/200] [Batch 900/938] loss_G: 3.490600, loss_D: 0.227498\n",
      "[Epoch 164/200] [Batch 910/938] loss_G: 3.509555, loss_D: 0.198061\n",
      "[Epoch 164/200] [Batch 920/938] loss_G: 3.065749, loss_D: 0.194523\n",
      "[Epoch 164/200] [Batch 930/938] loss_G: 2.997018, loss_D: 0.200645\n",
      "[Epoch 165/200] [Batch 0/938] loss_G: 3.221980, loss_D: 0.199292\n",
      "[Epoch 165/200] [Batch 10/938] loss_G: 3.323395, loss_D: 0.140214\n",
      "[Epoch 165/200] [Batch 20/938] loss_G: 3.232378, loss_D: 0.183241\n",
      "[Epoch 165/200] [Batch 30/938] loss_G: 4.051796, loss_D: 0.195416\n",
      "[Epoch 165/200] [Batch 40/938] loss_G: 3.176321, loss_D: 0.218180\n",
      "[Epoch 165/200] [Batch 50/938] loss_G: 3.437563, loss_D: 0.178958\n",
      "[Epoch 165/200] [Batch 60/938] loss_G: 3.330992, loss_D: 0.173616\n",
      "[Epoch 165/200] [Batch 70/938] loss_G: 3.273552, loss_D: 0.194200\n",
      "[Epoch 165/200] [Batch 80/938] loss_G: 3.468674, loss_D: 0.183879\n",
      "[Epoch 165/200] [Batch 90/938] loss_G: 3.617518, loss_D: 0.184556\n",
      "[Epoch 165/200] [Batch 100/938] loss_G: 3.173331, loss_D: 0.233267\n",
      "[Epoch 165/200] [Batch 110/938] loss_G: 3.567825, loss_D: 0.189837\n",
      "[Epoch 165/200] [Batch 120/938] loss_G: 3.534766, loss_D: 0.295376\n",
      "[Epoch 165/200] [Batch 130/938] loss_G: 3.407204, loss_D: 0.197161\n",
      "[Epoch 165/200] [Batch 140/938] loss_G: 3.203580, loss_D: 0.166067\n",
      "[Epoch 165/200] [Batch 150/938] loss_G: 3.345296, loss_D: 0.209148\n",
      "[Epoch 165/200] [Batch 160/938] loss_G: 3.523549, loss_D: 0.166775\n",
      "[Epoch 165/200] [Batch 170/938] loss_G: 3.163596, loss_D: 0.218369\n",
      "[Epoch 165/200] [Batch 180/938] loss_G: 3.469198, loss_D: 0.170111\n",
      "[Epoch 165/200] [Batch 190/938] loss_G: 3.520672, loss_D: 0.144913\n",
      "[Epoch 165/200] [Batch 200/938] loss_G: 3.515906, loss_D: 0.170772\n",
      "[Epoch 165/200] [Batch 210/938] loss_G: 3.641430, loss_D: 0.197492\n",
      "[Epoch 165/200] [Batch 220/938] loss_G: 3.227584, loss_D: 0.135547\n",
      "[Epoch 165/200] [Batch 230/938] loss_G: 3.114274, loss_D: 0.192380\n",
      "[Epoch 165/200] [Batch 240/938] loss_G: 4.030193, loss_D: 0.115141\n",
      "[Epoch 165/200] [Batch 250/938] loss_G: 2.827312, loss_D: 0.228327\n",
      "[Epoch 165/200] [Batch 260/938] loss_G: 2.893847, loss_D: 0.201006\n",
      "[Epoch 165/200] [Batch 270/938] loss_G: 3.246504, loss_D: 0.332373\n",
      "[Epoch 165/200] [Batch 280/938] loss_G: 3.320647, loss_D: 0.184730\n",
      "[Epoch 165/200] [Batch 290/938] loss_G: 3.353925, loss_D: 0.248269\n",
      "[Epoch 165/200] [Batch 300/938] loss_G: 3.223988, loss_D: 0.162167\n",
      "[Epoch 165/200] [Batch 310/938] loss_G: 3.695868, loss_D: 0.112488\n",
      "[Epoch 165/200] [Batch 320/938] loss_G: 3.600569, loss_D: 0.180190\n",
      "[Epoch 165/200] [Batch 330/938] loss_G: 3.579794, loss_D: 0.146691\n",
      "[Epoch 165/200] [Batch 340/938] loss_G: 3.334260, loss_D: 0.209673\n",
      "[Epoch 165/200] [Batch 350/938] loss_G: 3.131128, loss_D: 0.192407\n",
      "[Epoch 165/200] [Batch 360/938] loss_G: 3.244741, loss_D: 0.197091\n",
      "[Epoch 165/200] [Batch 370/938] loss_G: 3.931473, loss_D: 0.188804\n",
      "[Epoch 165/200] [Batch 380/938] loss_G: 3.066278, loss_D: 0.148509\n",
      "[Epoch 165/200] [Batch 390/938] loss_G: 3.855845, loss_D: 0.222426\n",
      "[Epoch 165/200] [Batch 400/938] loss_G: 3.664212, loss_D: 0.206462\n",
      "[Epoch 165/200] [Batch 410/938] loss_G: 3.102590, loss_D: 0.267507\n",
      "[Epoch 165/200] [Batch 420/938] loss_G: 3.293485, loss_D: 0.167543\n",
      "[Epoch 165/200] [Batch 430/938] loss_G: 3.631314, loss_D: 0.159705\n",
      "[Epoch 165/200] [Batch 440/938] loss_G: 3.361635, loss_D: 0.216479\n",
      "[Epoch 165/200] [Batch 450/938] loss_G: 3.686330, loss_D: 0.144093\n",
      "[Epoch 165/200] [Batch 460/938] loss_G: 3.093826, loss_D: 0.175546\n",
      "[Epoch 165/200] [Batch 470/938] loss_G: 3.321759, loss_D: 0.129279\n",
      "[Epoch 165/200] [Batch 480/938] loss_G: 3.579627, loss_D: 0.192206\n",
      "[Epoch 165/200] [Batch 490/938] loss_G: 3.149097, loss_D: 0.172038\n",
      "[Epoch 165/200] [Batch 500/938] loss_G: 3.278993, loss_D: 0.205405\n",
      "[Epoch 165/200] [Batch 510/938] loss_G: 3.535957, loss_D: 0.255532\n",
      "[Epoch 165/200] [Batch 520/938] loss_G: 3.368259, loss_D: 0.168821\n",
      "[Epoch 165/200] [Batch 530/938] loss_G: 3.071078, loss_D: 0.210849\n",
      "[Epoch 165/200] [Batch 540/938] loss_G: 2.994414, loss_D: 0.166311\n",
      "[Epoch 165/200] [Batch 550/938] loss_G: 3.165843, loss_D: 0.199415\n",
      "[Epoch 165/200] [Batch 560/938] loss_G: 3.490100, loss_D: 0.171851\n",
      "[Epoch 165/200] [Batch 570/938] loss_G: 3.427829, loss_D: 0.193035\n",
      "[Epoch 165/200] [Batch 580/938] loss_G: 3.389459, loss_D: 0.250585\n",
      "[Epoch 165/200] [Batch 590/938] loss_G: 3.069168, loss_D: 0.210982\n",
      "[Epoch 165/200] [Batch 600/938] loss_G: 3.388314, loss_D: 0.218087\n",
      "[Epoch 165/200] [Batch 610/938] loss_G: 3.402136, loss_D: 0.221582\n",
      "[Epoch 165/200] [Batch 620/938] loss_G: 3.349907, loss_D: 0.178800\n",
      "[Epoch 165/200] [Batch 630/938] loss_G: 3.232995, loss_D: 0.263442\n",
      "[Epoch 165/200] [Batch 640/938] loss_G: 3.341999, loss_D: 0.233370\n",
      "[Epoch 165/200] [Batch 650/938] loss_G: 3.227936, loss_D: 0.157900\n",
      "[Epoch 165/200] [Batch 660/938] loss_G: 3.131453, loss_D: 0.164908\n",
      "[Epoch 165/200] [Batch 670/938] loss_G: 3.233289, loss_D: 0.208424\n",
      "[Epoch 165/200] [Batch 680/938] loss_G: 3.197045, loss_D: 0.156714\n",
      "[Epoch 165/200] [Batch 690/938] loss_G: 3.413483, loss_D: 0.170283\n",
      "[Epoch 165/200] [Batch 700/938] loss_G: 3.398722, loss_D: 0.208801\n",
      "[Epoch 165/200] [Batch 710/938] loss_G: 3.170588, loss_D: 0.213508\n",
      "[Epoch 165/200] [Batch 720/938] loss_G: 3.700400, loss_D: 0.153688\n",
      "[Epoch 165/200] [Batch 730/938] loss_G: 3.606605, loss_D: 0.198384\n",
      "[Epoch 165/200] [Batch 740/938] loss_G: 3.107960, loss_D: 0.164720\n",
      "[Epoch 165/200] [Batch 750/938] loss_G: 3.125254, loss_D: 0.253494\n",
      "[Epoch 165/200] [Batch 760/938] loss_G: 3.538053, loss_D: 0.184924\n",
      "[Epoch 165/200] [Batch 770/938] loss_G: 2.935346, loss_D: 0.220650\n",
      "[Epoch 165/200] [Batch 780/938] loss_G: 3.505619, loss_D: 0.269734\n",
      "[Epoch 165/200] [Batch 790/938] loss_G: 2.985743, loss_D: 0.336241\n",
      "[Epoch 165/200] [Batch 800/938] loss_G: 3.721457, loss_D: 0.148449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 165/200] [Batch 810/938] loss_G: 3.393367, loss_D: 0.142105\n",
      "[Epoch 165/200] [Batch 820/938] loss_G: 2.896231, loss_D: 0.170525\n",
      "[Epoch 165/200] [Batch 830/938] loss_G: 3.509846, loss_D: 0.198364\n",
      "[Epoch 165/200] [Batch 840/938] loss_G: 2.975647, loss_D: 0.144505\n",
      "[Epoch 165/200] [Batch 850/938] loss_G: 3.227488, loss_D: 0.256428\n",
      "[Epoch 165/200] [Batch 860/938] loss_G: 3.619645, loss_D: 0.124593\n",
      "[Epoch 165/200] [Batch 870/938] loss_G: 3.345759, loss_D: 0.171040\n",
      "[Epoch 165/200] [Batch 880/938] loss_G: 3.426040, loss_D: 0.127673\n",
      "[Epoch 165/200] [Batch 890/938] loss_G: 3.714699, loss_D: 0.171798\n",
      "[Epoch 165/200] [Batch 900/938] loss_G: 3.250000, loss_D: 0.263032\n",
      "[Epoch 165/200] [Batch 910/938] loss_G: 3.640909, loss_D: 0.112628\n",
      "[Epoch 165/200] [Batch 920/938] loss_G: 3.377398, loss_D: 0.170088\n",
      "[Epoch 165/200] [Batch 930/938] loss_G: 2.613572, loss_D: 0.230599\n",
      "[Epoch 166/200] [Batch 0/938] loss_G: 3.858063, loss_D: 0.096377\n",
      "[Epoch 166/200] [Batch 10/938] loss_G: 3.600459, loss_D: 0.217641\n",
      "[Epoch 166/200] [Batch 20/938] loss_G: 3.445792, loss_D: 0.203388\n",
      "[Epoch 166/200] [Batch 30/938] loss_G: 3.162614, loss_D: 0.169581\n",
      "[Epoch 166/200] [Batch 40/938] loss_G: 3.578752, loss_D: 0.186450\n",
      "[Epoch 166/200] [Batch 50/938] loss_G: 3.162866, loss_D: 0.213165\n",
      "[Epoch 166/200] [Batch 60/938] loss_G: 3.226069, loss_D: 0.179822\n",
      "[Epoch 166/200] [Batch 70/938] loss_G: 3.298534, loss_D: 0.224412\n",
      "[Epoch 166/200] [Batch 80/938] loss_G: 3.182489, loss_D: 0.142473\n",
      "[Epoch 166/200] [Batch 90/938] loss_G: 3.869149, loss_D: 0.134263\n",
      "[Epoch 166/200] [Batch 100/938] loss_G: 3.471411, loss_D: 0.144582\n",
      "[Epoch 166/200] [Batch 110/938] loss_G: 3.312647, loss_D: 0.107396\n",
      "[Epoch 166/200] [Batch 120/938] loss_G: 3.381285, loss_D: 0.221212\n",
      "[Epoch 166/200] [Batch 130/938] loss_G: 3.364228, loss_D: 0.131879\n",
      "[Epoch 166/200] [Batch 140/938] loss_G: 3.930225, loss_D: 0.125162\n",
      "[Epoch 166/200] [Batch 150/938] loss_G: 3.508416, loss_D: 0.164586\n",
      "[Epoch 166/200] [Batch 160/938] loss_G: 3.429393, loss_D: 0.185122\n",
      "[Epoch 166/200] [Batch 170/938] loss_G: 3.193459, loss_D: 0.122091\n",
      "[Epoch 166/200] [Batch 180/938] loss_G: 3.586221, loss_D: 0.161192\n",
      "[Epoch 166/200] [Batch 190/938] loss_G: 3.071577, loss_D: 0.291515\n",
      "[Epoch 166/200] [Batch 200/938] loss_G: 3.246660, loss_D: 0.144709\n",
      "[Epoch 166/200] [Batch 210/938] loss_G: 3.476488, loss_D: 0.247710\n",
      "[Epoch 166/200] [Batch 220/938] loss_G: 3.204109, loss_D: 0.276391\n",
      "[Epoch 166/200] [Batch 230/938] loss_G: 3.118482, loss_D: 0.170924\n",
      "[Epoch 166/200] [Batch 240/938] loss_G: 3.079147, loss_D: 0.208158\n",
      "[Epoch 166/200] [Batch 250/938] loss_G: 3.611788, loss_D: 0.184175\n",
      "[Epoch 166/200] [Batch 260/938] loss_G: 3.523111, loss_D: 0.169031\n",
      "[Epoch 166/200] [Batch 270/938] loss_G: 3.706174, loss_D: 0.148122\n",
      "[Epoch 166/200] [Batch 280/938] loss_G: 3.089444, loss_D: 0.273780\n",
      "[Epoch 166/200] [Batch 290/938] loss_G: 3.548955, loss_D: 0.188516\n",
      "[Epoch 166/200] [Batch 300/938] loss_G: 3.321264, loss_D: 0.244938\n",
      "[Epoch 166/200] [Batch 310/938] loss_G: 3.326585, loss_D: 0.243070\n",
      "[Epoch 166/200] [Batch 320/938] loss_G: 3.636949, loss_D: 0.174997\n",
      "[Epoch 166/200] [Batch 330/938] loss_G: 3.981979, loss_D: 0.147353\n",
      "[Epoch 166/200] [Batch 340/938] loss_G: 3.176153, loss_D: 0.192955\n",
      "[Epoch 166/200] [Batch 350/938] loss_G: 3.797159, loss_D: 0.138426\n",
      "[Epoch 166/200] [Batch 360/938] loss_G: 3.202468, loss_D: 0.392712\n",
      "[Epoch 166/200] [Batch 370/938] loss_G: 3.325694, loss_D: 0.227135\n",
      "[Epoch 166/200] [Batch 380/938] loss_G: 3.460318, loss_D: 0.156011\n",
      "[Epoch 166/200] [Batch 390/938] loss_G: 3.158211, loss_D: 0.153537\n",
      "[Epoch 166/200] [Batch 400/938] loss_G: 3.371777, loss_D: 0.152881\n",
      "[Epoch 166/200] [Batch 410/938] loss_G: 3.175610, loss_D: 0.225143\n",
      "[Epoch 166/200] [Batch 420/938] loss_G: 3.520254, loss_D: 0.276782\n",
      "[Epoch 166/200] [Batch 430/938] loss_G: 3.262587, loss_D: 0.222473\n",
      "[Epoch 166/200] [Batch 440/938] loss_G: 3.364683, loss_D: 0.175160\n",
      "[Epoch 166/200] [Batch 450/938] loss_G: 3.511761, loss_D: 0.205838\n",
      "[Epoch 166/200] [Batch 460/938] loss_G: 3.797467, loss_D: 0.204565\n",
      "[Epoch 166/200] [Batch 470/938] loss_G: 2.997554, loss_D: 0.197465\n",
      "[Epoch 166/200] [Batch 480/938] loss_G: 3.598066, loss_D: 0.191737\n",
      "[Epoch 166/200] [Batch 490/938] loss_G: 3.364574, loss_D: 0.226696\n",
      "[Epoch 166/200] [Batch 500/938] loss_G: 3.627507, loss_D: 0.180787\n",
      "[Epoch 166/200] [Batch 510/938] loss_G: 3.197174, loss_D: 0.126833\n",
      "[Epoch 166/200] [Batch 520/938] loss_G: 3.760911, loss_D: 0.158270\n",
      "[Epoch 166/200] [Batch 530/938] loss_G: 3.015926, loss_D: 0.253625\n",
      "[Epoch 166/200] [Batch 540/938] loss_G: 3.540448, loss_D: 0.150305\n",
      "[Epoch 166/200] [Batch 550/938] loss_G: 3.462534, loss_D: 0.230459\n",
      "[Epoch 166/200] [Batch 560/938] loss_G: 3.382150, loss_D: 0.192722\n",
      "[Epoch 166/200] [Batch 570/938] loss_G: 3.387570, loss_D: 0.229175\n",
      "[Epoch 166/200] [Batch 580/938] loss_G: 3.067087, loss_D: 0.158134\n",
      "[Epoch 166/200] [Batch 590/938] loss_G: 3.865632, loss_D: 0.096646\n",
      "[Epoch 166/200] [Batch 600/938] loss_G: 3.589699, loss_D: 0.133168\n",
      "[Epoch 166/200] [Batch 610/938] loss_G: 2.856211, loss_D: 0.195023\n",
      "[Epoch 166/200] [Batch 620/938] loss_G: 3.507407, loss_D: 0.140599\n",
      "[Epoch 166/200] [Batch 630/938] loss_G: 3.179937, loss_D: 0.164901\n",
      "[Epoch 166/200] [Batch 640/938] loss_G: 3.141436, loss_D: 0.191356\n",
      "[Epoch 166/200] [Batch 650/938] loss_G: 3.229560, loss_D: 0.267673\n",
      "[Epoch 166/200] [Batch 660/938] loss_G: 3.190566, loss_D: 0.244457\n",
      "[Epoch 166/200] [Batch 670/938] loss_G: 3.169867, loss_D: 0.213517\n",
      "[Epoch 166/200] [Batch 680/938] loss_G: 2.844646, loss_D: 0.203532\n",
      "[Epoch 166/200] [Batch 690/938] loss_G: 3.507445, loss_D: 0.157722\n",
      "[Epoch 166/200] [Batch 700/938] loss_G: 3.193404, loss_D: 0.199400\n",
      "[Epoch 166/200] [Batch 710/938] loss_G: 3.366101, loss_D: 0.181755\n",
      "[Epoch 166/200] [Batch 720/938] loss_G: 3.049470, loss_D: 0.196711\n",
      "[Epoch 166/200] [Batch 730/938] loss_G: 3.239301, loss_D: 0.209745\n",
      "[Epoch 166/200] [Batch 740/938] loss_G: 3.647050, loss_D: 0.110787\n",
      "[Epoch 166/200] [Batch 750/938] loss_G: 3.325982, loss_D: 0.224076\n",
      "[Epoch 166/200] [Batch 760/938] loss_G: 3.475467, loss_D: 0.152990\n",
      "[Epoch 166/200] [Batch 770/938] loss_G: 3.092966, loss_D: 0.193393\n",
      "[Epoch 166/200] [Batch 780/938] loss_G: 3.085134, loss_D: 0.220952\n",
      "[Epoch 166/200] [Batch 790/938] loss_G: 3.294400, loss_D: 0.276414\n",
      "[Epoch 166/200] [Batch 800/938] loss_G: 2.998417, loss_D: 0.175022\n",
      "[Epoch 166/200] [Batch 810/938] loss_G: 3.121395, loss_D: 0.136248\n",
      "[Epoch 166/200] [Batch 820/938] loss_G: 3.476437, loss_D: 0.172353\n",
      "[Epoch 166/200] [Batch 830/938] loss_G: 3.342182, loss_D: 0.139152\n",
      "[Epoch 166/200] [Batch 840/938] loss_G: 3.522549, loss_D: 0.239774\n",
      "[Epoch 166/200] [Batch 850/938] loss_G: 3.593729, loss_D: 0.207688\n",
      "[Epoch 166/200] [Batch 860/938] loss_G: 3.265446, loss_D: 0.208414\n",
      "[Epoch 166/200] [Batch 870/938] loss_G: 3.180819, loss_D: 0.208794\n",
      "[Epoch 166/200] [Batch 880/938] loss_G: 3.559247, loss_D: 0.157101\n",
      "[Epoch 166/200] [Batch 890/938] loss_G: 3.287675, loss_D: 0.119967\n",
      "[Epoch 166/200] [Batch 900/938] loss_G: 3.341915, loss_D: 0.201785\n",
      "[Epoch 166/200] [Batch 910/938] loss_G: 3.354947, loss_D: 0.146522\n",
      "[Epoch 166/200] [Batch 920/938] loss_G: 3.229059, loss_D: 0.183386\n",
      "[Epoch 166/200] [Batch 930/938] loss_G: 3.554105, loss_D: 0.228824\n",
      "[Epoch 167/200] [Batch 0/938] loss_G: 3.416182, loss_D: 0.158122\n",
      "[Epoch 167/200] [Batch 10/938] loss_G: 3.652644, loss_D: 0.133922\n",
      "[Epoch 167/200] [Batch 20/938] loss_G: 3.580287, loss_D: 0.183870\n",
      "[Epoch 167/200] [Batch 30/938] loss_G: 3.287734, loss_D: 0.169359\n",
      "[Epoch 167/200] [Batch 40/938] loss_G: 2.969747, loss_D: 0.228768\n",
      "[Epoch 167/200] [Batch 50/938] loss_G: 3.588776, loss_D: 0.131541\n",
      "[Epoch 167/200] [Batch 60/938] loss_G: 3.011261, loss_D: 0.288375\n",
      "[Epoch 167/200] [Batch 70/938] loss_G: 3.158814, loss_D: 0.162760\n",
      "[Epoch 167/200] [Batch 80/938] loss_G: 3.617704, loss_D: 0.166500\n",
      "[Epoch 167/200] [Batch 90/938] loss_G: 3.148124, loss_D: 0.147296\n",
      "[Epoch 167/200] [Batch 100/938] loss_G: 3.412454, loss_D: 0.178809\n",
      "[Epoch 167/200] [Batch 110/938] loss_G: 3.298725, loss_D: 0.135874\n",
      "[Epoch 167/200] [Batch 120/938] loss_G: 3.301188, loss_D: 0.200252\n",
      "[Epoch 167/200] [Batch 130/938] loss_G: 3.090041, loss_D: 0.230849\n",
      "[Epoch 167/200] [Batch 140/938] loss_G: 4.191777, loss_D: 0.231873\n",
      "[Epoch 167/200] [Batch 150/938] loss_G: 3.445298, loss_D: 0.130251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 167/200] [Batch 160/938] loss_G: 3.272491, loss_D: 0.127170\n",
      "[Epoch 167/200] [Batch 170/938] loss_G: 2.976002, loss_D: 0.156939\n",
      "[Epoch 167/200] [Batch 180/938] loss_G: 3.220329, loss_D: 0.205343\n",
      "[Epoch 167/200] [Batch 190/938] loss_G: 3.257133, loss_D: 0.149728\n",
      "[Epoch 167/200] [Batch 200/938] loss_G: 3.126361, loss_D: 0.217245\n",
      "[Epoch 167/200] [Batch 210/938] loss_G: 3.463834, loss_D: 0.131972\n",
      "[Epoch 167/200] [Batch 220/938] loss_G: 3.177053, loss_D: 0.191878\n",
      "[Epoch 167/200] [Batch 230/938] loss_G: 3.264384, loss_D: 0.183634\n",
      "[Epoch 167/200] [Batch 240/938] loss_G: 3.805475, loss_D: 0.186518\n",
      "[Epoch 167/200] [Batch 250/938] loss_G: 3.354172, loss_D: 0.127193\n",
      "[Epoch 167/200] [Batch 260/938] loss_G: 3.568403, loss_D: 0.178486\n",
      "[Epoch 167/200] [Batch 270/938] loss_G: 3.510817, loss_D: 0.142145\n",
      "[Epoch 167/200] [Batch 280/938] loss_G: 3.356894, loss_D: 0.189915\n",
      "[Epoch 167/200] [Batch 290/938] loss_G: 3.396152, loss_D: 0.116115\n",
      "[Epoch 167/200] [Batch 300/938] loss_G: 3.620357, loss_D: 0.129837\n",
      "[Epoch 167/200] [Batch 310/938] loss_G: 3.225677, loss_D: 0.202736\n",
      "[Epoch 167/200] [Batch 320/938] loss_G: 3.309129, loss_D: 0.191808\n",
      "[Epoch 167/200] [Batch 330/938] loss_G: 3.111961, loss_D: 0.166647\n",
      "[Epoch 167/200] [Batch 340/938] loss_G: 3.265841, loss_D: 0.156252\n",
      "[Epoch 167/200] [Batch 350/938] loss_G: 3.253323, loss_D: 0.161924\n",
      "[Epoch 167/200] [Batch 360/938] loss_G: 3.082066, loss_D: 0.213547\n",
      "[Epoch 167/200] [Batch 370/938] loss_G: 3.542303, loss_D: 0.168212\n",
      "[Epoch 167/200] [Batch 380/938] loss_G: 3.499491, loss_D: 0.171049\n",
      "[Epoch 167/200] [Batch 390/938] loss_G: 3.038132, loss_D: 0.189079\n",
      "[Epoch 167/200] [Batch 400/938] loss_G: 3.146122, loss_D: 0.321966\n",
      "[Epoch 167/200] [Batch 410/938] loss_G: 3.602580, loss_D: 0.208544\n",
      "[Epoch 167/200] [Batch 420/938] loss_G: 3.125203, loss_D: 0.211724\n",
      "[Epoch 167/200] [Batch 430/938] loss_G: 3.506857, loss_D: 0.180956\n",
      "[Epoch 167/200] [Batch 440/938] loss_G: 3.146058, loss_D: 0.238127\n",
      "[Epoch 167/200] [Batch 450/938] loss_G: 3.525484, loss_D: 0.136477\n",
      "[Epoch 167/200] [Batch 460/938] loss_G: 3.081008, loss_D: 0.147939\n",
      "[Epoch 167/200] [Batch 470/938] loss_G: 3.662590, loss_D: 0.216264\n",
      "[Epoch 167/200] [Batch 480/938] loss_G: 3.314616, loss_D: 0.219443\n",
      "[Epoch 167/200] [Batch 490/938] loss_G: 3.105791, loss_D: 0.248318\n",
      "[Epoch 167/200] [Batch 500/938] loss_G: 3.205095, loss_D: 0.099090\n",
      "[Epoch 167/200] [Batch 510/938] loss_G: 3.370526, loss_D: 0.144572\n",
      "[Epoch 167/200] [Batch 520/938] loss_G: 3.431276, loss_D: 0.164269\n",
      "[Epoch 167/200] [Batch 530/938] loss_G: 3.667052, loss_D: 0.222419\n",
      "[Epoch 167/200] [Batch 540/938] loss_G: 3.779558, loss_D: 0.191234\n",
      "[Epoch 167/200] [Batch 550/938] loss_G: 3.446820, loss_D: 0.214694\n",
      "[Epoch 167/200] [Batch 560/938] loss_G: 3.218956, loss_D: 0.206048\n",
      "[Epoch 167/200] [Batch 570/938] loss_G: 3.161681, loss_D: 0.185324\n",
      "[Epoch 167/200] [Batch 580/938] loss_G: 3.629896, loss_D: 0.151878\n",
      "[Epoch 167/200] [Batch 590/938] loss_G: 3.398939, loss_D: 0.201625\n",
      "[Epoch 167/200] [Batch 600/938] loss_G: 3.650177, loss_D: 0.170553\n",
      "[Epoch 167/200] [Batch 610/938] loss_G: 3.511005, loss_D: 0.134315\n",
      "[Epoch 167/200] [Batch 620/938] loss_G: 3.283784, loss_D: 0.210977\n",
      "[Epoch 167/200] [Batch 630/938] loss_G: 3.499148, loss_D: 0.208081\n",
      "[Epoch 167/200] [Batch 640/938] loss_G: 3.226470, loss_D: 0.237501\n",
      "[Epoch 167/200] [Batch 650/938] loss_G: 3.182398, loss_D: 0.211454\n",
      "[Epoch 167/200] [Batch 660/938] loss_G: 3.398624, loss_D: 0.230677\n",
      "[Epoch 167/200] [Batch 670/938] loss_G: 3.341345, loss_D: 0.147954\n",
      "[Epoch 167/200] [Batch 680/938] loss_G: 3.216592, loss_D: 0.138943\n",
      "[Epoch 167/200] [Batch 690/938] loss_G: 3.383723, loss_D: 0.186551\n",
      "[Epoch 167/200] [Batch 700/938] loss_G: 3.112652, loss_D: 0.186731\n",
      "[Epoch 167/200] [Batch 710/938] loss_G: 2.874773, loss_D: 0.221562\n",
      "[Epoch 167/200] [Batch 720/938] loss_G: 3.381899, loss_D: 0.259758\n",
      "[Epoch 167/200] [Batch 730/938] loss_G: 3.409313, loss_D: 0.238473\n",
      "[Epoch 167/200] [Batch 740/938] loss_G: 3.620362, loss_D: 0.238573\n",
      "[Epoch 167/200] [Batch 750/938] loss_G: 3.157561, loss_D: 0.200191\n",
      "[Epoch 167/200] [Batch 760/938] loss_G: 3.435347, loss_D: 0.165324\n",
      "[Epoch 167/200] [Batch 770/938] loss_G: 3.175148, loss_D: 0.144870\n",
      "[Epoch 167/200] [Batch 780/938] loss_G: 2.979198, loss_D: 0.161843\n",
      "[Epoch 167/200] [Batch 790/938] loss_G: 3.286247, loss_D: 0.180493\n",
      "[Epoch 167/200] [Batch 800/938] loss_G: 3.233241, loss_D: 0.198120\n",
      "[Epoch 167/200] [Batch 810/938] loss_G: 3.372738, loss_D: 0.163314\n",
      "[Epoch 167/200] [Batch 820/938] loss_G: 2.987395, loss_D: 0.236216\n",
      "[Epoch 167/200] [Batch 830/938] loss_G: 2.822766, loss_D: 0.240762\n",
      "[Epoch 167/200] [Batch 840/938] loss_G: 3.512373, loss_D: 0.178359\n",
      "[Epoch 167/200] [Batch 850/938] loss_G: 3.469198, loss_D: 0.164630\n",
      "[Epoch 167/200] [Batch 860/938] loss_G: 3.560838, loss_D: 0.168887\n",
      "[Epoch 167/200] [Batch 870/938] loss_G: 3.120208, loss_D: 0.200779\n",
      "[Epoch 167/200] [Batch 880/938] loss_G: 3.533398, loss_D: 0.216111\n",
      "[Epoch 167/200] [Batch 890/938] loss_G: 3.760989, loss_D: 0.202750\n",
      "[Epoch 167/200] [Batch 900/938] loss_G: 3.532023, loss_D: 0.209011\n",
      "[Epoch 167/200] [Batch 910/938] loss_G: 3.379723, loss_D: 0.232799\n",
      "[Epoch 167/200] [Batch 920/938] loss_G: 3.530670, loss_D: 0.199172\n",
      "[Epoch 167/200] [Batch 930/938] loss_G: 3.868781, loss_D: 0.153157\n",
      "[Epoch 168/200] [Batch 0/938] loss_G: 3.358458, loss_D: 0.276527\n",
      "[Epoch 168/200] [Batch 10/938] loss_G: 3.548570, loss_D: 0.251544\n",
      "[Epoch 168/200] [Batch 20/938] loss_G: 3.441483, loss_D: 0.120474\n",
      "[Epoch 168/200] [Batch 30/938] loss_G: 3.609403, loss_D: 0.232635\n",
      "[Epoch 168/200] [Batch 40/938] loss_G: 3.509833, loss_D: 0.243284\n",
      "[Epoch 168/200] [Batch 50/938] loss_G: 3.425341, loss_D: 0.124973\n",
      "[Epoch 168/200] [Batch 60/938] loss_G: 3.361097, loss_D: 0.181294\n",
      "[Epoch 168/200] [Batch 70/938] loss_G: 3.144137, loss_D: 0.152573\n",
      "[Epoch 168/200] [Batch 80/938] loss_G: 3.200905, loss_D: 0.104897\n",
      "[Epoch 168/200] [Batch 90/938] loss_G: 3.401126, loss_D: 0.201263\n",
      "[Epoch 168/200] [Batch 100/938] loss_G: 3.189469, loss_D: 0.134083\n",
      "[Epoch 168/200] [Batch 110/938] loss_G: 3.829814, loss_D: 0.156770\n",
      "[Epoch 168/200] [Batch 120/938] loss_G: 3.168983, loss_D: 0.140847\n",
      "[Epoch 168/200] [Batch 130/938] loss_G: 3.432542, loss_D: 0.167354\n",
      "[Epoch 168/200] [Batch 140/938] loss_G: 3.440066, loss_D: 0.154157\n",
      "[Epoch 168/200] [Batch 150/938] loss_G: 3.200501, loss_D: 0.143185\n",
      "[Epoch 168/200] [Batch 160/938] loss_G: 3.591588, loss_D: 0.194814\n",
      "[Epoch 168/200] [Batch 170/938] loss_G: 3.497165, loss_D: 0.186768\n",
      "[Epoch 168/200] [Batch 180/938] loss_G: 3.355345, loss_D: 0.158588\n",
      "[Epoch 168/200] [Batch 190/938] loss_G: 3.421810, loss_D: 0.175559\n",
      "[Epoch 168/200] [Batch 200/938] loss_G: 3.583215, loss_D: 0.193267\n",
      "[Epoch 168/200] [Batch 210/938] loss_G: 3.179039, loss_D: 0.163846\n",
      "[Epoch 168/200] [Batch 220/938] loss_G: 3.626227, loss_D: 0.198238\n",
      "[Epoch 168/200] [Batch 230/938] loss_G: 3.169708, loss_D: 0.163805\n",
      "[Epoch 168/200] [Batch 240/938] loss_G: 2.968315, loss_D: 0.231958\n",
      "[Epoch 168/200] [Batch 250/938] loss_G: 3.444608, loss_D: 0.115690\n",
      "[Epoch 168/200] [Batch 260/938] loss_G: 3.268378, loss_D: 0.232400\n",
      "[Epoch 168/200] [Batch 270/938] loss_G: 3.684295, loss_D: 0.198952\n",
      "[Epoch 168/200] [Batch 280/938] loss_G: 3.747846, loss_D: 0.110783\n",
      "[Epoch 168/200] [Batch 290/938] loss_G: 3.623603, loss_D: 0.158861\n",
      "[Epoch 168/200] [Batch 300/938] loss_G: 3.188677, loss_D: 0.187791\n",
      "[Epoch 168/200] [Batch 310/938] loss_G: 3.498437, loss_D: 0.194246\n",
      "[Epoch 168/200] [Batch 320/938] loss_G: 3.111052, loss_D: 0.169727\n",
      "[Epoch 168/200] [Batch 330/938] loss_G: 3.217028, loss_D: 0.185595\n",
      "[Epoch 168/200] [Batch 340/938] loss_G: 3.513834, loss_D: 0.141278\n",
      "[Epoch 168/200] [Batch 350/938] loss_G: 3.335402, loss_D: 0.114532\n",
      "[Epoch 168/200] [Batch 360/938] loss_G: 3.468852, loss_D: 0.209209\n",
      "[Epoch 168/200] [Batch 370/938] loss_G: 3.514804, loss_D: 0.249219\n",
      "[Epoch 168/200] [Batch 380/938] loss_G: 3.525982, loss_D: 0.206563\n",
      "[Epoch 168/200] [Batch 390/938] loss_G: 3.382842, loss_D: 0.168024\n",
      "[Epoch 168/200] [Batch 400/938] loss_G: 3.020976, loss_D: 0.149069\n",
      "[Epoch 168/200] [Batch 410/938] loss_G: 3.987185, loss_D: 0.185099\n",
      "[Epoch 168/200] [Batch 420/938] loss_G: 3.000993, loss_D: 0.219197\n",
      "[Epoch 168/200] [Batch 430/938] loss_G: 3.201913, loss_D: 0.182713\n",
      "[Epoch 168/200] [Batch 440/938] loss_G: 3.598528, loss_D: 0.261219\n",
      "[Epoch 168/200] [Batch 450/938] loss_G: 3.667068, loss_D: 0.144166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 168/200] [Batch 460/938] loss_G: 3.425591, loss_D: 0.209891\n",
      "[Epoch 168/200] [Batch 470/938] loss_G: 3.270707, loss_D: 0.135156\n",
      "[Epoch 168/200] [Batch 480/938] loss_G: 3.366165, loss_D: 0.114709\n",
      "[Epoch 168/200] [Batch 490/938] loss_G: 3.447648, loss_D: 0.172571\n",
      "[Epoch 168/200] [Batch 500/938] loss_G: 3.101915, loss_D: 0.231049\n",
      "[Epoch 168/200] [Batch 510/938] loss_G: 3.481008, loss_D: 0.188992\n",
      "[Epoch 168/200] [Batch 520/938] loss_G: 3.730685, loss_D: 0.204724\n",
      "[Epoch 168/200] [Batch 530/938] loss_G: 3.888158, loss_D: 0.108243\n",
      "[Epoch 168/200] [Batch 540/938] loss_G: 3.131658, loss_D: 0.266096\n",
      "[Epoch 168/200] [Batch 550/938] loss_G: 3.572196, loss_D: 0.277826\n",
      "[Epoch 168/200] [Batch 560/938] loss_G: 3.055479, loss_D: 0.130141\n",
      "[Epoch 168/200] [Batch 570/938] loss_G: 3.239738, loss_D: 0.118288\n",
      "[Epoch 168/200] [Batch 580/938] loss_G: 3.108606, loss_D: 0.155925\n",
      "[Epoch 168/200] [Batch 590/938] loss_G: 3.354781, loss_D: 0.173395\n",
      "[Epoch 168/200] [Batch 600/938] loss_G: 2.882781, loss_D: 0.188195\n",
      "[Epoch 168/200] [Batch 610/938] loss_G: 3.250213, loss_D: 0.195016\n",
      "[Epoch 168/200] [Batch 620/938] loss_G: 3.171119, loss_D: 0.107326\n",
      "[Epoch 168/200] [Batch 630/938] loss_G: 3.321579, loss_D: 0.137250\n",
      "[Epoch 168/200] [Batch 640/938] loss_G: 3.226491, loss_D: 0.190675\n",
      "[Epoch 168/200] [Batch 650/938] loss_G: 3.222657, loss_D: 0.144125\n",
      "[Epoch 168/200] [Batch 660/938] loss_G: 3.058777, loss_D: 0.233081\n",
      "[Epoch 168/200] [Batch 670/938] loss_G: 3.244924, loss_D: 0.212015\n",
      "[Epoch 168/200] [Batch 680/938] loss_G: 3.383761, loss_D: 0.180243\n",
      "[Epoch 168/200] [Batch 690/938] loss_G: 3.593839, loss_D: 0.150068\n",
      "[Epoch 168/200] [Batch 700/938] loss_G: 3.463102, loss_D: 0.231871\n",
      "[Epoch 168/200] [Batch 710/938] loss_G: 3.178584, loss_D: 0.245716\n",
      "[Epoch 168/200] [Batch 720/938] loss_G: 3.347901, loss_D: 0.146550\n",
      "[Epoch 168/200] [Batch 730/938] loss_G: 3.224500, loss_D: 0.217720\n",
      "[Epoch 168/200] [Batch 740/938] loss_G: 3.368493, loss_D: 0.160048\n",
      "[Epoch 168/200] [Batch 750/938] loss_G: 3.327751, loss_D: 0.248974\n",
      "[Epoch 168/200] [Batch 760/938] loss_G: 3.271605, loss_D: 0.225551\n",
      "[Epoch 168/200] [Batch 770/938] loss_G: 3.246891, loss_D: 0.176381\n",
      "[Epoch 168/200] [Batch 780/938] loss_G: 2.945126, loss_D: 0.225233\n",
      "[Epoch 168/200] [Batch 790/938] loss_G: 3.540895, loss_D: 0.080313\n",
      "[Epoch 168/200] [Batch 800/938] loss_G: 3.059764, loss_D: 0.213562\n",
      "[Epoch 168/200] [Batch 810/938] loss_G: 3.228240, loss_D: 0.233773\n",
      "[Epoch 168/200] [Batch 820/938] loss_G: 3.517356, loss_D: 0.181283\n",
      "[Epoch 168/200] [Batch 830/938] loss_G: 3.373431, loss_D: 0.271745\n",
      "[Epoch 168/200] [Batch 840/938] loss_G: 3.301629, loss_D: 0.166494\n",
      "[Epoch 168/200] [Batch 850/938] loss_G: 3.375762, loss_D: 0.206004\n",
      "[Epoch 168/200] [Batch 860/938] loss_G: 3.378600, loss_D: 0.217059\n",
      "[Epoch 168/200] [Batch 870/938] loss_G: 3.241221, loss_D: 0.192153\n",
      "[Epoch 168/200] [Batch 880/938] loss_G: 3.536469, loss_D: 0.166059\n",
      "[Epoch 168/200] [Batch 890/938] loss_G: 3.555864, loss_D: 0.162877\n",
      "[Epoch 168/200] [Batch 900/938] loss_G: 3.058906, loss_D: 0.121732\n",
      "[Epoch 168/200] [Batch 910/938] loss_G: 3.581643, loss_D: 0.111079\n",
      "[Epoch 168/200] [Batch 920/938] loss_G: 3.155242, loss_D: 0.179084\n",
      "[Epoch 168/200] [Batch 930/938] loss_G: 3.591010, loss_D: 0.146488\n",
      "[Epoch 169/200] [Batch 0/938] loss_G: 3.206446, loss_D: 0.106498\n",
      "[Epoch 169/200] [Batch 10/938] loss_G: 3.307056, loss_D: 0.152610\n",
      "[Epoch 169/200] [Batch 20/938] loss_G: 3.401959, loss_D: 0.208604\n",
      "[Epoch 169/200] [Batch 30/938] loss_G: 3.363388, loss_D: 0.230992\n",
      "[Epoch 169/200] [Batch 40/938] loss_G: 3.315427, loss_D: 0.174446\n",
      "[Epoch 169/200] [Batch 50/938] loss_G: 3.398125, loss_D: 0.164195\n",
      "[Epoch 169/200] [Batch 60/938] loss_G: 3.515179, loss_D: 0.243937\n",
      "[Epoch 169/200] [Batch 70/938] loss_G: 3.507802, loss_D: 0.134922\n",
      "[Epoch 169/200] [Batch 80/938] loss_G: 3.328437, loss_D: 0.128255\n",
      "[Epoch 169/200] [Batch 90/938] loss_G: 3.421830, loss_D: 0.178770\n",
      "[Epoch 169/200] [Batch 100/938] loss_G: 3.747581, loss_D: 0.083054\n",
      "[Epoch 169/200] [Batch 110/938] loss_G: 3.203950, loss_D: 0.172610\n",
      "[Epoch 169/200] [Batch 120/938] loss_G: 3.665259, loss_D: 0.093273\n",
      "[Epoch 169/200] [Batch 130/938] loss_G: 3.496149, loss_D: 0.150688\n",
      "[Epoch 169/200] [Batch 140/938] loss_G: 3.611921, loss_D: 0.158297\n",
      "[Epoch 169/200] [Batch 150/938] loss_G: 3.648935, loss_D: 0.231590\n",
      "[Epoch 169/200] [Batch 160/938] loss_G: 3.038041, loss_D: 0.161347\n",
      "[Epoch 169/200] [Batch 170/938] loss_G: 3.192174, loss_D: 0.181977\n",
      "[Epoch 169/200] [Batch 180/938] loss_G: 3.461715, loss_D: 0.252354\n",
      "[Epoch 169/200] [Batch 190/938] loss_G: 3.239916, loss_D: 0.234525\n",
      "[Epoch 169/200] [Batch 200/938] loss_G: 3.374932, loss_D: 0.223440\n",
      "[Epoch 169/200] [Batch 210/938] loss_G: 4.001687, loss_D: 0.177966\n",
      "[Epoch 169/200] [Batch 220/938] loss_G: 3.629001, loss_D: 0.206684\n",
      "[Epoch 169/200] [Batch 230/938] loss_G: 3.141445, loss_D: 0.166810\n",
      "[Epoch 169/200] [Batch 240/938] loss_G: 3.539902, loss_D: 0.237704\n",
      "[Epoch 169/200] [Batch 250/938] loss_G: 3.753632, loss_D: 0.234751\n",
      "[Epoch 169/200] [Batch 260/938] loss_G: 3.649207, loss_D: 0.199443\n",
      "[Epoch 169/200] [Batch 270/938] loss_G: 3.592668, loss_D: 0.179334\n",
      "[Epoch 169/200] [Batch 280/938] loss_G: 3.517789, loss_D: 0.238719\n",
      "[Epoch 169/200] [Batch 290/938] loss_G: 3.860525, loss_D: 0.191586\n",
      "[Epoch 169/200] [Batch 300/938] loss_G: 3.178002, loss_D: 0.209386\n",
      "[Epoch 169/200] [Batch 310/938] loss_G: 3.716083, loss_D: 0.239588\n",
      "[Epoch 169/200] [Batch 320/938] loss_G: 3.492720, loss_D: 0.225915\n",
      "[Epoch 169/200] [Batch 330/938] loss_G: 3.066178, loss_D: 0.242760\n",
      "[Epoch 169/200] [Batch 340/938] loss_G: 2.912713, loss_D: 0.257845\n",
      "[Epoch 169/200] [Batch 350/938] loss_G: 3.341721, loss_D: 0.113451\n",
      "[Epoch 169/200] [Batch 360/938] loss_G: 3.575643, loss_D: 0.153934\n",
      "[Epoch 169/200] [Batch 370/938] loss_G: 3.356230, loss_D: 0.187435\n",
      "[Epoch 169/200] [Batch 380/938] loss_G: 3.757887, loss_D: 0.184267\n",
      "[Epoch 169/200] [Batch 390/938] loss_G: 3.380260, loss_D: 0.212064\n",
      "[Epoch 169/200] [Batch 400/938] loss_G: 3.491555, loss_D: 0.235914\n",
      "[Epoch 169/200] [Batch 410/938] loss_G: 3.179852, loss_D: 0.177859\n",
      "[Epoch 169/200] [Batch 420/938] loss_G: 3.173366, loss_D: 0.295092\n",
      "[Epoch 169/200] [Batch 430/938] loss_G: 3.319635, loss_D: 0.233038\n",
      "[Epoch 169/200] [Batch 440/938] loss_G: 3.545321, loss_D: 0.120186\n",
      "[Epoch 169/200] [Batch 450/938] loss_G: 4.011426, loss_D: 0.100762\n",
      "[Epoch 169/200] [Batch 460/938] loss_G: 3.339769, loss_D: 0.144945\n",
      "[Epoch 169/200] [Batch 470/938] loss_G: 3.507599, loss_D: 0.268740\n",
      "[Epoch 169/200] [Batch 480/938] loss_G: 3.179780, loss_D: 0.111005\n",
      "[Epoch 169/200] [Batch 490/938] loss_G: 2.988934, loss_D: 0.167026\n",
      "[Epoch 169/200] [Batch 500/938] loss_G: 3.315488, loss_D: 0.169264\n",
      "[Epoch 169/200] [Batch 510/938] loss_G: 3.446459, loss_D: 0.085913\n",
      "[Epoch 169/200] [Batch 520/938] loss_G: 3.534271, loss_D: 0.158034\n",
      "[Epoch 169/200] [Batch 530/938] loss_G: 3.276224, loss_D: 0.188296\n",
      "[Epoch 169/200] [Batch 540/938] loss_G: 3.098239, loss_D: 0.191638\n",
      "[Epoch 169/200] [Batch 550/938] loss_G: 3.679086, loss_D: 0.173843\n",
      "[Epoch 169/200] [Batch 560/938] loss_G: 3.076517, loss_D: 0.174137\n",
      "[Epoch 169/200] [Batch 570/938] loss_G: 3.165304, loss_D: 0.105457\n",
      "[Epoch 169/200] [Batch 580/938] loss_G: 3.202241, loss_D: 0.174830\n",
      "[Epoch 169/200] [Batch 590/938] loss_G: 3.404601, loss_D: 0.203703\n",
      "[Epoch 169/200] [Batch 600/938] loss_G: 3.107271, loss_D: 0.189529\n",
      "[Epoch 169/200] [Batch 610/938] loss_G: 3.153193, loss_D: 0.256778\n",
      "[Epoch 169/200] [Batch 620/938] loss_G: 3.100197, loss_D: 0.187110\n",
      "[Epoch 169/200] [Batch 630/938] loss_G: 3.868688, loss_D: 0.113608\n",
      "[Epoch 169/200] [Batch 640/938] loss_G: 3.486879, loss_D: 0.248931\n",
      "[Epoch 169/200] [Batch 650/938] loss_G: 3.496885, loss_D: 0.223630\n",
      "[Epoch 169/200] [Batch 660/938] loss_G: 3.477842, loss_D: 0.189466\n",
      "[Epoch 169/200] [Batch 670/938] loss_G: 3.453384, loss_D: 0.178897\n",
      "[Epoch 169/200] [Batch 680/938] loss_G: 3.154335, loss_D: 0.174063\n",
      "[Epoch 169/200] [Batch 690/938] loss_G: 3.186357, loss_D: 0.174202\n",
      "[Epoch 169/200] [Batch 700/938] loss_G: 3.646729, loss_D: 0.181657\n",
      "[Epoch 169/200] [Batch 710/938] loss_G: 3.081395, loss_D: 0.166075\n",
      "[Epoch 169/200] [Batch 720/938] loss_G: 3.244229, loss_D: 0.177817\n",
      "[Epoch 169/200] [Batch 730/938] loss_G: 3.171707, loss_D: 0.219793\n",
      "[Epoch 169/200] [Batch 740/938] loss_G: 3.694578, loss_D: 0.116968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 169/200] [Batch 750/938] loss_G: 3.168242, loss_D: 0.140288\n",
      "[Epoch 169/200] [Batch 760/938] loss_G: 3.451681, loss_D: 0.152910\n",
      "[Epoch 169/200] [Batch 770/938] loss_G: 3.209048, loss_D: 0.144970\n",
      "[Epoch 169/200] [Batch 780/938] loss_G: 3.752499, loss_D: 0.179654\n",
      "[Epoch 169/200] [Batch 790/938] loss_G: 3.229440, loss_D: 0.220438\n",
      "[Epoch 169/200] [Batch 800/938] loss_G: 3.514746, loss_D: 0.190392\n",
      "[Epoch 169/200] [Batch 810/938] loss_G: 3.356295, loss_D: 0.093069\n",
      "[Epoch 169/200] [Batch 820/938] loss_G: 3.242873, loss_D: 0.177365\n",
      "[Epoch 169/200] [Batch 830/938] loss_G: 3.407169, loss_D: 0.206324\n",
      "[Epoch 169/200] [Batch 840/938] loss_G: 3.673722, loss_D: 0.129044\n",
      "[Epoch 169/200] [Batch 850/938] loss_G: 3.704273, loss_D: 0.185990\n",
      "[Epoch 169/200] [Batch 860/938] loss_G: 3.489308, loss_D: 0.159355\n",
      "[Epoch 169/200] [Batch 870/938] loss_G: 3.269354, loss_D: 0.149217\n",
      "[Epoch 169/200] [Batch 880/938] loss_G: 2.975020, loss_D: 0.233664\n",
      "[Epoch 169/200] [Batch 890/938] loss_G: 3.367333, loss_D: 0.178614\n",
      "[Epoch 169/200] [Batch 900/938] loss_G: 3.317128, loss_D: 0.217786\n",
      "[Epoch 169/200] [Batch 910/938] loss_G: 3.367861, loss_D: 0.245985\n",
      "[Epoch 169/200] [Batch 920/938] loss_G: 3.314165, loss_D: 0.133783\n",
      "[Epoch 169/200] [Batch 930/938] loss_G: 3.485674, loss_D: 0.161758\n",
      "[Epoch 170/200] [Batch 0/938] loss_G: 3.124543, loss_D: 0.154016\n",
      "[Epoch 170/200] [Batch 10/938] loss_G: 3.190664, loss_D: 0.238674\n",
      "[Epoch 170/200] [Batch 20/938] loss_G: 3.315202, loss_D: 0.236805\n",
      "[Epoch 170/200] [Batch 30/938] loss_G: 3.381935, loss_D: 0.150842\n",
      "[Epoch 170/200] [Batch 40/938] loss_G: 3.240157, loss_D: 0.240453\n",
      "[Epoch 170/200] [Batch 50/938] loss_G: 2.826890, loss_D: 0.258637\n",
      "[Epoch 170/200] [Batch 60/938] loss_G: 3.751854, loss_D: 0.091398\n",
      "[Epoch 170/200] [Batch 70/938] loss_G: 3.640140, loss_D: 0.129449\n",
      "[Epoch 170/200] [Batch 80/938] loss_G: 3.464764, loss_D: 0.224749\n",
      "[Epoch 170/200] [Batch 90/938] loss_G: 3.444334, loss_D: 0.176765\n",
      "[Epoch 170/200] [Batch 100/938] loss_G: 3.643305, loss_D: 0.123498\n",
      "[Epoch 170/200] [Batch 110/938] loss_G: 3.094228, loss_D: 0.127632\n",
      "[Epoch 170/200] [Batch 120/938] loss_G: 3.552759, loss_D: 0.205010\n",
      "[Epoch 170/200] [Batch 130/938] loss_G: 3.262355, loss_D: 0.200277\n",
      "[Epoch 170/200] [Batch 140/938] loss_G: 3.390562, loss_D: 0.146019\n",
      "[Epoch 170/200] [Batch 150/938] loss_G: 3.278303, loss_D: 0.201341\n",
      "[Epoch 170/200] [Batch 160/938] loss_G: 3.341405, loss_D: 0.123432\n",
      "[Epoch 170/200] [Batch 170/938] loss_G: 3.594793, loss_D: 0.114043\n",
      "[Epoch 170/200] [Batch 180/938] loss_G: 3.365484, loss_D: 0.259569\n",
      "[Epoch 170/200] [Batch 190/938] loss_G: 3.037717, loss_D: 0.186194\n",
      "[Epoch 170/200] [Batch 200/938] loss_G: 3.169090, loss_D: 0.240676\n",
      "[Epoch 170/200] [Batch 210/938] loss_G: 3.229627, loss_D: 0.216523\n",
      "[Epoch 170/200] [Batch 220/938] loss_G: 3.154283, loss_D: 0.115714\n",
      "[Epoch 170/200] [Batch 230/938] loss_G: 3.100088, loss_D: 0.202148\n",
      "[Epoch 170/200] [Batch 240/938] loss_G: 3.103642, loss_D: 0.236923\n",
      "[Epoch 170/200] [Batch 250/938] loss_G: 3.625625, loss_D: 0.234934\n",
      "[Epoch 170/200] [Batch 260/938] loss_G: 3.794489, loss_D: 0.242483\n",
      "[Epoch 170/200] [Batch 270/938] loss_G: 3.907272, loss_D: 0.131404\n",
      "[Epoch 170/200] [Batch 280/938] loss_G: 3.397255, loss_D: 0.193998\n",
      "[Epoch 170/200] [Batch 290/938] loss_G: 2.961460, loss_D: 0.284662\n",
      "[Epoch 170/200] [Batch 300/938] loss_G: 3.518929, loss_D: 0.186016\n",
      "[Epoch 170/200] [Batch 310/938] loss_G: 3.635706, loss_D: 0.087234\n",
      "[Epoch 170/200] [Batch 320/938] loss_G: 3.652843, loss_D: 0.223510\n",
      "[Epoch 170/200] [Batch 330/938] loss_G: 3.329182, loss_D: 0.180350\n",
      "[Epoch 170/200] [Batch 340/938] loss_G: 3.539393, loss_D: 0.222172\n",
      "[Epoch 170/200] [Batch 350/938] loss_G: 3.288260, loss_D: 0.147495\n",
      "[Epoch 170/200] [Batch 360/938] loss_G: 3.562956, loss_D: 0.194578\n",
      "[Epoch 170/200] [Batch 370/938] loss_G: 3.085223, loss_D: 0.148865\n",
      "[Epoch 170/200] [Batch 380/938] loss_G: 3.312050, loss_D: 0.147859\n",
      "[Epoch 170/200] [Batch 390/938] loss_G: 3.280169, loss_D: 0.169372\n",
      "[Epoch 170/200] [Batch 400/938] loss_G: 3.113093, loss_D: 0.150867\n",
      "[Epoch 170/200] [Batch 410/938] loss_G: 2.940723, loss_D: 0.283103\n",
      "[Epoch 170/200] [Batch 420/938] loss_G: 3.569596, loss_D: 0.121349\n",
      "[Epoch 170/200] [Batch 430/938] loss_G: 3.814342, loss_D: 0.176262\n",
      "[Epoch 170/200] [Batch 440/938] loss_G: 3.525981, loss_D: 0.115884\n",
      "[Epoch 170/200] [Batch 450/938] loss_G: 3.510710, loss_D: 0.167535\n",
      "[Epoch 170/200] [Batch 460/938] loss_G: 3.210104, loss_D: 0.274860\n",
      "[Epoch 170/200] [Batch 470/938] loss_G: 2.701052, loss_D: 0.253377\n",
      "[Epoch 170/200] [Batch 480/938] loss_G: 3.597877, loss_D: 0.125181\n",
      "[Epoch 170/200] [Batch 490/938] loss_G: 3.364292, loss_D: 0.208631\n",
      "[Epoch 170/200] [Batch 500/938] loss_G: 3.048844, loss_D: 0.149574\n",
      "[Epoch 170/200] [Batch 510/938] loss_G: 3.733541, loss_D: 0.191287\n",
      "[Epoch 170/200] [Batch 520/938] loss_G: 3.111740, loss_D: 0.186040\n",
      "[Epoch 170/200] [Batch 530/938] loss_G: 2.931948, loss_D: 0.254908\n",
      "[Epoch 170/200] [Batch 540/938] loss_G: 3.708488, loss_D: 0.119681\n",
      "[Epoch 170/200] [Batch 550/938] loss_G: 3.562926, loss_D: 0.173184\n",
      "[Epoch 170/200] [Batch 560/938] loss_G: 3.534803, loss_D: 0.140578\n",
      "[Epoch 170/200] [Batch 570/938] loss_G: 3.437778, loss_D: 0.147412\n",
      "[Epoch 170/200] [Batch 580/938] loss_G: 3.500896, loss_D: 0.216473\n",
      "[Epoch 170/200] [Batch 590/938] loss_G: 3.378435, loss_D: 0.218074\n",
      "[Epoch 170/200] [Batch 600/938] loss_G: 3.667592, loss_D: 0.159354\n",
      "[Epoch 170/200] [Batch 610/938] loss_G: 3.152190, loss_D: 0.174014\n",
      "[Epoch 170/200] [Batch 620/938] loss_G: 3.650952, loss_D: 0.141657\n",
      "[Epoch 170/200] [Batch 630/938] loss_G: 3.500905, loss_D: 0.144091\n",
      "[Epoch 170/200] [Batch 640/938] loss_G: 3.072658, loss_D: 0.162438\n",
      "[Epoch 170/200] [Batch 650/938] loss_G: 3.358549, loss_D: 0.134033\n",
      "[Epoch 170/200] [Batch 660/938] loss_G: 3.288516, loss_D: 0.270479\n",
      "[Epoch 170/200] [Batch 670/938] loss_G: 3.425672, loss_D: 0.162133\n",
      "[Epoch 170/200] [Batch 680/938] loss_G: 3.760877, loss_D: 0.202625\n",
      "[Epoch 170/200] [Batch 690/938] loss_G: 3.061695, loss_D: 0.169385\n",
      "[Epoch 170/200] [Batch 700/938] loss_G: 3.257481, loss_D: 0.119530\n",
      "[Epoch 170/200] [Batch 710/938] loss_G: 3.188787, loss_D: 0.302133\n",
      "[Epoch 170/200] [Batch 720/938] loss_G: 3.226753, loss_D: 0.209237\n",
      "[Epoch 170/200] [Batch 730/938] loss_G: 3.162712, loss_D: 0.182639\n",
      "[Epoch 170/200] [Batch 740/938] loss_G: 3.160155, loss_D: 0.180963\n",
      "[Epoch 170/200] [Batch 750/938] loss_G: 3.374496, loss_D: 0.210811\n",
      "[Epoch 170/200] [Batch 760/938] loss_G: 2.932611, loss_D: 0.163260\n",
      "[Epoch 170/200] [Batch 770/938] loss_G: 3.241689, loss_D: 0.141865\n",
      "[Epoch 170/200] [Batch 780/938] loss_G: 3.046809, loss_D: 0.202270\n",
      "[Epoch 170/200] [Batch 790/938] loss_G: 3.462338, loss_D: 0.167306\n",
      "[Epoch 170/200] [Batch 800/938] loss_G: 3.155272, loss_D: 0.272566\n",
      "[Epoch 170/200] [Batch 810/938] loss_G: 3.440357, loss_D: 0.200222\n",
      "[Epoch 170/200] [Batch 820/938] loss_G: 3.408989, loss_D: 0.177466\n",
      "[Epoch 170/200] [Batch 830/938] loss_G: 3.448217, loss_D: 0.134974\n",
      "[Epoch 170/200] [Batch 840/938] loss_G: 3.268220, loss_D: 0.184534\n",
      "[Epoch 170/200] [Batch 850/938] loss_G: 3.425995, loss_D: 0.239168\n",
      "[Epoch 170/200] [Batch 860/938] loss_G: 3.089437, loss_D: 0.127944\n",
      "[Epoch 170/200] [Batch 870/938] loss_G: 3.266549, loss_D: 0.169790\n",
      "[Epoch 170/200] [Batch 880/938] loss_G: 2.689691, loss_D: 0.258910\n",
      "[Epoch 170/200] [Batch 890/938] loss_G: 3.587020, loss_D: 0.178282\n",
      "[Epoch 170/200] [Batch 900/938] loss_G: 2.983913, loss_D: 0.164348\n",
      "[Epoch 170/200] [Batch 910/938] loss_G: 3.669665, loss_D: 0.170554\n",
      "[Epoch 170/200] [Batch 920/938] loss_G: 3.087765, loss_D: 0.188893\n",
      "[Epoch 170/200] [Batch 930/938] loss_G: 3.453819, loss_D: 0.242170\n",
      "[Epoch 171/200] [Batch 0/938] loss_G: 3.685947, loss_D: 0.200682\n",
      "[Epoch 171/200] [Batch 10/938] loss_G: 3.524683, loss_D: 0.175267\n",
      "[Epoch 171/200] [Batch 20/938] loss_G: 3.476582, loss_D: 0.237248\n",
      "[Epoch 171/200] [Batch 30/938] loss_G: 3.452596, loss_D: 0.204619\n",
      "[Epoch 171/200] [Batch 40/938] loss_G: 3.562830, loss_D: 0.248735\n",
      "[Epoch 171/200] [Batch 50/938] loss_G: 3.863680, loss_D: 0.150285\n",
      "[Epoch 171/200] [Batch 60/938] loss_G: 3.375443, loss_D: 0.151528\n",
      "[Epoch 171/200] [Batch 70/938] loss_G: 3.441655, loss_D: 0.146131\n",
      "[Epoch 171/200] [Batch 80/938] loss_G: 3.028404, loss_D: 0.212676\n",
      "[Epoch 171/200] [Batch 90/938] loss_G: 3.027050, loss_D: 0.168952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 171/200] [Batch 100/938] loss_G: 3.497165, loss_D: 0.193041\n",
      "[Epoch 171/200] [Batch 110/938] loss_G: 3.538302, loss_D: 0.205349\n",
      "[Epoch 171/200] [Batch 120/938] loss_G: 3.697918, loss_D: 0.200892\n",
      "[Epoch 171/200] [Batch 130/938] loss_G: 3.201548, loss_D: 0.144211\n",
      "[Epoch 171/200] [Batch 140/938] loss_G: 3.145619, loss_D: 0.170206\n",
      "[Epoch 171/200] [Batch 150/938] loss_G: 4.103523, loss_D: 0.133780\n",
      "[Epoch 171/200] [Batch 160/938] loss_G: 3.241715, loss_D: 0.137693\n",
      "[Epoch 171/200] [Batch 170/938] loss_G: 3.751715, loss_D: 0.106130\n",
      "[Epoch 171/200] [Batch 180/938] loss_G: 3.221964, loss_D: 0.251704\n",
      "[Epoch 171/200] [Batch 190/938] loss_G: 3.372307, loss_D: 0.159000\n",
      "[Epoch 171/200] [Batch 200/938] loss_G: 3.455378, loss_D: 0.162167\n",
      "[Epoch 171/200] [Batch 210/938] loss_G: 3.718932, loss_D: 0.139365\n",
      "[Epoch 171/200] [Batch 220/938] loss_G: 3.750980, loss_D: 0.116626\n",
      "[Epoch 171/200] [Batch 230/938] loss_G: 3.576092, loss_D: 0.181881\n",
      "[Epoch 171/200] [Batch 240/938] loss_G: 2.681859, loss_D: 0.235963\n",
      "[Epoch 171/200] [Batch 250/938] loss_G: 3.077189, loss_D: 0.142559\n",
      "[Epoch 171/200] [Batch 260/938] loss_G: 3.145421, loss_D: 0.155954\n",
      "[Epoch 171/200] [Batch 270/938] loss_G: 3.189216, loss_D: 0.209517\n",
      "[Epoch 171/200] [Batch 280/938] loss_G: 3.150282, loss_D: 0.216228\n",
      "[Epoch 171/200] [Batch 290/938] loss_G: 3.720220, loss_D: 0.194233\n",
      "[Epoch 171/200] [Batch 300/938] loss_G: 3.151057, loss_D: 0.150490\n",
      "[Epoch 171/200] [Batch 310/938] loss_G: 3.406213, loss_D: 0.204456\n",
      "[Epoch 171/200] [Batch 320/938] loss_G: 3.606846, loss_D: 0.158633\n",
      "[Epoch 171/200] [Batch 330/938] loss_G: 3.058300, loss_D: 0.252734\n",
      "[Epoch 171/200] [Batch 340/938] loss_G: 3.685331, loss_D: 0.188601\n",
      "[Epoch 171/200] [Batch 350/938] loss_G: 3.888210, loss_D: 0.229002\n",
      "[Epoch 171/200] [Batch 360/938] loss_G: 3.615096, loss_D: 0.138634\n",
      "[Epoch 171/200] [Batch 370/938] loss_G: 3.249187, loss_D: 0.251914\n",
      "[Epoch 171/200] [Batch 380/938] loss_G: 3.552205, loss_D: 0.210568\n",
      "[Epoch 171/200] [Batch 390/938] loss_G: 3.342876, loss_D: 0.156511\n",
      "[Epoch 171/200] [Batch 400/938] loss_G: 3.231261, loss_D: 0.148122\n",
      "[Epoch 171/200] [Batch 410/938] loss_G: 3.462028, loss_D: 0.181684\n",
      "[Epoch 171/200] [Batch 420/938] loss_G: 3.594217, loss_D: 0.134472\n",
      "[Epoch 171/200] [Batch 430/938] loss_G: 3.306833, loss_D: 0.164323\n",
      "[Epoch 171/200] [Batch 440/938] loss_G: 2.872272, loss_D: 0.195277\n",
      "[Epoch 171/200] [Batch 450/938] loss_G: 3.301474, loss_D: 0.294022\n",
      "[Epoch 171/200] [Batch 460/938] loss_G: 3.805437, loss_D: 0.174355\n",
      "[Epoch 171/200] [Batch 470/938] loss_G: 3.207554, loss_D: 0.160374\n",
      "[Epoch 171/200] [Batch 480/938] loss_G: 3.432723, loss_D: 0.157672\n",
      "[Epoch 171/200] [Batch 490/938] loss_G: 3.191000, loss_D: 0.215394\n",
      "[Epoch 171/200] [Batch 500/938] loss_G: 3.120577, loss_D: 0.178040\n",
      "[Epoch 171/200] [Batch 510/938] loss_G: 3.026117, loss_D: 0.215170\n",
      "[Epoch 171/200] [Batch 520/938] loss_G: 3.375423, loss_D: 0.120879\n",
      "[Epoch 171/200] [Batch 530/938] loss_G: 3.484676, loss_D: 0.259668\n",
      "[Epoch 171/200] [Batch 540/938] loss_G: 3.349394, loss_D: 0.170536\n",
      "[Epoch 171/200] [Batch 550/938] loss_G: 3.314397, loss_D: 0.091599\n",
      "[Epoch 171/200] [Batch 560/938] loss_G: 3.413230, loss_D: 0.295047\n",
      "[Epoch 171/200] [Batch 570/938] loss_G: 3.226697, loss_D: 0.202765\n",
      "[Epoch 171/200] [Batch 580/938] loss_G: 3.385988, loss_D: 0.246949\n",
      "[Epoch 171/200] [Batch 590/938] loss_G: 3.436052, loss_D: 0.166473\n",
      "[Epoch 171/200] [Batch 600/938] loss_G: 3.845018, loss_D: 0.126026\n",
      "[Epoch 171/200] [Batch 610/938] loss_G: 3.266209, loss_D: 0.186393\n",
      "[Epoch 171/200] [Batch 620/938] loss_G: 3.256574, loss_D: 0.200625\n",
      "[Epoch 171/200] [Batch 630/938] loss_G: 2.821316, loss_D: 0.162847\n",
      "[Epoch 171/200] [Batch 640/938] loss_G: 3.682456, loss_D: 0.100787\n",
      "[Epoch 171/200] [Batch 650/938] loss_G: 3.598815, loss_D: 0.142367\n",
      "[Epoch 171/200] [Batch 660/938] loss_G: 3.287713, loss_D: 0.120228\n",
      "[Epoch 171/200] [Batch 670/938] loss_G: 3.050836, loss_D: 0.200067\n",
      "[Epoch 171/200] [Batch 680/938] loss_G: 3.607064, loss_D: 0.147352\n",
      "[Epoch 171/200] [Batch 690/938] loss_G: 2.930780, loss_D: 0.194411\n",
      "[Epoch 171/200] [Batch 700/938] loss_G: 3.286046, loss_D: 0.101686\n",
      "[Epoch 171/200] [Batch 710/938] loss_G: 3.262267, loss_D: 0.139402\n",
      "[Epoch 171/200] [Batch 720/938] loss_G: 3.128053, loss_D: 0.157924\n",
      "[Epoch 171/200] [Batch 730/938] loss_G: 3.693086, loss_D: 0.147762\n",
      "[Epoch 171/200] [Batch 740/938] loss_G: 3.090348, loss_D: 0.118374\n",
      "[Epoch 171/200] [Batch 750/938] loss_G: 3.249800, loss_D: 0.141184\n",
      "[Epoch 171/200] [Batch 760/938] loss_G: 3.580181, loss_D: 0.184226\n",
      "[Epoch 171/200] [Batch 770/938] loss_G: 3.016106, loss_D: 0.220949\n",
      "[Epoch 171/200] [Batch 780/938] loss_G: 3.503239, loss_D: 0.157047\n",
      "[Epoch 171/200] [Batch 790/938] loss_G: 3.347213, loss_D: 0.227807\n",
      "[Epoch 171/200] [Batch 800/938] loss_G: 3.536520, loss_D: 0.271285\n",
      "[Epoch 171/200] [Batch 810/938] loss_G: 3.674629, loss_D: 0.124695\n",
      "[Epoch 171/200] [Batch 820/938] loss_G: 2.971118, loss_D: 0.135247\n",
      "[Epoch 171/200] [Batch 830/938] loss_G: 3.350055, loss_D: 0.302101\n",
      "[Epoch 171/200] [Batch 840/938] loss_G: 3.706588, loss_D: 0.121704\n",
      "[Epoch 171/200] [Batch 850/938] loss_G: 2.958806, loss_D: 0.192093\n",
      "[Epoch 171/200] [Batch 860/938] loss_G: 3.127317, loss_D: 0.231876\n",
      "[Epoch 171/200] [Batch 870/938] loss_G: 3.376787, loss_D: 0.143227\n",
      "[Epoch 171/200] [Batch 880/938] loss_G: 3.275244, loss_D: 0.094061\n",
      "[Epoch 171/200] [Batch 890/938] loss_G: 3.403838, loss_D: 0.250945\n",
      "[Epoch 171/200] [Batch 900/938] loss_G: 3.827368, loss_D: 0.267547\n",
      "[Epoch 171/200] [Batch 910/938] loss_G: 3.455334, loss_D: 0.210783\n",
      "[Epoch 171/200] [Batch 920/938] loss_G: 3.259790, loss_D: 0.255000\n",
      "[Epoch 171/200] [Batch 930/938] loss_G: 3.047044, loss_D: 0.181203\n",
      "[Epoch 172/200] [Batch 0/938] loss_G: 3.516997, loss_D: 0.150055\n",
      "[Epoch 172/200] [Batch 10/938] loss_G: 3.632477, loss_D: 0.184609\n",
      "[Epoch 172/200] [Batch 20/938] loss_G: 3.140772, loss_D: 0.191522\n",
      "[Epoch 172/200] [Batch 30/938] loss_G: 3.462672, loss_D: 0.156495\n",
      "[Epoch 172/200] [Batch 40/938] loss_G: 3.570910, loss_D: 0.149036\n",
      "[Epoch 172/200] [Batch 50/938] loss_G: 3.086271, loss_D: 0.178508\n",
      "[Epoch 172/200] [Batch 60/938] loss_G: 3.271438, loss_D: 0.215954\n",
      "[Epoch 172/200] [Batch 70/938] loss_G: 3.276530, loss_D: 0.209660\n",
      "[Epoch 172/200] [Batch 80/938] loss_G: 3.503026, loss_D: 0.207253\n",
      "[Epoch 172/200] [Batch 90/938] loss_G: 3.796086, loss_D: 0.175341\n",
      "[Epoch 172/200] [Batch 100/938] loss_G: 3.544746, loss_D: 0.138512\n",
      "[Epoch 172/200] [Batch 110/938] loss_G: 3.133573, loss_D: 0.266909\n",
      "[Epoch 172/200] [Batch 120/938] loss_G: 3.333014, loss_D: 0.252142\n",
      "[Epoch 172/200] [Batch 130/938] loss_G: 3.322142, loss_D: 0.234650\n",
      "[Epoch 172/200] [Batch 140/938] loss_G: 3.011799, loss_D: 0.170611\n",
      "[Epoch 172/200] [Batch 150/938] loss_G: 3.386743, loss_D: 0.140900\n",
      "[Epoch 172/200] [Batch 160/938] loss_G: 3.554232, loss_D: 0.128169\n",
      "[Epoch 172/200] [Batch 170/938] loss_G: 3.152903, loss_D: 0.153220\n",
      "[Epoch 172/200] [Batch 180/938] loss_G: 3.361003, loss_D: 0.211975\n",
      "[Epoch 172/200] [Batch 190/938] loss_G: 3.412711, loss_D: 0.229523\n",
      "[Epoch 172/200] [Batch 200/938] loss_G: 3.140104, loss_D: 0.173683\n",
      "[Epoch 172/200] [Batch 210/938] loss_G: 3.610428, loss_D: 0.125800\n",
      "[Epoch 172/200] [Batch 220/938] loss_G: 3.035407, loss_D: 0.218278\n",
      "[Epoch 172/200] [Batch 230/938] loss_G: 3.352609, loss_D: 0.243882\n",
      "[Epoch 172/200] [Batch 240/938] loss_G: 3.930444, loss_D: 0.127414\n",
      "[Epoch 172/200] [Batch 250/938] loss_G: 3.422133, loss_D: 0.152286\n",
      "[Epoch 172/200] [Batch 260/938] loss_G: 3.527277, loss_D: 0.086451\n",
      "[Epoch 172/200] [Batch 270/938] loss_G: 3.225854, loss_D: 0.323132\n",
      "[Epoch 172/200] [Batch 280/938] loss_G: 3.092013, loss_D: 0.292490\n",
      "[Epoch 172/200] [Batch 290/938] loss_G: 2.998688, loss_D: 0.210087\n",
      "[Epoch 172/200] [Batch 300/938] loss_G: 3.434657, loss_D: 0.161973\n",
      "[Epoch 172/200] [Batch 310/938] loss_G: 2.979805, loss_D: 0.219654\n",
      "[Epoch 172/200] [Batch 320/938] loss_G: 3.438120, loss_D: 0.205354\n",
      "[Epoch 172/200] [Batch 330/938] loss_G: 3.377657, loss_D: 0.193150\n",
      "[Epoch 172/200] [Batch 340/938] loss_G: 3.731788, loss_D: 0.160208\n",
      "[Epoch 172/200] [Batch 350/938] loss_G: 3.316254, loss_D: 0.221449\n",
      "[Epoch 172/200] [Batch 360/938] loss_G: 3.668555, loss_D: 0.176281\n",
      "[Epoch 172/200] [Batch 370/938] loss_G: 3.361098, loss_D: 0.143542\n",
      "[Epoch 172/200] [Batch 380/938] loss_G: 4.043233, loss_D: 0.134881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 172/200] [Batch 390/938] loss_G: 3.345441, loss_D: 0.134897\n",
      "[Epoch 172/200] [Batch 400/938] loss_G: 3.603691, loss_D: 0.134134\n",
      "[Epoch 172/200] [Batch 410/938] loss_G: 3.558527, loss_D: 0.108511\n",
      "[Epoch 172/200] [Batch 420/938] loss_G: 3.116294, loss_D: 0.195775\n",
      "[Epoch 172/200] [Batch 430/938] loss_G: 3.370981, loss_D: 0.145079\n",
      "[Epoch 172/200] [Batch 440/938] loss_G: 3.405639, loss_D: 0.202377\n",
      "[Epoch 172/200] [Batch 450/938] loss_G: 3.320371, loss_D: 0.218688\n",
      "[Epoch 172/200] [Batch 460/938] loss_G: 3.521378, loss_D: 0.270963\n",
      "[Epoch 172/200] [Batch 470/938] loss_G: 2.848511, loss_D: 0.265428\n",
      "[Epoch 172/200] [Batch 480/938] loss_G: 3.161537, loss_D: 0.246024\n",
      "[Epoch 172/200] [Batch 490/938] loss_G: 3.199341, loss_D: 0.130057\n",
      "[Epoch 172/200] [Batch 500/938] loss_G: 3.498209, loss_D: 0.140005\n",
      "[Epoch 172/200] [Batch 510/938] loss_G: 3.175113, loss_D: 0.175899\n",
      "[Epoch 172/200] [Batch 520/938] loss_G: 3.824208, loss_D: 0.243546\n",
      "[Epoch 172/200] [Batch 530/938] loss_G: 3.432794, loss_D: 0.182998\n",
      "[Epoch 172/200] [Batch 540/938] loss_G: 3.786720, loss_D: 0.140477\n",
      "[Epoch 172/200] [Batch 550/938] loss_G: 3.415863, loss_D: 0.169563\n",
      "[Epoch 172/200] [Batch 560/938] loss_G: 3.372080, loss_D: 0.160721\n",
      "[Epoch 172/200] [Batch 570/938] loss_G: 3.342286, loss_D: 0.134458\n",
      "[Epoch 172/200] [Batch 580/938] loss_G: 3.344024, loss_D: 0.086203\n",
      "[Epoch 172/200] [Batch 590/938] loss_G: 3.649075, loss_D: 0.253656\n",
      "[Epoch 172/200] [Batch 600/938] loss_G: 3.101096, loss_D: 0.300697\n",
      "[Epoch 172/200] [Batch 610/938] loss_G: 3.261128, loss_D: 0.134436\n",
      "[Epoch 172/200] [Batch 620/938] loss_G: 3.917481, loss_D: 0.120447\n",
      "[Epoch 172/200] [Batch 630/938] loss_G: 3.210575, loss_D: 0.168292\n",
      "[Epoch 172/200] [Batch 640/938] loss_G: 3.225261, loss_D: 0.171233\n",
      "[Epoch 172/200] [Batch 650/938] loss_G: 3.377357, loss_D: 0.266192\n",
      "[Epoch 172/200] [Batch 660/938] loss_G: 3.384138, loss_D: 0.210884\n",
      "[Epoch 172/200] [Batch 670/938] loss_G: 3.313500, loss_D: 0.189271\n",
      "[Epoch 172/200] [Batch 680/938] loss_G: 3.688818, loss_D: 0.136877\n",
      "[Epoch 172/200] [Batch 690/938] loss_G: 3.061402, loss_D: 0.161320\n",
      "[Epoch 172/200] [Batch 700/938] loss_G: 3.367342, loss_D: 0.246890\n",
      "[Epoch 172/200] [Batch 710/938] loss_G: 3.471615, loss_D: 0.197742\n",
      "[Epoch 172/200] [Batch 720/938] loss_G: 3.695355, loss_D: 0.207670\n",
      "[Epoch 172/200] [Batch 730/938] loss_G: 3.717083, loss_D: 0.125002\n",
      "[Epoch 172/200] [Batch 740/938] loss_G: 3.366969, loss_D: 0.216374\n",
      "[Epoch 172/200] [Batch 750/938] loss_G: 3.938324, loss_D: 0.215193\n",
      "[Epoch 172/200] [Batch 760/938] loss_G: 3.021267, loss_D: 0.199855\n",
      "[Epoch 172/200] [Batch 770/938] loss_G: 3.348470, loss_D: 0.145599\n",
      "[Epoch 172/200] [Batch 780/938] loss_G: 3.571784, loss_D: 0.185936\n",
      "[Epoch 172/200] [Batch 790/938] loss_G: 3.451490, loss_D: 0.150026\n",
      "[Epoch 172/200] [Batch 800/938] loss_G: 3.212262, loss_D: 0.211245\n",
      "[Epoch 172/200] [Batch 810/938] loss_G: 3.694923, loss_D: 0.173234\n",
      "[Epoch 172/200] [Batch 820/938] loss_G: 3.367011, loss_D: 0.194412\n",
      "[Epoch 172/200] [Batch 830/938] loss_G: 3.363817, loss_D: 0.248412\n",
      "[Epoch 172/200] [Batch 840/938] loss_G: 3.340269, loss_D: 0.275358\n",
      "[Epoch 172/200] [Batch 850/938] loss_G: 2.915818, loss_D: 0.198530\n",
      "[Epoch 172/200] [Batch 860/938] loss_G: 3.333266, loss_D: 0.199437\n",
      "[Epoch 172/200] [Batch 870/938] loss_G: 3.431259, loss_D: 0.127334\n",
      "[Epoch 172/200] [Batch 880/938] loss_G: 3.280717, loss_D: 0.143314\n",
      "[Epoch 172/200] [Batch 890/938] loss_G: 3.477942, loss_D: 0.152971\n",
      "[Epoch 172/200] [Batch 900/938] loss_G: 3.601909, loss_D: 0.174172\n",
      "[Epoch 172/200] [Batch 910/938] loss_G: 3.679105, loss_D: 0.156786\n",
      "[Epoch 172/200] [Batch 920/938] loss_G: 2.722978, loss_D: 0.176535\n",
      "[Epoch 172/200] [Batch 930/938] loss_G: 3.128994, loss_D: 0.222949\n",
      "[Epoch 173/200] [Batch 0/938] loss_G: 3.570893, loss_D: 0.173245\n",
      "[Epoch 173/200] [Batch 10/938] loss_G: 3.284798, loss_D: 0.133931\n",
      "[Epoch 173/200] [Batch 20/938] loss_G: 3.010216, loss_D: 0.183556\n",
      "[Epoch 173/200] [Batch 30/938] loss_G: 3.686806, loss_D: 0.201961\n",
      "[Epoch 173/200] [Batch 40/938] loss_G: 3.860443, loss_D: 0.129665\n",
      "[Epoch 173/200] [Batch 50/938] loss_G: 3.175964, loss_D: 0.145309\n",
      "[Epoch 173/200] [Batch 60/938] loss_G: 3.562860, loss_D: 0.155486\n",
      "[Epoch 173/200] [Batch 70/938] loss_G: 3.591561, loss_D: 0.149263\n",
      "[Epoch 173/200] [Batch 80/938] loss_G: 3.374575, loss_D: 0.126972\n",
      "[Epoch 173/200] [Batch 90/938] loss_G: 3.278550, loss_D: 0.134340\n",
      "[Epoch 173/200] [Batch 100/938] loss_G: 3.172378, loss_D: 0.199722\n",
      "[Epoch 173/200] [Batch 110/938] loss_G: 3.449410, loss_D: 0.226223\n",
      "[Epoch 173/200] [Batch 120/938] loss_G: 3.394178, loss_D: 0.183408\n",
      "[Epoch 173/200] [Batch 130/938] loss_G: 3.621486, loss_D: 0.215242\n",
      "[Epoch 173/200] [Batch 140/938] loss_G: 3.545261, loss_D: 0.132281\n",
      "[Epoch 173/200] [Batch 150/938] loss_G: 3.354325, loss_D: 0.138106\n",
      "[Epoch 173/200] [Batch 160/938] loss_G: 3.597747, loss_D: 0.124476\n",
      "[Epoch 173/200] [Batch 170/938] loss_G: 3.406758, loss_D: 0.170307\n",
      "[Epoch 173/200] [Batch 180/938] loss_G: 3.449092, loss_D: 0.219330\n",
      "[Epoch 173/200] [Batch 190/938] loss_G: 3.521846, loss_D: 0.212487\n",
      "[Epoch 173/200] [Batch 200/938] loss_G: 3.731929, loss_D: 0.187550\n",
      "[Epoch 173/200] [Batch 210/938] loss_G: 3.680704, loss_D: 0.132219\n",
      "[Epoch 173/200] [Batch 220/938] loss_G: 3.177954, loss_D: 0.214666\n",
      "[Epoch 173/200] [Batch 230/938] loss_G: 3.438879, loss_D: 0.190408\n",
      "[Epoch 173/200] [Batch 240/938] loss_G: 3.275687, loss_D: 0.160030\n",
      "[Epoch 173/200] [Batch 250/938] loss_G: 3.319474, loss_D: 0.244367\n",
      "[Epoch 173/200] [Batch 260/938] loss_G: 3.144515, loss_D: 0.237441\n",
      "[Epoch 173/200] [Batch 270/938] loss_G: 3.572050, loss_D: 0.168444\n",
      "[Epoch 173/200] [Batch 280/938] loss_G: 3.287221, loss_D: 0.262876\n",
      "[Epoch 173/200] [Batch 290/938] loss_G: 3.205465, loss_D: 0.338689\n",
      "[Epoch 173/200] [Batch 300/938] loss_G: 2.941585, loss_D: 0.188659\n",
      "[Epoch 173/200] [Batch 310/938] loss_G: 3.409341, loss_D: 0.236626\n",
      "[Epoch 173/200] [Batch 320/938] loss_G: 3.837172, loss_D: 0.095435\n",
      "[Epoch 173/200] [Batch 330/938] loss_G: 3.175795, loss_D: 0.172351\n",
      "[Epoch 173/200] [Batch 340/938] loss_G: 3.132430, loss_D: 0.145921\n",
      "[Epoch 173/200] [Batch 350/938] loss_G: 3.426826, loss_D: 0.194305\n",
      "[Epoch 173/200] [Batch 360/938] loss_G: 3.865202, loss_D: 0.107023\n",
      "[Epoch 173/200] [Batch 370/938] loss_G: 3.462957, loss_D: 0.239986\n",
      "[Epoch 173/200] [Batch 380/938] loss_G: 3.408837, loss_D: 0.124921\n",
      "[Epoch 173/200] [Batch 390/938] loss_G: 3.446633, loss_D: 0.177026\n",
      "[Epoch 173/200] [Batch 400/938] loss_G: 3.447423, loss_D: 0.110825\n",
      "[Epoch 173/200] [Batch 410/938] loss_G: 3.477377, loss_D: 0.241922\n",
      "[Epoch 173/200] [Batch 420/938] loss_G: 3.572250, loss_D: 0.149061\n",
      "[Epoch 173/200] [Batch 430/938] loss_G: 3.389649, loss_D: 0.139043\n",
      "[Epoch 173/200] [Batch 440/938] loss_G: 3.133876, loss_D: 0.207830\n",
      "[Epoch 173/200] [Batch 450/938] loss_G: 3.596588, loss_D: 0.256970\n",
      "[Epoch 173/200] [Batch 460/938] loss_G: 3.385044, loss_D: 0.213795\n",
      "[Epoch 173/200] [Batch 470/938] loss_G: 3.295064, loss_D: 0.148564\n",
      "[Epoch 173/200] [Batch 480/938] loss_G: 3.433543, loss_D: 0.178007\n",
      "[Epoch 173/200] [Batch 490/938] loss_G: 3.584656, loss_D: 0.076763\n",
      "[Epoch 173/200] [Batch 500/938] loss_G: 3.766009, loss_D: 0.108896\n",
      "[Epoch 173/200] [Batch 510/938] loss_G: 3.007104, loss_D: 0.134682\n",
      "[Epoch 173/200] [Batch 520/938] loss_G: 3.684382, loss_D: 0.163951\n",
      "[Epoch 173/200] [Batch 530/938] loss_G: 3.237889, loss_D: 0.196296\n",
      "[Epoch 173/200] [Batch 540/938] loss_G: 3.836180, loss_D: 0.136186\n",
      "[Epoch 173/200] [Batch 550/938] loss_G: 3.298898, loss_D: 0.207677\n",
      "[Epoch 173/200] [Batch 560/938] loss_G: 3.329245, loss_D: 0.135857\n",
      "[Epoch 173/200] [Batch 570/938] loss_G: 3.754100, loss_D: 0.187105\n",
      "[Epoch 173/200] [Batch 580/938] loss_G: 3.476038, loss_D: 0.160222\n",
      "[Epoch 173/200] [Batch 590/938] loss_G: 3.148437, loss_D: 0.208849\n",
      "[Epoch 173/200] [Batch 600/938] loss_G: 3.246652, loss_D: 0.178404\n",
      "[Epoch 173/200] [Batch 610/938] loss_G: 3.248980, loss_D: 0.230300\n",
      "[Epoch 173/200] [Batch 620/938] loss_G: 3.327594, loss_D: 0.190922\n",
      "[Epoch 173/200] [Batch 630/938] loss_G: 3.467570, loss_D: 0.152760\n",
      "[Epoch 173/200] [Batch 640/938] loss_G: 3.246266, loss_D: 0.206302\n",
      "[Epoch 173/200] [Batch 650/938] loss_G: 3.937071, loss_D: 0.227787\n",
      "[Epoch 173/200] [Batch 660/938] loss_G: 3.115627, loss_D: 0.132437\n",
      "[Epoch 173/200] [Batch 670/938] loss_G: 3.478500, loss_D: 0.191356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 173/200] [Batch 680/938] loss_G: 3.982800, loss_D: 0.163809\n",
      "[Epoch 173/200] [Batch 690/938] loss_G: 3.733813, loss_D: 0.256826\n",
      "[Epoch 173/200] [Batch 700/938] loss_G: 3.857487, loss_D: 0.259357\n",
      "[Epoch 173/200] [Batch 710/938] loss_G: 3.310304, loss_D: 0.204152\n",
      "[Epoch 173/200] [Batch 720/938] loss_G: 3.247083, loss_D: 0.128044\n",
      "[Epoch 173/200] [Batch 730/938] loss_G: 3.216407, loss_D: 0.211640\n",
      "[Epoch 173/200] [Batch 740/938] loss_G: 3.372908, loss_D: 0.231548\n",
      "[Epoch 173/200] [Batch 750/938] loss_G: 3.604722, loss_D: 0.263508\n",
      "[Epoch 173/200] [Batch 760/938] loss_G: 3.852953, loss_D: 0.175335\n",
      "[Epoch 173/200] [Batch 770/938] loss_G: 3.060892, loss_D: 0.223565\n",
      "[Epoch 173/200] [Batch 780/938] loss_G: 3.067714, loss_D: 0.257698\n",
      "[Epoch 173/200] [Batch 790/938] loss_G: 3.307729, loss_D: 0.147817\n",
      "[Epoch 173/200] [Batch 800/938] loss_G: 3.509541, loss_D: 0.162075\n",
      "[Epoch 173/200] [Batch 810/938] loss_G: 3.080363, loss_D: 0.226253\n",
      "[Epoch 173/200] [Batch 820/938] loss_G: 3.776167, loss_D: 0.171213\n",
      "[Epoch 173/200] [Batch 830/938] loss_G: 3.323577, loss_D: 0.196848\n",
      "[Epoch 173/200] [Batch 840/938] loss_G: 3.346491, loss_D: 0.178413\n",
      "[Epoch 173/200] [Batch 850/938] loss_G: 3.404182, loss_D: 0.227408\n",
      "[Epoch 173/200] [Batch 860/938] loss_G: 3.506291, loss_D: 0.284807\n",
      "[Epoch 173/200] [Batch 870/938] loss_G: 3.570020, loss_D: 0.198802\n",
      "[Epoch 173/200] [Batch 880/938] loss_G: 3.154831, loss_D: 0.185563\n",
      "[Epoch 173/200] [Batch 890/938] loss_G: 3.157640, loss_D: 0.220950\n",
      "[Epoch 173/200] [Batch 900/938] loss_G: 3.711021, loss_D: 0.194931\n",
      "[Epoch 173/200] [Batch 910/938] loss_G: 3.571059, loss_D: 0.138779\n",
      "[Epoch 173/200] [Batch 920/938] loss_G: 3.245349, loss_D: 0.186415\n",
      "[Epoch 173/200] [Batch 930/938] loss_G: 3.136428, loss_D: 0.126999\n",
      "[Epoch 174/200] [Batch 0/938] loss_G: 3.029573, loss_D: 0.149340\n",
      "[Epoch 174/200] [Batch 10/938] loss_G: 3.768472, loss_D: 0.235822\n",
      "[Epoch 174/200] [Batch 20/938] loss_G: 3.295867, loss_D: 0.184089\n",
      "[Epoch 174/200] [Batch 30/938] loss_G: 3.354082, loss_D: 0.152437\n",
      "[Epoch 174/200] [Batch 40/938] loss_G: 3.472664, loss_D: 0.181302\n",
      "[Epoch 174/200] [Batch 50/938] loss_G: 3.596065, loss_D: 0.143958\n",
      "[Epoch 174/200] [Batch 60/938] loss_G: 3.251443, loss_D: 0.165483\n",
      "[Epoch 174/200] [Batch 70/938] loss_G: 3.344956, loss_D: 0.117064\n",
      "[Epoch 174/200] [Batch 80/938] loss_G: 3.181464, loss_D: 0.253802\n",
      "[Epoch 174/200] [Batch 90/938] loss_G: 3.336225, loss_D: 0.184777\n",
      "[Epoch 174/200] [Batch 100/938] loss_G: 3.326692, loss_D: 0.241731\n",
      "[Epoch 174/200] [Batch 110/938] loss_G: 3.261238, loss_D: 0.226978\n",
      "[Epoch 174/200] [Batch 120/938] loss_G: 3.242013, loss_D: 0.214457\n",
      "[Epoch 174/200] [Batch 130/938] loss_G: 3.632196, loss_D: 0.160967\n",
      "[Epoch 174/200] [Batch 140/938] loss_G: 2.969362, loss_D: 0.123775\n",
      "[Epoch 174/200] [Batch 150/938] loss_G: 3.477445, loss_D: 0.199650\n",
      "[Epoch 174/200] [Batch 160/938] loss_G: 3.570981, loss_D: 0.158786\n",
      "[Epoch 174/200] [Batch 170/938] loss_G: 3.385350, loss_D: 0.140812\n",
      "[Epoch 174/200] [Batch 180/938] loss_G: 3.188080, loss_D: 0.198034\n",
      "[Epoch 174/200] [Batch 190/938] loss_G: 4.048368, loss_D: 0.119594\n",
      "[Epoch 174/200] [Batch 200/938] loss_G: 3.285893, loss_D: 0.227642\n",
      "[Epoch 174/200] [Batch 210/938] loss_G: 3.449911, loss_D: 0.202372\n",
      "[Epoch 174/200] [Batch 220/938] loss_G: 3.593333, loss_D: 0.150868\n",
      "[Epoch 174/200] [Batch 230/938] loss_G: 3.310053, loss_D: 0.127966\n",
      "[Epoch 174/200] [Batch 240/938] loss_G: 3.766155, loss_D: 0.181881\n",
      "[Epoch 174/200] [Batch 250/938] loss_G: 3.516218, loss_D: 0.268919\n",
      "[Epoch 174/200] [Batch 260/938] loss_G: 3.845125, loss_D: 0.134354\n",
      "[Epoch 174/200] [Batch 270/938] loss_G: 3.411376, loss_D: 0.158289\n",
      "[Epoch 174/200] [Batch 280/938] loss_G: 3.190755, loss_D: 0.209709\n",
      "[Epoch 174/200] [Batch 290/938] loss_G: 3.403989, loss_D: 0.105987\n",
      "[Epoch 174/200] [Batch 300/938] loss_G: 3.041745, loss_D: 0.249543\n",
      "[Epoch 174/200] [Batch 310/938] loss_G: 3.274659, loss_D: 0.176975\n",
      "[Epoch 174/200] [Batch 320/938] loss_G: 3.414067, loss_D: 0.152167\n",
      "[Epoch 174/200] [Batch 330/938] loss_G: 3.492627, loss_D: 0.172219\n",
      "[Epoch 174/200] [Batch 340/938] loss_G: 3.393137, loss_D: 0.177757\n",
      "[Epoch 174/200] [Batch 350/938] loss_G: 3.066993, loss_D: 0.127217\n",
      "[Epoch 174/200] [Batch 360/938] loss_G: 3.436784, loss_D: 0.135779\n",
      "[Epoch 174/200] [Batch 370/938] loss_G: 3.240641, loss_D: 0.115697\n",
      "[Epoch 174/200] [Batch 380/938] loss_G: 3.602181, loss_D: 0.126734\n",
      "[Epoch 174/200] [Batch 390/938] loss_G: 3.628909, loss_D: 0.159962\n",
      "[Epoch 174/200] [Batch 400/938] loss_G: 3.327304, loss_D: 0.194976\n",
      "[Epoch 174/200] [Batch 410/938] loss_G: 3.513959, loss_D: 0.196058\n",
      "[Epoch 174/200] [Batch 420/938] loss_G: 3.582930, loss_D: 0.202902\n",
      "[Epoch 174/200] [Batch 430/938] loss_G: 3.351567, loss_D: 0.175199\n",
      "[Epoch 174/200] [Batch 440/938] loss_G: 3.206671, loss_D: 0.160777\n",
      "[Epoch 174/200] [Batch 450/938] loss_G: 3.390651, loss_D: 0.162463\n",
      "[Epoch 174/200] [Batch 460/938] loss_G: 3.629282, loss_D: 0.160964\n",
      "[Epoch 174/200] [Batch 470/938] loss_G: 3.062414, loss_D: 0.236962\n",
      "[Epoch 174/200] [Batch 480/938] loss_G: 3.267660, loss_D: 0.229598\n",
      "[Epoch 174/200] [Batch 490/938] loss_G: 3.122139, loss_D: 0.260232\n",
      "[Epoch 174/200] [Batch 500/938] loss_G: 3.777963, loss_D: 0.212864\n",
      "[Epoch 174/200] [Batch 510/938] loss_G: 3.643137, loss_D: 0.187890\n",
      "[Epoch 174/200] [Batch 520/938] loss_G: 3.739354, loss_D: 0.171035\n",
      "[Epoch 174/200] [Batch 530/938] loss_G: 3.525300, loss_D: 0.179954\n",
      "[Epoch 174/200] [Batch 540/938] loss_G: 3.543713, loss_D: 0.184998\n",
      "[Epoch 174/200] [Batch 550/938] loss_G: 2.924580, loss_D: 0.238846\n",
      "[Epoch 174/200] [Batch 560/938] loss_G: 3.022397, loss_D: 0.249639\n",
      "[Epoch 174/200] [Batch 570/938] loss_G: 2.888200, loss_D: 0.173056\n",
      "[Epoch 174/200] [Batch 580/938] loss_G: 2.950755, loss_D: 0.259227\n",
      "[Epoch 174/200] [Batch 590/938] loss_G: 3.547380, loss_D: 0.227528\n",
      "[Epoch 174/200] [Batch 600/938] loss_G: 3.578034, loss_D: 0.132027\n",
      "[Epoch 174/200] [Batch 610/938] loss_G: 3.147418, loss_D: 0.275151\n",
      "[Epoch 174/200] [Batch 620/938] loss_G: 3.433426, loss_D: 0.167895\n",
      "[Epoch 174/200] [Batch 630/938] loss_G: 2.930273, loss_D: 0.243911\n",
      "[Epoch 174/200] [Batch 640/938] loss_G: 3.478411, loss_D: 0.191172\n",
      "[Epoch 174/200] [Batch 650/938] loss_G: 3.343808, loss_D: 0.179878\n",
      "[Epoch 174/200] [Batch 660/938] loss_G: 3.507565, loss_D: 0.158013\n",
      "[Epoch 174/200] [Batch 670/938] loss_G: 3.771562, loss_D: 0.129875\n",
      "[Epoch 174/200] [Batch 680/938] loss_G: 3.686985, loss_D: 0.158187\n",
      "[Epoch 174/200] [Batch 690/938] loss_G: 2.945674, loss_D: 0.269125\n",
      "[Epoch 174/200] [Batch 700/938] loss_G: 3.221790, loss_D: 0.212913\n",
      "[Epoch 174/200] [Batch 710/938] loss_G: 3.303382, loss_D: 0.178012\n",
      "[Epoch 174/200] [Batch 720/938] loss_G: 3.409544, loss_D: 0.199565\n",
      "[Epoch 174/200] [Batch 730/938] loss_G: 3.443023, loss_D: 0.209323\n",
      "[Epoch 174/200] [Batch 740/938] loss_G: 3.238938, loss_D: 0.164099\n",
      "[Epoch 174/200] [Batch 750/938] loss_G: 3.548353, loss_D: 0.158630\n",
      "[Epoch 174/200] [Batch 760/938] loss_G: 3.301636, loss_D: 0.165542\n",
      "[Epoch 174/200] [Batch 770/938] loss_G: 3.179574, loss_D: 0.241800\n",
      "[Epoch 174/200] [Batch 780/938] loss_G: 3.069780, loss_D: 0.195847\n",
      "[Epoch 174/200] [Batch 790/938] loss_G: 3.201693, loss_D: 0.129901\n",
      "[Epoch 174/200] [Batch 800/938] loss_G: 3.373327, loss_D: 0.241459\n",
      "[Epoch 174/200] [Batch 810/938] loss_G: 3.640322, loss_D: 0.159257\n",
      "[Epoch 174/200] [Batch 820/938] loss_G: 3.460176, loss_D: 0.198866\n",
      "[Epoch 174/200] [Batch 830/938] loss_G: 3.602687, loss_D: 0.135493\n",
      "[Epoch 174/200] [Batch 840/938] loss_G: 3.814679, loss_D: 0.161721\n",
      "[Epoch 174/200] [Batch 850/938] loss_G: 3.269804, loss_D: 0.284877\n",
      "[Epoch 174/200] [Batch 860/938] loss_G: 3.766092, loss_D: 0.112291\n",
      "[Epoch 174/200] [Batch 870/938] loss_G: 3.884817, loss_D: 0.208558\n",
      "[Epoch 174/200] [Batch 880/938] loss_G: 3.042371, loss_D: 0.167400\n",
      "[Epoch 174/200] [Batch 890/938] loss_G: 3.897123, loss_D: 0.148934\n",
      "[Epoch 174/200] [Batch 900/938] loss_G: 3.473878, loss_D: 0.179738\n",
      "[Epoch 174/200] [Batch 910/938] loss_G: 3.386882, loss_D: 0.176047\n",
      "[Epoch 174/200] [Batch 920/938] loss_G: 3.445669, loss_D: 0.176844\n",
      "[Epoch 174/200] [Batch 930/938] loss_G: 3.185934, loss_D: 0.153315\n",
      "[Epoch 175/200] [Batch 0/938] loss_G: 3.244310, loss_D: 0.204083\n",
      "[Epoch 175/200] [Batch 10/938] loss_G: 3.309593, loss_D: 0.211933\n",
      "[Epoch 175/200] [Batch 20/938] loss_G: 3.212315, loss_D: 0.217304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 175/200] [Batch 30/938] loss_G: 3.644554, loss_D: 0.102689\n",
      "[Epoch 175/200] [Batch 40/938] loss_G: 3.633035, loss_D: 0.186004\n",
      "[Epoch 175/200] [Batch 50/938] loss_G: 3.169080, loss_D: 0.268090\n",
      "[Epoch 175/200] [Batch 60/938] loss_G: 3.164635, loss_D: 0.214455\n",
      "[Epoch 175/200] [Batch 70/938] loss_G: 3.404741, loss_D: 0.143657\n",
      "[Epoch 175/200] [Batch 80/938] loss_G: 3.561910, loss_D: 0.130530\n",
      "[Epoch 175/200] [Batch 90/938] loss_G: 3.233734, loss_D: 0.241753\n",
      "[Epoch 175/200] [Batch 100/938] loss_G: 3.894998, loss_D: 0.093660\n",
      "[Epoch 175/200] [Batch 110/938] loss_G: 3.675060, loss_D: 0.179838\n",
      "[Epoch 175/200] [Batch 120/938] loss_G: 3.392266, loss_D: 0.181529\n",
      "[Epoch 175/200] [Batch 130/938] loss_G: 3.518534, loss_D: 0.155771\n",
      "[Epoch 175/200] [Batch 140/938] loss_G: 3.625496, loss_D: 0.137862\n",
      "[Epoch 175/200] [Batch 150/938] loss_G: 3.190008, loss_D: 0.229682\n",
      "[Epoch 175/200] [Batch 160/938] loss_G: 3.149949, loss_D: 0.262735\n",
      "[Epoch 175/200] [Batch 170/938] loss_G: 3.496410, loss_D: 0.179700\n",
      "[Epoch 175/200] [Batch 180/938] loss_G: 3.679631, loss_D: 0.178584\n",
      "[Epoch 175/200] [Batch 190/938] loss_G: 3.256379, loss_D: 0.194908\n",
      "[Epoch 175/200] [Batch 200/938] loss_G: 3.499342, loss_D: 0.159694\n",
      "[Epoch 175/200] [Batch 210/938] loss_G: 3.120938, loss_D: 0.204596\n",
      "[Epoch 175/200] [Batch 220/938] loss_G: 3.617161, loss_D: 0.134396\n",
      "[Epoch 175/200] [Batch 230/938] loss_G: 3.334313, loss_D: 0.265290\n",
      "[Epoch 175/200] [Batch 240/938] loss_G: 3.424710, loss_D: 0.186968\n",
      "[Epoch 175/200] [Batch 250/938] loss_G: 3.709571, loss_D: 0.191368\n",
      "[Epoch 175/200] [Batch 260/938] loss_G: 3.618163, loss_D: 0.198661\n",
      "[Epoch 175/200] [Batch 270/938] loss_G: 3.192331, loss_D: 0.137267\n",
      "[Epoch 175/200] [Batch 280/938] loss_G: 3.071493, loss_D: 0.250029\n",
      "[Epoch 175/200] [Batch 290/938] loss_G: 3.250046, loss_D: 0.162256\n",
      "[Epoch 175/200] [Batch 300/938] loss_G: 3.802809, loss_D: 0.230995\n",
      "[Epoch 175/200] [Batch 310/938] loss_G: 2.962782, loss_D: 0.128532\n",
      "[Epoch 175/200] [Batch 320/938] loss_G: 3.297597, loss_D: 0.250602\n",
      "[Epoch 175/200] [Batch 330/938] loss_G: 3.187125, loss_D: 0.210081\n",
      "[Epoch 175/200] [Batch 340/938] loss_G: 3.512047, loss_D: 0.122457\n",
      "[Epoch 175/200] [Batch 350/938] loss_G: 3.355291, loss_D: 0.233494\n",
      "[Epoch 175/200] [Batch 360/938] loss_G: 3.361597, loss_D: 0.156240\n",
      "[Epoch 175/200] [Batch 370/938] loss_G: 3.363957, loss_D: 0.195957\n",
      "[Epoch 175/200] [Batch 380/938] loss_G: 2.916338, loss_D: 0.171914\n",
      "[Epoch 175/200] [Batch 390/938] loss_G: 3.618065, loss_D: 0.171945\n",
      "[Epoch 175/200] [Batch 400/938] loss_G: 3.147314, loss_D: 0.219615\n",
      "[Epoch 175/200] [Batch 410/938] loss_G: 3.231930, loss_D: 0.179074\n",
      "[Epoch 175/200] [Batch 420/938] loss_G: 3.261413, loss_D: 0.229687\n",
      "[Epoch 175/200] [Batch 430/938] loss_G: 3.113136, loss_D: 0.238182\n",
      "[Epoch 175/200] [Batch 440/938] loss_G: 3.667582, loss_D: 0.165550\n",
      "[Epoch 175/200] [Batch 450/938] loss_G: 3.567370, loss_D: 0.206147\n",
      "[Epoch 175/200] [Batch 460/938] loss_G: 3.003863, loss_D: 0.168993\n",
      "[Epoch 175/200] [Batch 470/938] loss_G: 3.569602, loss_D: 0.148031\n",
      "[Epoch 175/200] [Batch 480/938] loss_G: 3.708563, loss_D: 0.177495\n",
      "[Epoch 175/200] [Batch 490/938] loss_G: 3.575327, loss_D: 0.158462\n",
      "[Epoch 175/200] [Batch 500/938] loss_G: 3.491640, loss_D: 0.172248\n",
      "[Epoch 175/200] [Batch 510/938] loss_G: 3.284451, loss_D: 0.206259\n",
      "[Epoch 175/200] [Batch 520/938] loss_G: 3.275411, loss_D: 0.255472\n",
      "[Epoch 175/200] [Batch 530/938] loss_G: 3.258888, loss_D: 0.270137\n",
      "[Epoch 175/200] [Batch 540/938] loss_G: 3.533624, loss_D: 0.153668\n",
      "[Epoch 175/200] [Batch 550/938] loss_G: 3.625953, loss_D: 0.259910\n",
      "[Epoch 175/200] [Batch 560/938] loss_G: 3.340875, loss_D: 0.152729\n",
      "[Epoch 175/200] [Batch 570/938] loss_G: 3.290790, loss_D: 0.115528\n",
      "[Epoch 175/200] [Batch 580/938] loss_G: 3.199217, loss_D: 0.160571\n",
      "[Epoch 175/200] [Batch 590/938] loss_G: 3.649255, loss_D: 0.149632\n",
      "[Epoch 175/200] [Batch 600/938] loss_G: 3.015286, loss_D: 0.179828\n",
      "[Epoch 175/200] [Batch 610/938] loss_G: 3.191113, loss_D: 0.177991\n",
      "[Epoch 175/200] [Batch 620/938] loss_G: 3.138680, loss_D: 0.232237\n",
      "[Epoch 175/200] [Batch 630/938] loss_G: 3.445548, loss_D: 0.110735\n",
      "[Epoch 175/200] [Batch 640/938] loss_G: 3.185696, loss_D: 0.158968\n",
      "[Epoch 175/200] [Batch 650/938] loss_G: 3.438156, loss_D: 0.191903\n",
      "[Epoch 175/200] [Batch 660/938] loss_G: 3.662895, loss_D: 0.229905\n",
      "[Epoch 175/200] [Batch 670/938] loss_G: 3.403054, loss_D: 0.128964\n",
      "[Epoch 175/200] [Batch 680/938] loss_G: 3.443151, loss_D: 0.199933\n",
      "[Epoch 175/200] [Batch 690/938] loss_G: 3.349898, loss_D: 0.170508\n",
      "[Epoch 175/200] [Batch 700/938] loss_G: 3.250388, loss_D: 0.162133\n",
      "[Epoch 175/200] [Batch 710/938] loss_G: 3.051422, loss_D: 0.169049\n",
      "[Epoch 175/200] [Batch 720/938] loss_G: 3.085814, loss_D: 0.222419\n",
      "[Epoch 175/200] [Batch 730/938] loss_G: 3.252248, loss_D: 0.154619\n",
      "[Epoch 175/200] [Batch 740/938] loss_G: 3.657752, loss_D: 0.206933\n",
      "[Epoch 175/200] [Batch 750/938] loss_G: 3.331428, loss_D: 0.209666\n",
      "[Epoch 175/200] [Batch 760/938] loss_G: 3.343098, loss_D: 0.158904\n",
      "[Epoch 175/200] [Batch 770/938] loss_G: 3.412769, loss_D: 0.180935\n",
      "[Epoch 175/200] [Batch 780/938] loss_G: 2.947755, loss_D: 0.254659\n",
      "[Epoch 175/200] [Batch 790/938] loss_G: 3.166679, loss_D: 0.131585\n",
      "[Epoch 175/200] [Batch 800/938] loss_G: 3.519086, loss_D: 0.163672\n",
      "[Epoch 175/200] [Batch 810/938] loss_G: 3.496118, loss_D: 0.166568\n",
      "[Epoch 175/200] [Batch 820/938] loss_G: 3.400807, loss_D: 0.177631\n",
      "[Epoch 175/200] [Batch 830/938] loss_G: 3.475351, loss_D: 0.170999\n",
      "[Epoch 175/200] [Batch 840/938] loss_G: 3.115333, loss_D: 0.225021\n",
      "[Epoch 175/200] [Batch 850/938] loss_G: 3.280563, loss_D: 0.129773\n",
      "[Epoch 175/200] [Batch 860/938] loss_G: 3.291376, loss_D: 0.219824\n",
      "[Epoch 175/200] [Batch 870/938] loss_G: 3.032668, loss_D: 0.257352\n",
      "[Epoch 175/200] [Batch 880/938] loss_G: 3.464655, loss_D: 0.182157\n",
      "[Epoch 175/200] [Batch 890/938] loss_G: 3.690869, loss_D: 0.117557\n",
      "[Epoch 175/200] [Batch 900/938] loss_G: 3.087709, loss_D: 0.204345\n",
      "[Epoch 175/200] [Batch 910/938] loss_G: 3.523278, loss_D: 0.108947\n",
      "[Epoch 175/200] [Batch 920/938] loss_G: 3.720940, loss_D: 0.123393\n",
      "[Epoch 175/200] [Batch 930/938] loss_G: 3.798359, loss_D: 0.138281\n",
      "[Epoch 176/200] [Batch 0/938] loss_G: 3.376334, loss_D: 0.229203\n",
      "[Epoch 176/200] [Batch 10/938] loss_G: 3.644442, loss_D: 0.144944\n",
      "[Epoch 176/200] [Batch 20/938] loss_G: 3.271363, loss_D: 0.189835\n",
      "[Epoch 176/200] [Batch 30/938] loss_G: 4.224624, loss_D: 0.078903\n",
      "[Epoch 176/200] [Batch 40/938] loss_G: 3.143265, loss_D: 0.242077\n",
      "[Epoch 176/200] [Batch 50/938] loss_G: 3.380227, loss_D: 0.162909\n",
      "[Epoch 176/200] [Batch 60/938] loss_G: 3.344524, loss_D: 0.217299\n",
      "[Epoch 176/200] [Batch 70/938] loss_G: 2.897095, loss_D: 0.176750\n",
      "[Epoch 176/200] [Batch 80/938] loss_G: 3.725687, loss_D: 0.127228\n",
      "[Epoch 176/200] [Batch 90/938] loss_G: 3.407696, loss_D: 0.198171\n",
      "[Epoch 176/200] [Batch 100/938] loss_G: 3.011393, loss_D: 0.138893\n",
      "[Epoch 176/200] [Batch 110/938] loss_G: 3.588934, loss_D: 0.257128\n",
      "[Epoch 176/200] [Batch 120/938] loss_G: 3.250669, loss_D: 0.122713\n",
      "[Epoch 176/200] [Batch 130/938] loss_G: 3.173525, loss_D: 0.203259\n",
      "[Epoch 176/200] [Batch 140/938] loss_G: 3.379283, loss_D: 0.171427\n",
      "[Epoch 176/200] [Batch 150/938] loss_G: 3.383768, loss_D: 0.206362\n",
      "[Epoch 176/200] [Batch 160/938] loss_G: 4.363377, loss_D: 0.144730\n",
      "[Epoch 176/200] [Batch 170/938] loss_G: 3.137388, loss_D: 0.137371\n",
      "[Epoch 176/200] [Batch 180/938] loss_G: 3.594189, loss_D: 0.162274\n",
      "[Epoch 176/200] [Batch 190/938] loss_G: 3.146221, loss_D: 0.273115\n",
      "[Epoch 176/200] [Batch 200/938] loss_G: 3.234688, loss_D: 0.209756\n",
      "[Epoch 176/200] [Batch 210/938] loss_G: 3.384737, loss_D: 0.144801\n",
      "[Epoch 176/200] [Batch 220/938] loss_G: 3.096528, loss_D: 0.189779\n",
      "[Epoch 176/200] [Batch 230/938] loss_G: 3.210435, loss_D: 0.176811\n",
      "[Epoch 176/200] [Batch 240/938] loss_G: 3.111582, loss_D: 0.145012\n",
      "[Epoch 176/200] [Batch 250/938] loss_G: 3.294693, loss_D: 0.098718\n",
      "[Epoch 176/200] [Batch 260/938] loss_G: 3.402051, loss_D: 0.205804\n",
      "[Epoch 176/200] [Batch 270/938] loss_G: 3.314908, loss_D: 0.190239\n",
      "[Epoch 176/200] [Batch 280/938] loss_G: 3.532975, loss_D: 0.108946\n",
      "[Epoch 176/200] [Batch 290/938] loss_G: 3.682418, loss_D: 0.190884\n",
      "[Epoch 176/200] [Batch 300/938] loss_G: 3.500579, loss_D: 0.171138\n",
      "[Epoch 176/200] [Batch 310/938] loss_G: 3.511737, loss_D: 0.091094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 176/200] [Batch 320/938] loss_G: 3.495160, loss_D: 0.191459\n",
      "[Epoch 176/200] [Batch 330/938] loss_G: 3.204427, loss_D: 0.202798\n",
      "[Epoch 176/200] [Batch 340/938] loss_G: 3.414277, loss_D: 0.185798\n",
      "[Epoch 176/200] [Batch 350/938] loss_G: 3.533057, loss_D: 0.167538\n",
      "[Epoch 176/200] [Batch 360/938] loss_G: 3.865529, loss_D: 0.134649\n",
      "[Epoch 176/200] [Batch 370/938] loss_G: 3.161217, loss_D: 0.144052\n",
      "[Epoch 176/200] [Batch 380/938] loss_G: 3.248208, loss_D: 0.092363\n",
      "[Epoch 176/200] [Batch 390/938] loss_G: 3.363477, loss_D: 0.093532\n",
      "[Epoch 176/200] [Batch 400/938] loss_G: 3.524447, loss_D: 0.121421\n",
      "[Epoch 176/200] [Batch 410/938] loss_G: 3.143397, loss_D: 0.232664\n",
      "[Epoch 176/200] [Batch 420/938] loss_G: 3.706344, loss_D: 0.266957\n",
      "[Epoch 176/200] [Batch 430/938] loss_G: 3.439679, loss_D: 0.200814\n",
      "[Epoch 176/200] [Batch 440/938] loss_G: 3.469999, loss_D: 0.166325\n",
      "[Epoch 176/200] [Batch 450/938] loss_G: 3.671240, loss_D: 0.183662\n",
      "[Epoch 176/200] [Batch 460/938] loss_G: 3.588364, loss_D: 0.164722\n",
      "[Epoch 176/200] [Batch 470/938] loss_G: 3.210679, loss_D: 0.169455\n",
      "[Epoch 176/200] [Batch 480/938] loss_G: 3.710599, loss_D: 0.178611\n",
      "[Epoch 176/200] [Batch 490/938] loss_G: 3.002377, loss_D: 0.138189\n",
      "[Epoch 176/200] [Batch 500/938] loss_G: 3.319802, loss_D: 0.196305\n",
      "[Epoch 176/200] [Batch 510/938] loss_G: 3.776207, loss_D: 0.155316\n",
      "[Epoch 176/200] [Batch 520/938] loss_G: 3.498041, loss_D: 0.117614\n",
      "[Epoch 176/200] [Batch 530/938] loss_G: 3.465345, loss_D: 0.204056\n",
      "[Epoch 176/200] [Batch 540/938] loss_G: 3.032476, loss_D: 0.119101\n",
      "[Epoch 176/200] [Batch 550/938] loss_G: 3.431103, loss_D: 0.206409\n",
      "[Epoch 176/200] [Batch 560/938] loss_G: 3.355510, loss_D: 0.140565\n",
      "[Epoch 176/200] [Batch 570/938] loss_G: 3.896340, loss_D: 0.162488\n",
      "[Epoch 176/200] [Batch 580/938] loss_G: 3.414881, loss_D: 0.176354\n",
      "[Epoch 176/200] [Batch 590/938] loss_G: 3.294773, loss_D: 0.175850\n",
      "[Epoch 176/200] [Batch 600/938] loss_G: 3.655190, loss_D: 0.233108\n",
      "[Epoch 176/200] [Batch 610/938] loss_G: 3.281906, loss_D: 0.129968\n",
      "[Epoch 176/200] [Batch 620/938] loss_G: 3.372416, loss_D: 0.173580\n",
      "[Epoch 176/200] [Batch 630/938] loss_G: 3.278492, loss_D: 0.202275\n",
      "[Epoch 176/200] [Batch 640/938] loss_G: 3.338748, loss_D: 0.167636\n",
      "[Epoch 176/200] [Batch 650/938] loss_G: 2.898974, loss_D: 0.172034\n",
      "[Epoch 176/200] [Batch 660/938] loss_G: 3.205531, loss_D: 0.184945\n",
      "[Epoch 176/200] [Batch 670/938] loss_G: 3.501414, loss_D: 0.184531\n",
      "[Epoch 176/200] [Batch 680/938] loss_G: 3.265272, loss_D: 0.140502\n",
      "[Epoch 176/200] [Batch 690/938] loss_G: 3.166951, loss_D: 0.207981\n",
      "[Epoch 176/200] [Batch 700/938] loss_G: 3.548596, loss_D: 0.138209\n",
      "[Epoch 176/200] [Batch 710/938] loss_G: 3.315783, loss_D: 0.208633\n",
      "[Epoch 176/200] [Batch 720/938] loss_G: 3.336445, loss_D: 0.224966\n",
      "[Epoch 176/200] [Batch 730/938] loss_G: 3.464526, loss_D: 0.149578\n",
      "[Epoch 176/200] [Batch 740/938] loss_G: 3.428822, loss_D: 0.206842\n",
      "[Epoch 176/200] [Batch 750/938] loss_G: 3.651336, loss_D: 0.170672\n",
      "[Epoch 176/200] [Batch 760/938] loss_G: 2.870030, loss_D: 0.204596\n",
      "[Epoch 176/200] [Batch 770/938] loss_G: 3.672810, loss_D: 0.104489\n",
      "[Epoch 176/200] [Batch 780/938] loss_G: 3.611392, loss_D: 0.174410\n",
      "[Epoch 176/200] [Batch 790/938] loss_G: 3.411680, loss_D: 0.132252\n",
      "[Epoch 176/200] [Batch 800/938] loss_G: 3.059868, loss_D: 0.149482\n",
      "[Epoch 176/200] [Batch 810/938] loss_G: 3.028734, loss_D: 0.286486\n",
      "[Epoch 176/200] [Batch 820/938] loss_G: 3.741974, loss_D: 0.139839\n",
      "[Epoch 176/200] [Batch 830/938] loss_G: 3.858233, loss_D: 0.168193\n",
      "[Epoch 176/200] [Batch 840/938] loss_G: 3.169558, loss_D: 0.172326\n",
      "[Epoch 176/200] [Batch 850/938] loss_G: 3.897360, loss_D: 0.212562\n",
      "[Epoch 176/200] [Batch 860/938] loss_G: 3.738241, loss_D: 0.199999\n",
      "[Epoch 176/200] [Batch 870/938] loss_G: 3.491424, loss_D: 0.204533\n",
      "[Epoch 176/200] [Batch 880/938] loss_G: 3.017426, loss_D: 0.189947\n",
      "[Epoch 176/200] [Batch 890/938] loss_G: 3.503138, loss_D: 0.169527\n",
      "[Epoch 176/200] [Batch 900/938] loss_G: 3.382431, loss_D: 0.308491\n",
      "[Epoch 176/200] [Batch 910/938] loss_G: 3.023526, loss_D: 0.167496\n",
      "[Epoch 176/200] [Batch 920/938] loss_G: 3.155110, loss_D: 0.179033\n",
      "[Epoch 176/200] [Batch 930/938] loss_G: 3.632953, loss_D: 0.195828\n",
      "[Epoch 177/200] [Batch 0/938] loss_G: 3.785139, loss_D: 0.176240\n",
      "[Epoch 177/200] [Batch 10/938] loss_G: 3.418806, loss_D: 0.095917\n",
      "[Epoch 177/200] [Batch 20/938] loss_G: 3.883061, loss_D: 0.226232\n",
      "[Epoch 177/200] [Batch 30/938] loss_G: 3.138743, loss_D: 0.115037\n",
      "[Epoch 177/200] [Batch 40/938] loss_G: 3.883791, loss_D: 0.189296\n",
      "[Epoch 177/200] [Batch 50/938] loss_G: 3.499939, loss_D: 0.165029\n",
      "[Epoch 177/200] [Batch 60/938] loss_G: 3.116725, loss_D: 0.223202\n",
      "[Epoch 177/200] [Batch 70/938] loss_G: 3.224645, loss_D: 0.164018\n",
      "[Epoch 177/200] [Batch 80/938] loss_G: 3.093120, loss_D: 0.160224\n",
      "[Epoch 177/200] [Batch 90/938] loss_G: 3.403181, loss_D: 0.165180\n",
      "[Epoch 177/200] [Batch 100/938] loss_G: 3.275318, loss_D: 0.173421\n",
      "[Epoch 177/200] [Batch 110/938] loss_G: 3.362030, loss_D: 0.171816\n",
      "[Epoch 177/200] [Batch 120/938] loss_G: 3.455654, loss_D: 0.186238\n",
      "[Epoch 177/200] [Batch 130/938] loss_G: 3.443414, loss_D: 0.145527\n",
      "[Epoch 177/200] [Batch 140/938] loss_G: 3.897166, loss_D: 0.132270\n",
      "[Epoch 177/200] [Batch 150/938] loss_G: 3.359506, loss_D: 0.078878\n",
      "[Epoch 177/200] [Batch 160/938] loss_G: 3.528578, loss_D: 0.191443\n",
      "[Epoch 177/200] [Batch 170/938] loss_G: 2.755166, loss_D: 0.209509\n",
      "[Epoch 177/200] [Batch 180/938] loss_G: 2.990041, loss_D: 0.184605\n",
      "[Epoch 177/200] [Batch 190/938] loss_G: 3.704136, loss_D: 0.177283\n",
      "[Epoch 177/200] [Batch 200/938] loss_G: 3.182966, loss_D: 0.208623\n",
      "[Epoch 177/200] [Batch 210/938] loss_G: 3.240889, loss_D: 0.214902\n",
      "[Epoch 177/200] [Batch 220/938] loss_G: 3.720703, loss_D: 0.112850\n",
      "[Epoch 177/200] [Batch 230/938] loss_G: 3.720575, loss_D: 0.226118\n",
      "[Epoch 177/200] [Batch 240/938] loss_G: 3.195717, loss_D: 0.235076\n",
      "[Epoch 177/200] [Batch 250/938] loss_G: 2.948367, loss_D: 0.172810\n",
      "[Epoch 177/200] [Batch 260/938] loss_G: 3.356581, loss_D: 0.189835\n",
      "[Epoch 177/200] [Batch 270/938] loss_G: 3.996850, loss_D: 0.158762\n",
      "[Epoch 177/200] [Batch 280/938] loss_G: 3.400040, loss_D: 0.125683\n",
      "[Epoch 177/200] [Batch 290/938] loss_G: 3.627643, loss_D: 0.215867\n",
      "[Epoch 177/200] [Batch 300/938] loss_G: 3.757233, loss_D: 0.146373\n",
      "[Epoch 177/200] [Batch 310/938] loss_G: 3.342837, loss_D: 0.283058\n",
      "[Epoch 177/200] [Batch 320/938] loss_G: 3.379125, loss_D: 0.131857\n",
      "[Epoch 177/200] [Batch 330/938] loss_G: 3.586482, loss_D: 0.130565\n",
      "[Epoch 177/200] [Batch 340/938] loss_G: 3.601506, loss_D: 0.152012\n",
      "[Epoch 177/200] [Batch 350/938] loss_G: 3.346167, loss_D: 0.144379\n",
      "[Epoch 177/200] [Batch 360/938] loss_G: 3.237837, loss_D: 0.105717\n",
      "[Epoch 177/200] [Batch 370/938] loss_G: 3.340657, loss_D: 0.222786\n",
      "[Epoch 177/200] [Batch 380/938] loss_G: 3.763720, loss_D: 0.168652\n",
      "[Epoch 177/200] [Batch 390/938] loss_G: 3.759607, loss_D: 0.178124\n",
      "[Epoch 177/200] [Batch 400/938] loss_G: 3.180881, loss_D: 0.206061\n",
      "[Epoch 177/200] [Batch 410/938] loss_G: 3.946253, loss_D: 0.139998\n",
      "[Epoch 177/200] [Batch 420/938] loss_G: 2.961170, loss_D: 0.252514\n",
      "[Epoch 177/200] [Batch 430/938] loss_G: 3.327132, loss_D: 0.247455\n",
      "[Epoch 177/200] [Batch 440/938] loss_G: 3.200856, loss_D: 0.265975\n",
      "[Epoch 177/200] [Batch 450/938] loss_G: 3.353771, loss_D: 0.191938\n",
      "[Epoch 177/200] [Batch 460/938] loss_G: 3.202124, loss_D: 0.256499\n",
      "[Epoch 177/200] [Batch 470/938] loss_G: 3.439350, loss_D: 0.214115\n",
      "[Epoch 177/200] [Batch 480/938] loss_G: 3.374086, loss_D: 0.305645\n",
      "[Epoch 177/200] [Batch 490/938] loss_G: 3.420644, loss_D: 0.147348\n",
      "[Epoch 177/200] [Batch 500/938] loss_G: 3.151745, loss_D: 0.133238\n",
      "[Epoch 177/200] [Batch 510/938] loss_G: 3.932218, loss_D: 0.162695\n",
      "[Epoch 177/200] [Batch 520/938] loss_G: 3.301349, loss_D: 0.145089\n",
      "[Epoch 177/200] [Batch 530/938] loss_G: 3.533433, loss_D: 0.222297\n",
      "[Epoch 177/200] [Batch 540/938] loss_G: 3.340405, loss_D: 0.183001\n",
      "[Epoch 177/200] [Batch 550/938] loss_G: 3.542537, loss_D: 0.222252\n",
      "[Epoch 177/200] [Batch 560/938] loss_G: 3.826073, loss_D: 0.131821\n",
      "[Epoch 177/200] [Batch 570/938] loss_G: 3.116122, loss_D: 0.197426\n",
      "[Epoch 177/200] [Batch 580/938] loss_G: 3.580021, loss_D: 0.163545\n",
      "[Epoch 177/200] [Batch 590/938] loss_G: 3.351351, loss_D: 0.183467\n",
      "[Epoch 177/200] [Batch 600/938] loss_G: 3.349958, loss_D: 0.188913\n",
      "[Epoch 177/200] [Batch 610/938] loss_G: 3.708663, loss_D: 0.131002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 177/200] [Batch 620/938] loss_G: 2.762191, loss_D: 0.169629\n",
      "[Epoch 177/200] [Batch 630/938] loss_G: 3.115988, loss_D: 0.182783\n",
      "[Epoch 177/200] [Batch 640/938] loss_G: 3.516993, loss_D: 0.109122\n",
      "[Epoch 177/200] [Batch 650/938] loss_G: 3.043851, loss_D: 0.228695\n",
      "[Epoch 177/200] [Batch 660/938] loss_G: 3.176780, loss_D: 0.193515\n",
      "[Epoch 177/200] [Batch 670/938] loss_G: 3.251344, loss_D: 0.172547\n",
      "[Epoch 177/200] [Batch 680/938] loss_G: 3.430307, loss_D: 0.128256\n",
      "[Epoch 177/200] [Batch 690/938] loss_G: 3.298161, loss_D: 0.139436\n",
      "[Epoch 177/200] [Batch 700/938] loss_G: 3.243568, loss_D: 0.173554\n",
      "[Epoch 177/200] [Batch 710/938] loss_G: 3.163092, loss_D: 0.187495\n",
      "[Epoch 177/200] [Batch 720/938] loss_G: 3.577250, loss_D: 0.160758\n",
      "[Epoch 177/200] [Batch 730/938] loss_G: 3.476218, loss_D: 0.174357\n",
      "[Epoch 177/200] [Batch 740/938] loss_G: 3.249434, loss_D: 0.163710\n",
      "[Epoch 177/200] [Batch 750/938] loss_G: 2.888460, loss_D: 0.207445\n",
      "[Epoch 177/200] [Batch 760/938] loss_G: 3.746392, loss_D: 0.192705\n",
      "[Epoch 177/200] [Batch 770/938] loss_G: 3.238807, loss_D: 0.163462\n",
      "[Epoch 177/200] [Batch 780/938] loss_G: 3.314919, loss_D: 0.242373\n",
      "[Epoch 177/200] [Batch 790/938] loss_G: 3.610338, loss_D: 0.151776\n",
      "[Epoch 177/200] [Batch 800/938] loss_G: 3.122386, loss_D: 0.222551\n",
      "[Epoch 177/200] [Batch 810/938] loss_G: 3.522013, loss_D: 0.159302\n",
      "[Epoch 177/200] [Batch 820/938] loss_G: 3.291340, loss_D: 0.179561\n",
      "[Epoch 177/200] [Batch 830/938] loss_G: 3.476791, loss_D: 0.208481\n",
      "[Epoch 177/200] [Batch 840/938] loss_G: 3.541911, loss_D: 0.126742\n",
      "[Epoch 177/200] [Batch 850/938] loss_G: 3.041998, loss_D: 0.212402\n",
      "[Epoch 177/200] [Batch 860/938] loss_G: 3.178963, loss_D: 0.210058\n",
      "[Epoch 177/200] [Batch 870/938] loss_G: 3.221868, loss_D: 0.268505\n",
      "[Epoch 177/200] [Batch 880/938] loss_G: 3.216717, loss_D: 0.140701\n",
      "[Epoch 177/200] [Batch 890/938] loss_G: 3.311082, loss_D: 0.165388\n",
      "[Epoch 177/200] [Batch 900/938] loss_G: 2.958457, loss_D: 0.223130\n",
      "[Epoch 177/200] [Batch 910/938] loss_G: 3.094762, loss_D: 0.108240\n",
      "[Epoch 177/200] [Batch 920/938] loss_G: 3.650559, loss_D: 0.203853\n",
      "[Epoch 177/200] [Batch 930/938] loss_G: 2.843950, loss_D: 0.269918\n",
      "[Epoch 178/200] [Batch 0/938] loss_G: 3.262819, loss_D: 0.214693\n",
      "[Epoch 178/200] [Batch 10/938] loss_G: 3.443363, loss_D: 0.173790\n",
      "[Epoch 178/200] [Batch 20/938] loss_G: 3.540438, loss_D: 0.193425\n",
      "[Epoch 178/200] [Batch 30/938] loss_G: 3.030360, loss_D: 0.162732\n",
      "[Epoch 178/200] [Batch 40/938] loss_G: 3.394255, loss_D: 0.229722\n",
      "[Epoch 178/200] [Batch 50/938] loss_G: 3.101668, loss_D: 0.314281\n",
      "[Epoch 178/200] [Batch 60/938] loss_G: 3.347512, loss_D: 0.145723\n",
      "[Epoch 178/200] [Batch 70/938] loss_G: 3.720537, loss_D: 0.147995\n",
      "[Epoch 178/200] [Batch 80/938] loss_G: 3.645697, loss_D: 0.293009\n",
      "[Epoch 178/200] [Batch 90/938] loss_G: 2.981721, loss_D: 0.231186\n",
      "[Epoch 178/200] [Batch 100/938] loss_G: 3.441179, loss_D: 0.160411\n",
      "[Epoch 178/200] [Batch 110/938] loss_G: 3.108650, loss_D: 0.235115\n",
      "[Epoch 178/200] [Batch 120/938] loss_G: 3.648305, loss_D: 0.218264\n",
      "[Epoch 178/200] [Batch 130/938] loss_G: 3.346156, loss_D: 0.145942\n",
      "[Epoch 178/200] [Batch 140/938] loss_G: 3.571403, loss_D: 0.137442\n",
      "[Epoch 178/200] [Batch 150/938] loss_G: 3.186286, loss_D: 0.232476\n",
      "[Epoch 178/200] [Batch 160/938] loss_G: 3.243872, loss_D: 0.161973\n",
      "[Epoch 178/200] [Batch 170/938] loss_G: 3.287601, loss_D: 0.218250\n",
      "[Epoch 178/200] [Batch 180/938] loss_G: 3.250245, loss_D: 0.154787\n",
      "[Epoch 178/200] [Batch 190/938] loss_G: 3.435057, loss_D: 0.162983\n",
      "[Epoch 178/200] [Batch 200/938] loss_G: 3.800358, loss_D: 0.147499\n",
      "[Epoch 178/200] [Batch 210/938] loss_G: 2.928119, loss_D: 0.168946\n",
      "[Epoch 178/200] [Batch 220/938] loss_G: 3.262413, loss_D: 0.148023\n",
      "[Epoch 178/200] [Batch 230/938] loss_G: 3.422322, loss_D: 0.166264\n",
      "[Epoch 178/200] [Batch 240/938] loss_G: 3.038658, loss_D: 0.321353\n",
      "[Epoch 178/200] [Batch 250/938] loss_G: 3.458268, loss_D: 0.161633\n",
      "[Epoch 178/200] [Batch 260/938] loss_G: 3.089318, loss_D: 0.147791\n",
      "[Epoch 178/200] [Batch 270/938] loss_G: 3.434060, loss_D: 0.163752\n",
      "[Epoch 178/200] [Batch 280/938] loss_G: 3.340993, loss_D: 0.342038\n",
      "[Epoch 178/200] [Batch 290/938] loss_G: 3.704460, loss_D: 0.109530\n",
      "[Epoch 178/200] [Batch 300/938] loss_G: 3.312447, loss_D: 0.178329\n",
      "[Epoch 178/200] [Batch 310/938] loss_G: 3.601427, loss_D: 0.203229\n",
      "[Epoch 178/200] [Batch 320/938] loss_G: 3.458746, loss_D: 0.184328\n",
      "[Epoch 178/200] [Batch 330/938] loss_G: 3.225517, loss_D: 0.178629\n",
      "[Epoch 178/200] [Batch 340/938] loss_G: 3.424963, loss_D: 0.154819\n",
      "[Epoch 178/200] [Batch 350/938] loss_G: 3.448552, loss_D: 0.148232\n",
      "[Epoch 178/200] [Batch 360/938] loss_G: 3.175894, loss_D: 0.227143\n",
      "[Epoch 178/200] [Batch 370/938] loss_G: 3.303868, loss_D: 0.218266\n",
      "[Epoch 178/200] [Batch 380/938] loss_G: 3.109526, loss_D: 0.119729\n",
      "[Epoch 178/200] [Batch 390/938] loss_G: 3.342638, loss_D: 0.136302\n",
      "[Epoch 178/200] [Batch 400/938] loss_G: 3.370631, loss_D: 0.169205\n",
      "[Epoch 178/200] [Batch 410/938] loss_G: 3.266299, loss_D: 0.145840\n",
      "[Epoch 178/200] [Batch 420/938] loss_G: 3.398165, loss_D: 0.280709\n",
      "[Epoch 178/200] [Batch 430/938] loss_G: 3.435533, loss_D: 0.188836\n",
      "[Epoch 178/200] [Batch 440/938] loss_G: 3.175753, loss_D: 0.242102\n",
      "[Epoch 178/200] [Batch 450/938] loss_G: 3.476140, loss_D: 0.227827\n",
      "[Epoch 178/200] [Batch 460/938] loss_G: 3.589947, loss_D: 0.144561\n",
      "[Epoch 178/200] [Batch 470/938] loss_G: 3.201507, loss_D: 0.277273\n",
      "[Epoch 178/200] [Batch 480/938] loss_G: 3.908556, loss_D: 0.262336\n",
      "[Epoch 178/200] [Batch 490/938] loss_G: 3.547248, loss_D: 0.251478\n",
      "[Epoch 178/200] [Batch 500/938] loss_G: 3.652985, loss_D: 0.190914\n",
      "[Epoch 178/200] [Batch 510/938] loss_G: 3.427172, loss_D: 0.090877\n",
      "[Epoch 178/200] [Batch 520/938] loss_G: 3.541807, loss_D: 0.254222\n",
      "[Epoch 178/200] [Batch 530/938] loss_G: 3.156621, loss_D: 0.194510\n",
      "[Epoch 178/200] [Batch 540/938] loss_G: 3.382393, loss_D: 0.154765\n",
      "[Epoch 178/200] [Batch 550/938] loss_G: 3.446483, loss_D: 0.111125\n",
      "[Epoch 178/200] [Batch 560/938] loss_G: 3.111261, loss_D: 0.165213\n",
      "[Epoch 178/200] [Batch 570/938] loss_G: 3.413111, loss_D: 0.125985\n",
      "[Epoch 178/200] [Batch 580/938] loss_G: 3.008295, loss_D: 0.188263\n",
      "[Epoch 178/200] [Batch 590/938] loss_G: 3.375321, loss_D: 0.257150\n",
      "[Epoch 178/200] [Batch 600/938] loss_G: 3.297165, loss_D: 0.186703\n",
      "[Epoch 178/200] [Batch 610/938] loss_G: 2.910678, loss_D: 0.162587\n",
      "[Epoch 178/200] [Batch 620/938] loss_G: 3.393418, loss_D: 0.164308\n",
      "[Epoch 178/200] [Batch 630/938] loss_G: 3.326872, loss_D: 0.238090\n",
      "[Epoch 178/200] [Batch 640/938] loss_G: 3.278838, loss_D: 0.161276\n",
      "[Epoch 178/200] [Batch 650/938] loss_G: 3.334535, loss_D: 0.189614\n",
      "[Epoch 178/200] [Batch 660/938] loss_G: 3.189119, loss_D: 0.205638\n",
      "[Epoch 178/200] [Batch 670/938] loss_G: 3.432022, loss_D: 0.215841\n",
      "[Epoch 178/200] [Batch 680/938] loss_G: 3.522191, loss_D: 0.184475\n",
      "[Epoch 178/200] [Batch 690/938] loss_G: 3.395355, loss_D: 0.181779\n",
      "[Epoch 178/200] [Batch 700/938] loss_G: 3.840860, loss_D: 0.141333\n",
      "[Epoch 178/200] [Batch 710/938] loss_G: 3.237550, loss_D: 0.145617\n",
      "[Epoch 178/200] [Batch 720/938] loss_G: 3.338696, loss_D: 0.179128\n",
      "[Epoch 178/200] [Batch 730/938] loss_G: 3.651438, loss_D: 0.160499\n",
      "[Epoch 178/200] [Batch 740/938] loss_G: 3.231976, loss_D: 0.259670\n",
      "[Epoch 178/200] [Batch 750/938] loss_G: 3.625195, loss_D: 0.192483\n",
      "[Epoch 178/200] [Batch 760/938] loss_G: 3.500455, loss_D: 0.186463\n",
      "[Epoch 178/200] [Batch 770/938] loss_G: 3.244480, loss_D: 0.229619\n",
      "[Epoch 178/200] [Batch 780/938] loss_G: 3.163758, loss_D: 0.263018\n",
      "[Epoch 178/200] [Batch 790/938] loss_G: 3.248796, loss_D: 0.225143\n",
      "[Epoch 178/200] [Batch 800/938] loss_G: 3.398485, loss_D: 0.213751\n",
      "[Epoch 178/200] [Batch 810/938] loss_G: 3.202701, loss_D: 0.165169\n",
      "[Epoch 178/200] [Batch 820/938] loss_G: 3.437294, loss_D: 0.217659\n",
      "[Epoch 178/200] [Batch 830/938] loss_G: 3.335974, loss_D: 0.216510\n",
      "[Epoch 178/200] [Batch 840/938] loss_G: 3.192973, loss_D: 0.208546\n",
      "[Epoch 178/200] [Batch 850/938] loss_G: 3.193459, loss_D: 0.294257\n",
      "[Epoch 178/200] [Batch 860/938] loss_G: 3.429955, loss_D: 0.261540\n",
      "[Epoch 178/200] [Batch 870/938] loss_G: 3.004320, loss_D: 0.229351\n",
      "[Epoch 178/200] [Batch 880/938] loss_G: 3.664792, loss_D: 0.303669\n",
      "[Epoch 178/200] [Batch 890/938] loss_G: 3.430036, loss_D: 0.239757\n",
      "[Epoch 178/200] [Batch 900/938] loss_G: 3.380282, loss_D: 0.256318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 178/200] [Batch 910/938] loss_G: 3.375237, loss_D: 0.255025\n",
      "[Epoch 178/200] [Batch 920/938] loss_G: 3.400855, loss_D: 0.183419\n",
      "[Epoch 178/200] [Batch 930/938] loss_G: 3.409364, loss_D: 0.128175\n",
      "[Epoch 179/200] [Batch 0/938] loss_G: 3.020344, loss_D: 0.155149\n",
      "[Epoch 179/200] [Batch 10/938] loss_G: 3.196133, loss_D: 0.192094\n",
      "[Epoch 179/200] [Batch 20/938] loss_G: 3.670777, loss_D: 0.158382\n",
      "[Epoch 179/200] [Batch 30/938] loss_G: 3.561409, loss_D: 0.186415\n",
      "[Epoch 179/200] [Batch 40/938] loss_G: 3.566108, loss_D: 0.158480\n",
      "[Epoch 179/200] [Batch 50/938] loss_G: 3.474793, loss_D: 0.154397\n",
      "[Epoch 179/200] [Batch 60/938] loss_G: 3.477267, loss_D: 0.200878\n",
      "[Epoch 179/200] [Batch 70/938] loss_G: 3.600520, loss_D: 0.166926\n",
      "[Epoch 179/200] [Batch 80/938] loss_G: 3.032749, loss_D: 0.183054\n",
      "[Epoch 179/200] [Batch 90/938] loss_G: 3.379384, loss_D: 0.168083\n",
      "[Epoch 179/200] [Batch 100/938] loss_G: 3.367911, loss_D: 0.173223\n",
      "[Epoch 179/200] [Batch 110/938] loss_G: 3.310963, loss_D: 0.188985\n",
      "[Epoch 179/200] [Batch 120/938] loss_G: 3.534435, loss_D: 0.206999\n",
      "[Epoch 179/200] [Batch 130/938] loss_G: 3.578077, loss_D: 0.140814\n",
      "[Epoch 179/200] [Batch 140/938] loss_G: 3.488674, loss_D: 0.145499\n",
      "[Epoch 179/200] [Batch 150/938] loss_G: 3.333836, loss_D: 0.240148\n",
      "[Epoch 179/200] [Batch 160/938] loss_G: 3.451131, loss_D: 0.193870\n",
      "[Epoch 179/200] [Batch 170/938] loss_G: 3.356297, loss_D: 0.166747\n",
      "[Epoch 179/200] [Batch 180/938] loss_G: 3.209013, loss_D: 0.141357\n",
      "[Epoch 179/200] [Batch 190/938] loss_G: 3.401124, loss_D: 0.143819\n",
      "[Epoch 179/200] [Batch 200/938] loss_G: 3.165519, loss_D: 0.219504\n",
      "[Epoch 179/200] [Batch 210/938] loss_G: 3.514261, loss_D: 0.149076\n",
      "[Epoch 179/200] [Batch 220/938] loss_G: 3.204363, loss_D: 0.163653\n",
      "[Epoch 179/200] [Batch 230/938] loss_G: 3.348324, loss_D: 0.168786\n",
      "[Epoch 179/200] [Batch 240/938] loss_G: 3.400266, loss_D: 0.162683\n",
      "[Epoch 179/200] [Batch 250/938] loss_G: 3.199363, loss_D: 0.186987\n",
      "[Epoch 179/200] [Batch 260/938] loss_G: 3.479189, loss_D: 0.215180\n",
      "[Epoch 179/200] [Batch 270/938] loss_G: 3.836988, loss_D: 0.181669\n",
      "[Epoch 179/200] [Batch 280/938] loss_G: 3.663351, loss_D: 0.170112\n",
      "[Epoch 179/200] [Batch 290/938] loss_G: 3.521214, loss_D: 0.109983\n",
      "[Epoch 179/200] [Batch 300/938] loss_G: 2.891331, loss_D: 0.173024\n",
      "[Epoch 179/200] [Batch 310/938] loss_G: 3.491273, loss_D: 0.184565\n",
      "[Epoch 179/200] [Batch 320/938] loss_G: 3.927208, loss_D: 0.095866\n",
      "[Epoch 179/200] [Batch 330/938] loss_G: 3.239686, loss_D: 0.159914\n",
      "[Epoch 179/200] [Batch 340/938] loss_G: 3.732569, loss_D: 0.129086\n",
      "[Epoch 179/200] [Batch 350/938] loss_G: 3.560013, loss_D: 0.247795\n",
      "[Epoch 179/200] [Batch 360/938] loss_G: 3.387112, loss_D: 0.167489\n",
      "[Epoch 179/200] [Batch 370/938] loss_G: 3.496965, loss_D: 0.188016\n",
      "[Epoch 179/200] [Batch 380/938] loss_G: 3.921776, loss_D: 0.174636\n",
      "[Epoch 179/200] [Batch 390/938] loss_G: 3.318813, loss_D: 0.169043\n",
      "[Epoch 179/200] [Batch 400/938] loss_G: 3.137714, loss_D: 0.217601\n",
      "[Epoch 179/200] [Batch 410/938] loss_G: 3.453482, loss_D: 0.147302\n",
      "[Epoch 179/200] [Batch 420/938] loss_G: 3.278280, loss_D: 0.170644\n",
      "[Epoch 179/200] [Batch 430/938] loss_G: 3.064672, loss_D: 0.195890\n",
      "[Epoch 179/200] [Batch 440/938] loss_G: 3.627613, loss_D: 0.122652\n",
      "[Epoch 179/200] [Batch 450/938] loss_G: 3.382932, loss_D: 0.142182\n",
      "[Epoch 179/200] [Batch 460/938] loss_G: 3.814861, loss_D: 0.163524\n",
      "[Epoch 179/200] [Batch 470/938] loss_G: 3.361269, loss_D: 0.189828\n",
      "[Epoch 179/200] [Batch 480/938] loss_G: 3.492276, loss_D: 0.175306\n",
      "[Epoch 179/200] [Batch 490/938] loss_G: 3.368033, loss_D: 0.177732\n",
      "[Epoch 179/200] [Batch 500/938] loss_G: 3.186707, loss_D: 0.125736\n",
      "[Epoch 179/200] [Batch 510/938] loss_G: 3.131508, loss_D: 0.151876\n",
      "[Epoch 179/200] [Batch 520/938] loss_G: 3.774906, loss_D: 0.131100\n",
      "[Epoch 179/200] [Batch 530/938] loss_G: 3.258384, loss_D: 0.205076\n",
      "[Epoch 179/200] [Batch 540/938] loss_G: 3.684921, loss_D: 0.196261\n",
      "[Epoch 179/200] [Batch 550/938] loss_G: 3.093191, loss_D: 0.178666\n",
      "[Epoch 179/200] [Batch 560/938] loss_G: 3.362425, loss_D: 0.246756\n",
      "[Epoch 179/200] [Batch 570/938] loss_G: 3.740478, loss_D: 0.124082\n",
      "[Epoch 179/200] [Batch 580/938] loss_G: 3.783293, loss_D: 0.173714\n",
      "[Epoch 179/200] [Batch 590/938] loss_G: 3.297607, loss_D: 0.179315\n",
      "[Epoch 179/200] [Batch 600/938] loss_G: 3.142437, loss_D: 0.177928\n",
      "[Epoch 179/200] [Batch 610/938] loss_G: 3.755320, loss_D: 0.162498\n",
      "[Epoch 179/200] [Batch 620/938] loss_G: 3.389239, loss_D: 0.170929\n",
      "[Epoch 179/200] [Batch 630/938] loss_G: 3.143466, loss_D: 0.164207\n",
      "[Epoch 179/200] [Batch 640/938] loss_G: 3.590797, loss_D: 0.204778\n",
      "[Epoch 179/200] [Batch 650/938] loss_G: 3.346764, loss_D: 0.154810\n",
      "[Epoch 179/200] [Batch 660/938] loss_G: 3.367963, loss_D: 0.182795\n",
      "[Epoch 179/200] [Batch 670/938] loss_G: 3.271822, loss_D: 0.186921\n",
      "[Epoch 179/200] [Batch 680/938] loss_G: 3.449326, loss_D: 0.223547\n",
      "[Epoch 179/200] [Batch 690/938] loss_G: 3.487317, loss_D: 0.173500\n",
      "[Epoch 179/200] [Batch 700/938] loss_G: 3.681681, loss_D: 0.091541\n",
      "[Epoch 179/200] [Batch 710/938] loss_G: 3.463218, loss_D: 0.172543\n",
      "[Epoch 179/200] [Batch 720/938] loss_G: 3.599274, loss_D: 0.273680\n",
      "[Epoch 179/200] [Batch 730/938] loss_G: 2.975688, loss_D: 0.136830\n",
      "[Epoch 179/200] [Batch 740/938] loss_G: 3.494071, loss_D: 0.260853\n",
      "[Epoch 179/200] [Batch 750/938] loss_G: 3.497143, loss_D: 0.149877\n",
      "[Epoch 179/200] [Batch 760/938] loss_G: 3.856585, loss_D: 0.110062\n",
      "[Epoch 179/200] [Batch 770/938] loss_G: 3.747941, loss_D: 0.254789\n",
      "[Epoch 179/200] [Batch 780/938] loss_G: 3.298285, loss_D: 0.201028\n",
      "[Epoch 179/200] [Batch 790/938] loss_G: 3.042532, loss_D: 0.191500\n",
      "[Epoch 179/200] [Batch 800/938] loss_G: 3.127272, loss_D: 0.144991\n",
      "[Epoch 179/200] [Batch 810/938] loss_G: 3.341425, loss_D: 0.190347\n",
      "[Epoch 179/200] [Batch 820/938] loss_G: 3.525041, loss_D: 0.237877\n",
      "[Epoch 179/200] [Batch 830/938] loss_G: 3.305057, loss_D: 0.129962\n",
      "[Epoch 179/200] [Batch 840/938] loss_G: 3.756789, loss_D: 0.185385\n",
      "[Epoch 179/200] [Batch 850/938] loss_G: 3.212821, loss_D: 0.221697\n",
      "[Epoch 179/200] [Batch 860/938] loss_G: 3.551328, loss_D: 0.261302\n",
      "[Epoch 179/200] [Batch 870/938] loss_G: 3.616756, loss_D: 0.127354\n",
      "[Epoch 179/200] [Batch 880/938] loss_G: 3.361119, loss_D: 0.187950\n",
      "[Epoch 179/200] [Batch 890/938] loss_G: 3.405161, loss_D: 0.186728\n",
      "[Epoch 179/200] [Batch 900/938] loss_G: 3.182589, loss_D: 0.084927\n",
      "[Epoch 179/200] [Batch 910/938] loss_G: 3.583807, loss_D: 0.212375\n",
      "[Epoch 179/200] [Batch 920/938] loss_G: 3.491596, loss_D: 0.164209\n",
      "[Epoch 179/200] [Batch 930/938] loss_G: 3.121955, loss_D: 0.219429\n",
      "[Epoch 180/200] [Batch 0/938] loss_G: 3.490586, loss_D: 0.172874\n",
      "[Epoch 180/200] [Batch 10/938] loss_G: 3.687232, loss_D: 0.206059\n",
      "[Epoch 180/200] [Batch 20/938] loss_G: 3.196099, loss_D: 0.260433\n",
      "[Epoch 180/200] [Batch 30/938] loss_G: 3.227953, loss_D: 0.245044\n",
      "[Epoch 180/200] [Batch 40/938] loss_G: 3.444107, loss_D: 0.202485\n",
      "[Epoch 180/200] [Batch 50/938] loss_G: 3.764046, loss_D: 0.149449\n",
      "[Epoch 180/200] [Batch 60/938] loss_G: 3.257178, loss_D: 0.168317\n",
      "[Epoch 180/200] [Batch 70/938] loss_G: 3.410303, loss_D: 0.132322\n",
      "[Epoch 180/200] [Batch 80/938] loss_G: 3.525434, loss_D: 0.250154\n",
      "[Epoch 180/200] [Batch 90/938] loss_G: 3.514877, loss_D: 0.204513\n",
      "[Epoch 180/200] [Batch 100/938] loss_G: 3.046494, loss_D: 0.196705\n",
      "[Epoch 180/200] [Batch 110/938] loss_G: 3.175404, loss_D: 0.248410\n",
      "[Epoch 180/200] [Batch 120/938] loss_G: 3.467332, loss_D: 0.145618\n",
      "[Epoch 180/200] [Batch 130/938] loss_G: 3.545939, loss_D: 0.141637\n",
      "[Epoch 180/200] [Batch 140/938] loss_G: 3.238266, loss_D: 0.180747\n",
      "[Epoch 180/200] [Batch 150/938] loss_G: 3.670879, loss_D: 0.156062\n",
      "[Epoch 180/200] [Batch 160/938] loss_G: 3.471083, loss_D: 0.153836\n",
      "[Epoch 180/200] [Batch 170/938] loss_G: 4.024439, loss_D: 0.154111\n",
      "[Epoch 180/200] [Batch 180/938] loss_G: 3.439425, loss_D: 0.189358\n",
      "[Epoch 180/200] [Batch 190/938] loss_G: 3.768151, loss_D: 0.149374\n",
      "[Epoch 180/200] [Batch 200/938] loss_G: 3.810189, loss_D: 0.284852\n",
      "[Epoch 180/200] [Batch 210/938] loss_G: 3.320692, loss_D: 0.116776\n",
      "[Epoch 180/200] [Batch 220/938] loss_G: 3.215794, loss_D: 0.169538\n",
      "[Epoch 180/200] [Batch 230/938] loss_G: 3.835257, loss_D: 0.253012\n",
      "[Epoch 180/200] [Batch 240/938] loss_G: 2.956671, loss_D: 0.249205\n",
      "[Epoch 180/200] [Batch 250/938] loss_G: 3.613540, loss_D: 0.216255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 180/200] [Batch 260/938] loss_G: 3.666995, loss_D: 0.117926\n",
      "[Epoch 180/200] [Batch 270/938] loss_G: 3.579166, loss_D: 0.171034\n",
      "[Epoch 180/200] [Batch 280/938] loss_G: 3.517619, loss_D: 0.285324\n",
      "[Epoch 180/200] [Batch 290/938] loss_G: 3.240688, loss_D: 0.157881\n",
      "[Epoch 180/200] [Batch 300/938] loss_G: 2.837407, loss_D: 0.177775\n",
      "[Epoch 180/200] [Batch 310/938] loss_G: 3.494147, loss_D: 0.195441\n",
      "[Epoch 180/200] [Batch 320/938] loss_G: 3.188830, loss_D: 0.251535\n",
      "[Epoch 180/200] [Batch 330/938] loss_G: 3.369452, loss_D: 0.138816\n",
      "[Epoch 180/200] [Batch 340/938] loss_G: 3.255352, loss_D: 0.156865\n",
      "[Epoch 180/200] [Batch 350/938] loss_G: 3.431859, loss_D: 0.251670\n",
      "[Epoch 180/200] [Batch 360/938] loss_G: 3.577710, loss_D: 0.205684\n",
      "[Epoch 180/200] [Batch 370/938] loss_G: 2.929932, loss_D: 0.179275\n",
      "[Epoch 180/200] [Batch 380/938] loss_G: 3.494674, loss_D: 0.203246\n",
      "[Epoch 180/200] [Batch 390/938] loss_G: 3.401081, loss_D: 0.203691\n",
      "[Epoch 180/200] [Batch 400/938] loss_G: 3.243590, loss_D: 0.185678\n",
      "[Epoch 180/200] [Batch 410/938] loss_G: 3.177300, loss_D: 0.139970\n",
      "[Epoch 180/200] [Batch 420/938] loss_G: 3.332234, loss_D: 0.163800\n",
      "[Epoch 180/200] [Batch 430/938] loss_G: 3.420673, loss_D: 0.148400\n",
      "[Epoch 180/200] [Batch 440/938] loss_G: 3.620313, loss_D: 0.177825\n",
      "[Epoch 180/200] [Batch 450/938] loss_G: 3.309036, loss_D: 0.233073\n",
      "[Epoch 180/200] [Batch 460/938] loss_G: 3.338003, loss_D: 0.213713\n",
      "[Epoch 180/200] [Batch 470/938] loss_G: 3.296202, loss_D: 0.149906\n",
      "[Epoch 180/200] [Batch 480/938] loss_G: 3.748665, loss_D: 0.138816\n",
      "[Epoch 180/200] [Batch 490/938] loss_G: 3.581897, loss_D: 0.106979\n",
      "[Epoch 180/200] [Batch 500/938] loss_G: 3.256167, loss_D: 0.210361\n",
      "[Epoch 180/200] [Batch 510/938] loss_G: 3.184033, loss_D: 0.129603\n",
      "[Epoch 180/200] [Batch 520/938] loss_G: 3.711228, loss_D: 0.139006\n",
      "[Epoch 180/200] [Batch 530/938] loss_G: 3.908897, loss_D: 0.224014\n",
      "[Epoch 180/200] [Batch 540/938] loss_G: 3.024152, loss_D: 0.161997\n",
      "[Epoch 180/200] [Batch 550/938] loss_G: 3.351095, loss_D: 0.171571\n",
      "[Epoch 180/200] [Batch 560/938] loss_G: 3.156803, loss_D: 0.177335\n",
      "[Epoch 180/200] [Batch 570/938] loss_G: 3.700614, loss_D: 0.146220\n",
      "[Epoch 180/200] [Batch 580/938] loss_G: 2.810158, loss_D: 0.221111\n",
      "[Epoch 180/200] [Batch 590/938] loss_G: 3.209626, loss_D: 0.258822\n",
      "[Epoch 180/200] [Batch 600/938] loss_G: 3.340957, loss_D: 0.228738\n",
      "[Epoch 180/200] [Batch 610/938] loss_G: 2.718904, loss_D: 0.293459\n",
      "[Epoch 180/200] [Batch 620/938] loss_G: 3.588650, loss_D: 0.183664\n",
      "[Epoch 180/200] [Batch 630/938] loss_G: 3.286706, loss_D: 0.134104\n",
      "[Epoch 180/200] [Batch 640/938] loss_G: 3.371052, loss_D: 0.134129\n",
      "[Epoch 180/200] [Batch 650/938] loss_G: 3.613756, loss_D: 0.147290\n",
      "[Epoch 180/200] [Batch 660/938] loss_G: 3.317743, loss_D: 0.229763\n",
      "[Epoch 180/200] [Batch 670/938] loss_G: 3.173638, loss_D: 0.163543\n",
      "[Epoch 180/200] [Batch 680/938] loss_G: 3.742124, loss_D: 0.157511\n",
      "[Epoch 180/200] [Batch 690/938] loss_G: 3.361290, loss_D: 0.211472\n",
      "[Epoch 180/200] [Batch 700/938] loss_G: 3.192611, loss_D: 0.162554\n",
      "[Epoch 180/200] [Batch 710/938] loss_G: 3.652337, loss_D: 0.153032\n",
      "[Epoch 180/200] [Batch 720/938] loss_G: 3.409457, loss_D: 0.163424\n",
      "[Epoch 180/200] [Batch 730/938] loss_G: 3.552497, loss_D: 0.185462\n",
      "[Epoch 180/200] [Batch 740/938] loss_G: 3.778368, loss_D: 0.168079\n",
      "[Epoch 180/200] [Batch 750/938] loss_G: 3.408994, loss_D: 0.154520\n",
      "[Epoch 180/200] [Batch 760/938] loss_G: 3.255954, loss_D: 0.145606\n",
      "[Epoch 180/200] [Batch 770/938] loss_G: 3.352699, loss_D: 0.138416\n",
      "[Epoch 180/200] [Batch 780/938] loss_G: 3.744089, loss_D: 0.164568\n",
      "[Epoch 180/200] [Batch 790/938] loss_G: 3.590535, loss_D: 0.247101\n",
      "[Epoch 180/200] [Batch 800/938] loss_G: 3.360368, loss_D: 0.239251\n",
      "[Epoch 180/200] [Batch 810/938] loss_G: 3.871763, loss_D: 0.157575\n",
      "[Epoch 180/200] [Batch 820/938] loss_G: 3.824395, loss_D: 0.231781\n",
      "[Epoch 180/200] [Batch 830/938] loss_G: 3.372202, loss_D: 0.117938\n",
      "[Epoch 180/200] [Batch 840/938] loss_G: 3.507782, loss_D: 0.107588\n",
      "[Epoch 180/200] [Batch 850/938] loss_G: 3.795590, loss_D: 0.118303\n",
      "[Epoch 180/200] [Batch 860/938] loss_G: 3.267581, loss_D: 0.310185\n",
      "[Epoch 180/200] [Batch 870/938] loss_G: 3.088174, loss_D: 0.152328\n",
      "[Epoch 180/200] [Batch 880/938] loss_G: 3.125721, loss_D: 0.227141\n",
      "[Epoch 180/200] [Batch 890/938] loss_G: 3.256254, loss_D: 0.178677\n",
      "[Epoch 180/200] [Batch 900/938] loss_G: 3.350781, loss_D: 0.143375\n",
      "[Epoch 180/200] [Batch 910/938] loss_G: 4.014075, loss_D: 0.219093\n",
      "[Epoch 180/200] [Batch 920/938] loss_G: 3.385576, loss_D: 0.236095\n",
      "[Epoch 180/200] [Batch 930/938] loss_G: 3.490046, loss_D: 0.153441\n",
      "[Epoch 181/200] [Batch 0/938] loss_G: 3.523523, loss_D: 0.152249\n",
      "[Epoch 181/200] [Batch 10/938] loss_G: 3.185777, loss_D: 0.265159\n",
      "[Epoch 181/200] [Batch 20/938] loss_G: 3.542422, loss_D: 0.203627\n",
      "[Epoch 181/200] [Batch 30/938] loss_G: 3.161639, loss_D: 0.107670\n",
      "[Epoch 181/200] [Batch 40/938] loss_G: 3.910515, loss_D: 0.203696\n",
      "[Epoch 181/200] [Batch 50/938] loss_G: 3.384803, loss_D: 0.225815\n",
      "[Epoch 181/200] [Batch 60/938] loss_G: 3.136124, loss_D: 0.168749\n",
      "[Epoch 181/200] [Batch 70/938] loss_G: 3.396068, loss_D: 0.172604\n",
      "[Epoch 181/200] [Batch 80/938] loss_G: 3.147254, loss_D: 0.195718\n",
      "[Epoch 181/200] [Batch 90/938] loss_G: 3.983838, loss_D: 0.139360\n",
      "[Epoch 181/200] [Batch 100/938] loss_G: 3.761673, loss_D: 0.169417\n",
      "[Epoch 181/200] [Batch 110/938] loss_G: 3.124677, loss_D: 0.252978\n",
      "[Epoch 181/200] [Batch 120/938] loss_G: 3.791033, loss_D: 0.102890\n",
      "[Epoch 181/200] [Batch 130/938] loss_G: 3.440595, loss_D: 0.173083\n",
      "[Epoch 181/200] [Batch 140/938] loss_G: 3.358360, loss_D: 0.154841\n",
      "[Epoch 181/200] [Batch 150/938] loss_G: 3.729041, loss_D: 0.141314\n",
      "[Epoch 181/200] [Batch 160/938] loss_G: 3.527075, loss_D: 0.133678\n",
      "[Epoch 181/200] [Batch 170/938] loss_G: 3.254985, loss_D: 0.235243\n",
      "[Epoch 181/200] [Batch 180/938] loss_G: 3.427026, loss_D: 0.181871\n",
      "[Epoch 181/200] [Batch 190/938] loss_G: 3.787633, loss_D: 0.214775\n",
      "[Epoch 181/200] [Batch 200/938] loss_G: 3.468592, loss_D: 0.130436\n",
      "[Epoch 181/200] [Batch 210/938] loss_G: 3.186155, loss_D: 0.118268\n",
      "[Epoch 181/200] [Batch 220/938] loss_G: 3.480958, loss_D: 0.211777\n",
      "[Epoch 181/200] [Batch 230/938] loss_G: 3.153522, loss_D: 0.191814\n",
      "[Epoch 181/200] [Batch 240/938] loss_G: 3.531043, loss_D: 0.146055\n",
      "[Epoch 181/200] [Batch 250/938] loss_G: 3.625009, loss_D: 0.182984\n",
      "[Epoch 181/200] [Batch 260/938] loss_G: 3.075254, loss_D: 0.181438\n",
      "[Epoch 181/200] [Batch 270/938] loss_G: 3.435620, loss_D: 0.241185\n",
      "[Epoch 181/200] [Batch 280/938] loss_G: 3.512660, loss_D: 0.118036\n",
      "[Epoch 181/200] [Batch 290/938] loss_G: 2.958282, loss_D: 0.142224\n",
      "[Epoch 181/200] [Batch 300/938] loss_G: 3.744006, loss_D: 0.196481\n",
      "[Epoch 181/200] [Batch 310/938] loss_G: 3.045890, loss_D: 0.304032\n",
      "[Epoch 181/200] [Batch 320/938] loss_G: 3.521578, loss_D: 0.270438\n",
      "[Epoch 181/200] [Batch 330/938] loss_G: 3.651967, loss_D: 0.098474\n",
      "[Epoch 181/200] [Batch 340/938] loss_G: 3.789404, loss_D: 0.156617\n",
      "[Epoch 181/200] [Batch 350/938] loss_G: 3.651235, loss_D: 0.127874\n",
      "[Epoch 181/200] [Batch 360/938] loss_G: 3.374190, loss_D: 0.203247\n",
      "[Epoch 181/200] [Batch 370/938] loss_G: 3.266747, loss_D: 0.115817\n",
      "[Epoch 181/200] [Batch 380/938] loss_G: 3.049386, loss_D: 0.220897\n",
      "[Epoch 181/200] [Batch 390/938] loss_G: 3.399602, loss_D: 0.149212\n",
      "[Epoch 181/200] [Batch 400/938] loss_G: 3.451788, loss_D: 0.245747\n",
      "[Epoch 181/200] [Batch 410/938] loss_G: 3.302526, loss_D: 0.217763\n",
      "[Epoch 181/200] [Batch 420/938] loss_G: 3.552343, loss_D: 0.176444\n",
      "[Epoch 181/200] [Batch 430/938] loss_G: 3.197170, loss_D: 0.202457\n",
      "[Epoch 181/200] [Batch 440/938] loss_G: 3.251279, loss_D: 0.217539\n",
      "[Epoch 181/200] [Batch 450/938] loss_G: 3.169159, loss_D: 0.170866\n",
      "[Epoch 181/200] [Batch 460/938] loss_G: 3.379789, loss_D: 0.156901\n",
      "[Epoch 181/200] [Batch 470/938] loss_G: 3.553741, loss_D: 0.180626\n",
      "[Epoch 181/200] [Batch 480/938] loss_G: 3.808933, loss_D: 0.296768\n",
      "[Epoch 181/200] [Batch 490/938] loss_G: 3.236698, loss_D: 0.201605\n",
      "[Epoch 181/200] [Batch 500/938] loss_G: 3.446076, loss_D: 0.277789\n",
      "[Epoch 181/200] [Batch 510/938] loss_G: 2.863131, loss_D: 0.286326\n",
      "[Epoch 181/200] [Batch 520/938] loss_G: 3.400533, loss_D: 0.145401\n",
      "[Epoch 181/200] [Batch 530/938] loss_G: 3.500674, loss_D: 0.157522\n",
      "[Epoch 181/200] [Batch 540/938] loss_G: 3.208740, loss_D: 0.194323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 181/200] [Batch 550/938] loss_G: 3.095534, loss_D: 0.182277\n",
      "[Epoch 181/200] [Batch 560/938] loss_G: 3.420342, loss_D: 0.279982\n",
      "[Epoch 181/200] [Batch 570/938] loss_G: 3.527582, loss_D: 0.157025\n",
      "[Epoch 181/200] [Batch 580/938] loss_G: 3.649427, loss_D: 0.190025\n",
      "[Epoch 181/200] [Batch 590/938] loss_G: 3.106353, loss_D: 0.182547\n",
      "[Epoch 181/200] [Batch 600/938] loss_G: 2.919594, loss_D: 0.218873\n",
      "[Epoch 181/200] [Batch 610/938] loss_G: 3.663083, loss_D: 0.241544\n",
      "[Epoch 181/200] [Batch 620/938] loss_G: 3.209746, loss_D: 0.184419\n",
      "[Epoch 181/200] [Batch 630/938] loss_G: 3.555552, loss_D: 0.261014\n",
      "[Epoch 181/200] [Batch 640/938] loss_G: 3.123352, loss_D: 0.132381\n",
      "[Epoch 181/200] [Batch 650/938] loss_G: 3.075640, loss_D: 0.164575\n",
      "[Epoch 181/200] [Batch 660/938] loss_G: 3.498425, loss_D: 0.145237\n",
      "[Epoch 181/200] [Batch 670/938] loss_G: 2.950863, loss_D: 0.194813\n",
      "[Epoch 181/200] [Batch 680/938] loss_G: 3.242060, loss_D: 0.277623\n",
      "[Epoch 181/200] [Batch 690/938] loss_G: 3.562550, loss_D: 0.275173\n",
      "[Epoch 181/200] [Batch 700/938] loss_G: 3.530572, loss_D: 0.204984\n",
      "[Epoch 181/200] [Batch 710/938] loss_G: 3.246958, loss_D: 0.200039\n",
      "[Epoch 181/200] [Batch 720/938] loss_G: 3.504024, loss_D: 0.179075\n",
      "[Epoch 181/200] [Batch 730/938] loss_G: 3.409017, loss_D: 0.247434\n",
      "[Epoch 181/200] [Batch 740/938] loss_G: 3.647746, loss_D: 0.206922\n",
      "[Epoch 181/200] [Batch 750/938] loss_G: 3.177879, loss_D: 0.176797\n",
      "[Epoch 181/200] [Batch 760/938] loss_G: 3.719458, loss_D: 0.145289\n",
      "[Epoch 181/200] [Batch 770/938] loss_G: 3.522807, loss_D: 0.260230\n",
      "[Epoch 181/200] [Batch 780/938] loss_G: 3.426389, loss_D: 0.158290\n",
      "[Epoch 181/200] [Batch 790/938] loss_G: 3.197136, loss_D: 0.131258\n",
      "[Epoch 181/200] [Batch 800/938] loss_G: 3.244070, loss_D: 0.137248\n",
      "[Epoch 181/200] [Batch 810/938] loss_G: 3.490830, loss_D: 0.140131\n",
      "[Epoch 181/200] [Batch 820/938] loss_G: 3.402230, loss_D: 0.159181\n",
      "[Epoch 181/200] [Batch 830/938] loss_G: 3.335997, loss_D: 0.278155\n",
      "[Epoch 181/200] [Batch 840/938] loss_G: 3.231797, loss_D: 0.257711\n",
      "[Epoch 181/200] [Batch 850/938] loss_G: 3.535555, loss_D: 0.187869\n",
      "[Epoch 181/200] [Batch 860/938] loss_G: 3.411610, loss_D: 0.163669\n",
      "[Epoch 181/200] [Batch 870/938] loss_G: 3.479842, loss_D: 0.205006\n",
      "[Epoch 181/200] [Batch 880/938] loss_G: 3.209033, loss_D: 0.185071\n",
      "[Epoch 181/200] [Batch 890/938] loss_G: 3.544586, loss_D: 0.186679\n",
      "[Epoch 181/200] [Batch 900/938] loss_G: 3.448281, loss_D: 0.195061\n",
      "[Epoch 181/200] [Batch 910/938] loss_G: 3.384936, loss_D: 0.100099\n",
      "[Epoch 181/200] [Batch 920/938] loss_G: 3.255950, loss_D: 0.162781\n",
      "[Epoch 181/200] [Batch 930/938] loss_G: 3.311082, loss_D: 0.210073\n",
      "[Epoch 182/200] [Batch 0/938] loss_G: 3.786401, loss_D: 0.181340\n",
      "[Epoch 182/200] [Batch 10/938] loss_G: 3.207083, loss_D: 0.164712\n",
      "[Epoch 182/200] [Batch 20/938] loss_G: 3.529814, loss_D: 0.171042\n",
      "[Epoch 182/200] [Batch 30/938] loss_G: 2.994828, loss_D: 0.299888\n",
      "[Epoch 182/200] [Batch 40/938] loss_G: 3.111011, loss_D: 0.184384\n",
      "[Epoch 182/200] [Batch 50/938] loss_G: 3.651391, loss_D: 0.152187\n",
      "[Epoch 182/200] [Batch 60/938] loss_G: 3.893974, loss_D: 0.094729\n",
      "[Epoch 182/200] [Batch 70/938] loss_G: 3.609807, loss_D: 0.186137\n",
      "[Epoch 182/200] [Batch 80/938] loss_G: 3.376433, loss_D: 0.137399\n",
      "[Epoch 182/200] [Batch 90/938] loss_G: 3.589242, loss_D: 0.246217\n",
      "[Epoch 182/200] [Batch 100/938] loss_G: 3.431138, loss_D: 0.201973\n",
      "[Epoch 182/200] [Batch 110/938] loss_G: 3.358409, loss_D: 0.167855\n",
      "[Epoch 182/200] [Batch 120/938] loss_G: 3.277457, loss_D: 0.187907\n",
      "[Epoch 182/200] [Batch 130/938] loss_G: 2.931726, loss_D: 0.159051\n",
      "[Epoch 182/200] [Batch 140/938] loss_G: 3.376738, loss_D: 0.230065\n",
      "[Epoch 182/200] [Batch 150/938] loss_G: 3.514434, loss_D: 0.185270\n",
      "[Epoch 182/200] [Batch 160/938] loss_G: 3.283571, loss_D: 0.159213\n",
      "[Epoch 182/200] [Batch 170/938] loss_G: 3.160101, loss_D: 0.231595\n",
      "[Epoch 182/200] [Batch 180/938] loss_G: 2.977286, loss_D: 0.223432\n",
      "[Epoch 182/200] [Batch 190/938] loss_G: 3.464754, loss_D: 0.099217\n",
      "[Epoch 182/200] [Batch 200/938] loss_G: 3.479078, loss_D: 0.151370\n",
      "[Epoch 182/200] [Batch 210/938] loss_G: 3.227880, loss_D: 0.244826\n",
      "[Epoch 182/200] [Batch 220/938] loss_G: 3.541296, loss_D: 0.228412\n",
      "[Epoch 182/200] [Batch 230/938] loss_G: 3.283988, loss_D: 0.195845\n",
      "[Epoch 182/200] [Batch 240/938] loss_G: 3.852176, loss_D: 0.287780\n",
      "[Epoch 182/200] [Batch 250/938] loss_G: 3.305480, loss_D: 0.182997\n",
      "[Epoch 182/200] [Batch 260/938] loss_G: 3.201958, loss_D: 0.231838\n",
      "[Epoch 182/200] [Batch 270/938] loss_G: 3.089803, loss_D: 0.197420\n",
      "[Epoch 182/200] [Batch 280/938] loss_G: 3.281328, loss_D: 0.216255\n",
      "[Epoch 182/200] [Batch 290/938] loss_G: 3.570866, loss_D: 0.223652\n",
      "[Epoch 182/200] [Batch 300/938] loss_G: 3.468299, loss_D: 0.207062\n",
      "[Epoch 182/200] [Batch 310/938] loss_G: 3.299902, loss_D: 0.186632\n",
      "[Epoch 182/200] [Batch 320/938] loss_G: 3.786929, loss_D: 0.207586\n",
      "[Epoch 182/200] [Batch 330/938] loss_G: 3.425428, loss_D: 0.156596\n",
      "[Epoch 182/200] [Batch 340/938] loss_G: 3.873083, loss_D: 0.159968\n",
      "[Epoch 182/200] [Batch 350/938] loss_G: 3.740484, loss_D: 0.139624\n",
      "[Epoch 182/200] [Batch 360/938] loss_G: 3.121077, loss_D: 0.246120\n",
      "[Epoch 182/200] [Batch 370/938] loss_G: 3.716406, loss_D: 0.104659\n",
      "[Epoch 182/200] [Batch 380/938] loss_G: 2.982809, loss_D: 0.214368\n",
      "[Epoch 182/200] [Batch 390/938] loss_G: 3.186125, loss_D: 0.194244\n",
      "[Epoch 182/200] [Batch 400/938] loss_G: 3.105043, loss_D: 0.200653\n",
      "[Epoch 182/200] [Batch 410/938] loss_G: 3.930029, loss_D: 0.152116\n",
      "[Epoch 182/200] [Batch 420/938] loss_G: 3.301775, loss_D: 0.146142\n",
      "[Epoch 182/200] [Batch 430/938] loss_G: 3.565295, loss_D: 0.108586\n",
      "[Epoch 182/200] [Batch 440/938] loss_G: 3.619406, loss_D: 0.350524\n",
      "[Epoch 182/200] [Batch 450/938] loss_G: 3.682248, loss_D: 0.270833\n",
      "[Epoch 182/200] [Batch 460/938] loss_G: 3.612696, loss_D: 0.177935\n",
      "[Epoch 182/200] [Batch 470/938] loss_G: 3.414066, loss_D: 0.199795\n",
      "[Epoch 182/200] [Batch 480/938] loss_G: 3.053141, loss_D: 0.152069\n",
      "[Epoch 182/200] [Batch 490/938] loss_G: 3.324932, loss_D: 0.127626\n",
      "[Epoch 182/200] [Batch 500/938] loss_G: 3.440108, loss_D: 0.280976\n",
      "[Epoch 182/200] [Batch 510/938] loss_G: 3.217942, loss_D: 0.119178\n",
      "[Epoch 182/200] [Batch 520/938] loss_G: 3.219158, loss_D: 0.225661\n",
      "[Epoch 182/200] [Batch 530/938] loss_G: 3.445001, loss_D: 0.174253\n",
      "[Epoch 182/200] [Batch 540/938] loss_G: 3.577891, loss_D: 0.160503\n",
      "[Epoch 182/200] [Batch 550/938] loss_G: 3.529269, loss_D: 0.151633\n",
      "[Epoch 182/200] [Batch 560/938] loss_G: 3.429361, loss_D: 0.106079\n",
      "[Epoch 182/200] [Batch 570/938] loss_G: 3.711297, loss_D: 0.145472\n",
      "[Epoch 182/200] [Batch 580/938] loss_G: 3.722980, loss_D: 0.182401\n",
      "[Epoch 182/200] [Batch 590/938] loss_G: 3.025981, loss_D: 0.150054\n",
      "[Epoch 182/200] [Batch 600/938] loss_G: 3.130042, loss_D: 0.216434\n",
      "[Epoch 182/200] [Batch 610/938] loss_G: 3.500084, loss_D: 0.227287\n",
      "[Epoch 182/200] [Batch 620/938] loss_G: 3.702752, loss_D: 0.177415\n",
      "[Epoch 182/200] [Batch 630/938] loss_G: 3.416218, loss_D: 0.273390\n",
      "[Epoch 182/200] [Batch 640/938] loss_G: 3.178866, loss_D: 0.185092\n",
      "[Epoch 182/200] [Batch 650/938] loss_G: 3.309614, loss_D: 0.201420\n",
      "[Epoch 182/200] [Batch 660/938] loss_G: 3.289092, loss_D: 0.151650\n",
      "[Epoch 182/200] [Batch 670/938] loss_G: 3.354332, loss_D: 0.111053\n",
      "[Epoch 182/200] [Batch 680/938] loss_G: 3.593472, loss_D: 0.151005\n",
      "[Epoch 182/200] [Batch 690/938] loss_G: 3.375713, loss_D: 0.121670\n",
      "[Epoch 182/200] [Batch 700/938] loss_G: 3.993139, loss_D: 0.186741\n",
      "[Epoch 182/200] [Batch 710/938] loss_G: 3.331337, loss_D: 0.188745\n",
      "[Epoch 182/200] [Batch 720/938] loss_G: 3.756478, loss_D: 0.199570\n",
      "[Epoch 182/200] [Batch 730/938] loss_G: 3.377460, loss_D: 0.155853\n",
      "[Epoch 182/200] [Batch 740/938] loss_G: 3.380725, loss_D: 0.274530\n",
      "[Epoch 182/200] [Batch 750/938] loss_G: 3.608147, loss_D: 0.261344\n",
      "[Epoch 182/200] [Batch 760/938] loss_G: 3.536037, loss_D: 0.093907\n",
      "[Epoch 182/200] [Batch 770/938] loss_G: 3.526437, loss_D: 0.160046\n",
      "[Epoch 182/200] [Batch 780/938] loss_G: 3.447526, loss_D: 0.160053\n",
      "[Epoch 182/200] [Batch 790/938] loss_G: 3.117494, loss_D: 0.418665\n",
      "[Epoch 182/200] [Batch 800/938] loss_G: 3.787685, loss_D: 0.205493\n",
      "[Epoch 182/200] [Batch 810/938] loss_G: 3.586004, loss_D: 0.122016\n",
      "[Epoch 182/200] [Batch 820/938] loss_G: 3.806859, loss_D: 0.139910\n",
      "[Epoch 182/200] [Batch 830/938] loss_G: 3.131800, loss_D: 0.128864\n",
      "[Epoch 182/200] [Batch 840/938] loss_G: 3.680860, loss_D: 0.137676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 182/200] [Batch 850/938] loss_G: 3.188921, loss_D: 0.227220\n",
      "[Epoch 182/200] [Batch 860/938] loss_G: 3.293283, loss_D: 0.143521\n",
      "[Epoch 182/200] [Batch 870/938] loss_G: 3.651334, loss_D: 0.149364\n",
      "[Epoch 182/200] [Batch 880/938] loss_G: 3.470099, loss_D: 0.178935\n",
      "[Epoch 182/200] [Batch 890/938] loss_G: 3.031047, loss_D: 0.148663\n",
      "[Epoch 182/200] [Batch 900/938] loss_G: 3.422284, loss_D: 0.295709\n",
      "[Epoch 182/200] [Batch 910/938] loss_G: 3.221218, loss_D: 0.151862\n",
      "[Epoch 182/200] [Batch 920/938] loss_G: 3.635149, loss_D: 0.136382\n",
      "[Epoch 182/200] [Batch 930/938] loss_G: 3.048431, loss_D: 0.224307\n",
      "[Epoch 183/200] [Batch 0/938] loss_G: 3.778872, loss_D: 0.126398\n",
      "[Epoch 183/200] [Batch 10/938] loss_G: 3.493686, loss_D: 0.151739\n",
      "[Epoch 183/200] [Batch 20/938] loss_G: 3.015295, loss_D: 0.206688\n",
      "[Epoch 183/200] [Batch 30/938] loss_G: 3.156508, loss_D: 0.133708\n",
      "[Epoch 183/200] [Batch 40/938] loss_G: 3.386746, loss_D: 0.154010\n",
      "[Epoch 183/200] [Batch 50/938] loss_G: 3.546446, loss_D: 0.178115\n",
      "[Epoch 183/200] [Batch 60/938] loss_G: 3.332563, loss_D: 0.161840\n",
      "[Epoch 183/200] [Batch 70/938] loss_G: 3.717409, loss_D: 0.116649\n",
      "[Epoch 183/200] [Batch 80/938] loss_G: 3.432211, loss_D: 0.183168\n",
      "[Epoch 183/200] [Batch 90/938] loss_G: 3.730878, loss_D: 0.199549\n",
      "[Epoch 183/200] [Batch 100/938] loss_G: 3.131218, loss_D: 0.147538\n",
      "[Epoch 183/200] [Batch 110/938] loss_G: 3.654807, loss_D: 0.189721\n",
      "[Epoch 183/200] [Batch 120/938] loss_G: 3.410886, loss_D: 0.203411\n",
      "[Epoch 183/200] [Batch 130/938] loss_G: 3.530700, loss_D: 0.118654\n",
      "[Epoch 183/200] [Batch 140/938] loss_G: 3.692937, loss_D: 0.121038\n",
      "[Epoch 183/200] [Batch 150/938] loss_G: 3.437310, loss_D: 0.228599\n",
      "[Epoch 183/200] [Batch 160/938] loss_G: 3.411146, loss_D: 0.151754\n",
      "[Epoch 183/200] [Batch 170/938] loss_G: 3.515210, loss_D: 0.157683\n",
      "[Epoch 183/200] [Batch 180/938] loss_G: 3.589623, loss_D: 0.183074\n",
      "[Epoch 183/200] [Batch 190/938] loss_G: 3.240393, loss_D: 0.134899\n",
      "[Epoch 183/200] [Batch 200/938] loss_G: 3.326559, loss_D: 0.109076\n",
      "[Epoch 183/200] [Batch 210/938] loss_G: 3.382102, loss_D: 0.268643\n",
      "[Epoch 183/200] [Batch 220/938] loss_G: 3.255944, loss_D: 0.185010\n",
      "[Epoch 183/200] [Batch 230/938] loss_G: 3.396922, loss_D: 0.128324\n",
      "[Epoch 183/200] [Batch 240/938] loss_G: 3.254985, loss_D: 0.137128\n",
      "[Epoch 183/200] [Batch 250/938] loss_G: 3.436654, loss_D: 0.176922\n",
      "[Epoch 183/200] [Batch 260/938] loss_G: 3.492266, loss_D: 0.156291\n",
      "[Epoch 183/200] [Batch 270/938] loss_G: 3.667853, loss_D: 0.305522\n",
      "[Epoch 183/200] [Batch 280/938] loss_G: 3.932249, loss_D: 0.113335\n",
      "[Epoch 183/200] [Batch 290/938] loss_G: 3.574782, loss_D: 0.104829\n",
      "[Epoch 183/200] [Batch 300/938] loss_G: 3.186274, loss_D: 0.186675\n",
      "[Epoch 183/200] [Batch 310/938] loss_G: 3.420453, loss_D: 0.137078\n",
      "[Epoch 183/200] [Batch 320/938] loss_G: 3.502954, loss_D: 0.218986\n",
      "[Epoch 183/200] [Batch 330/938] loss_G: 3.245205, loss_D: 0.182767\n",
      "[Epoch 183/200] [Batch 340/938] loss_G: 3.568844, loss_D: 0.151312\n",
      "[Epoch 183/200] [Batch 350/938] loss_G: 3.471428, loss_D: 0.171209\n",
      "[Epoch 183/200] [Batch 360/938] loss_G: 3.237616, loss_D: 0.139579\n",
      "[Epoch 183/200] [Batch 370/938] loss_G: 3.513118, loss_D: 0.124884\n",
      "[Epoch 183/200] [Batch 380/938] loss_G: 3.547596, loss_D: 0.181263\n",
      "[Epoch 183/200] [Batch 390/938] loss_G: 3.097362, loss_D: 0.164412\n",
      "[Epoch 183/200] [Batch 400/938] loss_G: 3.511944, loss_D: 0.164629\n",
      "[Epoch 183/200] [Batch 410/938] loss_G: 3.416512, loss_D: 0.203144\n",
      "[Epoch 183/200] [Batch 420/938] loss_G: 3.292483, loss_D: 0.178362\n",
      "[Epoch 183/200] [Batch 430/938] loss_G: 3.281454, loss_D: 0.205390\n",
      "[Epoch 183/200] [Batch 440/938] loss_G: 3.264632, loss_D: 0.254873\n",
      "[Epoch 183/200] [Batch 450/938] loss_G: 3.744333, loss_D: 0.195028\n",
      "[Epoch 183/200] [Batch 460/938] loss_G: 3.335816, loss_D: 0.118759\n",
      "[Epoch 183/200] [Batch 470/938] loss_G: 2.682321, loss_D: 0.182251\n",
      "[Epoch 183/200] [Batch 480/938] loss_G: 3.397754, loss_D: 0.148969\n",
      "[Epoch 183/200] [Batch 490/938] loss_G: 3.400997, loss_D: 0.202153\n",
      "[Epoch 183/200] [Batch 500/938] loss_G: 3.636593, loss_D: 0.220698\n",
      "[Epoch 183/200] [Batch 510/938] loss_G: 3.224583, loss_D: 0.242743\n",
      "[Epoch 183/200] [Batch 520/938] loss_G: 3.795331, loss_D: 0.143953\n",
      "[Epoch 183/200] [Batch 530/938] loss_G: 3.865236, loss_D: 0.184590\n",
      "[Epoch 183/200] [Batch 540/938] loss_G: 3.576185, loss_D: 0.150943\n",
      "[Epoch 183/200] [Batch 550/938] loss_G: 3.873721, loss_D: 0.170365\n",
      "[Epoch 183/200] [Batch 560/938] loss_G: 3.409693, loss_D: 0.163766\n",
      "[Epoch 183/200] [Batch 570/938] loss_G: 3.595735, loss_D: 0.183507\n",
      "[Epoch 183/200] [Batch 580/938] loss_G: 3.546361, loss_D: 0.190033\n",
      "[Epoch 183/200] [Batch 590/938] loss_G: 3.688982, loss_D: 0.180907\n",
      "[Epoch 183/200] [Batch 600/938] loss_G: 3.148054, loss_D: 0.134390\n",
      "[Epoch 183/200] [Batch 610/938] loss_G: 3.214855, loss_D: 0.257308\n",
      "[Epoch 183/200] [Batch 620/938] loss_G: 3.774428, loss_D: 0.107538\n",
      "[Epoch 183/200] [Batch 630/938] loss_G: 3.349081, loss_D: 0.178006\n",
      "[Epoch 183/200] [Batch 640/938] loss_G: 3.772796, loss_D: 0.183187\n",
      "[Epoch 183/200] [Batch 650/938] loss_G: 3.274815, loss_D: 0.170474\n",
      "[Epoch 183/200] [Batch 660/938] loss_G: 3.448162, loss_D: 0.218850\n",
      "[Epoch 183/200] [Batch 670/938] loss_G: 3.855269, loss_D: 0.123628\n",
      "[Epoch 183/200] [Batch 680/938] loss_G: 3.830178, loss_D: 0.156258\n",
      "[Epoch 183/200] [Batch 690/938] loss_G: 3.299837, loss_D: 0.177141\n",
      "[Epoch 183/200] [Batch 700/938] loss_G: 3.485296, loss_D: 0.191323\n",
      "[Epoch 183/200] [Batch 710/938] loss_G: 3.736170, loss_D: 0.150184\n",
      "[Epoch 183/200] [Batch 720/938] loss_G: 3.507718, loss_D: 0.127011\n",
      "[Epoch 183/200] [Batch 730/938] loss_G: 3.283748, loss_D: 0.179418\n",
      "[Epoch 183/200] [Batch 740/938] loss_G: 3.485247, loss_D: 0.233661\n",
      "[Epoch 183/200] [Batch 750/938] loss_G: 3.687536, loss_D: 0.235900\n",
      "[Epoch 183/200] [Batch 760/938] loss_G: 3.303053, loss_D: 0.196256\n",
      "[Epoch 183/200] [Batch 770/938] loss_G: 3.875682, loss_D: 0.194148\n",
      "[Epoch 183/200] [Batch 780/938] loss_G: 3.464167, loss_D: 0.215935\n",
      "[Epoch 183/200] [Batch 790/938] loss_G: 3.318460, loss_D: 0.161119\n",
      "[Epoch 183/200] [Batch 800/938] loss_G: 3.830980, loss_D: 0.180930\n",
      "[Epoch 183/200] [Batch 810/938] loss_G: 3.498771, loss_D: 0.174261\n",
      "[Epoch 183/200] [Batch 820/938] loss_G: 3.283968, loss_D: 0.201892\n",
      "[Epoch 183/200] [Batch 830/938] loss_G: 3.411266, loss_D: 0.238632\n",
      "[Epoch 183/200] [Batch 840/938] loss_G: 3.699269, loss_D: 0.195861\n",
      "[Epoch 183/200] [Batch 850/938] loss_G: 3.058775, loss_D: 0.170835\n",
      "[Epoch 183/200] [Batch 860/938] loss_G: 3.569142, loss_D: 0.235584\n",
      "[Epoch 183/200] [Batch 870/938] loss_G: 3.174949, loss_D: 0.190851\n",
      "[Epoch 183/200] [Batch 880/938] loss_G: 3.003261, loss_D: 0.221807\n",
      "[Epoch 183/200] [Batch 890/938] loss_G: 3.567747, loss_D: 0.165645\n",
      "[Epoch 183/200] [Batch 900/938] loss_G: 3.296072, loss_D: 0.171869\n",
      "[Epoch 183/200] [Batch 910/938] loss_G: 3.218520, loss_D: 0.170782\n",
      "[Epoch 183/200] [Batch 920/938] loss_G: 3.628083, loss_D: 0.128098\n",
      "[Epoch 183/200] [Batch 930/938] loss_G: 3.524092, loss_D: 0.189795\n",
      "[Epoch 184/200] [Batch 0/938] loss_G: 3.753377, loss_D: 0.190492\n",
      "[Epoch 184/200] [Batch 10/938] loss_G: 3.645942, loss_D: 0.250636\n",
      "[Epoch 184/200] [Batch 20/938] loss_G: 3.318780, loss_D: 0.176482\n",
      "[Epoch 184/200] [Batch 30/938] loss_G: 3.401253, loss_D: 0.119840\n",
      "[Epoch 184/200] [Batch 40/938] loss_G: 3.373500, loss_D: 0.197890\n",
      "[Epoch 184/200] [Batch 50/938] loss_G: 3.866059, loss_D: 0.130396\n",
      "[Epoch 184/200] [Batch 60/938] loss_G: 3.716730, loss_D: 0.130409\n",
      "[Epoch 184/200] [Batch 70/938] loss_G: 3.764586, loss_D: 0.129542\n",
      "[Epoch 184/200] [Batch 80/938] loss_G: 3.434226, loss_D: 0.267601\n",
      "[Epoch 184/200] [Batch 90/938] loss_G: 3.661373, loss_D: 0.131422\n",
      "[Epoch 184/200] [Batch 100/938] loss_G: 3.356886, loss_D: 0.169761\n",
      "[Epoch 184/200] [Batch 110/938] loss_G: 3.481023, loss_D: 0.178391\n",
      "[Epoch 184/200] [Batch 120/938] loss_G: 3.405633, loss_D: 0.193980\n",
      "[Epoch 184/200] [Batch 130/938] loss_G: 2.973686, loss_D: 0.137031\n",
      "[Epoch 184/200] [Batch 140/938] loss_G: 3.692297, loss_D: 0.207666\n",
      "[Epoch 184/200] [Batch 150/938] loss_G: 3.438383, loss_D: 0.200625\n",
      "[Epoch 184/200] [Batch 160/938] loss_G: 3.319324, loss_D: 0.145763\n",
      "[Epoch 184/200] [Batch 170/938] loss_G: 3.373628, loss_D: 0.131391\n",
      "[Epoch 184/200] [Batch 180/938] loss_G: 3.242204, loss_D: 0.279985\n",
      "[Epoch 184/200] [Batch 190/938] loss_G: 3.046159, loss_D: 0.190642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 184/200] [Batch 200/938] loss_G: 3.352057, loss_D: 0.201811\n",
      "[Epoch 184/200] [Batch 210/938] loss_G: 3.260741, loss_D: 0.178883\n",
      "[Epoch 184/200] [Batch 220/938] loss_G: 2.912706, loss_D: 0.152018\n",
      "[Epoch 184/200] [Batch 230/938] loss_G: 3.319347, loss_D: 0.250830\n",
      "[Epoch 184/200] [Batch 240/938] loss_G: 3.729578, loss_D: 0.168887\n",
      "[Epoch 184/200] [Batch 250/938] loss_G: 3.792387, loss_D: 0.157850\n",
      "[Epoch 184/200] [Batch 260/938] loss_G: 3.470433, loss_D: 0.204198\n",
      "[Epoch 184/200] [Batch 270/938] loss_G: 3.402338, loss_D: 0.173874\n",
      "[Epoch 184/200] [Batch 280/938] loss_G: 3.369258, loss_D: 0.164404\n",
      "[Epoch 184/200] [Batch 290/938] loss_G: 3.529214, loss_D: 0.120000\n",
      "[Epoch 184/200] [Batch 300/938] loss_G: 3.513610, loss_D: 0.119340\n",
      "[Epoch 184/200] [Batch 310/938] loss_G: 3.141565, loss_D: 0.142065\n",
      "[Epoch 184/200] [Batch 320/938] loss_G: 3.315683, loss_D: 0.164610\n",
      "[Epoch 184/200] [Batch 330/938] loss_G: 3.158225, loss_D: 0.138950\n",
      "[Epoch 184/200] [Batch 340/938] loss_G: 4.198156, loss_D: 0.143960\n",
      "[Epoch 184/200] [Batch 350/938] loss_G: 3.199058, loss_D: 0.199153\n",
      "[Epoch 184/200] [Batch 360/938] loss_G: 3.599497, loss_D: 0.211401\n",
      "[Epoch 184/200] [Batch 370/938] loss_G: 3.290041, loss_D: 0.181798\n",
      "[Epoch 184/200] [Batch 380/938] loss_G: 3.116642, loss_D: 0.247838\n",
      "[Epoch 184/200] [Batch 390/938] loss_G: 2.820777, loss_D: 0.180394\n",
      "[Epoch 184/200] [Batch 400/938] loss_G: 3.326869, loss_D: 0.149032\n",
      "[Epoch 184/200] [Batch 410/938] loss_G: 3.183692, loss_D: 0.148219\n",
      "[Epoch 184/200] [Batch 420/938] loss_G: 3.382369, loss_D: 0.197325\n",
      "[Epoch 184/200] [Batch 430/938] loss_G: 3.184926, loss_D: 0.142130\n",
      "[Epoch 184/200] [Batch 440/938] loss_G: 3.841391, loss_D: 0.168875\n",
      "[Epoch 184/200] [Batch 450/938] loss_G: 2.940097, loss_D: 0.256973\n",
      "[Epoch 184/200] [Batch 460/938] loss_G: 3.429718, loss_D: 0.193254\n",
      "[Epoch 184/200] [Batch 470/938] loss_G: 3.813874, loss_D: 0.169412\n",
      "[Epoch 184/200] [Batch 480/938] loss_G: 3.358089, loss_D: 0.198537\n",
      "[Epoch 184/200] [Batch 490/938] loss_G: 3.314788, loss_D: 0.278864\n",
      "[Epoch 184/200] [Batch 500/938] loss_G: 3.450410, loss_D: 0.144221\n",
      "[Epoch 184/200] [Batch 510/938] loss_G: 3.187302, loss_D: 0.185164\n",
      "[Epoch 184/200] [Batch 520/938] loss_G: 3.183473, loss_D: 0.203907\n",
      "[Epoch 184/200] [Batch 530/938] loss_G: 3.637092, loss_D: 0.191258\n",
      "[Epoch 184/200] [Batch 540/938] loss_G: 3.211610, loss_D: 0.158398\n",
      "[Epoch 184/200] [Batch 550/938] loss_G: 3.620719, loss_D: 0.147748\n",
      "[Epoch 184/200] [Batch 560/938] loss_G: 2.878816, loss_D: 0.167551\n",
      "[Epoch 184/200] [Batch 570/938] loss_G: 3.326036, loss_D: 0.200081\n",
      "[Epoch 184/200] [Batch 580/938] loss_G: 2.872535, loss_D: 0.267994\n",
      "[Epoch 184/200] [Batch 590/938] loss_G: 3.616753, loss_D: 0.132717\n",
      "[Epoch 184/200] [Batch 600/938] loss_G: 3.405634, loss_D: 0.240112\n",
      "[Epoch 184/200] [Batch 610/938] loss_G: 3.020360, loss_D: 0.196675\n",
      "[Epoch 184/200] [Batch 620/938] loss_G: 3.183028, loss_D: 0.173300\n",
      "[Epoch 184/200] [Batch 630/938] loss_G: 2.994396, loss_D: 0.209931\n",
      "[Epoch 184/200] [Batch 640/938] loss_G: 3.751356, loss_D: 0.212986\n",
      "[Epoch 184/200] [Batch 650/938] loss_G: 3.784532, loss_D: 0.122424\n",
      "[Epoch 184/200] [Batch 660/938] loss_G: 3.487819, loss_D: 0.276785\n",
      "[Epoch 184/200] [Batch 670/938] loss_G: 3.124836, loss_D: 0.211287\n",
      "[Epoch 184/200] [Batch 680/938] loss_G: 3.635316, loss_D: 0.121082\n",
      "[Epoch 184/200] [Batch 690/938] loss_G: 3.054874, loss_D: 0.150189\n",
      "[Epoch 184/200] [Batch 700/938] loss_G: 3.626066, loss_D: 0.182893\n",
      "[Epoch 184/200] [Batch 710/938] loss_G: 3.277185, loss_D: 0.185381\n",
      "[Epoch 184/200] [Batch 720/938] loss_G: 3.486860, loss_D: 0.173800\n",
      "[Epoch 184/200] [Batch 730/938] loss_G: 3.494016, loss_D: 0.165242\n",
      "[Epoch 184/200] [Batch 740/938] loss_G: 3.391853, loss_D: 0.299839\n",
      "[Epoch 184/200] [Batch 750/938] loss_G: 3.715440, loss_D: 0.242110\n",
      "[Epoch 184/200] [Batch 760/938] loss_G: 3.337268, loss_D: 0.177250\n",
      "[Epoch 184/200] [Batch 770/938] loss_G: 3.511774, loss_D: 0.232749\n",
      "[Epoch 184/200] [Batch 780/938] loss_G: 3.637604, loss_D: 0.206923\n",
      "[Epoch 184/200] [Batch 790/938] loss_G: 3.582345, loss_D: 0.153047\n",
      "[Epoch 184/200] [Batch 800/938] loss_G: 3.047943, loss_D: 0.290888\n",
      "[Epoch 184/200] [Batch 810/938] loss_G: 3.129975, loss_D: 0.122596\n",
      "[Epoch 184/200] [Batch 820/938] loss_G: 3.260797, loss_D: 0.193606\n",
      "[Epoch 184/200] [Batch 830/938] loss_G: 3.708553, loss_D: 0.207163\n",
      "[Epoch 184/200] [Batch 840/938] loss_G: 3.885993, loss_D: 0.139320\n",
      "[Epoch 184/200] [Batch 850/938] loss_G: 3.600728, loss_D: 0.124294\n",
      "[Epoch 184/200] [Batch 860/938] loss_G: 3.759974, loss_D: 0.111800\n",
      "[Epoch 184/200] [Batch 870/938] loss_G: 3.340217, loss_D: 0.211584\n",
      "[Epoch 184/200] [Batch 880/938] loss_G: 3.063155, loss_D: 0.174147\n",
      "[Epoch 184/200] [Batch 890/938] loss_G: 3.518034, loss_D: 0.164578\n",
      "[Epoch 184/200] [Batch 900/938] loss_G: 3.290770, loss_D: 0.161219\n",
      "[Epoch 184/200] [Batch 910/938] loss_G: 3.228261, loss_D: 0.149316\n",
      "[Epoch 184/200] [Batch 920/938] loss_G: 3.222586, loss_D: 0.194861\n",
      "[Epoch 184/200] [Batch 930/938] loss_G: 3.176535, loss_D: 0.212769\n",
      "[Epoch 185/200] [Batch 0/938] loss_G: 3.837263, loss_D: 0.159234\n",
      "[Epoch 185/200] [Batch 10/938] loss_G: 3.504658, loss_D: 0.248309\n",
      "[Epoch 185/200] [Batch 20/938] loss_G: 3.337791, loss_D: 0.165419\n",
      "[Epoch 185/200] [Batch 30/938] loss_G: 3.108089, loss_D: 0.235708\n",
      "[Epoch 185/200] [Batch 40/938] loss_G: 2.960587, loss_D: 0.208010\n",
      "[Epoch 185/200] [Batch 50/938] loss_G: 3.409481, loss_D: 0.192147\n",
      "[Epoch 185/200] [Batch 60/938] loss_G: 3.234634, loss_D: 0.184348\n",
      "[Epoch 185/200] [Batch 70/938] loss_G: 3.058455, loss_D: 0.143406\n",
      "[Epoch 185/200] [Batch 80/938] loss_G: 3.065718, loss_D: 0.134345\n",
      "[Epoch 185/200] [Batch 90/938] loss_G: 3.379072, loss_D: 0.123137\n",
      "[Epoch 185/200] [Batch 100/938] loss_G: 3.223305, loss_D: 0.223946\n",
      "[Epoch 185/200] [Batch 110/938] loss_G: 3.233112, loss_D: 0.182945\n",
      "[Epoch 185/200] [Batch 120/938] loss_G: 3.486179, loss_D: 0.214005\n",
      "[Epoch 185/200] [Batch 130/938] loss_G: 3.407378, loss_D: 0.117566\n",
      "[Epoch 185/200] [Batch 140/938] loss_G: 3.527247, loss_D: 0.240141\n",
      "[Epoch 185/200] [Batch 150/938] loss_G: 3.537206, loss_D: 0.294893\n",
      "[Epoch 185/200] [Batch 160/938] loss_G: 3.586560, loss_D: 0.114087\n",
      "[Epoch 185/200] [Batch 170/938] loss_G: 2.926470, loss_D: 0.153433\n",
      "[Epoch 185/200] [Batch 180/938] loss_G: 3.527829, loss_D: 0.187084\n",
      "[Epoch 185/200] [Batch 190/938] loss_G: 3.412192, loss_D: 0.153714\n",
      "[Epoch 185/200] [Batch 200/938] loss_G: 3.411571, loss_D: 0.104046\n",
      "[Epoch 185/200] [Batch 210/938] loss_G: 3.175416, loss_D: 0.233053\n",
      "[Epoch 185/200] [Batch 220/938] loss_G: 3.306308, loss_D: 0.239498\n",
      "[Epoch 185/200] [Batch 230/938] loss_G: 3.509700, loss_D: 0.174025\n",
      "[Epoch 185/200] [Batch 240/938] loss_G: 3.816204, loss_D: 0.219688\n",
      "[Epoch 185/200] [Batch 250/938] loss_G: 3.212121, loss_D: 0.159139\n",
      "[Epoch 185/200] [Batch 260/938] loss_G: 3.349911, loss_D: 0.147139\n",
      "[Epoch 185/200] [Batch 270/938] loss_G: 3.461720, loss_D: 0.174356\n",
      "[Epoch 185/200] [Batch 280/938] loss_G: 2.338677, loss_D: 0.229155\n",
      "[Epoch 185/200] [Batch 290/938] loss_G: 3.929719, loss_D: 0.173319\n",
      "[Epoch 185/200] [Batch 300/938] loss_G: 3.748658, loss_D: 0.162596\n",
      "[Epoch 185/200] [Batch 310/938] loss_G: 3.452703, loss_D: 0.213538\n",
      "[Epoch 185/200] [Batch 320/938] loss_G: 3.721232, loss_D: 0.152967\n",
      "[Epoch 185/200] [Batch 330/938] loss_G: 3.482811, loss_D: 0.131469\n",
      "[Epoch 185/200] [Batch 340/938] loss_G: 3.567495, loss_D: 0.141622\n",
      "[Epoch 185/200] [Batch 350/938] loss_G: 3.258382, loss_D: 0.133419\n",
      "[Epoch 185/200] [Batch 360/938] loss_G: 4.005017, loss_D: 0.214943\n",
      "[Epoch 185/200] [Batch 370/938] loss_G: 3.335765, loss_D: 0.184651\n",
      "[Epoch 185/200] [Batch 380/938] loss_G: 3.275091, loss_D: 0.252719\n",
      "[Epoch 185/200] [Batch 390/938] loss_G: 3.143208, loss_D: 0.087575\n",
      "[Epoch 185/200] [Batch 400/938] loss_G: 3.962954, loss_D: 0.174830\n",
      "[Epoch 185/200] [Batch 410/938] loss_G: 3.645977, loss_D: 0.097329\n",
      "[Epoch 185/200] [Batch 420/938] loss_G: 3.396117, loss_D: 0.168628\n",
      "[Epoch 185/200] [Batch 430/938] loss_G: 3.618602, loss_D: 0.150659\n",
      "[Epoch 185/200] [Batch 440/938] loss_G: 3.712293, loss_D: 0.151171\n",
      "[Epoch 185/200] [Batch 450/938] loss_G: 3.705017, loss_D: 0.217541\n",
      "[Epoch 185/200] [Batch 460/938] loss_G: 3.725236, loss_D: 0.141064\n",
      "[Epoch 185/200] [Batch 470/938] loss_G: 3.348260, loss_D: 0.141277\n",
      "[Epoch 185/200] [Batch 480/938] loss_G: 3.484999, loss_D: 0.145179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 185/200] [Batch 490/938] loss_G: 3.332626, loss_D: 0.215796\n",
      "[Epoch 185/200] [Batch 500/938] loss_G: 3.679158, loss_D: 0.221631\n",
      "[Epoch 185/200] [Batch 510/938] loss_G: 3.099859, loss_D: 0.173989\n",
      "[Epoch 185/200] [Batch 520/938] loss_G: 3.334764, loss_D: 0.267062\n",
      "[Epoch 185/200] [Batch 530/938] loss_G: 3.496754, loss_D: 0.141966\n",
      "[Epoch 185/200] [Batch 540/938] loss_G: 3.104421, loss_D: 0.164824\n",
      "[Epoch 185/200] [Batch 550/938] loss_G: 3.445822, loss_D: 0.239656\n",
      "[Epoch 185/200] [Batch 560/938] loss_G: 3.968037, loss_D: 0.251563\n",
      "[Epoch 185/200] [Batch 570/938] loss_G: 3.167928, loss_D: 0.211573\n",
      "[Epoch 185/200] [Batch 580/938] loss_G: 3.544343, loss_D: 0.182812\n",
      "[Epoch 185/200] [Batch 590/938] loss_G: 3.178363, loss_D: 0.196888\n",
      "[Epoch 185/200] [Batch 600/938] loss_G: 3.367142, loss_D: 0.169817\n",
      "[Epoch 185/200] [Batch 610/938] loss_G: 3.358715, loss_D: 0.260049\n",
      "[Epoch 185/200] [Batch 620/938] loss_G: 3.406158, loss_D: 0.250419\n",
      "[Epoch 185/200] [Batch 630/938] loss_G: 3.063009, loss_D: 0.105283\n",
      "[Epoch 185/200] [Batch 640/938] loss_G: 3.488309, loss_D: 0.149480\n",
      "[Epoch 185/200] [Batch 650/938] loss_G: 3.607859, loss_D: 0.107858\n",
      "[Epoch 185/200] [Batch 660/938] loss_G: 3.272510, loss_D: 0.144096\n",
      "[Epoch 185/200] [Batch 670/938] loss_G: 3.039429, loss_D: 0.186315\n",
      "[Epoch 185/200] [Batch 680/938] loss_G: 3.320665, loss_D: 0.097110\n",
      "[Epoch 185/200] [Batch 690/938] loss_G: 3.108296, loss_D: 0.148622\n",
      "[Epoch 185/200] [Batch 700/938] loss_G: 2.879035, loss_D: 0.249802\n",
      "[Epoch 185/200] [Batch 710/938] loss_G: 3.080397, loss_D: 0.195033\n",
      "[Epoch 185/200] [Batch 720/938] loss_G: 3.320532, loss_D: 0.288805\n",
      "[Epoch 185/200] [Batch 730/938] loss_G: 3.361113, loss_D: 0.125604\n",
      "[Epoch 185/200] [Batch 740/938] loss_G: 2.957231, loss_D: 0.190377\n",
      "[Epoch 185/200] [Batch 750/938] loss_G: 3.347035, loss_D: 0.209106\n",
      "[Epoch 185/200] [Batch 760/938] loss_G: 3.341153, loss_D: 0.199085\n",
      "[Epoch 185/200] [Batch 770/938] loss_G: 3.262148, loss_D: 0.157331\n",
      "[Epoch 185/200] [Batch 780/938] loss_G: 2.972519, loss_D: 0.226060\n",
      "[Epoch 185/200] [Batch 790/938] loss_G: 3.464317, loss_D: 0.179622\n",
      "[Epoch 185/200] [Batch 800/938] loss_G: 3.302479, loss_D: 0.167426\n",
      "[Epoch 185/200] [Batch 810/938] loss_G: 3.224502, loss_D: 0.256500\n",
      "[Epoch 185/200] [Batch 820/938] loss_G: 3.084305, loss_D: 0.143590\n",
      "[Epoch 185/200] [Batch 830/938] loss_G: 2.638688, loss_D: 0.173231\n",
      "[Epoch 185/200] [Batch 840/938] loss_G: 2.971516, loss_D: 0.255515\n",
      "[Epoch 185/200] [Batch 850/938] loss_G: 3.802887, loss_D: 0.240513\n",
      "[Epoch 185/200] [Batch 860/938] loss_G: 3.530693, loss_D: 0.191028\n",
      "[Epoch 185/200] [Batch 870/938] loss_G: 3.468793, loss_D: 0.169904\n",
      "[Epoch 185/200] [Batch 880/938] loss_G: 3.175901, loss_D: 0.198840\n",
      "[Epoch 185/200] [Batch 890/938] loss_G: 3.004537, loss_D: 0.204529\n",
      "[Epoch 185/200] [Batch 900/938] loss_G: 3.518129, loss_D: 0.139707\n",
      "[Epoch 185/200] [Batch 910/938] loss_G: 2.827975, loss_D: 0.212335\n",
      "[Epoch 185/200] [Batch 920/938] loss_G: 3.102086, loss_D: 0.174778\n",
      "[Epoch 185/200] [Batch 930/938] loss_G: 3.500497, loss_D: 0.183160\n",
      "[Epoch 186/200] [Batch 0/938] loss_G: 3.595368, loss_D: 0.120583\n",
      "[Epoch 186/200] [Batch 10/938] loss_G: 3.370497, loss_D: 0.137177\n",
      "[Epoch 186/200] [Batch 20/938] loss_G: 3.602821, loss_D: 0.181680\n",
      "[Epoch 186/200] [Batch 30/938] loss_G: 3.420681, loss_D: 0.102135\n",
      "[Epoch 186/200] [Batch 40/938] loss_G: 3.560981, loss_D: 0.309680\n",
      "[Epoch 186/200] [Batch 50/938] loss_G: 3.159837, loss_D: 0.242175\n",
      "[Epoch 186/200] [Batch 60/938] loss_G: 3.391190, loss_D: 0.159125\n",
      "[Epoch 186/200] [Batch 70/938] loss_G: 3.507487, loss_D: 0.267452\n",
      "[Epoch 186/200] [Batch 80/938] loss_G: 3.264702, loss_D: 0.145569\n",
      "[Epoch 186/200] [Batch 90/938] loss_G: 3.065242, loss_D: 0.133073\n",
      "[Epoch 186/200] [Batch 100/938] loss_G: 3.064496, loss_D: 0.232259\n",
      "[Epoch 186/200] [Batch 110/938] loss_G: 2.971687, loss_D: 0.194123\n",
      "[Epoch 186/200] [Batch 120/938] loss_G: 2.962779, loss_D: 0.194443\n",
      "[Epoch 186/200] [Batch 130/938] loss_G: 3.301965, loss_D: 0.177961\n",
      "[Epoch 186/200] [Batch 140/938] loss_G: 2.894302, loss_D: 0.207462\n",
      "[Epoch 186/200] [Batch 150/938] loss_G: 3.204113, loss_D: 0.147056\n",
      "[Epoch 186/200] [Batch 160/938] loss_G: 3.976676, loss_D: 0.123193\n",
      "[Epoch 186/200] [Batch 170/938] loss_G: 3.411015, loss_D: 0.291325\n",
      "[Epoch 186/200] [Batch 180/938] loss_G: 3.316759, loss_D: 0.265611\n",
      "[Epoch 186/200] [Batch 190/938] loss_G: 3.233053, loss_D: 0.150223\n",
      "[Epoch 186/200] [Batch 200/938] loss_G: 3.441491, loss_D: 0.154176\n",
      "[Epoch 186/200] [Batch 210/938] loss_G: 3.461387, loss_D: 0.089880\n",
      "[Epoch 186/200] [Batch 220/938] loss_G: 3.443703, loss_D: 0.171600\n",
      "[Epoch 186/200] [Batch 230/938] loss_G: 3.510023, loss_D: 0.154659\n",
      "[Epoch 186/200] [Batch 240/938] loss_G: 3.139454, loss_D: 0.185576\n",
      "[Epoch 186/200] [Batch 250/938] loss_G: 3.467476, loss_D: 0.152151\n",
      "[Epoch 186/200] [Batch 260/938] loss_G: 3.226955, loss_D: 0.149236\n",
      "[Epoch 186/200] [Batch 270/938] loss_G: 3.525594, loss_D: 0.149346\n",
      "[Epoch 186/200] [Batch 280/938] loss_G: 3.155887, loss_D: 0.235848\n",
      "[Epoch 186/200] [Batch 290/938] loss_G: 3.548813, loss_D: 0.155800\n",
      "[Epoch 186/200] [Batch 300/938] loss_G: 3.225529, loss_D: 0.092849\n",
      "[Epoch 186/200] [Batch 310/938] loss_G: 3.272642, loss_D: 0.173352\n",
      "[Epoch 186/200] [Batch 320/938] loss_G: 3.346957, loss_D: 0.226795\n",
      "[Epoch 186/200] [Batch 330/938] loss_G: 3.250021, loss_D: 0.132537\n",
      "[Epoch 186/200] [Batch 340/938] loss_G: 3.440872, loss_D: 0.117482\n",
      "[Epoch 186/200] [Batch 350/938] loss_G: 3.130563, loss_D: 0.177261\n",
      "[Epoch 186/200] [Batch 360/938] loss_G: 3.414668, loss_D: 0.212516\n",
      "[Epoch 186/200] [Batch 370/938] loss_G: 3.186105, loss_D: 0.141949\n",
      "[Epoch 186/200] [Batch 380/938] loss_G: 3.772428, loss_D: 0.211230\n",
      "[Epoch 186/200] [Batch 390/938] loss_G: 3.467082, loss_D: 0.137606\n",
      "[Epoch 186/200] [Batch 400/938] loss_G: 3.502297, loss_D: 0.179132\n",
      "[Epoch 186/200] [Batch 410/938] loss_G: 3.333904, loss_D: 0.178975\n",
      "[Epoch 186/200] [Batch 420/938] loss_G: 3.657222, loss_D: 0.137734\n",
      "[Epoch 186/200] [Batch 430/938] loss_G: 3.505047, loss_D: 0.205718\n",
      "[Epoch 186/200] [Batch 440/938] loss_G: 3.423810, loss_D: 0.300070\n",
      "[Epoch 186/200] [Batch 450/938] loss_G: 3.585678, loss_D: 0.204908\n",
      "[Epoch 186/200] [Batch 460/938] loss_G: 3.776588, loss_D: 0.125456\n",
      "[Epoch 186/200] [Batch 470/938] loss_G: 3.294505, loss_D: 0.153444\n",
      "[Epoch 186/200] [Batch 480/938] loss_G: 3.012941, loss_D: 0.150809\n",
      "[Epoch 186/200] [Batch 490/938] loss_G: 3.436757, loss_D: 0.161752\n",
      "[Epoch 186/200] [Batch 500/938] loss_G: 3.441877, loss_D: 0.238425\n",
      "[Epoch 186/200] [Batch 510/938] loss_G: 3.119068, loss_D: 0.228570\n",
      "[Epoch 186/200] [Batch 520/938] loss_G: 3.392237, loss_D: 0.221617\n",
      "[Epoch 186/200] [Batch 530/938] loss_G: 3.470602, loss_D: 0.171028\n",
      "[Epoch 186/200] [Batch 540/938] loss_G: 3.424608, loss_D: 0.131096\n",
      "[Epoch 186/200] [Batch 550/938] loss_G: 3.425476, loss_D: 0.164606\n",
      "[Epoch 186/200] [Batch 560/938] loss_G: 3.263697, loss_D: 0.181106\n",
      "[Epoch 186/200] [Batch 570/938] loss_G: 3.290467, loss_D: 0.182418\n",
      "[Epoch 186/200] [Batch 580/938] loss_G: 3.254254, loss_D: 0.130824\n",
      "[Epoch 186/200] [Batch 590/938] loss_G: 3.446318, loss_D: 0.154454\n",
      "[Epoch 186/200] [Batch 600/938] loss_G: 3.649292, loss_D: 0.124140\n",
      "[Epoch 186/200] [Batch 610/938] loss_G: 3.089050, loss_D: 0.240587\n",
      "[Epoch 186/200] [Batch 620/938] loss_G: 3.188141, loss_D: 0.263994\n",
      "[Epoch 186/200] [Batch 630/938] loss_G: 3.553456, loss_D: 0.136126\n",
      "[Epoch 186/200] [Batch 640/938] loss_G: 3.048198, loss_D: 0.199474\n",
      "[Epoch 186/200] [Batch 650/938] loss_G: 3.728823, loss_D: 0.199016\n",
      "[Epoch 186/200] [Batch 660/938] loss_G: 3.465884, loss_D: 0.133336\n",
      "[Epoch 186/200] [Batch 670/938] loss_G: 3.277138, loss_D: 0.187636\n",
      "[Epoch 186/200] [Batch 680/938] loss_G: 3.288465, loss_D: 0.107814\n",
      "[Epoch 186/200] [Batch 690/938] loss_G: 3.367353, loss_D: 0.196637\n",
      "[Epoch 186/200] [Batch 700/938] loss_G: 3.206483, loss_D: 0.278463\n",
      "[Epoch 186/200] [Batch 710/938] loss_G: 2.991492, loss_D: 0.154054\n",
      "[Epoch 186/200] [Batch 720/938] loss_G: 4.019780, loss_D: 0.180312\n",
      "[Epoch 186/200] [Batch 730/938] loss_G: 3.945495, loss_D: 0.174853\n",
      "[Epoch 186/200] [Batch 740/938] loss_G: 3.366680, loss_D: 0.147835\n",
      "[Epoch 186/200] [Batch 750/938] loss_G: 3.601826, loss_D: 0.187149\n",
      "[Epoch 186/200] [Batch 760/938] loss_G: 3.144007, loss_D: 0.162686\n",
      "[Epoch 186/200] [Batch 770/938] loss_G: 3.536457, loss_D: 0.089770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 186/200] [Batch 780/938] loss_G: 3.601047, loss_D: 0.184164\n",
      "[Epoch 186/200] [Batch 790/938] loss_G: 3.347697, loss_D: 0.146598\n",
      "[Epoch 186/200] [Batch 800/938] loss_G: 3.028483, loss_D: 0.139946\n",
      "[Epoch 186/200] [Batch 810/938] loss_G: 3.552637, loss_D: 0.187856\n",
      "[Epoch 186/200] [Batch 820/938] loss_G: 3.409850, loss_D: 0.171939\n",
      "[Epoch 186/200] [Batch 830/938] loss_G: 3.158820, loss_D: 0.241667\n",
      "[Epoch 186/200] [Batch 840/938] loss_G: 3.275691, loss_D: 0.226580\n",
      "[Epoch 186/200] [Batch 850/938] loss_G: 3.633225, loss_D: 0.134083\n",
      "[Epoch 186/200] [Batch 860/938] loss_G: 3.139873, loss_D: 0.218660\n",
      "[Epoch 186/200] [Batch 870/938] loss_G: 3.387686, loss_D: 0.144174\n",
      "[Epoch 186/200] [Batch 880/938] loss_G: 3.118839, loss_D: 0.164912\n",
      "[Epoch 186/200] [Batch 890/938] loss_G: 3.148126, loss_D: 0.219589\n",
      "[Epoch 186/200] [Batch 900/938] loss_G: 3.566871, loss_D: 0.143836\n",
      "[Epoch 186/200] [Batch 910/938] loss_G: 3.538720, loss_D: 0.158392\n",
      "[Epoch 186/200] [Batch 920/938] loss_G: 3.231639, loss_D: 0.210480\n",
      "[Epoch 186/200] [Batch 930/938] loss_G: 3.463476, loss_D: 0.276079\n",
      "[Epoch 187/200] [Batch 0/938] loss_G: 3.462417, loss_D: 0.210139\n",
      "[Epoch 187/200] [Batch 10/938] loss_G: 3.459402, loss_D: 0.207638\n",
      "[Epoch 187/200] [Batch 20/938] loss_G: 3.064870, loss_D: 0.210575\n",
      "[Epoch 187/200] [Batch 30/938] loss_G: 3.212081, loss_D: 0.155294\n",
      "[Epoch 187/200] [Batch 40/938] loss_G: 3.378839, loss_D: 0.151177\n",
      "[Epoch 187/200] [Batch 50/938] loss_G: 3.369957, loss_D: 0.129343\n",
      "[Epoch 187/200] [Batch 60/938] loss_G: 3.886580, loss_D: 0.236779\n",
      "[Epoch 187/200] [Batch 70/938] loss_G: 3.709046, loss_D: 0.127658\n",
      "[Epoch 187/200] [Batch 80/938] loss_G: 3.133148, loss_D: 0.291065\n",
      "[Epoch 187/200] [Batch 90/938] loss_G: 3.701736, loss_D: 0.154223\n",
      "[Epoch 187/200] [Batch 100/938] loss_G: 3.319318, loss_D: 0.285118\n",
      "[Epoch 187/200] [Batch 110/938] loss_G: 3.335547, loss_D: 0.110211\n",
      "[Epoch 187/200] [Batch 120/938] loss_G: 3.778711, loss_D: 0.219979\n",
      "[Epoch 187/200] [Batch 130/938] loss_G: 3.238897, loss_D: 0.166950\n",
      "[Epoch 187/200] [Batch 140/938] loss_G: 3.426049, loss_D: 0.180853\n",
      "[Epoch 187/200] [Batch 150/938] loss_G: 3.417906, loss_D: 0.119710\n",
      "[Epoch 187/200] [Batch 160/938] loss_G: 3.565350, loss_D: 0.152621\n",
      "[Epoch 187/200] [Batch 170/938] loss_G: 3.355699, loss_D: 0.181236\n",
      "[Epoch 187/200] [Batch 180/938] loss_G: 3.191047, loss_D: 0.255546\n",
      "[Epoch 187/200] [Batch 190/938] loss_G: 3.283607, loss_D: 0.183074\n",
      "[Epoch 187/200] [Batch 200/938] loss_G: 3.389644, loss_D: 0.144125\n",
      "[Epoch 187/200] [Batch 210/938] loss_G: 3.547404, loss_D: 0.220912\n",
      "[Epoch 187/200] [Batch 220/938] loss_G: 3.413193, loss_D: 0.129615\n",
      "[Epoch 187/200] [Batch 230/938] loss_G: 3.633692, loss_D: 0.190680\n",
      "[Epoch 187/200] [Batch 240/938] loss_G: 3.348021, loss_D: 0.183383\n",
      "[Epoch 187/200] [Batch 250/938] loss_G: 3.386438, loss_D: 0.232268\n",
      "[Epoch 187/200] [Batch 260/938] loss_G: 3.362217, loss_D: 0.200513\n",
      "[Epoch 187/200] [Batch 270/938] loss_G: 3.356412, loss_D: 0.156092\n",
      "[Epoch 187/200] [Batch 280/938] loss_G: 3.629377, loss_D: 0.111023\n",
      "[Epoch 187/200] [Batch 290/938] loss_G: 3.416587, loss_D: 0.240155\n",
      "[Epoch 187/200] [Batch 300/938] loss_G: 3.763317, loss_D: 0.165028\n",
      "[Epoch 187/200] [Batch 310/938] loss_G: 3.376755, loss_D: 0.233397\n",
      "[Epoch 187/200] [Batch 320/938] loss_G: 3.624342, loss_D: 0.162820\n",
      "[Epoch 187/200] [Batch 330/938] loss_G: 3.529356, loss_D: 0.290192\n",
      "[Epoch 187/200] [Batch 340/938] loss_G: 3.459282, loss_D: 0.188234\n",
      "[Epoch 187/200] [Batch 350/938] loss_G: 3.358532, loss_D: 0.192406\n",
      "[Epoch 187/200] [Batch 360/938] loss_G: 3.267890, loss_D: 0.201035\n",
      "[Epoch 187/200] [Batch 370/938] loss_G: 3.483953, loss_D: 0.166355\n",
      "[Epoch 187/200] [Batch 380/938] loss_G: 3.171945, loss_D: 0.145566\n",
      "[Epoch 187/200] [Batch 390/938] loss_G: 3.195830, loss_D: 0.230068\n",
      "[Epoch 187/200] [Batch 400/938] loss_G: 3.543537, loss_D: 0.277057\n",
      "[Epoch 187/200] [Batch 410/938] loss_G: 3.236343, loss_D: 0.209156\n",
      "[Epoch 187/200] [Batch 420/938] loss_G: 3.482970, loss_D: 0.198831\n",
      "[Epoch 187/200] [Batch 430/938] loss_G: 2.935351, loss_D: 0.120377\n",
      "[Epoch 187/200] [Batch 440/938] loss_G: 3.250641, loss_D: 0.257818\n",
      "[Epoch 187/200] [Batch 450/938] loss_G: 3.441089, loss_D: 0.169779\n",
      "[Epoch 187/200] [Batch 460/938] loss_G: 3.324390, loss_D: 0.123862\n",
      "[Epoch 187/200] [Batch 470/938] loss_G: 3.475001, loss_D: 0.133379\n",
      "[Epoch 187/200] [Batch 480/938] loss_G: 3.257140, loss_D: 0.114527\n",
      "[Epoch 187/200] [Batch 490/938] loss_G: 3.764671, loss_D: 0.160198\n",
      "[Epoch 187/200] [Batch 500/938] loss_G: 3.574225, loss_D: 0.207531\n",
      "[Epoch 187/200] [Batch 510/938] loss_G: 3.100359, loss_D: 0.202858\n",
      "[Epoch 187/200] [Batch 520/938] loss_G: 3.276967, loss_D: 0.128140\n",
      "[Epoch 187/200] [Batch 530/938] loss_G: 3.412304, loss_D: 0.274677\n",
      "[Epoch 187/200] [Batch 540/938] loss_G: 3.292722, loss_D: 0.162043\n",
      "[Epoch 187/200] [Batch 550/938] loss_G: 3.476348, loss_D: 0.129846\n",
      "[Epoch 187/200] [Batch 560/938] loss_G: 3.579825, loss_D: 0.152376\n",
      "[Epoch 187/200] [Batch 570/938] loss_G: 3.277253, loss_D: 0.212706\n",
      "[Epoch 187/200] [Batch 580/938] loss_G: 3.052615, loss_D: 0.266522\n",
      "[Epoch 187/200] [Batch 590/938] loss_G: 3.094328, loss_D: 0.137779\n",
      "[Epoch 187/200] [Batch 600/938] loss_G: 2.903038, loss_D: 0.240151\n",
      "[Epoch 187/200] [Batch 610/938] loss_G: 3.493378, loss_D: 0.258205\n",
      "[Epoch 187/200] [Batch 620/938] loss_G: 3.828513, loss_D: 0.171358\n",
      "[Epoch 187/200] [Batch 630/938] loss_G: 3.378175, loss_D: 0.175283\n",
      "[Epoch 187/200] [Batch 640/938] loss_G: 3.570923, loss_D: 0.186996\n",
      "[Epoch 187/200] [Batch 650/938] loss_G: 3.579258, loss_D: 0.210192\n",
      "[Epoch 187/200] [Batch 660/938] loss_G: 3.098303, loss_D: 0.225437\n",
      "[Epoch 187/200] [Batch 670/938] loss_G: 3.191040, loss_D: 0.207469\n",
      "[Epoch 187/200] [Batch 680/938] loss_G: 3.302927, loss_D: 0.249369\n",
      "[Epoch 187/200] [Batch 690/938] loss_G: 3.272924, loss_D: 0.187258\n",
      "[Epoch 187/200] [Batch 700/938] loss_G: 3.620784, loss_D: 0.217535\n",
      "[Epoch 187/200] [Batch 710/938] loss_G: 3.394329, loss_D: 0.193602\n",
      "[Epoch 187/200] [Batch 720/938] loss_G: 3.469069, loss_D: 0.190758\n",
      "[Epoch 187/200] [Batch 730/938] loss_G: 3.395154, loss_D: 0.175534\n",
      "[Epoch 187/200] [Batch 740/938] loss_G: 3.281756, loss_D: 0.164751\n",
      "[Epoch 187/200] [Batch 750/938] loss_G: 3.545156, loss_D: 0.171525\n",
      "[Epoch 187/200] [Batch 760/938] loss_G: 3.595261, loss_D: 0.122906\n",
      "[Epoch 187/200] [Batch 770/938] loss_G: 3.612514, loss_D: 0.129714\n",
      "[Epoch 187/200] [Batch 780/938] loss_G: 3.313222, loss_D: 0.196679\n",
      "[Epoch 187/200] [Batch 790/938] loss_G: 3.336311, loss_D: 0.267989\n",
      "[Epoch 187/200] [Batch 800/938] loss_G: 3.392179, loss_D: 0.151527\n",
      "[Epoch 187/200] [Batch 810/938] loss_G: 3.330171, loss_D: 0.177233\n",
      "[Epoch 187/200] [Batch 820/938] loss_G: 3.200213, loss_D: 0.188511\n",
      "[Epoch 187/200] [Batch 830/938] loss_G: 3.489518, loss_D: 0.238808\n",
      "[Epoch 187/200] [Batch 840/938] loss_G: 3.398662, loss_D: 0.171336\n",
      "[Epoch 187/200] [Batch 850/938] loss_G: 3.220936, loss_D: 0.170949\n",
      "[Epoch 187/200] [Batch 860/938] loss_G: 3.528490, loss_D: 0.137970\n",
      "[Epoch 187/200] [Batch 870/938] loss_G: 3.000386, loss_D: 0.219062\n",
      "[Epoch 187/200] [Batch 880/938] loss_G: 3.570012, loss_D: 0.150642\n",
      "[Epoch 187/200] [Batch 890/938] loss_G: 3.552708, loss_D: 0.200955\n",
      "[Epoch 187/200] [Batch 900/938] loss_G: 3.276802, loss_D: 0.198928\n",
      "[Epoch 187/200] [Batch 910/938] loss_G: 3.057196, loss_D: 0.156973\n",
      "[Epoch 187/200] [Batch 920/938] loss_G: 3.606463, loss_D: 0.107928\n",
      "[Epoch 187/200] [Batch 930/938] loss_G: 3.319231, loss_D: 0.190013\n",
      "[Epoch 188/200] [Batch 0/938] loss_G: 3.322712, loss_D: 0.225851\n",
      "[Epoch 188/200] [Batch 10/938] loss_G: 3.595083, loss_D: 0.180958\n",
      "[Epoch 188/200] [Batch 20/938] loss_G: 3.714803, loss_D: 0.160585\n",
      "[Epoch 188/200] [Batch 30/938] loss_G: 3.378146, loss_D: 0.147100\n",
      "[Epoch 188/200] [Batch 40/938] loss_G: 3.490098, loss_D: 0.199775\n",
      "[Epoch 188/200] [Batch 50/938] loss_G: 3.856631, loss_D: 0.197205\n",
      "[Epoch 188/200] [Batch 60/938] loss_G: 3.524980, loss_D: 0.186125\n",
      "[Epoch 188/200] [Batch 70/938] loss_G: 3.082218, loss_D: 0.164390\n",
      "[Epoch 188/200] [Batch 80/938] loss_G: 3.106452, loss_D: 0.221753\n",
      "[Epoch 188/200] [Batch 90/938] loss_G: 3.452129, loss_D: 0.140267\n",
      "[Epoch 188/200] [Batch 100/938] loss_G: 3.432082, loss_D: 0.242711\n",
      "[Epoch 188/200] [Batch 110/938] loss_G: 3.068606, loss_D: 0.194200\n",
      "[Epoch 188/200] [Batch 120/938] loss_G: 3.396631, loss_D: 0.120023\n",
      "[Epoch 188/200] [Batch 130/938] loss_G: 3.151628, loss_D: 0.184097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 188/200] [Batch 140/938] loss_G: 3.570993, loss_D: 0.162116\n",
      "[Epoch 188/200] [Batch 150/938] loss_G: 3.505322, loss_D: 0.155909\n",
      "[Epoch 188/200] [Batch 160/938] loss_G: 3.604197, loss_D: 0.187867\n",
      "[Epoch 188/200] [Batch 170/938] loss_G: 3.828499, loss_D: 0.279782\n",
      "[Epoch 188/200] [Batch 180/938] loss_G: 3.155811, loss_D: 0.175651\n",
      "[Epoch 188/200] [Batch 190/938] loss_G: 3.738460, loss_D: 0.179374\n",
      "[Epoch 188/200] [Batch 200/938] loss_G: 3.634205, loss_D: 0.137069\n",
      "[Epoch 188/200] [Batch 210/938] loss_G: 3.585614, loss_D: 0.182089\n",
      "[Epoch 188/200] [Batch 220/938] loss_G: 3.336192, loss_D: 0.186462\n",
      "[Epoch 188/200] [Batch 230/938] loss_G: 3.799675, loss_D: 0.143746\n",
      "[Epoch 188/200] [Batch 240/938] loss_G: 3.189795, loss_D: 0.109285\n",
      "[Epoch 188/200] [Batch 250/938] loss_G: 3.785253, loss_D: 0.226573\n",
      "[Epoch 188/200] [Batch 260/938] loss_G: 3.381142, loss_D: 0.186026\n",
      "[Epoch 188/200] [Batch 270/938] loss_G: 3.216899, loss_D: 0.257805\n",
      "[Epoch 188/200] [Batch 280/938] loss_G: 3.306874, loss_D: 0.242750\n",
      "[Epoch 188/200] [Batch 290/938] loss_G: 3.310966, loss_D: 0.206050\n",
      "[Epoch 188/200] [Batch 300/938] loss_G: 3.682452, loss_D: 0.205024\n",
      "[Epoch 188/200] [Batch 310/938] loss_G: 3.429184, loss_D: 0.115866\n",
      "[Epoch 188/200] [Batch 320/938] loss_G: 3.569013, loss_D: 0.107030\n",
      "[Epoch 188/200] [Batch 330/938] loss_G: 3.223476, loss_D: 0.152750\n",
      "[Epoch 188/200] [Batch 340/938] loss_G: 3.272745, loss_D: 0.170397\n",
      "[Epoch 188/200] [Batch 350/938] loss_G: 3.224008, loss_D: 0.182937\n",
      "[Epoch 188/200] [Batch 360/938] loss_G: 3.139398, loss_D: 0.285702\n",
      "[Epoch 188/200] [Batch 370/938] loss_G: 3.237407, loss_D: 0.172026\n",
      "[Epoch 188/200] [Batch 380/938] loss_G: 3.132178, loss_D: 0.193136\n",
      "[Epoch 188/200] [Batch 390/938] loss_G: 3.187596, loss_D: 0.196306\n",
      "[Epoch 188/200] [Batch 400/938] loss_G: 3.409799, loss_D: 0.116921\n",
      "[Epoch 188/200] [Batch 410/938] loss_G: 3.719400, loss_D: 0.135293\n",
      "[Epoch 188/200] [Batch 420/938] loss_G: 2.990906, loss_D: 0.210808\n",
      "[Epoch 188/200] [Batch 430/938] loss_G: 3.319214, loss_D: 0.188619\n",
      "[Epoch 188/200] [Batch 440/938] loss_G: 3.590256, loss_D: 0.124835\n",
      "[Epoch 188/200] [Batch 450/938] loss_G: 3.244805, loss_D: 0.179402\n",
      "[Epoch 188/200] [Batch 460/938] loss_G: 3.309767, loss_D: 0.187203\n",
      "[Epoch 188/200] [Batch 470/938] loss_G: 3.599625, loss_D: 0.144840\n",
      "[Epoch 188/200] [Batch 480/938] loss_G: 3.599424, loss_D: 0.110980\n",
      "[Epoch 188/200] [Batch 490/938] loss_G: 3.162938, loss_D: 0.186190\n",
      "[Epoch 188/200] [Batch 500/938] loss_G: 3.181545, loss_D: 0.251702\n",
      "[Epoch 188/200] [Batch 510/938] loss_G: 3.086064, loss_D: 0.192842\n",
      "[Epoch 188/200] [Batch 520/938] loss_G: 3.561877, loss_D: 0.161657\n",
      "[Epoch 188/200] [Batch 530/938] loss_G: 3.029234, loss_D: 0.162559\n",
      "[Epoch 188/200] [Batch 540/938] loss_G: 3.663687, loss_D: 0.148583\n",
      "[Epoch 188/200] [Batch 550/938] loss_G: 3.503566, loss_D: 0.299204\n",
      "[Epoch 188/200] [Batch 560/938] loss_G: 3.328943, loss_D: 0.244772\n",
      "[Epoch 188/200] [Batch 570/938] loss_G: 2.854227, loss_D: 0.177777\n",
      "[Epoch 188/200] [Batch 580/938] loss_G: 3.858864, loss_D: 0.103759\n",
      "[Epoch 188/200] [Batch 590/938] loss_G: 3.503502, loss_D: 0.216015\n",
      "[Epoch 188/200] [Batch 600/938] loss_G: 3.031842, loss_D: 0.172158\n",
      "[Epoch 188/200] [Batch 610/938] loss_G: 3.194261, loss_D: 0.204450\n",
      "[Epoch 188/200] [Batch 620/938] loss_G: 3.155739, loss_D: 0.165054\n",
      "[Epoch 188/200] [Batch 630/938] loss_G: 3.606906, loss_D: 0.205445\n",
      "[Epoch 188/200] [Batch 640/938] loss_G: 3.120928, loss_D: 0.132418\n",
      "[Epoch 188/200] [Batch 650/938] loss_G: 3.092611, loss_D: 0.298309\n",
      "[Epoch 188/200] [Batch 660/938] loss_G: 3.578902, loss_D: 0.178053\n",
      "[Epoch 188/200] [Batch 670/938] loss_G: 3.557247, loss_D: 0.209422\n",
      "[Epoch 188/200] [Batch 680/938] loss_G: 3.167593, loss_D: 0.153619\n",
      "[Epoch 188/200] [Batch 690/938] loss_G: 3.600561, loss_D: 0.110691\n",
      "[Epoch 188/200] [Batch 700/938] loss_G: 3.361346, loss_D: 0.154931\n",
      "[Epoch 188/200] [Batch 710/938] loss_G: 3.242628, loss_D: 0.175554\n",
      "[Epoch 188/200] [Batch 720/938] loss_G: 2.811922, loss_D: 0.171015\n",
      "[Epoch 188/200] [Batch 730/938] loss_G: 3.655794, loss_D: 0.193755\n",
      "[Epoch 188/200] [Batch 740/938] loss_G: 3.621417, loss_D: 0.151850\n",
      "[Epoch 188/200] [Batch 750/938] loss_G: 3.254211, loss_D: 0.242243\n",
      "[Epoch 188/200] [Batch 760/938] loss_G: 3.064987, loss_D: 0.258615\n",
      "[Epoch 188/200] [Batch 770/938] loss_G: 3.339327, loss_D: 0.226849\n",
      "[Epoch 188/200] [Batch 780/938] loss_G: 3.405580, loss_D: 0.195144\n",
      "[Epoch 188/200] [Batch 790/938] loss_G: 3.285678, loss_D: 0.229429\n",
      "[Epoch 188/200] [Batch 800/938] loss_G: 3.559811, loss_D: 0.153029\n",
      "[Epoch 188/200] [Batch 810/938] loss_G: 3.445932, loss_D: 0.180591\n",
      "[Epoch 188/200] [Batch 820/938] loss_G: 3.235330, loss_D: 0.125387\n",
      "[Epoch 188/200] [Batch 830/938] loss_G: 2.933255, loss_D: 0.210649\n",
      "[Epoch 188/200] [Batch 840/938] loss_G: 2.856749, loss_D: 0.229175\n",
      "[Epoch 188/200] [Batch 850/938] loss_G: 3.179565, loss_D: 0.170419\n",
      "[Epoch 188/200] [Batch 860/938] loss_G: 3.560282, loss_D: 0.197475\n",
      "[Epoch 188/200] [Batch 870/938] loss_G: 3.199245, loss_D: 0.243990\n",
      "[Epoch 188/200] [Batch 880/938] loss_G: 3.647080, loss_D: 0.165365\n",
      "[Epoch 188/200] [Batch 890/938] loss_G: 3.433465, loss_D: 0.197973\n",
      "[Epoch 188/200] [Batch 900/938] loss_G: 3.503942, loss_D: 0.269598\n",
      "[Epoch 188/200] [Batch 910/938] loss_G: 3.760216, loss_D: 0.148580\n",
      "[Epoch 188/200] [Batch 920/938] loss_G: 3.479072, loss_D: 0.189249\n",
      "[Epoch 188/200] [Batch 930/938] loss_G: 3.356068, loss_D: 0.136601\n",
      "[Epoch 189/200] [Batch 0/938] loss_G: 2.917231, loss_D: 0.235000\n",
      "[Epoch 189/200] [Batch 10/938] loss_G: 3.894014, loss_D: 0.098643\n",
      "[Epoch 189/200] [Batch 20/938] loss_G: 3.660120, loss_D: 0.126877\n",
      "[Epoch 189/200] [Batch 30/938] loss_G: 3.426838, loss_D: 0.122002\n",
      "[Epoch 189/200] [Batch 40/938] loss_G: 3.229786, loss_D: 0.249638\n",
      "[Epoch 189/200] [Batch 50/938] loss_G: 3.594790, loss_D: 0.173105\n",
      "[Epoch 189/200] [Batch 60/938] loss_G: 3.463194, loss_D: 0.194860\n",
      "[Epoch 189/200] [Batch 70/938] loss_G: 3.405661, loss_D: 0.225873\n",
      "[Epoch 189/200] [Batch 80/938] loss_G: 3.508399, loss_D: 0.156562\n",
      "[Epoch 189/200] [Batch 90/938] loss_G: 3.331384, loss_D: 0.158085\n",
      "[Epoch 189/200] [Batch 100/938] loss_G: 3.052316, loss_D: 0.216927\n",
      "[Epoch 189/200] [Batch 110/938] loss_G: 3.709795, loss_D: 0.182820\n",
      "[Epoch 189/200] [Batch 120/938] loss_G: 3.345969, loss_D: 0.208587\n",
      "[Epoch 189/200] [Batch 130/938] loss_G: 3.453448, loss_D: 0.183475\n",
      "[Epoch 189/200] [Batch 140/938] loss_G: 3.123334, loss_D: 0.140018\n",
      "[Epoch 189/200] [Batch 150/938] loss_G: 3.059587, loss_D: 0.195192\n",
      "[Epoch 189/200] [Batch 160/938] loss_G: 3.567645, loss_D: 0.258798\n",
      "[Epoch 189/200] [Batch 170/938] loss_G: 3.400000, loss_D: 0.185275\n",
      "[Epoch 189/200] [Batch 180/938] loss_G: 3.611021, loss_D: 0.156652\n",
      "[Epoch 189/200] [Batch 190/938] loss_G: 3.406039, loss_D: 0.174922\n",
      "[Epoch 189/200] [Batch 200/938] loss_G: 3.644122, loss_D: 0.249132\n",
      "[Epoch 189/200] [Batch 210/938] loss_G: 3.233966, loss_D: 0.182520\n",
      "[Epoch 189/200] [Batch 220/938] loss_G: 3.235337, loss_D: 0.239117\n",
      "[Epoch 189/200] [Batch 230/938] loss_G: 2.992952, loss_D: 0.197185\n",
      "[Epoch 189/200] [Batch 240/938] loss_G: 3.523145, loss_D: 0.205789\n",
      "[Epoch 189/200] [Batch 250/938] loss_G: 3.724217, loss_D: 0.153417\n",
      "[Epoch 189/200] [Batch 260/938] loss_G: 3.368300, loss_D: 0.135005\n",
      "[Epoch 189/200] [Batch 270/938] loss_G: 3.443524, loss_D: 0.193799\n",
      "[Epoch 189/200] [Batch 280/938] loss_G: 3.625432, loss_D: 0.155535\n",
      "[Epoch 189/200] [Batch 290/938] loss_G: 3.540306, loss_D: 0.163068\n",
      "[Epoch 189/200] [Batch 300/938] loss_G: 3.493696, loss_D: 0.185961\n",
      "[Epoch 189/200] [Batch 310/938] loss_G: 3.325747, loss_D: 0.192179\n",
      "[Epoch 189/200] [Batch 320/938] loss_G: 3.180297, loss_D: 0.154664\n",
      "[Epoch 189/200] [Batch 330/938] loss_G: 3.467246, loss_D: 0.183183\n",
      "[Epoch 189/200] [Batch 340/938] loss_G: 3.236144, loss_D: 0.173383\n",
      "[Epoch 189/200] [Batch 350/938] loss_G: 3.234985, loss_D: 0.167044\n",
      "[Epoch 189/200] [Batch 360/938] loss_G: 3.133537, loss_D: 0.217537\n",
      "[Epoch 189/200] [Batch 370/938] loss_G: 3.129495, loss_D: 0.159864\n",
      "[Epoch 189/200] [Batch 380/938] loss_G: 3.698653, loss_D: 0.154193\n",
      "[Epoch 189/200] [Batch 390/938] loss_G: 3.296517, loss_D: 0.275206\n",
      "[Epoch 189/200] [Batch 400/938] loss_G: 3.198055, loss_D: 0.129693\n",
      "[Epoch 189/200] [Batch 410/938] loss_G: 3.981991, loss_D: 0.141595\n",
      "[Epoch 189/200] [Batch 420/938] loss_G: 3.367206, loss_D: 0.333651\n",
      "[Epoch 189/200] [Batch 430/938] loss_G: 3.253277, loss_D: 0.163913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 189/200] [Batch 440/938] loss_G: 3.330516, loss_D: 0.158383\n",
      "[Epoch 189/200] [Batch 450/938] loss_G: 3.235254, loss_D: 0.231367\n",
      "[Epoch 189/200] [Batch 460/938] loss_G: 3.138155, loss_D: 0.193439\n",
      "[Epoch 189/200] [Batch 470/938] loss_G: 3.266442, loss_D: 0.171681\n",
      "[Epoch 189/200] [Batch 480/938] loss_G: 3.104674, loss_D: 0.121209\n",
      "[Epoch 189/200] [Batch 490/938] loss_G: 3.399629, loss_D: 0.182301\n",
      "[Epoch 189/200] [Batch 500/938] loss_G: 3.434445, loss_D: 0.219751\n",
      "[Epoch 189/200] [Batch 510/938] loss_G: 3.584320, loss_D: 0.186217\n",
      "[Epoch 189/200] [Batch 520/938] loss_G: 2.978940, loss_D: 0.148079\n",
      "[Epoch 189/200] [Batch 530/938] loss_G: 3.389259, loss_D: 0.154262\n",
      "[Epoch 189/200] [Batch 540/938] loss_G: 3.796838, loss_D: 0.134150\n",
      "[Epoch 189/200] [Batch 550/938] loss_G: 3.592747, loss_D: 0.150187\n",
      "[Epoch 189/200] [Batch 560/938] loss_G: 3.707903, loss_D: 0.296427\n",
      "[Epoch 189/200] [Batch 570/938] loss_G: 3.383308, loss_D: 0.142533\n",
      "[Epoch 189/200] [Batch 580/938] loss_G: 3.375702, loss_D: 0.168482\n",
      "[Epoch 189/200] [Batch 590/938] loss_G: 3.177242, loss_D: 0.137735\n",
      "[Epoch 189/200] [Batch 600/938] loss_G: 3.432949, loss_D: 0.186771\n",
      "[Epoch 189/200] [Batch 610/938] loss_G: 3.270740, loss_D: 0.124115\n",
      "[Epoch 189/200] [Batch 620/938] loss_G: 3.406937, loss_D: 0.174172\n",
      "[Epoch 189/200] [Batch 630/938] loss_G: 3.229166, loss_D: 0.228532\n",
      "[Epoch 189/200] [Batch 640/938] loss_G: 3.241071, loss_D: 0.212398\n",
      "[Epoch 189/200] [Batch 650/938] loss_G: 3.136329, loss_D: 0.208415\n",
      "[Epoch 189/200] [Batch 660/938] loss_G: 3.019193, loss_D: 0.221144\n",
      "[Epoch 189/200] [Batch 670/938] loss_G: 3.744437, loss_D: 0.155335\n",
      "[Epoch 189/200] [Batch 680/938] loss_G: 3.542910, loss_D: 0.158822\n",
      "[Epoch 189/200] [Batch 690/938] loss_G: 3.172815, loss_D: 0.134601\n",
      "[Epoch 189/200] [Batch 700/938] loss_G: 3.248189, loss_D: 0.187690\n",
      "[Epoch 189/200] [Batch 710/938] loss_G: 3.361195, loss_D: 0.207325\n",
      "[Epoch 189/200] [Batch 720/938] loss_G: 3.444267, loss_D: 0.124590\n",
      "[Epoch 189/200] [Batch 730/938] loss_G: 3.301898, loss_D: 0.202640\n",
      "[Epoch 189/200] [Batch 740/938] loss_G: 3.387427, loss_D: 0.197871\n",
      "[Epoch 189/200] [Batch 750/938] loss_G: 3.749926, loss_D: 0.252378\n",
      "[Epoch 189/200] [Batch 760/938] loss_G: 3.602018, loss_D: 0.189894\n",
      "[Epoch 189/200] [Batch 770/938] loss_G: 3.296425, loss_D: 0.108556\n",
      "[Epoch 189/200] [Batch 780/938] loss_G: 3.576813, loss_D: 0.232246\n",
      "[Epoch 189/200] [Batch 790/938] loss_G: 3.380494, loss_D: 0.199615\n",
      "[Epoch 189/200] [Batch 800/938] loss_G: 3.385100, loss_D: 0.159758\n",
      "[Epoch 189/200] [Batch 810/938] loss_G: 3.453556, loss_D: 0.135888\n",
      "[Epoch 189/200] [Batch 820/938] loss_G: 3.073924, loss_D: 0.167948\n",
      "[Epoch 189/200] [Batch 830/938] loss_G: 3.435292, loss_D: 0.132815\n",
      "[Epoch 189/200] [Batch 840/938] loss_G: 3.221206, loss_D: 0.187765\n",
      "[Epoch 189/200] [Batch 850/938] loss_G: 2.873046, loss_D: 0.228593\n",
      "[Epoch 189/200] [Batch 860/938] loss_G: 3.582467, loss_D: 0.188451\n",
      "[Epoch 189/200] [Batch 870/938] loss_G: 2.934106, loss_D: 0.214644\n",
      "[Epoch 189/200] [Batch 880/938] loss_G: 3.736001, loss_D: 0.186521\n",
      "[Epoch 189/200] [Batch 890/938] loss_G: 3.194480, loss_D: 0.189629\n",
      "[Epoch 189/200] [Batch 900/938] loss_G: 3.572067, loss_D: 0.171216\n",
      "[Epoch 189/200] [Batch 910/938] loss_G: 3.222227, loss_D: 0.140207\n",
      "[Epoch 189/200] [Batch 920/938] loss_G: 3.395056, loss_D: 0.258091\n",
      "[Epoch 189/200] [Batch 930/938] loss_G: 3.310637, loss_D: 0.179908\n",
      "[Epoch 190/200] [Batch 0/938] loss_G: 3.492400, loss_D: 0.120417\n",
      "[Epoch 190/200] [Batch 10/938] loss_G: 3.367807, loss_D: 0.159560\n",
      "[Epoch 190/200] [Batch 20/938] loss_G: 3.372424, loss_D: 0.157320\n",
      "[Epoch 190/200] [Batch 30/938] loss_G: 3.614270, loss_D: 0.175405\n",
      "[Epoch 190/200] [Batch 40/938] loss_G: 3.855041, loss_D: 0.225097\n",
      "[Epoch 190/200] [Batch 50/938] loss_G: 3.509398, loss_D: 0.168074\n",
      "[Epoch 190/200] [Batch 60/938] loss_G: 3.633113, loss_D: 0.224228\n",
      "[Epoch 190/200] [Batch 70/938] loss_G: 3.234478, loss_D: 0.193287\n",
      "[Epoch 190/200] [Batch 80/938] loss_G: 3.823714, loss_D: 0.211586\n",
      "[Epoch 190/200] [Batch 90/938] loss_G: 3.420929, loss_D: 0.189340\n",
      "[Epoch 190/200] [Batch 100/938] loss_G: 3.011481, loss_D: 0.171308\n",
      "[Epoch 190/200] [Batch 110/938] loss_G: 3.667997, loss_D: 0.210625\n",
      "[Epoch 190/200] [Batch 120/938] loss_G: 3.392636, loss_D: 0.191653\n",
      "[Epoch 190/200] [Batch 130/938] loss_G: 3.340573, loss_D: 0.204956\n",
      "[Epoch 190/200] [Batch 140/938] loss_G: 3.384604, loss_D: 0.151250\n",
      "[Epoch 190/200] [Batch 150/938] loss_G: 3.909977, loss_D: 0.093873\n",
      "[Epoch 190/200] [Batch 160/938] loss_G: 3.645621, loss_D: 0.210152\n",
      "[Epoch 190/200] [Batch 170/938] loss_G: 3.428409, loss_D: 0.188954\n",
      "[Epoch 190/200] [Batch 180/938] loss_G: 3.874013, loss_D: 0.253059\n",
      "[Epoch 190/200] [Batch 190/938] loss_G: 3.550304, loss_D: 0.211075\n",
      "[Epoch 190/200] [Batch 200/938] loss_G: 3.267436, loss_D: 0.194944\n",
      "[Epoch 190/200] [Batch 210/938] loss_G: 3.357601, loss_D: 0.207094\n",
      "[Epoch 190/200] [Batch 220/938] loss_G: 3.173119, loss_D: 0.168909\n",
      "[Epoch 190/200] [Batch 230/938] loss_G: 3.613833, loss_D: 0.180515\n",
      "[Epoch 190/200] [Batch 240/938] loss_G: 3.483533, loss_D: 0.201669\n",
      "[Epoch 190/200] [Batch 250/938] loss_G: 3.120864, loss_D: 0.184195\n",
      "[Epoch 190/200] [Batch 260/938] loss_G: 3.392906, loss_D: 0.185642\n",
      "[Epoch 190/200] [Batch 270/938] loss_G: 3.735296, loss_D: 0.112773\n",
      "[Epoch 190/200] [Batch 280/938] loss_G: 3.383222, loss_D: 0.221960\n",
      "[Epoch 190/200] [Batch 290/938] loss_G: 3.132594, loss_D: 0.161851\n",
      "[Epoch 190/200] [Batch 300/938] loss_G: 3.452170, loss_D: 0.111121\n",
      "[Epoch 190/200] [Batch 310/938] loss_G: 3.216442, loss_D: 0.201635\n",
      "[Epoch 190/200] [Batch 320/938] loss_G: 3.181803, loss_D: 0.108886\n",
      "[Epoch 190/200] [Batch 330/938] loss_G: 3.550254, loss_D: 0.133160\n",
      "[Epoch 190/200] [Batch 340/938] loss_G: 3.432645, loss_D: 0.177195\n",
      "[Epoch 190/200] [Batch 350/938] loss_G: 3.601053, loss_D: 0.158583\n",
      "[Epoch 190/200] [Batch 360/938] loss_G: 3.451653, loss_D: 0.158690\n",
      "[Epoch 190/200] [Batch 370/938] loss_G: 3.424969, loss_D: 0.186761\n",
      "[Epoch 190/200] [Batch 380/938] loss_G: 3.417688, loss_D: 0.200945\n",
      "[Epoch 190/200] [Batch 390/938] loss_G: 3.718419, loss_D: 0.149584\n",
      "[Epoch 190/200] [Batch 400/938] loss_G: 3.539258, loss_D: 0.157157\n",
      "[Epoch 190/200] [Batch 410/938] loss_G: 3.253700, loss_D: 0.187825\n",
      "[Epoch 190/200] [Batch 420/938] loss_G: 3.683345, loss_D: 0.229097\n",
      "[Epoch 190/200] [Batch 430/938] loss_G: 3.615526, loss_D: 0.095641\n",
      "[Epoch 190/200] [Batch 440/938] loss_G: 3.458641, loss_D: 0.225140\n",
      "[Epoch 190/200] [Batch 450/938] loss_G: 3.376180, loss_D: 0.215089\n",
      "[Epoch 190/200] [Batch 460/938] loss_G: 3.660586, loss_D: 0.185787\n",
      "[Epoch 190/200] [Batch 470/938] loss_G: 3.363626, loss_D: 0.207420\n",
      "[Epoch 190/200] [Batch 480/938] loss_G: 3.865893, loss_D: 0.237311\n",
      "[Epoch 190/200] [Batch 490/938] loss_G: 3.075186, loss_D: 0.203712\n",
      "[Epoch 190/200] [Batch 500/938] loss_G: 3.227488, loss_D: 0.215577\n",
      "[Epoch 190/200] [Batch 510/938] loss_G: 2.791409, loss_D: 0.229334\n",
      "[Epoch 190/200] [Batch 520/938] loss_G: 3.273648, loss_D: 0.173728\n",
      "[Epoch 190/200] [Batch 530/938] loss_G: 3.378753, loss_D: 0.210165\n",
      "[Epoch 190/200] [Batch 540/938] loss_G: 3.587028, loss_D: 0.201899\n",
      "[Epoch 190/200] [Batch 550/938] loss_G: 3.381017, loss_D: 0.149716\n",
      "[Epoch 190/200] [Batch 560/938] loss_G: 3.540769, loss_D: 0.155679\n",
      "[Epoch 190/200] [Batch 570/938] loss_G: 3.467140, loss_D: 0.164957\n",
      "[Epoch 190/200] [Batch 580/938] loss_G: 3.202506, loss_D: 0.171712\n",
      "[Epoch 190/200] [Batch 590/938] loss_G: 3.462389, loss_D: 0.180990\n",
      "[Epoch 190/200] [Batch 600/938] loss_G: 3.148401, loss_D: 0.210655\n",
      "[Epoch 190/200] [Batch 610/938] loss_G: 3.358306, loss_D: 0.178234\n",
      "[Epoch 190/200] [Batch 620/938] loss_G: 3.678759, loss_D: 0.192664\n",
      "[Epoch 190/200] [Batch 630/938] loss_G: 4.000460, loss_D: 0.154464\n",
      "[Epoch 190/200] [Batch 640/938] loss_G: 3.268578, loss_D: 0.203500\n",
      "[Epoch 190/200] [Batch 650/938] loss_G: 3.053513, loss_D: 0.256324\n",
      "[Epoch 190/200] [Batch 660/938] loss_G: 3.086723, loss_D: 0.216004\n",
      "[Epoch 190/200] [Batch 670/938] loss_G: 3.841323, loss_D: 0.137254\n",
      "[Epoch 190/200] [Batch 680/938] loss_G: 3.727760, loss_D: 0.105080\n",
      "[Epoch 190/200] [Batch 690/938] loss_G: 3.325302, loss_D: 0.113974\n",
      "[Epoch 190/200] [Batch 700/938] loss_G: 3.649676, loss_D: 0.186977\n",
      "[Epoch 190/200] [Batch 710/938] loss_G: 3.302503, loss_D: 0.130076\n",
      "[Epoch 190/200] [Batch 720/938] loss_G: 2.843291, loss_D: 0.356520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 190/200] [Batch 730/938] loss_G: 3.185517, loss_D: 0.088603\n",
      "[Epoch 190/200] [Batch 740/938] loss_G: 3.516914, loss_D: 0.260974\n",
      "[Epoch 190/200] [Batch 750/938] loss_G: 3.939125, loss_D: 0.118727\n",
      "[Epoch 190/200] [Batch 760/938] loss_G: 3.388227, loss_D: 0.199862\n",
      "[Epoch 190/200] [Batch 770/938] loss_G: 3.478820, loss_D: 0.156731\n",
      "[Epoch 190/200] [Batch 780/938] loss_G: 3.316949, loss_D: 0.167656\n",
      "[Epoch 190/200] [Batch 790/938] loss_G: 3.127080, loss_D: 0.197011\n",
      "[Epoch 190/200] [Batch 800/938] loss_G: 2.998099, loss_D: 0.183297\n",
      "[Epoch 190/200] [Batch 810/938] loss_G: 3.401878, loss_D: 0.141315\n",
      "[Epoch 190/200] [Batch 820/938] loss_G: 3.285895, loss_D: 0.212051\n",
      "[Epoch 190/200] [Batch 830/938] loss_G: 3.568667, loss_D: 0.283333\n",
      "[Epoch 190/200] [Batch 840/938] loss_G: 2.829383, loss_D: 0.245039\n",
      "[Epoch 190/200] [Batch 850/938] loss_G: 3.429574, loss_D: 0.263990\n",
      "[Epoch 190/200] [Batch 860/938] loss_G: 3.277359, loss_D: 0.231589\n",
      "[Epoch 190/200] [Batch 870/938] loss_G: 3.494003, loss_D: 0.115253\n",
      "[Epoch 190/200] [Batch 880/938] loss_G: 3.378724, loss_D: 0.151560\n",
      "[Epoch 190/200] [Batch 890/938] loss_G: 3.387267, loss_D: 0.218610\n",
      "[Epoch 190/200] [Batch 900/938] loss_G: 3.525563, loss_D: 0.237107\n",
      "[Epoch 190/200] [Batch 910/938] loss_G: 3.354495, loss_D: 0.176754\n",
      "[Epoch 190/200] [Batch 920/938] loss_G: 3.570382, loss_D: 0.125087\n",
      "[Epoch 190/200] [Batch 930/938] loss_G: 2.986009, loss_D: 0.188831\n",
      "[Epoch 191/200] [Batch 0/938] loss_G: 3.889263, loss_D: 0.108593\n",
      "[Epoch 191/200] [Batch 10/938] loss_G: 3.567694, loss_D: 0.201691\n",
      "[Epoch 191/200] [Batch 20/938] loss_G: 3.381407, loss_D: 0.205027\n",
      "[Epoch 191/200] [Batch 30/938] loss_G: 3.332498, loss_D: 0.084651\n",
      "[Epoch 191/200] [Batch 40/938] loss_G: 3.215203, loss_D: 0.194584\n",
      "[Epoch 191/200] [Batch 50/938] loss_G: 3.654945, loss_D: 0.182896\n",
      "[Epoch 191/200] [Batch 60/938] loss_G: 3.931170, loss_D: 0.189386\n",
      "[Epoch 191/200] [Batch 70/938] loss_G: 3.027283, loss_D: 0.284909\n",
      "[Epoch 191/200] [Batch 80/938] loss_G: 3.297096, loss_D: 0.208350\n",
      "[Epoch 191/200] [Batch 90/938] loss_G: 3.528131, loss_D: 0.138871\n",
      "[Epoch 191/200] [Batch 100/938] loss_G: 3.442321, loss_D: 0.136427\n",
      "[Epoch 191/200] [Batch 110/938] loss_G: 3.392988, loss_D: 0.253001\n",
      "[Epoch 191/200] [Batch 120/938] loss_G: 3.271830, loss_D: 0.162804\n",
      "[Epoch 191/200] [Batch 130/938] loss_G: 3.507866, loss_D: 0.189830\n",
      "[Epoch 191/200] [Batch 140/938] loss_G: 3.933244, loss_D: 0.216837\n",
      "[Epoch 191/200] [Batch 150/938] loss_G: 3.613882, loss_D: 0.193681\n",
      "[Epoch 191/200] [Batch 160/938] loss_G: 3.450636, loss_D: 0.126824\n",
      "[Epoch 191/200] [Batch 170/938] loss_G: 3.392225, loss_D: 0.207443\n",
      "[Epoch 191/200] [Batch 180/938] loss_G: 3.785583, loss_D: 0.172636\n",
      "[Epoch 191/200] [Batch 190/938] loss_G: 3.446201, loss_D: 0.163743\n",
      "[Epoch 191/200] [Batch 200/938] loss_G: 3.690040, loss_D: 0.174679\n",
      "[Epoch 191/200] [Batch 210/938] loss_G: 3.518004, loss_D: 0.221410\n",
      "[Epoch 191/200] [Batch 220/938] loss_G: 3.668290, loss_D: 0.223914\n",
      "[Epoch 191/200] [Batch 230/938] loss_G: 3.468187, loss_D: 0.180961\n",
      "[Epoch 191/200] [Batch 240/938] loss_G: 3.453667, loss_D: 0.206554\n",
      "[Epoch 191/200] [Batch 250/938] loss_G: 3.448372, loss_D: 0.183429\n",
      "[Epoch 191/200] [Batch 260/938] loss_G: 3.134504, loss_D: 0.198881\n",
      "[Epoch 191/200] [Batch 270/938] loss_G: 3.654254, loss_D: 0.166546\n",
      "[Epoch 191/200] [Batch 280/938] loss_G: 3.278904, loss_D: 0.195260\n",
      "[Epoch 191/200] [Batch 290/938] loss_G: 2.994369, loss_D: 0.202439\n",
      "[Epoch 191/200] [Batch 300/938] loss_G: 3.815579, loss_D: 0.214131\n",
      "[Epoch 191/200] [Batch 310/938] loss_G: 3.470191, loss_D: 0.206295\n",
      "[Epoch 191/200] [Batch 320/938] loss_G: 3.175504, loss_D: 0.234808\n",
      "[Epoch 191/200] [Batch 330/938] loss_G: 4.116035, loss_D: 0.168145\n",
      "[Epoch 191/200] [Batch 340/938] loss_G: 3.398207, loss_D: 0.267332\n",
      "[Epoch 191/200] [Batch 350/938] loss_G: 3.489316, loss_D: 0.243253\n",
      "[Epoch 191/200] [Batch 360/938] loss_G: 3.256052, loss_D: 0.211377\n",
      "[Epoch 191/200] [Batch 370/938] loss_G: 3.126891, loss_D: 0.159081\n",
      "[Epoch 191/200] [Batch 380/938] loss_G: 3.414269, loss_D: 0.159857\n",
      "[Epoch 191/200] [Batch 390/938] loss_G: 3.354109, loss_D: 0.211682\n",
      "[Epoch 191/200] [Batch 400/938] loss_G: 3.015534, loss_D: 0.220614\n",
      "[Epoch 191/200] [Batch 410/938] loss_G: 3.345231, loss_D: 0.178597\n",
      "[Epoch 191/200] [Batch 420/938] loss_G: 3.530349, loss_D: 0.239112\n",
      "[Epoch 191/200] [Batch 430/938] loss_G: 3.514675, loss_D: 0.209264\n",
      "[Epoch 191/200] [Batch 440/938] loss_G: 3.459865, loss_D: 0.119565\n",
      "[Epoch 191/200] [Batch 450/938] loss_G: 3.260563, loss_D: 0.181556\n",
      "[Epoch 191/200] [Batch 460/938] loss_G: 3.394895, loss_D: 0.157171\n",
      "[Epoch 191/200] [Batch 470/938] loss_G: 2.774745, loss_D: 0.307053\n",
      "[Epoch 191/200] [Batch 480/938] loss_G: 3.161930, loss_D: 0.177176\n",
      "[Epoch 191/200] [Batch 490/938] loss_G: 3.735154, loss_D: 0.144489\n",
      "[Epoch 191/200] [Batch 500/938] loss_G: 3.238451, loss_D: 0.221919\n",
      "[Epoch 191/200] [Batch 510/938] loss_G: 2.994663, loss_D: 0.129500\n",
      "[Epoch 191/200] [Batch 520/938] loss_G: 3.774479, loss_D: 0.186275\n",
      "[Epoch 191/200] [Batch 530/938] loss_G: 3.414174, loss_D: 0.238159\n",
      "[Epoch 191/200] [Batch 540/938] loss_G: 3.364941, loss_D: 0.275234\n",
      "[Epoch 191/200] [Batch 550/938] loss_G: 3.441347, loss_D: 0.126839\n",
      "[Epoch 191/200] [Batch 560/938] loss_G: 3.217724, loss_D: 0.155222\n",
      "[Epoch 191/200] [Batch 570/938] loss_G: 3.294638, loss_D: 0.259577\n",
      "[Epoch 191/200] [Batch 580/938] loss_G: 3.131711, loss_D: 0.206436\n",
      "[Epoch 191/200] [Batch 590/938] loss_G: 3.898051, loss_D: 0.183003\n",
      "[Epoch 191/200] [Batch 600/938] loss_G: 3.402861, loss_D: 0.178890\n",
      "[Epoch 191/200] [Batch 610/938] loss_G: 3.293672, loss_D: 0.147784\n",
      "[Epoch 191/200] [Batch 620/938] loss_G: 3.700400, loss_D: 0.191045\n",
      "[Epoch 191/200] [Batch 630/938] loss_G: 3.462088, loss_D: 0.153423\n",
      "[Epoch 191/200] [Batch 640/938] loss_G: 3.365224, loss_D: 0.192878\n",
      "[Epoch 191/200] [Batch 650/938] loss_G: 3.035693, loss_D: 0.146884\n",
      "[Epoch 191/200] [Batch 660/938] loss_G: 2.963989, loss_D: 0.139385\n",
      "[Epoch 191/200] [Batch 670/938] loss_G: 3.544139, loss_D: 0.211829\n",
      "[Epoch 191/200] [Batch 680/938] loss_G: 3.429906, loss_D: 0.159789\n",
      "[Epoch 191/200] [Batch 690/938] loss_G: 3.153078, loss_D: 0.188740\n",
      "[Epoch 191/200] [Batch 700/938] loss_G: 3.241221, loss_D: 0.232859\n",
      "[Epoch 191/200] [Batch 710/938] loss_G: 3.521773, loss_D: 0.237310\n",
      "[Epoch 191/200] [Batch 720/938] loss_G: 3.722285, loss_D: 0.147856\n",
      "[Epoch 191/200] [Batch 730/938] loss_G: 3.365395, loss_D: 0.147362\n",
      "[Epoch 191/200] [Batch 740/938] loss_G: 3.231823, loss_D: 0.202471\n",
      "[Epoch 191/200] [Batch 750/938] loss_G: 3.414014, loss_D: 0.145125\n",
      "[Epoch 191/200] [Batch 760/938] loss_G: 3.556324, loss_D: 0.233531\n",
      "[Epoch 191/200] [Batch 770/938] loss_G: 3.765352, loss_D: 0.100358\n",
      "[Epoch 191/200] [Batch 780/938] loss_G: 3.482226, loss_D: 0.225263\n",
      "[Epoch 191/200] [Batch 790/938] loss_G: 3.677094, loss_D: 0.209875\n",
      "[Epoch 191/200] [Batch 800/938] loss_G: 3.635086, loss_D: 0.163510\n",
      "[Epoch 191/200] [Batch 810/938] loss_G: 3.316066, loss_D: 0.174133\n",
      "[Epoch 191/200] [Batch 820/938] loss_G: 3.546091, loss_D: 0.137380\n",
      "[Epoch 191/200] [Batch 830/938] loss_G: 3.288392, loss_D: 0.183597\n",
      "[Epoch 191/200] [Batch 840/938] loss_G: 3.580051, loss_D: 0.218611\n",
      "[Epoch 191/200] [Batch 850/938] loss_G: 3.535870, loss_D: 0.187124\n",
      "[Epoch 191/200] [Batch 860/938] loss_G: 2.998858, loss_D: 0.117050\n",
      "[Epoch 191/200] [Batch 870/938] loss_G: 3.077969, loss_D: 0.185141\n",
      "[Epoch 191/200] [Batch 880/938] loss_G: 3.060921, loss_D: 0.202409\n",
      "[Epoch 191/200] [Batch 890/938] loss_G: 3.235474, loss_D: 0.141971\n",
      "[Epoch 191/200] [Batch 900/938] loss_G: 3.306055, loss_D: 0.238345\n",
      "[Epoch 191/200] [Batch 910/938] loss_G: 3.356477, loss_D: 0.123682\n",
      "[Epoch 191/200] [Batch 920/938] loss_G: 3.299535, loss_D: 0.182453\n",
      "[Epoch 191/200] [Batch 930/938] loss_G: 3.328853, loss_D: 0.209255\n",
      "[Epoch 192/200] [Batch 0/938] loss_G: 3.173991, loss_D: 0.170078\n",
      "[Epoch 192/200] [Batch 10/938] loss_G: 3.373293, loss_D: 0.174527\n",
      "[Epoch 192/200] [Batch 20/938] loss_G: 3.220087, loss_D: 0.131847\n",
      "[Epoch 192/200] [Batch 30/938] loss_G: 3.580104, loss_D: 0.142828\n",
      "[Epoch 192/200] [Batch 40/938] loss_G: 3.670275, loss_D: 0.208392\n",
      "[Epoch 192/200] [Batch 50/938] loss_G: 3.163640, loss_D: 0.155670\n",
      "[Epoch 192/200] [Batch 60/938] loss_G: 3.349851, loss_D: 0.164080\n",
      "[Epoch 192/200] [Batch 70/938] loss_G: 3.477708, loss_D: 0.139800\n",
      "[Epoch 192/200] [Batch 80/938] loss_G: 3.714254, loss_D: 0.136752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 192/200] [Batch 90/938] loss_G: 3.614684, loss_D: 0.178925\n",
      "[Epoch 192/200] [Batch 100/938] loss_G: 3.721741, loss_D: 0.093532\n",
      "[Epoch 192/200] [Batch 110/938] loss_G: 3.611316, loss_D: 0.139172\n",
      "[Epoch 192/200] [Batch 120/938] loss_G: 3.481289, loss_D: 0.099454\n",
      "[Epoch 192/200] [Batch 130/938] loss_G: 3.424096, loss_D: 0.176200\n",
      "[Epoch 192/200] [Batch 140/938] loss_G: 3.705827, loss_D: 0.142392\n",
      "[Epoch 192/200] [Batch 150/938] loss_G: 3.470611, loss_D: 0.218269\n",
      "[Epoch 192/200] [Batch 160/938] loss_G: 3.502145, loss_D: 0.209073\n",
      "[Epoch 192/200] [Batch 170/938] loss_G: 3.248183, loss_D: 0.195871\n",
      "[Epoch 192/200] [Batch 180/938] loss_G: 3.646660, loss_D: 0.169680\n",
      "[Epoch 192/200] [Batch 190/938] loss_G: 3.708357, loss_D: 0.147246\n",
      "[Epoch 192/200] [Batch 200/938] loss_G: 3.516299, loss_D: 0.112691\n",
      "[Epoch 192/200] [Batch 210/938] loss_G: 3.688785, loss_D: 0.226624\n",
      "[Epoch 192/200] [Batch 220/938] loss_G: 3.422663, loss_D: 0.146437\n",
      "[Epoch 192/200] [Batch 230/938] loss_G: 3.688679, loss_D: 0.183002\n",
      "[Epoch 192/200] [Batch 240/938] loss_G: 3.537996, loss_D: 0.181497\n",
      "[Epoch 192/200] [Batch 250/938] loss_G: 3.524567, loss_D: 0.205008\n",
      "[Epoch 192/200] [Batch 260/938] loss_G: 3.956338, loss_D: 0.264335\n",
      "[Epoch 192/200] [Batch 270/938] loss_G: 3.433240, loss_D: 0.199874\n",
      "[Epoch 192/200] [Batch 280/938] loss_G: 3.358463, loss_D: 0.218768\n",
      "[Epoch 192/200] [Batch 290/938] loss_G: 3.419534, loss_D: 0.198566\n",
      "[Epoch 192/200] [Batch 300/938] loss_G: 3.372369, loss_D: 0.138020\n",
      "[Epoch 192/200] [Batch 310/938] loss_G: 3.248055, loss_D: 0.208243\n",
      "[Epoch 192/200] [Batch 320/938] loss_G: 3.781874, loss_D: 0.231067\n",
      "[Epoch 192/200] [Batch 330/938] loss_G: 3.524549, loss_D: 0.201880\n",
      "[Epoch 192/200] [Batch 340/938] loss_G: 3.075509, loss_D: 0.138881\n",
      "[Epoch 192/200] [Batch 350/938] loss_G: 3.709584, loss_D: 0.187208\n",
      "[Epoch 192/200] [Batch 360/938] loss_G: 3.449396, loss_D: 0.202860\n",
      "[Epoch 192/200] [Batch 370/938] loss_G: 3.495636, loss_D: 0.142654\n",
      "[Epoch 192/200] [Batch 380/938] loss_G: 3.857208, loss_D: 0.126100\n",
      "[Epoch 192/200] [Batch 390/938] loss_G: 3.572935, loss_D: 0.140093\n",
      "[Epoch 192/200] [Batch 400/938] loss_G: 3.685612, loss_D: 0.117939\n",
      "[Epoch 192/200] [Batch 410/938] loss_G: 3.632021, loss_D: 0.152674\n",
      "[Epoch 192/200] [Batch 420/938] loss_G: 3.393626, loss_D: 0.127641\n",
      "[Epoch 192/200] [Batch 430/938] loss_G: 3.367959, loss_D: 0.282692\n",
      "[Epoch 192/200] [Batch 440/938] loss_G: 3.347451, loss_D: 0.145881\n",
      "[Epoch 192/200] [Batch 450/938] loss_G: 3.335868, loss_D: 0.180208\n",
      "[Epoch 192/200] [Batch 460/938] loss_G: 3.580619, loss_D: 0.239255\n",
      "[Epoch 192/200] [Batch 470/938] loss_G: 2.819407, loss_D: 0.233924\n",
      "[Epoch 192/200] [Batch 480/938] loss_G: 3.413305, loss_D: 0.237334\n",
      "[Epoch 192/200] [Batch 490/938] loss_G: 3.170611, loss_D: 0.229865\n",
      "[Epoch 192/200] [Batch 500/938] loss_G: 3.667152, loss_D: 0.143523\n",
      "[Epoch 192/200] [Batch 510/938] loss_G: 3.590374, loss_D: 0.099626\n",
      "[Epoch 192/200] [Batch 520/938] loss_G: 3.408104, loss_D: 0.134833\n",
      "[Epoch 192/200] [Batch 530/938] loss_G: 3.214430, loss_D: 0.163671\n",
      "[Epoch 192/200] [Batch 540/938] loss_G: 3.502047, loss_D: 0.158024\n",
      "[Epoch 192/200] [Batch 550/938] loss_G: 3.507259, loss_D: 0.099754\n",
      "[Epoch 192/200] [Batch 560/938] loss_G: 3.206801, loss_D: 0.137967\n",
      "[Epoch 192/200] [Batch 570/938] loss_G: 3.238016, loss_D: 0.224612\n",
      "[Epoch 192/200] [Batch 580/938] loss_G: 3.604889, loss_D: 0.266862\n",
      "[Epoch 192/200] [Batch 590/938] loss_G: 3.379379, loss_D: 0.221122\n",
      "[Epoch 192/200] [Batch 600/938] loss_G: 3.334892, loss_D: 0.264769\n",
      "[Epoch 192/200] [Batch 610/938] loss_G: 3.576736, loss_D: 0.170638\n",
      "[Epoch 192/200] [Batch 620/938] loss_G: 3.592481, loss_D: 0.176619\n",
      "[Epoch 192/200] [Batch 630/938] loss_G: 2.942817, loss_D: 0.141429\n",
      "[Epoch 192/200] [Batch 640/938] loss_G: 3.965384, loss_D: 0.128850\n",
      "[Epoch 192/200] [Batch 650/938] loss_G: 3.637554, loss_D: 0.157652\n",
      "[Epoch 192/200] [Batch 660/938] loss_G: 3.551793, loss_D: 0.168078\n",
      "[Epoch 192/200] [Batch 670/938] loss_G: 3.341565, loss_D: 0.190239\n",
      "[Epoch 192/200] [Batch 680/938] loss_G: 3.222882, loss_D: 0.362301\n",
      "[Epoch 192/200] [Batch 690/938] loss_G: 3.315861, loss_D: 0.222981\n",
      "[Epoch 192/200] [Batch 700/938] loss_G: 3.515882, loss_D: 0.229622\n",
      "[Epoch 192/200] [Batch 710/938] loss_G: 3.480385, loss_D: 0.184414\n",
      "[Epoch 192/200] [Batch 720/938] loss_G: 3.314341, loss_D: 0.309371\n",
      "[Epoch 192/200] [Batch 730/938] loss_G: 3.674591, loss_D: 0.133154\n",
      "[Epoch 192/200] [Batch 740/938] loss_G: 3.552463, loss_D: 0.191887\n",
      "[Epoch 192/200] [Batch 750/938] loss_G: 3.517789, loss_D: 0.132537\n",
      "[Epoch 192/200] [Batch 760/938] loss_G: 3.808108, loss_D: 0.119889\n",
      "[Epoch 192/200] [Batch 770/938] loss_G: 3.152578, loss_D: 0.252841\n",
      "[Epoch 192/200] [Batch 780/938] loss_G: 3.079629, loss_D: 0.160996\n",
      "[Epoch 192/200] [Batch 790/938] loss_G: 3.351540, loss_D: 0.225263\n",
      "[Epoch 192/200] [Batch 800/938] loss_G: 3.230522, loss_D: 0.250891\n",
      "[Epoch 192/200] [Batch 810/938] loss_G: 3.512703, loss_D: 0.156676\n",
      "[Epoch 192/200] [Batch 820/938] loss_G: 3.360477, loss_D: 0.217770\n",
      "[Epoch 192/200] [Batch 830/938] loss_G: 3.091973, loss_D: 0.211752\n",
      "[Epoch 192/200] [Batch 840/938] loss_G: 3.318721, loss_D: 0.233850\n",
      "[Epoch 192/200] [Batch 850/938] loss_G: 3.411899, loss_D: 0.139651\n",
      "[Epoch 192/200] [Batch 860/938] loss_G: 3.227052, loss_D: 0.088681\n",
      "[Epoch 192/200] [Batch 870/938] loss_G: 3.425750, loss_D: 0.167748\n",
      "[Epoch 192/200] [Batch 880/938] loss_G: 3.111951, loss_D: 0.187393\n",
      "[Epoch 192/200] [Batch 890/938] loss_G: 3.283278, loss_D: 0.252181\n",
      "[Epoch 192/200] [Batch 900/938] loss_G: 3.421834, loss_D: 0.206080\n",
      "[Epoch 192/200] [Batch 910/938] loss_G: 4.004219, loss_D: 0.143185\n",
      "[Epoch 192/200] [Batch 920/938] loss_G: 3.715486, loss_D: 0.095278\n",
      "[Epoch 192/200] [Batch 930/938] loss_G: 3.214187, loss_D: 0.208571\n",
      "[Epoch 193/200] [Batch 0/938] loss_G: 3.549787, loss_D: 0.189951\n",
      "[Epoch 193/200] [Batch 10/938] loss_G: 3.468554, loss_D: 0.240798\n",
      "[Epoch 193/200] [Batch 20/938] loss_G: 3.370194, loss_D: 0.128028\n",
      "[Epoch 193/200] [Batch 30/938] loss_G: 3.229203, loss_D: 0.173985\n",
      "[Epoch 193/200] [Batch 40/938] loss_G: 3.523511, loss_D: 0.124298\n",
      "[Epoch 193/200] [Batch 50/938] loss_G: 3.422683, loss_D: 0.161930\n",
      "[Epoch 193/200] [Batch 60/938] loss_G: 3.360434, loss_D: 0.209261\n",
      "[Epoch 193/200] [Batch 70/938] loss_G: 3.209486, loss_D: 0.193360\n",
      "[Epoch 193/200] [Batch 80/938] loss_G: 3.727717, loss_D: 0.161519\n",
      "[Epoch 193/200] [Batch 90/938] loss_G: 3.232811, loss_D: 0.167561\n",
      "[Epoch 193/200] [Batch 100/938] loss_G: 3.081400, loss_D: 0.217152\n",
      "[Epoch 193/200] [Batch 110/938] loss_G: 3.248312, loss_D: 0.215245\n",
      "[Epoch 193/200] [Batch 120/938] loss_G: 3.574640, loss_D: 0.180493\n",
      "[Epoch 193/200] [Batch 130/938] loss_G: 3.515017, loss_D: 0.182031\n",
      "[Epoch 193/200] [Batch 140/938] loss_G: 3.414946, loss_D: 0.167295\n",
      "[Epoch 193/200] [Batch 150/938] loss_G: 3.295042, loss_D: 0.166544\n",
      "[Epoch 193/200] [Batch 160/938] loss_G: 3.470175, loss_D: 0.142302\n",
      "[Epoch 193/200] [Batch 170/938] loss_G: 3.449737, loss_D: 0.141570\n",
      "[Epoch 193/200] [Batch 180/938] loss_G: 3.181688, loss_D: 0.162280\n",
      "[Epoch 193/200] [Batch 190/938] loss_G: 3.632954, loss_D: 0.268797\n",
      "[Epoch 193/200] [Batch 200/938] loss_G: 3.017773, loss_D: 0.248162\n",
      "[Epoch 193/200] [Batch 210/938] loss_G: 3.389367, loss_D: 0.196285\n",
      "[Epoch 193/200] [Batch 220/938] loss_G: 3.385300, loss_D: 0.148648\n",
      "[Epoch 193/200] [Batch 230/938] loss_G: 3.091893, loss_D: 0.210602\n",
      "[Epoch 193/200] [Batch 240/938] loss_G: 3.335255, loss_D: 0.191880\n",
      "[Epoch 193/200] [Batch 250/938] loss_G: 3.223875, loss_D: 0.206076\n",
      "[Epoch 193/200] [Batch 260/938] loss_G: 3.691911, loss_D: 0.159496\n",
      "[Epoch 193/200] [Batch 270/938] loss_G: 3.506572, loss_D: 0.289177\n",
      "[Epoch 193/200] [Batch 280/938] loss_G: 3.605529, loss_D: 0.207329\n",
      "[Epoch 193/200] [Batch 290/938] loss_G: 3.474260, loss_D: 0.188900\n",
      "[Epoch 193/200] [Batch 300/938] loss_G: 3.399091, loss_D: 0.137254\n",
      "[Epoch 193/200] [Batch 310/938] loss_G: 3.876145, loss_D: 0.172703\n",
      "[Epoch 193/200] [Batch 320/938] loss_G: 3.519203, loss_D: 0.232992\n",
      "[Epoch 193/200] [Batch 330/938] loss_G: 3.232137, loss_D: 0.169071\n",
      "[Epoch 193/200] [Batch 340/938] loss_G: 2.764495, loss_D: 0.297753\n",
      "[Epoch 193/200] [Batch 350/938] loss_G: 3.583738, loss_D: 0.122376\n",
      "[Epoch 193/200] [Batch 360/938] loss_G: 3.480840, loss_D: 0.178146\n",
      "[Epoch 193/200] [Batch 370/938] loss_G: 3.218418, loss_D: 0.186771\n",
      "[Epoch 193/200] [Batch 380/938] loss_G: 3.660083, loss_D: 0.216990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 193/200] [Batch 390/938] loss_G: 3.052442, loss_D: 0.129150\n",
      "[Epoch 193/200] [Batch 400/938] loss_G: 3.461422, loss_D: 0.155251\n",
      "[Epoch 193/200] [Batch 410/938] loss_G: 3.338442, loss_D: 0.131961\n",
      "[Epoch 193/200] [Batch 420/938] loss_G: 3.515658, loss_D: 0.178303\n",
      "[Epoch 193/200] [Batch 430/938] loss_G: 3.349265, loss_D: 0.231813\n",
      "[Epoch 193/200] [Batch 440/938] loss_G: 3.882510, loss_D: 0.159553\n",
      "[Epoch 193/200] [Batch 450/938] loss_G: 3.146302, loss_D: 0.227986\n",
      "[Epoch 193/200] [Batch 460/938] loss_G: 3.580391, loss_D: 0.166475\n",
      "[Epoch 193/200] [Batch 470/938] loss_G: 3.367810, loss_D: 0.157550\n",
      "[Epoch 193/200] [Batch 480/938] loss_G: 3.245813, loss_D: 0.167377\n",
      "[Epoch 193/200] [Batch 490/938] loss_G: 3.166354, loss_D: 0.158073\n",
      "[Epoch 193/200] [Batch 500/938] loss_G: 3.629786, loss_D: 0.151973\n",
      "[Epoch 193/200] [Batch 510/938] loss_G: 3.588144, loss_D: 0.175934\n",
      "[Epoch 193/200] [Batch 520/938] loss_G: 3.495245, loss_D: 0.131006\n",
      "[Epoch 193/200] [Batch 530/938] loss_G: 3.578893, loss_D: 0.102295\n",
      "[Epoch 193/200] [Batch 540/938] loss_G: 3.869448, loss_D: 0.133658\n",
      "[Epoch 193/200] [Batch 550/938] loss_G: 3.233597, loss_D: 0.186671\n",
      "[Epoch 193/200] [Batch 560/938] loss_G: 3.160504, loss_D: 0.222484\n",
      "[Epoch 193/200] [Batch 570/938] loss_G: 3.459666, loss_D: 0.156889\n",
      "[Epoch 193/200] [Batch 580/938] loss_G: 3.668385, loss_D: 0.215751\n",
      "[Epoch 193/200] [Batch 590/938] loss_G: 3.580148, loss_D: 0.157722\n",
      "[Epoch 193/200] [Batch 600/938] loss_G: 3.406434, loss_D: 0.153888\n",
      "[Epoch 193/200] [Batch 610/938] loss_G: 3.246972, loss_D: 0.151351\n",
      "[Epoch 193/200] [Batch 620/938] loss_G: 3.668260, loss_D: 0.167366\n",
      "[Epoch 193/200] [Batch 630/938] loss_G: 3.056843, loss_D: 0.162933\n",
      "[Epoch 193/200] [Batch 640/938] loss_G: 3.649328, loss_D: 0.138155\n",
      "[Epoch 193/200] [Batch 650/938] loss_G: 3.645616, loss_D: 0.093117\n",
      "[Epoch 193/200] [Batch 660/938] loss_G: 3.268677, loss_D: 0.173339\n",
      "[Epoch 193/200] [Batch 670/938] loss_G: 3.379596, loss_D: 0.153718\n",
      "[Epoch 193/200] [Batch 680/938] loss_G: 3.553823, loss_D: 0.235329\n",
      "[Epoch 193/200] [Batch 690/938] loss_G: 3.441161, loss_D: 0.161073\n",
      "[Epoch 193/200] [Batch 700/938] loss_G: 4.118984, loss_D: 0.110682\n",
      "[Epoch 193/200] [Batch 710/938] loss_G: 3.818703, loss_D: 0.221193\n",
      "[Epoch 193/200] [Batch 720/938] loss_G: 3.592034, loss_D: 0.217692\n",
      "[Epoch 193/200] [Batch 730/938] loss_G: 3.694328, loss_D: 0.211059\n",
      "[Epoch 193/200] [Batch 740/938] loss_G: 3.464084, loss_D: 0.090866\n",
      "[Epoch 193/200] [Batch 750/938] loss_G: 3.385640, loss_D: 0.147218\n",
      "[Epoch 193/200] [Batch 760/938] loss_G: 3.370604, loss_D: 0.131480\n",
      "[Epoch 193/200] [Batch 770/938] loss_G: 3.550366, loss_D: 0.134743\n",
      "[Epoch 193/200] [Batch 780/938] loss_G: 3.113712, loss_D: 0.150946\n",
      "[Epoch 193/200] [Batch 790/938] loss_G: 3.519399, loss_D: 0.196773\n",
      "[Epoch 193/200] [Batch 800/938] loss_G: 3.497944, loss_D: 0.133867\n",
      "[Epoch 193/200] [Batch 810/938] loss_G: 3.355396, loss_D: 0.208214\n",
      "[Epoch 193/200] [Batch 820/938] loss_G: 3.452143, loss_D: 0.147138\n",
      "[Epoch 193/200] [Batch 830/938] loss_G: 3.305348, loss_D: 0.166750\n",
      "[Epoch 193/200] [Batch 840/938] loss_G: 3.165570, loss_D: 0.243284\n",
      "[Epoch 193/200] [Batch 850/938] loss_G: 3.372321, loss_D: 0.176294\n",
      "[Epoch 193/200] [Batch 860/938] loss_G: 3.254550, loss_D: 0.157173\n",
      "[Epoch 193/200] [Batch 870/938] loss_G: 3.070840, loss_D: 0.250220\n",
      "[Epoch 193/200] [Batch 880/938] loss_G: 3.903040, loss_D: 0.219766\n",
      "[Epoch 193/200] [Batch 890/938] loss_G: 3.372203, loss_D: 0.121523\n",
      "[Epoch 193/200] [Batch 900/938] loss_G: 2.914476, loss_D: 0.192906\n",
      "[Epoch 193/200] [Batch 910/938] loss_G: 3.191924, loss_D: 0.312212\n",
      "[Epoch 193/200] [Batch 920/938] loss_G: 3.289821, loss_D: 0.210294\n",
      "[Epoch 193/200] [Batch 930/938] loss_G: 3.457947, loss_D: 0.233672\n",
      "[Epoch 194/200] [Batch 0/938] loss_G: 3.791265, loss_D: 0.186464\n",
      "[Epoch 194/200] [Batch 10/938] loss_G: 3.077593, loss_D: 0.107693\n",
      "[Epoch 194/200] [Batch 20/938] loss_G: 3.499614, loss_D: 0.138276\n",
      "[Epoch 194/200] [Batch 30/938] loss_G: 3.638111, loss_D: 0.239201\n",
      "[Epoch 194/200] [Batch 40/938] loss_G: 3.123203, loss_D: 0.208112\n",
      "[Epoch 194/200] [Batch 50/938] loss_G: 3.285081, loss_D: 0.236882\n",
      "[Epoch 194/200] [Batch 60/938] loss_G: 3.656992, loss_D: 0.152821\n",
      "[Epoch 194/200] [Batch 70/938] loss_G: 3.696033, loss_D: 0.132400\n",
      "[Epoch 194/200] [Batch 80/938] loss_G: 3.122755, loss_D: 0.130441\n",
      "[Epoch 194/200] [Batch 90/938] loss_G: 3.304072, loss_D: 0.210212\n",
      "[Epoch 194/200] [Batch 100/938] loss_G: 3.533429, loss_D: 0.224495\n",
      "[Epoch 194/200] [Batch 110/938] loss_G: 3.548843, loss_D: 0.128854\n",
      "[Epoch 194/200] [Batch 120/938] loss_G: 3.365336, loss_D: 0.264785\n",
      "[Epoch 194/200] [Batch 130/938] loss_G: 2.941771, loss_D: 0.179119\n",
      "[Epoch 194/200] [Batch 140/938] loss_G: 3.465393, loss_D: 0.209534\n",
      "[Epoch 194/200] [Batch 150/938] loss_G: 3.442378, loss_D: 0.149335\n",
      "[Epoch 194/200] [Batch 160/938] loss_G: 3.633608, loss_D: 0.123901\n",
      "[Epoch 194/200] [Batch 170/938] loss_G: 3.101502, loss_D: 0.135872\n",
      "[Epoch 194/200] [Batch 180/938] loss_G: 3.308906, loss_D: 0.167007\n",
      "[Epoch 194/200] [Batch 190/938] loss_G: 3.488816, loss_D: 0.256116\n",
      "[Epoch 194/200] [Batch 200/938] loss_G: 3.830607, loss_D: 0.201394\n",
      "[Epoch 194/200] [Batch 210/938] loss_G: 3.312856, loss_D: 0.172976\n",
      "[Epoch 194/200] [Batch 220/938] loss_G: 3.088151, loss_D: 0.248824\n",
      "[Epoch 194/200] [Batch 230/938] loss_G: 3.450181, loss_D: 0.127419\n",
      "[Epoch 194/200] [Batch 240/938] loss_G: 3.237268, loss_D: 0.188804\n",
      "[Epoch 194/200] [Batch 250/938] loss_G: 3.276417, loss_D: 0.188071\n",
      "[Epoch 194/200] [Batch 260/938] loss_G: 3.089601, loss_D: 0.240548\n",
      "[Epoch 194/200] [Batch 270/938] loss_G: 3.517941, loss_D: 0.151146\n",
      "[Epoch 194/200] [Batch 280/938] loss_G: 3.665907, loss_D: 0.174952\n",
      "[Epoch 194/200] [Batch 290/938] loss_G: 3.536571, loss_D: 0.185902\n",
      "[Epoch 194/200] [Batch 300/938] loss_G: 3.763458, loss_D: 0.097508\n",
      "[Epoch 194/200] [Batch 310/938] loss_G: 3.984140, loss_D: 0.122641\n",
      "[Epoch 194/200] [Batch 320/938] loss_G: 3.636802, loss_D: 0.206911\n",
      "[Epoch 194/200] [Batch 330/938] loss_G: 3.227238, loss_D: 0.173823\n",
      "[Epoch 194/200] [Batch 340/938] loss_G: 3.410107, loss_D: 0.114803\n",
      "[Epoch 194/200] [Batch 350/938] loss_G: 3.556498, loss_D: 0.163165\n",
      "[Epoch 194/200] [Batch 360/938] loss_G: 3.517339, loss_D: 0.204569\n",
      "[Epoch 194/200] [Batch 370/938] loss_G: 2.917927, loss_D: 0.193375\n",
      "[Epoch 194/200] [Batch 380/938] loss_G: 3.244206, loss_D: 0.166986\n",
      "[Epoch 194/200] [Batch 390/938] loss_G: 3.757888, loss_D: 0.209961\n",
      "[Epoch 194/200] [Batch 400/938] loss_G: 3.465054, loss_D: 0.200032\n",
      "[Epoch 194/200] [Batch 410/938] loss_G: 3.324200, loss_D: 0.184611\n",
      "[Epoch 194/200] [Batch 420/938] loss_G: 3.507972, loss_D: 0.168920\n",
      "[Epoch 194/200] [Batch 430/938] loss_G: 3.539547, loss_D: 0.238356\n",
      "[Epoch 194/200] [Batch 440/938] loss_G: 3.491318, loss_D: 0.137125\n",
      "[Epoch 194/200] [Batch 450/938] loss_G: 3.313083, loss_D: 0.149032\n",
      "[Epoch 194/200] [Batch 460/938] loss_G: 3.717114, loss_D: 0.166962\n",
      "[Epoch 194/200] [Batch 470/938] loss_G: 3.524418, loss_D: 0.187379\n",
      "[Epoch 194/200] [Batch 480/938] loss_G: 3.609001, loss_D: 0.229011\n",
      "[Epoch 194/200] [Batch 490/938] loss_G: 2.824040, loss_D: 0.201508\n",
      "[Epoch 194/200] [Batch 500/938] loss_G: 3.568121, loss_D: 0.160295\n",
      "[Epoch 194/200] [Batch 510/938] loss_G: 3.414450, loss_D: 0.230274\n",
      "[Epoch 194/200] [Batch 520/938] loss_G: 3.647384, loss_D: 0.199132\n",
      "[Epoch 194/200] [Batch 530/938] loss_G: 3.511290, loss_D: 0.121245\n",
      "[Epoch 194/200] [Batch 540/938] loss_G: 3.745648, loss_D: 0.101849\n",
      "[Epoch 194/200] [Batch 550/938] loss_G: 3.125014, loss_D: 0.182592\n",
      "[Epoch 194/200] [Batch 560/938] loss_G: 3.139170, loss_D: 0.157112\n",
      "[Epoch 194/200] [Batch 570/938] loss_G: 3.061632, loss_D: 0.225417\n",
      "[Epoch 194/200] [Batch 580/938] loss_G: 3.432959, loss_D: 0.187311\n",
      "[Epoch 194/200] [Batch 590/938] loss_G: 3.489762, loss_D: 0.165807\n",
      "[Epoch 194/200] [Batch 600/938] loss_G: 3.416370, loss_D: 0.206844\n",
      "[Epoch 194/200] [Batch 610/938] loss_G: 3.800826, loss_D: 0.185684\n",
      "[Epoch 194/200] [Batch 620/938] loss_G: 3.792222, loss_D: 0.150366\n",
      "[Epoch 194/200] [Batch 630/938] loss_G: 3.457767, loss_D: 0.216204\n",
      "[Epoch 194/200] [Batch 640/938] loss_G: 3.474113, loss_D: 0.197545\n",
      "[Epoch 194/200] [Batch 650/938] loss_G: 3.182593, loss_D: 0.199980\n",
      "[Epoch 194/200] [Batch 660/938] loss_G: 3.943604, loss_D: 0.143046\n",
      "[Epoch 194/200] [Batch 670/938] loss_G: 3.831723, loss_D: 0.231388\n",
      "[Epoch 194/200] [Batch 680/938] loss_G: 3.143372, loss_D: 0.167399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 194/200] [Batch 690/938] loss_G: 3.215367, loss_D: 0.201606\n",
      "[Epoch 194/200] [Batch 700/938] loss_G: 3.715975, loss_D: 0.135939\n",
      "[Epoch 194/200] [Batch 710/938] loss_G: 2.860655, loss_D: 0.207515\n",
      "[Epoch 194/200] [Batch 720/938] loss_G: 3.179863, loss_D: 0.134586\n",
      "[Epoch 194/200] [Batch 730/938] loss_G: 3.541236, loss_D: 0.134984\n",
      "[Epoch 194/200] [Batch 740/938] loss_G: 3.275782, loss_D: 0.309254\n",
      "[Epoch 194/200] [Batch 750/938] loss_G: 3.017817, loss_D: 0.217319\n",
      "[Epoch 194/200] [Batch 760/938] loss_G: 3.599311, loss_D: 0.133735\n",
      "[Epoch 194/200] [Batch 770/938] loss_G: 3.068815, loss_D: 0.160973\n",
      "[Epoch 194/200] [Batch 780/938] loss_G: 3.432246, loss_D: 0.197335\n",
      "[Epoch 194/200] [Batch 790/938] loss_G: 3.464133, loss_D: 0.189242\n",
      "[Epoch 194/200] [Batch 800/938] loss_G: 3.273129, loss_D: 0.080569\n",
      "[Epoch 194/200] [Batch 810/938] loss_G: 3.308341, loss_D: 0.192165\n",
      "[Epoch 194/200] [Batch 820/938] loss_G: 3.624595, loss_D: 0.172376\n",
      "[Epoch 194/200] [Batch 830/938] loss_G: 3.311263, loss_D: 0.182650\n",
      "[Epoch 194/200] [Batch 840/938] loss_G: 3.547959, loss_D: 0.145495\n",
      "[Epoch 194/200] [Batch 850/938] loss_G: 3.393803, loss_D: 0.180229\n",
      "[Epoch 194/200] [Batch 860/938] loss_G: 3.469151, loss_D: 0.215037\n",
      "[Epoch 194/200] [Batch 870/938] loss_G: 3.348059, loss_D: 0.187723\n",
      "[Epoch 194/200] [Batch 880/938] loss_G: 3.792071, loss_D: 0.202130\n",
      "[Epoch 194/200] [Batch 890/938] loss_G: 3.460666, loss_D: 0.130396\n",
      "[Epoch 194/200] [Batch 900/938] loss_G: 3.726330, loss_D: 0.088574\n",
      "[Epoch 194/200] [Batch 910/938] loss_G: 3.335057, loss_D: 0.171129\n",
      "[Epoch 194/200] [Batch 920/938] loss_G: 3.067202, loss_D: 0.278569\n",
      "[Epoch 194/200] [Batch 930/938] loss_G: 3.310097, loss_D: 0.167964\n",
      "[Epoch 195/200] [Batch 0/938] loss_G: 3.708736, loss_D: 0.143838\n",
      "[Epoch 195/200] [Batch 10/938] loss_G: 3.079328, loss_D: 0.219024\n",
      "[Epoch 195/200] [Batch 20/938] loss_G: 3.566332, loss_D: 0.091273\n",
      "[Epoch 195/200] [Batch 30/938] loss_G: 3.587974, loss_D: 0.200208\n",
      "[Epoch 195/200] [Batch 40/938] loss_G: 3.820724, loss_D: 0.143770\n",
      "[Epoch 195/200] [Batch 50/938] loss_G: 3.268594, loss_D: 0.134060\n",
      "[Epoch 195/200] [Batch 60/938] loss_G: 3.495427, loss_D: 0.212359\n",
      "[Epoch 195/200] [Batch 70/938] loss_G: 3.302063, loss_D: 0.267523\n",
      "[Epoch 195/200] [Batch 80/938] loss_G: 3.343892, loss_D: 0.145792\n",
      "[Epoch 195/200] [Batch 90/938] loss_G: 3.504026, loss_D: 0.164484\n",
      "[Epoch 195/200] [Batch 100/938] loss_G: 3.674307, loss_D: 0.149184\n",
      "[Epoch 195/200] [Batch 110/938] loss_G: 3.580516, loss_D: 0.113163\n",
      "[Epoch 195/200] [Batch 120/938] loss_G: 3.459198, loss_D: 0.170921\n",
      "[Epoch 195/200] [Batch 130/938] loss_G: 3.499715, loss_D: 0.164289\n",
      "[Epoch 195/200] [Batch 140/938] loss_G: 3.233469, loss_D: 0.168208\n",
      "[Epoch 195/200] [Batch 150/938] loss_G: 3.690062, loss_D: 0.154242\n",
      "[Epoch 195/200] [Batch 160/938] loss_G: 3.257745, loss_D: 0.129655\n",
      "[Epoch 195/200] [Batch 170/938] loss_G: 3.278614, loss_D: 0.219039\n",
      "[Epoch 195/200] [Batch 180/938] loss_G: 3.409585, loss_D: 0.194431\n",
      "[Epoch 195/200] [Batch 190/938] loss_G: 3.090795, loss_D: 0.147557\n",
      "[Epoch 195/200] [Batch 200/938] loss_G: 3.510146, loss_D: 0.098956\n",
      "[Epoch 195/200] [Batch 210/938] loss_G: 3.315270, loss_D: 0.157568\n",
      "[Epoch 195/200] [Batch 220/938] loss_G: 3.239400, loss_D: 0.180755\n",
      "[Epoch 195/200] [Batch 230/938] loss_G: 3.662383, loss_D: 0.153053\n",
      "[Epoch 195/200] [Batch 240/938] loss_G: 3.050487, loss_D: 0.194470\n",
      "[Epoch 195/200] [Batch 250/938] loss_G: 3.098279, loss_D: 0.210174\n",
      "[Epoch 195/200] [Batch 260/938] loss_G: 3.000367, loss_D: 0.164572\n",
      "[Epoch 195/200] [Batch 270/938] loss_G: 3.676322, loss_D: 0.099074\n",
      "[Epoch 195/200] [Batch 280/938] loss_G: 3.369941, loss_D: 0.144510\n",
      "[Epoch 195/200] [Batch 290/938] loss_G: 3.384402, loss_D: 0.205231\n",
      "[Epoch 195/200] [Batch 300/938] loss_G: 3.527576, loss_D: 0.102288\n",
      "[Epoch 195/200] [Batch 310/938] loss_G: 3.437471, loss_D: 0.218926\n",
      "[Epoch 195/200] [Batch 320/938] loss_G: 3.260760, loss_D: 0.310197\n",
      "[Epoch 195/200] [Batch 330/938] loss_G: 3.112520, loss_D: 0.115993\n",
      "[Epoch 195/200] [Batch 340/938] loss_G: 3.299156, loss_D: 0.180192\n",
      "[Epoch 195/200] [Batch 350/938] loss_G: 2.945697, loss_D: 0.228791\n",
      "[Epoch 195/200] [Batch 360/938] loss_G: 3.418040, loss_D: 0.130062\n",
      "[Epoch 195/200] [Batch 370/938] loss_G: 3.381656, loss_D: 0.168242\n",
      "[Epoch 195/200] [Batch 380/938] loss_G: 3.642727, loss_D: 0.134258\n",
      "[Epoch 195/200] [Batch 390/938] loss_G: 3.718505, loss_D: 0.103148\n",
      "[Epoch 195/200] [Batch 400/938] loss_G: 3.523473, loss_D: 0.107763\n",
      "[Epoch 195/200] [Batch 410/938] loss_G: 3.767663, loss_D: 0.180391\n",
      "[Epoch 195/200] [Batch 420/938] loss_G: 3.163455, loss_D: 0.233979\n",
      "[Epoch 195/200] [Batch 430/938] loss_G: 3.480834, loss_D: 0.148333\n",
      "[Epoch 195/200] [Batch 440/938] loss_G: 3.539747, loss_D: 0.275580\n",
      "[Epoch 195/200] [Batch 450/938] loss_G: 3.209037, loss_D: 0.265390\n",
      "[Epoch 195/200] [Batch 460/938] loss_G: 3.412400, loss_D: 0.172120\n",
      "[Epoch 195/200] [Batch 470/938] loss_G: 3.710930, loss_D: 0.199817\n",
      "[Epoch 195/200] [Batch 480/938] loss_G: 3.186772, loss_D: 0.230101\n",
      "[Epoch 195/200] [Batch 490/938] loss_G: 3.638497, loss_D: 0.199180\n",
      "[Epoch 195/200] [Batch 500/938] loss_G: 2.895853, loss_D: 0.134478\n",
      "[Epoch 195/200] [Batch 510/938] loss_G: 3.751645, loss_D: 0.185106\n",
      "[Epoch 195/200] [Batch 520/938] loss_G: 3.720499, loss_D: 0.182793\n",
      "[Epoch 195/200] [Batch 530/938] loss_G: 3.716892, loss_D: 0.164536\n",
      "[Epoch 195/200] [Batch 540/938] loss_G: 3.361391, loss_D: 0.248332\n",
      "[Epoch 195/200] [Batch 550/938] loss_G: 3.270135, loss_D: 0.206685\n",
      "[Epoch 195/200] [Batch 560/938] loss_G: 3.661973, loss_D: 0.296927\n",
      "[Epoch 195/200] [Batch 570/938] loss_G: 3.607316, loss_D: 0.164104\n",
      "[Epoch 195/200] [Batch 580/938] loss_G: 2.910219, loss_D: 0.176241\n",
      "[Epoch 195/200] [Batch 590/938] loss_G: 3.840230, loss_D: 0.228051\n",
      "[Epoch 195/200] [Batch 600/938] loss_G: 3.427351, loss_D: 0.218196\n",
      "[Epoch 195/200] [Batch 610/938] loss_G: 3.170787, loss_D: 0.125135\n",
      "[Epoch 195/200] [Batch 620/938] loss_G: 3.534869, loss_D: 0.169091\n",
      "[Epoch 195/200] [Batch 630/938] loss_G: 3.338408, loss_D: 0.205729\n",
      "[Epoch 195/200] [Batch 640/938] loss_G: 3.781853, loss_D: 0.160792\n",
      "[Epoch 195/200] [Batch 650/938] loss_G: 3.559083, loss_D: 0.132670\n",
      "[Epoch 195/200] [Batch 660/938] loss_G: 3.051882, loss_D: 0.203535\n",
      "[Epoch 195/200] [Batch 670/938] loss_G: 3.415522, loss_D: 0.209942\n",
      "[Epoch 195/200] [Batch 680/938] loss_G: 3.964880, loss_D: 0.172495\n",
      "[Epoch 195/200] [Batch 690/938] loss_G: 3.759902, loss_D: 0.214724\n",
      "[Epoch 195/200] [Batch 700/938] loss_G: 3.563131, loss_D: 0.154630\n",
      "[Epoch 195/200] [Batch 710/938] loss_G: 3.577784, loss_D: 0.183816\n",
      "[Epoch 195/200] [Batch 720/938] loss_G: 3.782601, loss_D: 0.115819\n",
      "[Epoch 195/200] [Batch 730/938] loss_G: 3.484493, loss_D: 0.190223\n",
      "[Epoch 195/200] [Batch 740/938] loss_G: 3.774219, loss_D: 0.143145\n",
      "[Epoch 195/200] [Batch 750/938] loss_G: 3.848771, loss_D: 0.119292\n",
      "[Epoch 195/200] [Batch 760/938] loss_G: 3.690186, loss_D: 0.128438\n",
      "[Epoch 195/200] [Batch 770/938] loss_G: 3.173654, loss_D: 0.203650\n",
      "[Epoch 195/200] [Batch 780/938] loss_G: 3.118176, loss_D: 0.125540\n",
      "[Epoch 195/200] [Batch 790/938] loss_G: 3.330923, loss_D: 0.177514\n",
      "[Epoch 195/200] [Batch 800/938] loss_G: 3.621811, loss_D: 0.124378\n",
      "[Epoch 195/200] [Batch 810/938] loss_G: 2.908129, loss_D: 0.219036\n",
      "[Epoch 195/200] [Batch 820/938] loss_G: 3.464716, loss_D: 0.231801\n",
      "[Epoch 195/200] [Batch 830/938] loss_G: 3.450989, loss_D: 0.132800\n",
      "[Epoch 195/200] [Batch 840/938] loss_G: 3.772194, loss_D: 0.197918\n",
      "[Epoch 195/200] [Batch 850/938] loss_G: 3.409799, loss_D: 0.188140\n",
      "[Epoch 195/200] [Batch 860/938] loss_G: 3.705062, loss_D: 0.189908\n",
      "[Epoch 195/200] [Batch 870/938] loss_G: 3.457301, loss_D: 0.209462\n",
      "[Epoch 195/200] [Batch 880/938] loss_G: 3.313441, loss_D: 0.107040\n",
      "[Epoch 195/200] [Batch 890/938] loss_G: 3.638894, loss_D: 0.187245\n",
      "[Epoch 195/200] [Batch 900/938] loss_G: 3.546436, loss_D: 0.231278\n",
      "[Epoch 195/200] [Batch 910/938] loss_G: 3.313352, loss_D: 0.184465\n",
      "[Epoch 195/200] [Batch 920/938] loss_G: 3.417898, loss_D: 0.186013\n",
      "[Epoch 195/200] [Batch 930/938] loss_G: 3.581525, loss_D: 0.215153\n",
      "[Epoch 196/200] [Batch 0/938] loss_G: 3.180933, loss_D: 0.191868\n",
      "[Epoch 196/200] [Batch 10/938] loss_G: 3.802270, loss_D: 0.176338\n",
      "[Epoch 196/200] [Batch 20/938] loss_G: 3.933484, loss_D: 0.150429\n",
      "[Epoch 196/200] [Batch 30/938] loss_G: 3.339242, loss_D: 0.203014\n",
      "[Epoch 196/200] [Batch 40/938] loss_G: 3.498218, loss_D: 0.250640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 196/200] [Batch 50/938] loss_G: 3.146604, loss_D: 0.178385\n",
      "[Epoch 196/200] [Batch 60/938] loss_G: 3.199115, loss_D: 0.202298\n",
      "[Epoch 196/200] [Batch 70/938] loss_G: 3.084610, loss_D: 0.176707\n",
      "[Epoch 196/200] [Batch 80/938] loss_G: 3.293777, loss_D: 0.238409\n",
      "[Epoch 196/200] [Batch 90/938] loss_G: 3.881027, loss_D: 0.166104\n",
      "[Epoch 196/200] [Batch 100/938] loss_G: 3.213983, loss_D: 0.198888\n",
      "[Epoch 196/200] [Batch 110/938] loss_G: 3.772644, loss_D: 0.211377\n",
      "[Epoch 196/200] [Batch 120/938] loss_G: 3.090692, loss_D: 0.256059\n",
      "[Epoch 196/200] [Batch 130/938] loss_G: 3.430121, loss_D: 0.168899\n",
      "[Epoch 196/200] [Batch 140/938] loss_G: 2.986629, loss_D: 0.274920\n",
      "[Epoch 196/200] [Batch 150/938] loss_G: 3.602744, loss_D: 0.241603\n",
      "[Epoch 196/200] [Batch 160/938] loss_G: 3.440334, loss_D: 0.213265\n",
      "[Epoch 196/200] [Batch 170/938] loss_G: 3.728793, loss_D: 0.188490\n",
      "[Epoch 196/200] [Batch 180/938] loss_G: 3.270725, loss_D: 0.146978\n",
      "[Epoch 196/200] [Batch 190/938] loss_G: 3.849967, loss_D: 0.189926\n",
      "[Epoch 196/200] [Batch 200/938] loss_G: 3.593591, loss_D: 0.180446\n",
      "[Epoch 196/200] [Batch 210/938] loss_G: 3.744353, loss_D: 0.142004\n",
      "[Epoch 196/200] [Batch 220/938] loss_G: 2.879767, loss_D: 0.176522\n",
      "[Epoch 196/200] [Batch 230/938] loss_G: 3.377333, loss_D: 0.204571\n",
      "[Epoch 196/200] [Batch 240/938] loss_G: 3.800167, loss_D: 0.172375\n",
      "[Epoch 196/200] [Batch 250/938] loss_G: 3.536874, loss_D: 0.172901\n",
      "[Epoch 196/200] [Batch 260/938] loss_G: 3.332812, loss_D: 0.218679\n",
      "[Epoch 196/200] [Batch 270/938] loss_G: 3.583433, loss_D: 0.233174\n",
      "[Epoch 196/200] [Batch 280/938] loss_G: 3.062635, loss_D: 0.286518\n",
      "[Epoch 196/200] [Batch 290/938] loss_G: 3.738091, loss_D: 0.222487\n",
      "[Epoch 196/200] [Batch 300/938] loss_G: 3.363536, loss_D: 0.200479\n",
      "[Epoch 196/200] [Batch 310/938] loss_G: 3.685899, loss_D: 0.168969\n",
      "[Epoch 196/200] [Batch 320/938] loss_G: 3.183982, loss_D: 0.192601\n",
      "[Epoch 196/200] [Batch 330/938] loss_G: 3.638397, loss_D: 0.145635\n",
      "[Epoch 196/200] [Batch 340/938] loss_G: 3.141144, loss_D: 0.172307\n",
      "[Epoch 196/200] [Batch 350/938] loss_G: 3.327666, loss_D: 0.142844\n",
      "[Epoch 196/200] [Batch 360/938] loss_G: 2.932717, loss_D: 0.237735\n",
      "[Epoch 196/200] [Batch 370/938] loss_G: 3.625052, loss_D: 0.113572\n",
      "[Epoch 196/200] [Batch 380/938] loss_G: 3.514586, loss_D: 0.214278\n",
      "[Epoch 196/200] [Batch 390/938] loss_G: 3.641632, loss_D: 0.218202\n",
      "[Epoch 196/200] [Batch 400/938] loss_G: 3.949884, loss_D: 0.129952\n",
      "[Epoch 196/200] [Batch 410/938] loss_G: 3.690439, loss_D: 0.170497\n",
      "[Epoch 196/200] [Batch 420/938] loss_G: 3.434218, loss_D: 0.156049\n",
      "[Epoch 196/200] [Batch 430/938] loss_G: 3.291448, loss_D: 0.195441\n",
      "[Epoch 196/200] [Batch 440/938] loss_G: 3.106104, loss_D: 0.183551\n",
      "[Epoch 196/200] [Batch 450/938] loss_G: 3.613371, loss_D: 0.139216\n",
      "[Epoch 196/200] [Batch 460/938] loss_G: 3.766595, loss_D: 0.247522\n",
      "[Epoch 196/200] [Batch 470/938] loss_G: 3.413109, loss_D: 0.167558\n",
      "[Epoch 196/200] [Batch 480/938] loss_G: 3.667262, loss_D: 0.257614\n",
      "[Epoch 196/200] [Batch 490/938] loss_G: 3.561327, loss_D: 0.241668\n",
      "[Epoch 196/200] [Batch 500/938] loss_G: 2.851300, loss_D: 0.163166\n",
      "[Epoch 196/200] [Batch 510/938] loss_G: 3.373568, loss_D: 0.191693\n",
      "[Epoch 196/200] [Batch 520/938] loss_G: 3.416182, loss_D: 0.120172\n",
      "[Epoch 196/200] [Batch 530/938] loss_G: 3.669160, loss_D: 0.202533\n",
      "[Epoch 196/200] [Batch 540/938] loss_G: 3.369650, loss_D: 0.163181\n",
      "[Epoch 196/200] [Batch 550/938] loss_G: 3.320487, loss_D: 0.195776\n",
      "[Epoch 196/200] [Batch 560/938] loss_G: 3.237034, loss_D: 0.192005\n",
      "[Epoch 196/200] [Batch 570/938] loss_G: 3.076704, loss_D: 0.279287\n",
      "[Epoch 196/200] [Batch 580/938] loss_G: 3.343273, loss_D: 0.129458\n",
      "[Epoch 196/200] [Batch 590/938] loss_G: 3.342853, loss_D: 0.204662\n",
      "[Epoch 196/200] [Batch 600/938] loss_G: 3.105757, loss_D: 0.160664\n",
      "[Epoch 196/200] [Batch 610/938] loss_G: 3.307252, loss_D: 0.192052\n",
      "[Epoch 196/200] [Batch 620/938] loss_G: 3.033504, loss_D: 0.170434\n",
      "[Epoch 196/200] [Batch 630/938] loss_G: 3.571903, loss_D: 0.219361\n",
      "[Epoch 196/200] [Batch 640/938] loss_G: 3.680192, loss_D: 0.196401\n",
      "[Epoch 196/200] [Batch 650/938] loss_G: 3.899906, loss_D: 0.212888\n",
      "[Epoch 196/200] [Batch 660/938] loss_G: 3.463502, loss_D: 0.200582\n",
      "[Epoch 196/200] [Batch 670/938] loss_G: 3.508148, loss_D: 0.197781\n",
      "[Epoch 196/200] [Batch 680/938] loss_G: 3.184976, loss_D: 0.164791\n",
      "[Epoch 196/200] [Batch 690/938] loss_G: 3.216895, loss_D: 0.170231\n",
      "[Epoch 196/200] [Batch 700/938] loss_G: 3.139719, loss_D: 0.204076\n",
      "[Epoch 196/200] [Batch 710/938] loss_G: 3.494686, loss_D: 0.231091\n",
      "[Epoch 196/200] [Batch 720/938] loss_G: 3.192787, loss_D: 0.130122\n",
      "[Epoch 196/200] [Batch 730/938] loss_G: 4.143415, loss_D: 0.122701\n",
      "[Epoch 196/200] [Batch 740/938] loss_G: 3.930510, loss_D: 0.188319\n",
      "[Epoch 196/200] [Batch 750/938] loss_G: 3.385611, loss_D: 0.144688\n",
      "[Epoch 196/200] [Batch 760/938] loss_G: 3.539817, loss_D: 0.164759\n",
      "[Epoch 196/200] [Batch 770/938] loss_G: 3.315130, loss_D: 0.114194\n",
      "[Epoch 196/200] [Batch 780/938] loss_G: 2.992888, loss_D: 0.159657\n",
      "[Epoch 196/200] [Batch 790/938] loss_G: 3.258896, loss_D: 0.123969\n",
      "[Epoch 196/200] [Batch 800/938] loss_G: 3.471461, loss_D: 0.154948\n",
      "[Epoch 196/200] [Batch 810/938] loss_G: 3.398616, loss_D: 0.182621\n",
      "[Epoch 196/200] [Batch 820/938] loss_G: 3.753789, loss_D: 0.232248\n",
      "[Epoch 196/200] [Batch 830/938] loss_G: 3.442976, loss_D: 0.196685\n",
      "[Epoch 196/200] [Batch 840/938] loss_G: 3.351301, loss_D: 0.203572\n",
      "[Epoch 196/200] [Batch 850/938] loss_G: 3.642755, loss_D: 0.164708\n",
      "[Epoch 196/200] [Batch 860/938] loss_G: 3.412785, loss_D: 0.312005\n",
      "[Epoch 196/200] [Batch 870/938] loss_G: 3.462487, loss_D: 0.171001\n",
      "[Epoch 196/200] [Batch 880/938] loss_G: 3.204746, loss_D: 0.149344\n",
      "[Epoch 196/200] [Batch 890/938] loss_G: 3.254991, loss_D: 0.147077\n",
      "[Epoch 196/200] [Batch 900/938] loss_G: 3.261013, loss_D: 0.109247\n",
      "[Epoch 196/200] [Batch 910/938] loss_G: 3.900830, loss_D: 0.132728\n",
      "[Epoch 196/200] [Batch 920/938] loss_G: 3.290315, loss_D: 0.178709\n",
      "[Epoch 196/200] [Batch 930/938] loss_G: 3.590954, loss_D: 0.140816\n",
      "[Epoch 197/200] [Batch 0/938] loss_G: 3.558997, loss_D: 0.286870\n",
      "[Epoch 197/200] [Batch 10/938] loss_G: 3.251836, loss_D: 0.174595\n",
      "[Epoch 197/200] [Batch 20/938] loss_G: 3.577104, loss_D: 0.262822\n",
      "[Epoch 197/200] [Batch 30/938] loss_G: 3.567676, loss_D: 0.087137\n",
      "[Epoch 197/200] [Batch 40/938] loss_G: 3.271177, loss_D: 0.142720\n",
      "[Epoch 197/200] [Batch 50/938] loss_G: 3.341859, loss_D: 0.231019\n",
      "[Epoch 197/200] [Batch 60/938] loss_G: 3.195756, loss_D: 0.296919\n",
      "[Epoch 197/200] [Batch 70/938] loss_G: 3.661382, loss_D: 0.154810\n",
      "[Epoch 197/200] [Batch 80/938] loss_G: 3.230393, loss_D: 0.174698\n",
      "[Epoch 197/200] [Batch 90/938] loss_G: 3.708347, loss_D: 0.195879\n",
      "[Epoch 197/200] [Batch 100/938] loss_G: 2.969306, loss_D: 0.258174\n",
      "[Epoch 197/200] [Batch 110/938] loss_G: 3.824046, loss_D: 0.191353\n",
      "[Epoch 197/200] [Batch 120/938] loss_G: 3.381154, loss_D: 0.149911\n",
      "[Epoch 197/200] [Batch 130/938] loss_G: 3.838797, loss_D: 0.163306\n",
      "[Epoch 197/200] [Batch 140/938] loss_G: 3.670216, loss_D: 0.063709\n",
      "[Epoch 197/200] [Batch 150/938] loss_G: 3.364982, loss_D: 0.173361\n",
      "[Epoch 197/200] [Batch 160/938] loss_G: 3.651136, loss_D: 0.149800\n",
      "[Epoch 197/200] [Batch 170/938] loss_G: 3.545790, loss_D: 0.144819\n",
      "[Epoch 197/200] [Batch 180/938] loss_G: 3.605647, loss_D: 0.127765\n",
      "[Epoch 197/200] [Batch 190/938] loss_G: 3.545011, loss_D: 0.192805\n",
      "[Epoch 197/200] [Batch 200/938] loss_G: 3.736805, loss_D: 0.132658\n",
      "[Epoch 197/200] [Batch 210/938] loss_G: 3.212018, loss_D: 0.183051\n",
      "[Epoch 197/200] [Batch 220/938] loss_G: 3.578983, loss_D: 0.220780\n",
      "[Epoch 197/200] [Batch 230/938] loss_G: 3.870718, loss_D: 0.195235\n",
      "[Epoch 197/200] [Batch 240/938] loss_G: 3.348605, loss_D: 0.143802\n",
      "[Epoch 197/200] [Batch 250/938] loss_G: 3.377710, loss_D: 0.163104\n",
      "[Epoch 197/200] [Batch 260/938] loss_G: 3.357410, loss_D: 0.180890\n",
      "[Epoch 197/200] [Batch 270/938] loss_G: 3.461017, loss_D: 0.220084\n",
      "[Epoch 197/200] [Batch 280/938] loss_G: 3.522542, loss_D: 0.182103\n",
      "[Epoch 197/200] [Batch 290/938] loss_G: 3.869550, loss_D: 0.204570\n",
      "[Epoch 197/200] [Batch 300/938] loss_G: 3.290016, loss_D: 0.145560\n",
      "[Epoch 197/200] [Batch 310/938] loss_G: 3.323447, loss_D: 0.190385\n",
      "[Epoch 197/200] [Batch 320/938] loss_G: 3.830662, loss_D: 0.176296\n",
      "[Epoch 197/200] [Batch 330/938] loss_G: 3.460204, loss_D: 0.139482\n",
      "[Epoch 197/200] [Batch 340/938] loss_G: 3.408813, loss_D: 0.147033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 197/200] [Batch 350/938] loss_G: 3.102276, loss_D: 0.160348\n",
      "[Epoch 197/200] [Batch 360/938] loss_G: 3.529895, loss_D: 0.190964\n",
      "[Epoch 197/200] [Batch 370/938] loss_G: 3.755826, loss_D: 0.125537\n",
      "[Epoch 197/200] [Batch 380/938] loss_G: 3.975010, loss_D: 0.222518\n",
      "[Epoch 197/200] [Batch 390/938] loss_G: 3.699988, loss_D: 0.153166\n",
      "[Epoch 197/200] [Batch 400/938] loss_G: 3.315371, loss_D: 0.217034\n",
      "[Epoch 197/200] [Batch 410/938] loss_G: 3.441695, loss_D: 0.206085\n",
      "[Epoch 197/200] [Batch 420/938] loss_G: 3.080096, loss_D: 0.227544\n",
      "[Epoch 197/200] [Batch 430/938] loss_G: 3.392873, loss_D: 0.123651\n",
      "[Epoch 197/200] [Batch 440/938] loss_G: 3.723815, loss_D: 0.213090\n",
      "[Epoch 197/200] [Batch 450/938] loss_G: 3.869333, loss_D: 0.180471\n",
      "[Epoch 197/200] [Batch 460/938] loss_G: 3.365731, loss_D: 0.111856\n",
      "[Epoch 197/200] [Batch 470/938] loss_G: 3.288754, loss_D: 0.169219\n",
      "[Epoch 197/200] [Batch 480/938] loss_G: 3.062784, loss_D: 0.224351\n",
      "[Epoch 197/200] [Batch 490/938] loss_G: 3.150296, loss_D: 0.170023\n",
      "[Epoch 197/200] [Batch 500/938] loss_G: 2.967131, loss_D: 0.176935\n",
      "[Epoch 197/200] [Batch 510/938] loss_G: 3.666281, loss_D: 0.195189\n",
      "[Epoch 197/200] [Batch 520/938] loss_G: 3.325552, loss_D: 0.085107\n",
      "[Epoch 197/200] [Batch 530/938] loss_G: 3.302421, loss_D: 0.181687\n",
      "[Epoch 197/200] [Batch 540/938] loss_G: 3.412835, loss_D: 0.156086\n",
      "[Epoch 197/200] [Batch 550/938] loss_G: 3.401168, loss_D: 0.201477\n",
      "[Epoch 197/200] [Batch 560/938] loss_G: 3.524775, loss_D: 0.198947\n",
      "[Epoch 197/200] [Batch 570/938] loss_G: 3.077136, loss_D: 0.151212\n",
      "[Epoch 197/200] [Batch 580/938] loss_G: 3.615590, loss_D: 0.207918\n",
      "[Epoch 197/200] [Batch 590/938] loss_G: 3.419660, loss_D: 0.123724\n",
      "[Epoch 197/200] [Batch 600/938] loss_G: 3.379876, loss_D: 0.099486\n",
      "[Epoch 197/200] [Batch 610/938] loss_G: 3.150030, loss_D: 0.168170\n",
      "[Epoch 197/200] [Batch 620/938] loss_G: 3.506956, loss_D: 0.167433\n",
      "[Epoch 197/200] [Batch 630/938] loss_G: 3.601480, loss_D: 0.157860\n",
      "[Epoch 197/200] [Batch 640/938] loss_G: 3.391310, loss_D: 0.151647\n",
      "[Epoch 197/200] [Batch 650/938] loss_G: 3.353097, loss_D: 0.140160\n",
      "[Epoch 197/200] [Batch 660/938] loss_G: 3.389833, loss_D: 0.175839\n",
      "[Epoch 197/200] [Batch 670/938] loss_G: 3.688790, loss_D: 0.182657\n",
      "[Epoch 197/200] [Batch 680/938] loss_G: 3.057610, loss_D: 0.147612\n",
      "[Epoch 197/200] [Batch 690/938] loss_G: 3.555133, loss_D: 0.145398\n",
      "[Epoch 197/200] [Batch 700/938] loss_G: 3.687649, loss_D: 0.162942\n",
      "[Epoch 197/200] [Batch 710/938] loss_G: 3.615135, loss_D: 0.191309\n",
      "[Epoch 197/200] [Batch 720/938] loss_G: 3.361522, loss_D: 0.263012\n",
      "[Epoch 197/200] [Batch 730/938] loss_G: 3.339158, loss_D: 0.187231\n",
      "[Epoch 197/200] [Batch 740/938] loss_G: 3.571925, loss_D: 0.141173\n",
      "[Epoch 197/200] [Batch 750/938] loss_G: 3.533903, loss_D: 0.179522\n",
      "[Epoch 197/200] [Batch 760/938] loss_G: 3.469989, loss_D: 0.132047\n",
      "[Epoch 197/200] [Batch 770/938] loss_G: 3.346933, loss_D: 0.223980\n",
      "[Epoch 197/200] [Batch 780/938] loss_G: 3.244522, loss_D: 0.182543\n",
      "[Epoch 197/200] [Batch 790/938] loss_G: 3.347100, loss_D: 0.185985\n",
      "[Epoch 197/200] [Batch 800/938] loss_G: 3.563193, loss_D: 0.118961\n",
      "[Epoch 197/200] [Batch 810/938] loss_G: 3.835804, loss_D: 0.150426\n",
      "[Epoch 197/200] [Batch 820/938] loss_G: 3.275900, loss_D: 0.143205\n",
      "[Epoch 197/200] [Batch 830/938] loss_G: 3.380552, loss_D: 0.142351\n",
      "[Epoch 197/200] [Batch 840/938] loss_G: 3.178121, loss_D: 0.154256\n",
      "[Epoch 197/200] [Batch 850/938] loss_G: 3.040402, loss_D: 0.198456\n",
      "[Epoch 197/200] [Batch 860/938] loss_G: 3.211352, loss_D: 0.193963\n",
      "[Epoch 197/200] [Batch 870/938] loss_G: 3.640837, loss_D: 0.159078\n",
      "[Epoch 197/200] [Batch 880/938] loss_G: 3.487186, loss_D: 0.196232\n",
      "[Epoch 197/200] [Batch 890/938] loss_G: 3.168523, loss_D: 0.136077\n",
      "[Epoch 197/200] [Batch 900/938] loss_G: 3.375643, loss_D: 0.153942\n",
      "[Epoch 197/200] [Batch 910/938] loss_G: 3.099002, loss_D: 0.176381\n",
      "[Epoch 197/200] [Batch 920/938] loss_G: 3.486286, loss_D: 0.082395\n",
      "[Epoch 197/200] [Batch 930/938] loss_G: 3.714685, loss_D: 0.207410\n",
      "[Epoch 198/200] [Batch 0/938] loss_G: 3.298882, loss_D: 0.225320\n",
      "[Epoch 198/200] [Batch 10/938] loss_G: 3.299575, loss_D: 0.241530\n",
      "[Epoch 198/200] [Batch 20/938] loss_G: 3.209999, loss_D: 0.253902\n",
      "[Epoch 198/200] [Batch 30/938] loss_G: 3.614578, loss_D: 0.237117\n",
      "[Epoch 198/200] [Batch 40/938] loss_G: 3.627901, loss_D: 0.177759\n",
      "[Epoch 198/200] [Batch 50/938] loss_G: 3.433886, loss_D: 0.163797\n",
      "[Epoch 198/200] [Batch 60/938] loss_G: 3.435420, loss_D: 0.191049\n",
      "[Epoch 198/200] [Batch 70/938] loss_G: 3.743059, loss_D: 0.168594\n",
      "[Epoch 198/200] [Batch 80/938] loss_G: 3.243942, loss_D: 0.178285\n",
      "[Epoch 198/200] [Batch 90/938] loss_G: 3.352831, loss_D: 0.204732\n",
      "[Epoch 198/200] [Batch 100/938] loss_G: 3.597941, loss_D: 0.198632\n",
      "[Epoch 198/200] [Batch 110/938] loss_G: 3.082527, loss_D: 0.265216\n",
      "[Epoch 198/200] [Batch 120/938] loss_G: 3.592700, loss_D: 0.175776\n",
      "[Epoch 198/200] [Batch 130/938] loss_G: 3.641175, loss_D: 0.183152\n",
      "[Epoch 198/200] [Batch 140/938] loss_G: 3.580304, loss_D: 0.192842\n",
      "[Epoch 198/200] [Batch 150/938] loss_G: 3.621060, loss_D: 0.140890\n",
      "[Epoch 198/200] [Batch 160/938] loss_G: 3.197107, loss_D: 0.193114\n",
      "[Epoch 198/200] [Batch 170/938] loss_G: 3.536404, loss_D: 0.217381\n",
      "[Epoch 198/200] [Batch 180/938] loss_G: 3.104542, loss_D: 0.177314\n",
      "[Epoch 198/200] [Batch 190/938] loss_G: 3.220259, loss_D: 0.229385\n",
      "[Epoch 198/200] [Batch 200/938] loss_G: 3.668542, loss_D: 0.194683\n",
      "[Epoch 198/200] [Batch 210/938] loss_G: 3.519526, loss_D: 0.201637\n",
      "[Epoch 198/200] [Batch 220/938] loss_G: 3.471020, loss_D: 0.218592\n",
      "[Epoch 198/200] [Batch 230/938] loss_G: 3.353440, loss_D: 0.176189\n",
      "[Epoch 198/200] [Batch 240/938] loss_G: 3.395366, loss_D: 0.133602\n",
      "[Epoch 198/200] [Batch 250/938] loss_G: 3.432579, loss_D: 0.155818\n",
      "[Epoch 198/200] [Batch 260/938] loss_G: 3.879602, loss_D: 0.108902\n",
      "[Epoch 198/200] [Batch 270/938] loss_G: 3.504402, loss_D: 0.149544\n",
      "[Epoch 198/200] [Batch 280/938] loss_G: 3.124157, loss_D: 0.122159\n",
      "[Epoch 198/200] [Batch 290/938] loss_G: 3.500673, loss_D: 0.169133\n",
      "[Epoch 198/200] [Batch 300/938] loss_G: 3.515957, loss_D: 0.180843\n",
      "[Epoch 198/200] [Batch 310/938] loss_G: 3.475166, loss_D: 0.217872\n",
      "[Epoch 198/200] [Batch 320/938] loss_G: 3.131462, loss_D: 0.249880\n",
      "[Epoch 198/200] [Batch 330/938] loss_G: 3.707931, loss_D: 0.178323\n",
      "[Epoch 198/200] [Batch 340/938] loss_G: 3.471978, loss_D: 0.177563\n",
      "[Epoch 198/200] [Batch 350/938] loss_G: 3.519945, loss_D: 0.233335\n",
      "[Epoch 198/200] [Batch 360/938] loss_G: 3.457163, loss_D: 0.140345\n",
      "[Epoch 198/200] [Batch 370/938] loss_G: 3.563414, loss_D: 0.163272\n",
      "[Epoch 198/200] [Batch 380/938] loss_G: 2.874083, loss_D: 0.226676\n",
      "[Epoch 198/200] [Batch 390/938] loss_G: 3.628074, loss_D: 0.178970\n",
      "[Epoch 198/200] [Batch 400/938] loss_G: 3.788785, loss_D: 0.156044\n",
      "[Epoch 198/200] [Batch 410/938] loss_G: 3.220904, loss_D: 0.120693\n",
      "[Epoch 198/200] [Batch 420/938] loss_G: 3.804996, loss_D: 0.148087\n",
      "[Epoch 198/200] [Batch 430/938] loss_G: 3.578170, loss_D: 0.090902\n",
      "[Epoch 198/200] [Batch 440/938] loss_G: 3.425597, loss_D: 0.181707\n",
      "[Epoch 198/200] [Batch 450/938] loss_G: 3.582778, loss_D: 0.176227\n",
      "[Epoch 198/200] [Batch 460/938] loss_G: 3.056753, loss_D: 0.128793\n",
      "[Epoch 198/200] [Batch 470/938] loss_G: 3.608684, loss_D: 0.153336\n",
      "[Epoch 198/200] [Batch 480/938] loss_G: 3.525927, loss_D: 0.062849\n",
      "[Epoch 198/200] [Batch 490/938] loss_G: 3.599113, loss_D: 0.093272\n",
      "[Epoch 198/200] [Batch 500/938] loss_G: 3.422885, loss_D: 0.165556\n",
      "[Epoch 198/200] [Batch 510/938] loss_G: 3.683797, loss_D: 0.206028\n",
      "[Epoch 198/200] [Batch 520/938] loss_G: 3.305345, loss_D: 0.222536\n",
      "[Epoch 198/200] [Batch 530/938] loss_G: 3.503413, loss_D: 0.158017\n",
      "[Epoch 198/200] [Batch 540/938] loss_G: 3.571716, loss_D: 0.184570\n",
      "[Epoch 198/200] [Batch 550/938] loss_G: 3.771174, loss_D: 0.112699\n",
      "[Epoch 198/200] [Batch 560/938] loss_G: 3.299585, loss_D: 0.217379\n",
      "[Epoch 198/200] [Batch 570/938] loss_G: 3.620203, loss_D: 0.161722\n",
      "[Epoch 198/200] [Batch 580/938] loss_G: 3.674950, loss_D: 0.178232\n",
      "[Epoch 198/200] [Batch 590/938] loss_G: 3.707450, loss_D: 0.186647\n",
      "[Epoch 198/200] [Batch 600/938] loss_G: 3.528610, loss_D: 0.120988\n",
      "[Epoch 198/200] [Batch 610/938] loss_G: 3.961920, loss_D: 0.131532\n",
      "[Epoch 198/200] [Batch 620/938] loss_G: 3.372907, loss_D: 0.203191\n",
      "[Epoch 198/200] [Batch 630/938] loss_G: 3.033304, loss_D: 0.194810\n",
      "[Epoch 198/200] [Batch 640/938] loss_G: 3.722267, loss_D: 0.160080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 198/200] [Batch 650/938] loss_G: 3.647736, loss_D: 0.154087\n",
      "[Epoch 198/200] [Batch 660/938] loss_G: 3.199028, loss_D: 0.209850\n",
      "[Epoch 198/200] [Batch 670/938] loss_G: 3.534135, loss_D: 0.221587\n",
      "[Epoch 198/200] [Batch 680/938] loss_G: 3.435028, loss_D: 0.176940\n",
      "[Epoch 198/200] [Batch 690/938] loss_G: 2.944899, loss_D: 0.188782\n",
      "[Epoch 198/200] [Batch 700/938] loss_G: 3.745170, loss_D: 0.175557\n",
      "[Epoch 198/200] [Batch 710/938] loss_G: 3.457993, loss_D: 0.108702\n",
      "[Epoch 198/200] [Batch 720/938] loss_G: 3.590215, loss_D: 0.144117\n",
      "[Epoch 198/200] [Batch 730/938] loss_G: 3.312376, loss_D: 0.295888\n",
      "[Epoch 198/200] [Batch 740/938] loss_G: 3.325103, loss_D: 0.274796\n",
      "[Epoch 198/200] [Batch 750/938] loss_G: 3.141192, loss_D: 0.167283\n",
      "[Epoch 198/200] [Batch 760/938] loss_G: 2.783645, loss_D: 0.136105\n",
      "[Epoch 198/200] [Batch 770/938] loss_G: 3.413254, loss_D: 0.164644\n",
      "[Epoch 198/200] [Batch 780/938] loss_G: 3.641259, loss_D: 0.164923\n",
      "[Epoch 198/200] [Batch 790/938] loss_G: 3.701237, loss_D: 0.084065\n",
      "[Epoch 198/200] [Batch 800/938] loss_G: 3.678022, loss_D: 0.145098\n",
      "[Epoch 198/200] [Batch 810/938] loss_G: 3.482614, loss_D: 0.114516\n",
      "[Epoch 198/200] [Batch 820/938] loss_G: 3.171283, loss_D: 0.171706\n",
      "[Epoch 198/200] [Batch 830/938] loss_G: 3.272486, loss_D: 0.174804\n",
      "[Epoch 198/200] [Batch 840/938] loss_G: 2.770602, loss_D: 0.178991\n",
      "[Epoch 198/200] [Batch 850/938] loss_G: 3.527790, loss_D: 0.190400\n",
      "[Epoch 198/200] [Batch 860/938] loss_G: 3.427456, loss_D: 0.288046\n",
      "[Epoch 198/200] [Batch 870/938] loss_G: 3.702950, loss_D: 0.156115\n",
      "[Epoch 198/200] [Batch 880/938] loss_G: 3.729937, loss_D: 0.219638\n",
      "[Epoch 198/200] [Batch 890/938] loss_G: 3.543347, loss_D: 0.107497\n",
      "[Epoch 198/200] [Batch 900/938] loss_G: 3.369483, loss_D: 0.222097\n",
      "[Epoch 198/200] [Batch 910/938] loss_G: 3.430663, loss_D: 0.198727\n",
      "[Epoch 198/200] [Batch 920/938] loss_G: 3.335403, loss_D: 0.161784\n",
      "[Epoch 198/200] [Batch 930/938] loss_G: 3.487678, loss_D: 0.219369\n",
      "[Epoch 199/200] [Batch 0/938] loss_G: 2.879373, loss_D: 0.169159\n",
      "[Epoch 199/200] [Batch 10/938] loss_G: 3.187427, loss_D: 0.159230\n",
      "[Epoch 199/200] [Batch 20/938] loss_G: 4.004900, loss_D: 0.268590\n",
      "[Epoch 199/200] [Batch 30/938] loss_G: 3.567137, loss_D: 0.180671\n",
      "[Epoch 199/200] [Batch 40/938] loss_G: 3.514284, loss_D: 0.221288\n",
      "[Epoch 199/200] [Batch 50/938] loss_G: 3.595171, loss_D: 0.152730\n",
      "[Epoch 199/200] [Batch 60/938] loss_G: 3.373599, loss_D: 0.131343\n",
      "[Epoch 199/200] [Batch 70/938] loss_G: 3.571150, loss_D: 0.169020\n",
      "[Epoch 199/200] [Batch 80/938] loss_G: 3.058009, loss_D: 0.159309\n",
      "[Epoch 199/200] [Batch 90/938] loss_G: 3.015978, loss_D: 0.235573\n",
      "[Epoch 199/200] [Batch 100/938] loss_G: 3.411095, loss_D: 0.229170\n",
      "[Epoch 199/200] [Batch 110/938] loss_G: 3.714186, loss_D: 0.166238\n",
      "[Epoch 199/200] [Batch 120/938] loss_G: 3.487820, loss_D: 0.167800\n",
      "[Epoch 199/200] [Batch 130/938] loss_G: 3.450625, loss_D: 0.188936\n",
      "[Epoch 199/200] [Batch 140/938] loss_G: 3.380167, loss_D: 0.131573\n",
      "[Epoch 199/200] [Batch 150/938] loss_G: 3.553941, loss_D: 0.132094\n",
      "[Epoch 199/200] [Batch 160/938] loss_G: 3.712842, loss_D: 0.155062\n",
      "[Epoch 199/200] [Batch 170/938] loss_G: 3.534974, loss_D: 0.185815\n",
      "[Epoch 199/200] [Batch 180/938] loss_G: 3.734102, loss_D: 0.208395\n",
      "[Epoch 199/200] [Batch 190/938] loss_G: 3.561588, loss_D: 0.091927\n",
      "[Epoch 199/200] [Batch 200/938] loss_G: 3.345615, loss_D: 0.269589\n",
      "[Epoch 199/200] [Batch 210/938] loss_G: 3.423262, loss_D: 0.236342\n",
      "[Epoch 199/200] [Batch 220/938] loss_G: 3.867271, loss_D: 0.108473\n",
      "[Epoch 199/200] [Batch 230/938] loss_G: 3.397537, loss_D: 0.123791\n",
      "[Epoch 199/200] [Batch 240/938] loss_G: 3.300444, loss_D: 0.183271\n",
      "[Epoch 199/200] [Batch 250/938] loss_G: 3.181861, loss_D: 0.180489\n",
      "[Epoch 199/200] [Batch 260/938] loss_G: 3.389151, loss_D: 0.162609\n",
      "[Epoch 199/200] [Batch 270/938] loss_G: 3.890311, loss_D: 0.189554\n",
      "[Epoch 199/200] [Batch 280/938] loss_G: 3.575646, loss_D: 0.267582\n",
      "[Epoch 199/200] [Batch 290/938] loss_G: 3.308908, loss_D: 0.170345\n",
      "[Epoch 199/200] [Batch 300/938] loss_G: 3.554801, loss_D: 0.167290\n",
      "[Epoch 199/200] [Batch 310/938] loss_G: 3.499475, loss_D: 0.151208\n",
      "[Epoch 199/200] [Batch 320/938] loss_G: 3.511799, loss_D: 0.099598\n",
      "[Epoch 199/200] [Batch 330/938] loss_G: 3.931127, loss_D: 0.133112\n",
      "[Epoch 199/200] [Batch 340/938] loss_G: 3.604936, loss_D: 0.195647\n",
      "[Epoch 199/200] [Batch 350/938] loss_G: 3.808691, loss_D: 0.120686\n",
      "[Epoch 199/200] [Batch 360/938] loss_G: 3.165232, loss_D: 0.196828\n",
      "[Epoch 199/200] [Batch 370/938] loss_G: 3.518782, loss_D: 0.178535\n",
      "[Epoch 199/200] [Batch 380/938] loss_G: 3.233354, loss_D: 0.244308\n",
      "[Epoch 199/200] [Batch 390/938] loss_G: 3.264285, loss_D: 0.199140\n",
      "[Epoch 199/200] [Batch 400/938] loss_G: 3.489133, loss_D: 0.191050\n",
      "[Epoch 199/200] [Batch 410/938] loss_G: 3.407171, loss_D: 0.223379\n",
      "[Epoch 199/200] [Batch 420/938] loss_G: 3.742115, loss_D: 0.171321\n",
      "[Epoch 199/200] [Batch 430/938] loss_G: 3.613937, loss_D: 0.253193\n",
      "[Epoch 199/200] [Batch 440/938] loss_G: 3.973443, loss_D: 0.199051\n",
      "[Epoch 199/200] [Batch 450/938] loss_G: 3.564568, loss_D: 0.144389\n",
      "[Epoch 199/200] [Batch 460/938] loss_G: 3.566146, loss_D: 0.168619\n",
      "[Epoch 199/200] [Batch 470/938] loss_G: 3.664319, loss_D: 0.192796\n",
      "[Epoch 199/200] [Batch 480/938] loss_G: 3.191693, loss_D: 0.197506\n",
      "[Epoch 199/200] [Batch 490/938] loss_G: 3.654905, loss_D: 0.208935\n",
      "[Epoch 199/200] [Batch 500/938] loss_G: 3.574770, loss_D: 0.122171\n",
      "[Epoch 199/200] [Batch 510/938] loss_G: 3.045124, loss_D: 0.119157\n",
      "[Epoch 199/200] [Batch 520/938] loss_G: 3.244925, loss_D: 0.150053\n",
      "[Epoch 199/200] [Batch 530/938] loss_G: 3.241228, loss_D: 0.142024\n",
      "[Epoch 199/200] [Batch 540/938] loss_G: 3.230235, loss_D: 0.177539\n",
      "[Epoch 199/200] [Batch 550/938] loss_G: 3.004276, loss_D: 0.206556\n",
      "[Epoch 199/200] [Batch 560/938] loss_G: 3.443402, loss_D: 0.274324\n",
      "[Epoch 199/200] [Batch 570/938] loss_G: 3.041763, loss_D: 0.149733\n",
      "[Epoch 199/200] [Batch 580/938] loss_G: 3.298743, loss_D: 0.152386\n",
      "[Epoch 199/200] [Batch 590/938] loss_G: 3.075423, loss_D: 0.192587\n",
      "[Epoch 199/200] [Batch 600/938] loss_G: 3.559663, loss_D: 0.139820\n",
      "[Epoch 199/200] [Batch 610/938] loss_G: 3.339811, loss_D: 0.092135\n",
      "[Epoch 199/200] [Batch 620/938] loss_G: 3.536667, loss_D: 0.278987\n",
      "[Epoch 199/200] [Batch 630/938] loss_G: 3.251999, loss_D: 0.085332\n",
      "[Epoch 199/200] [Batch 640/938] loss_G: 3.905784, loss_D: 0.185504\n",
      "[Epoch 199/200] [Batch 650/938] loss_G: 3.352996, loss_D: 0.180814\n",
      "[Epoch 199/200] [Batch 660/938] loss_G: 3.451222, loss_D: 0.127601\n",
      "[Epoch 199/200] [Batch 670/938] loss_G: 4.040913, loss_D: 0.184766\n",
      "[Epoch 199/200] [Batch 680/938] loss_G: 3.791814, loss_D: 0.160973\n",
      "[Epoch 199/200] [Batch 690/938] loss_G: 3.228099, loss_D: 0.154064\n",
      "[Epoch 199/200] [Batch 700/938] loss_G: 3.222962, loss_D: 0.225971\n",
      "[Epoch 199/200] [Batch 710/938] loss_G: 3.118035, loss_D: 0.233207\n",
      "[Epoch 199/200] [Batch 720/938] loss_G: 3.868062, loss_D: 0.199723\n",
      "[Epoch 199/200] [Batch 730/938] loss_G: 2.943218, loss_D: 0.196446\n",
      "[Epoch 199/200] [Batch 740/938] loss_G: 3.385057, loss_D: 0.103827\n",
      "[Epoch 199/200] [Batch 750/938] loss_G: 3.462642, loss_D: 0.246248\n",
      "[Epoch 199/200] [Batch 760/938] loss_G: 3.443876, loss_D: 0.244556\n",
      "[Epoch 199/200] [Batch 770/938] loss_G: 3.900936, loss_D: 0.166520\n",
      "[Epoch 199/200] [Batch 780/938] loss_G: 3.029773, loss_D: 0.193256\n",
      "[Epoch 199/200] [Batch 790/938] loss_G: 3.511127, loss_D: 0.144114\n",
      "[Epoch 199/200] [Batch 800/938] loss_G: 3.290966, loss_D: 0.188538\n",
      "[Epoch 199/200] [Batch 810/938] loss_G: 3.372557, loss_D: 0.138685\n",
      "[Epoch 199/200] [Batch 820/938] loss_G: 3.347939, loss_D: 0.196084\n",
      "[Epoch 199/200] [Batch 830/938] loss_G: 3.590984, loss_D: 0.210321\n",
      "[Epoch 199/200] [Batch 840/938] loss_G: 3.279292, loss_D: 0.203716\n",
      "[Epoch 199/200] [Batch 850/938] loss_G: 3.669796, loss_D: 0.214487\n",
      "[Epoch 199/200] [Batch 860/938] loss_G: 3.420260, loss_D: 0.212793\n",
      "[Epoch 199/200] [Batch 870/938] loss_G: 3.869154, loss_D: 0.198635\n",
      "[Epoch 199/200] [Batch 880/938] loss_G: 3.241275, loss_D: 0.151279\n",
      "[Epoch 199/200] [Batch 890/938] loss_G: 3.124179, loss_D: 0.153596\n",
      "[Epoch 199/200] [Batch 900/938] loss_G: 3.769943, loss_D: 0.131024\n",
      "[Epoch 199/200] [Batch 910/938] loss_G: 3.365053, loss_D: 0.182886\n",
      "[Epoch 199/200] [Batch 920/938] loss_G: 3.289197, loss_D: 0.128745\n",
      "[Epoch 199/200] [Batch 930/938] loss_G: 3.861295, loss_D: 0.191810\n"
     ]
    }
   ],
   "source": [
    "for idx_epoch in range(num_epochs):\n",
    "    for idx_batch, (imgs, _) in enumerate(train_data_loader):\n",
    "        # Ground truth variables indicating real/fake\n",
    "        real_ground_truth = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "        fake_ground_truth = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False) \n",
    "        \n",
    "        # Real image\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "                \n",
    "        #####################\n",
    "        # Train Generator\n",
    "        \n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        # Random sample noise\n",
    "#         z = random_sample_z_space(imgs.size(0))\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], dim_noise))))\n",
    "                \n",
    "        # Generate image\n",
    "        gen_imgs = generator(z)\n",
    "        \n",
    "        # Generator's loss: loss between D(G(z)) and real ground truth\n",
    "        loss_G = adversarial_loss(discriminator(gen_imgs), real_ground_truth)\n",
    "        \n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        \n",
    "        #####################\n",
    "        # Train Discriminator\n",
    "        \n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        loss_real = adversarial_loss(discriminator(real_imgs), real_ground_truth)\n",
    "        loss_fake = adversarial_loss(discriminator(gen_imgs.detach()), fake_ground_truth)\n",
    "        loss_D = (loss_real+loss_fake)/2\n",
    "        \n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        \n",
    "        #####################\n",
    "        # Print progress\n",
    "        if idx_batch % 10 == 0:\n",
    "            print(\"[Epoch {}/{}] [Batch {}/{}] loss_G: {:.6f}, loss_D: {:.6f}\".format(idx_epoch, num_epochs,\n",
    "                                                                                      idx_batch, len(train_data_loader),\n",
    "                                                                                      loss_G, loss_D))\n",
    "                    \n",
    "        batches_done = idx_epoch * len(train_data_loader) + idx_batch\n",
    "        if batches_done % interval_save_img == 0:\n",
    "            utils.save_image(gen_imgs.data[:25], \"../result/GAN/1-GAN/4-{}.png\".format(batches_done), nrow=5, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQMAAAEnCAYAAACt7CbrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsvXl4luWZ/n+GJBK2JOwJyBJ2ZAdBRFRcEBesHajS0bYq1qU6852208VaO512WmudtlPb2lpr7T5qW61LsYoIKosCFQQUwg4JEAJhC9nJ8vvj9XM+T94gefM9jl/me8xxn/8Ekvd9nudenus6r/O67vtOa2pqUkBAQECH/+kHCAgI+H8DwRgEBARICsYgICDgAwRjEBAQICkYg4CAgA8QjEFAQICkYAwCAgI+QDAGAQEBkoIxCAgI+AAZ7XmzefPmNUlSx44dNWXKFElS3759JUlvvfWWJKlPnz4qKiqSJPXr10+StHbtWklSp06dNGTIEElSeXm5JOm1116TJN12222qra2VJDU0NDT7TLdu3bR+/XpJUl1dnSTpoosukiS9++67/t3FF18sSSosLPSz7N+/X5J01llnSZKeeOKJtNba+R//8R9NkrRv3z716NFDkjR69GhJ0q5duyRJRUVFOueccyRJZWVlkqS9e/dKkiZNmqTc3FxJUl5eniTpueee82cvv/xySdJ7773X7Npdu3bV0aNHJSX6OH7NEydOKCcnp1lbjh8/Lknq0qWLRo4cKUlavXp1yu28//77myRp2LBhWrZsmST5uTt16iQpMYY8Z0ZGYrpVVlZKkqqqqjRgwIBmz9KzZ0+3+9SpU80+Tz91797dfxs+fLgkiUraZcuWqaamplkfcM1BgwbpxIkTzfruhRdeaLWdkrRw4cImSTr77LPVtWtXSdKOHTskSbt37/b9OnfuLEm65JJLJEX9X1RU5LlLW7t37+7PvvTSS83awziuWrXK78qRI0eafWbVqlWaNGmS+0uStmzZIkkaP3689u3bJ0l68sknJUnr168/Y1vb1RhUVVVJSjSUF37Pnj2Sohd/165dflGXLl0qSZo7d64k6Y033vBAMxlmz54tSXr//ffdMa+++qqkaBJ0795d48ePlxQZCF7yXr16+RqHDx+WFE3k3bt3Kz8/X5L8MxUw4aZNm+b77Ny5U5L8Qqanp+vQoUOSpA4dEgStsbHRfXLhhRdKkpYsWSIpMmJTp061QeEF5rlHjx7tF4770l9Hjx7V2LFjJUWTOC0tMTfy8vK0bt06SYnJniq6dOkiqfkLyESnvxYtWuSX4P3332/Wzv79+3sSnzx5UlL0ApeVlam4uFiSVFFR0eyajY2NHkf6AkNx9OhRG0ueieu899577n/umyrolxUrVviFT09PlyRNmDBBUmK+0UacD4Zj8ODBWrFihaRo7k6bNk2SdN9999koMhdwSBkZGZ4n9BF9fPbZZzdzlPH7vfHGGzp27Jgk6eabb06pje1qDEaNGiVJys7OtmGgYdnZ2ZISA4g1hTXw2QsvvNDGIysrS1LkiQ4ePOhBomMHDhwoKTHB+BwTo1u3bpKkdevWqXfv3pKil4MOra+v90SGgaQCDM/ZZ5+t119/XVL04m7atElSgnVgNJgAvFyZmZn2AkOHDpUknX/++ZKk0tJS9w8T7rbbbpOU8EIbN26UFPUnLKmpqUkvv/xys/bF+477HDhwIOV28jJ069bNBok20b8TJ070fZmweMR422nv22+/LUkaO3asX1wM3NatWyVJ06dP9/jzN17u9957z9eAUUydOtXX5hlgkakCY3zBBRe4T3k+xmHdunWe47zw27dvlyR17txZc+bMkRQZKRjdvn37PAeZ84MHD5YkPfvss2Y9mZmZkmTjsHfvXhsImAhjUl5e7n/DglpD0AwCAgIktTMzwCNt377dlhkPgkfp0aOHPQCf57Nbt25VQUGBpMiTQA9ra2vtdYmpYAH9+vUzZcIrQUenTZvm2AoqiDWfOnWqtQxisVTwzjvvSEp4Wa6JZ4Fp9OrVyx6edq5Zs0ZSwssRHhAv4k1OnDhhL4in+PznPy8poXngaWEnfCYnJ8fM6bzzzpOUYBlSIsyAusOmUgH93bNnTw0bNkxS5OlhcJ07d3b4htejLYcPH1Z1dbWkiOl9+tOf9t9gjQAPWV9fby0GOg0zGTRokMMJKDuhxLRp0zwn8JqpgnFcvny5701oy5z6yEc+4lCAdjHuM2fO9LyAnWzYsEGSNGPGDH8eRvGXv/xFkjR//vwWHp45P2jQII0ZM0aS9N///d+SopCgsbFRixYtkhTNudYQmEFAQICkdmYGxKj5+fm20Ndcc42kSBxZsmSJrrvuOkkRI0AMk+TYCiX+73//uyRpzJgxuvbaayVFnhaP8Ne//tXMAC9FPLljxw5rDLCFESNGSJJKSkrs6WbMmJFyO/FylZWVmjx5sqREXM41pYSHWbBggaRIjUYbGT16tL0HP1GXc3JyzIp4bvSIadOmtYhV6bvu3bs7xv3Nb34jSfr4xz8uKcGgYBKbN29OuZ3EvEVFRe47WBYMbtCgQWZX3B+WlZuba3GQfsIjTp482UwGsRndBNYhtdQ/mpqarHvgzbnH8ePHzUSJ+1MF3jgrK8tsi7kI0zpw4IDnCSyGtjY0NOijH/2opGju0o7q6mrdd999kiL2dOutt0qSfv3rX6t///6SZM3h6aeflpSYp0888YSkKBPG+1BVVeV5jJ7QGgIzCAgIkNTOzABP3aNHD1vTN998U1Kkfk+cONFqKcr4FVdcISlhlUnRofz/wz/8g6RE3QBMAi/Rq1cvSQk2gDUnJUV67fjx4453icnwSGlpaX6uPn36pNxOvGJRUZE97fLlyyVFGsnChQutC+Dh8dR79uxxHIoXRwfp1q2bWdVNN90kSY4bt2zZokGDBjV7lvr6ev8bjYK+IGatr6/3v9FrUkH8s/QPDA/P++677/pveFfU98svv9y6BQyMdr/22mv+Hm0iNTpv3jyzqD/84Q+SIg2gf//+Zik8A+xq2LBhZi4wxVRBRmTIkCGu04Cx/PWvf5WUYGboCYwRWsAnPvEJ9z8ZJt6BTp06mcnBYvD4d9xxh//9+OOPS4qY54kTJzR9+nRJiVSiJF111VWSEvNk27Ztza7ZGtrVGDBgJ0+edBqNycOkKCkpsTAzb948SdIzzzwjKfFC0FhENCZkjx49bCCgynTevHnzbBhIRfFC5Obm2ggwwRC4CgoKTHGZYKkAMbRr165+AeI1D1JC3GLiMFgYjmHDhunZZ5+VFNE+BKKhQ4e6ndyHybhu3Tq3BQMDNT9x4oQmTpzY7D70ycqVK21QCKNSAf00btw4G27aSTh06tQphypQ4Ouvv15SIoziJUDs47mHDh1qOsxYnQ4895/+9CdJ0iOPPGJnQJiAQT98+LCNIxQ/VUD/L7/8cr3wwguSIuNGncrgwYMtel5wwQXNnj0zM9PGDMMbF/aYlzw7ovD69estiHI/Ptu9e3eHn//yL/8iSXr44YclSbNmzXIonGpIFMKEgIAASe3MDOKFNAhiePG4NSed9otf/EJSVOE1ZswYexyqzLDKcUA5b7nlFkmJNAvelBQaXmrkyJH2TtBSvFRRUZHFzL/97W8ptxMKmpmZaWtORSHe4aWXXjJdRlDibz/84Q/9nPRTvFAHcYoKTTxvdXW1RVQ8Bh5zwYIFLsaBEYCGhgZTXzx7KiCcirMcKCzCXv/+/R324fUZ6y1btrhfGI8bbrjhtM/4YeB5Cf/mzp1rxsS4wkKXL19uoZTnTBW0b926dR4TnpnQo0OHDmZfhIqwzdraWs8h3oOvfe1rkqTHHnvsQ+87adIkffWrX5UkX5vCps6dO2v+/PmSouI9qnUrKyv9HhCqtIbADAICAiS1MzMA5eXlLhLB2sVry4mPKYChNHPgwIEW0pLXCjQ2NlrQIU7Gw+/Zs8feCFCssnz5cnsJSnKxqMeOHXN815aafeLYgwcPWryiGIV4vVu3brrsssskRbE/LGnMmDFOO8YZAWAxEYyJ1GR2drYZE0IrwuWGDRucgiReRm+ZOXOm+wxRc+HCha22kz5NS0uzBySVhmc/ceKEmRLMh+c9ePCgP0eK+XSMAE+M6Jubm2vmgb5EPy9dutRskfvynAUFBc3Et7YAFtSrVy/PKxgd7SkpKTGjg7EwzxcvXuyCKhjvD37wA0kJAZc5x884GGeYxIsvvigp0dc8C6wWFvTmm29aV2PdSWsIzCAgIEBSOzMDvHpWVpY9CdYey1tXV+dVi8mKb9euXZ0GBBSY/PznP9c//uM/SopiOaz08OHDHT/+/Oc/lxTFgAMHDvQ1WQEGKioqHEsT76YCykA7dOigWbNmSYpUZeL2nJwcl6rCCPhZXFzs2C8ZP/nJT8yK8Ei096qrrrJaDjMgLbtmzRqndvkeaam///3vTnmeSblPBip1VVWV+xe9B5a2detW9y/saNy4cW4vzDB5rGtra62JsEgMHSQjI6OZV5WiGH3BggXuV1KSsIa1a9faWxLnpwqY5Pjx431PUoTxxUmwELJQ/Jw7d65+8pOfSIoYAenHnJwcp8XJfDA/0bokWTsgY3T06FF/D9bHcuVx48b5fUuVGbSrMWAS5uXl+eGZNEysxsZGp0QQheigSy+91Ncih8o68N69eztFx7Wg2BdddJHrEaDR5HwPHz7s65L6hEpu3LjR4QvPngowIDfddJPbQhqOdnfo0MHpOCboo48+KikxeZPpMm07evRoi5We3/nOdyQlKDITH9oPjS4rK/Mk4iWBwubn59ugJBvEMwGD/v7777sakbQXNLmgoMCCGeBeU6dOdegAPcY5bN++3QaNvRL43tVXX23jlUyTV61a5XbyYmJ80tPT3ebT0fEzgdTi0qVLHU4SvpL+ra2t9ctLfyCQnjx50s/P/GBstm3b5srL22+/XVJkwHCSUpTexjGlp6d7uT5znvBy4sSJ+s///E9JUZqzNYQwISAgQFI7MwM8YGNjo6kL1hsP2r9/fws/eFMo5MGDB20V8TxY15KSEgtNeKKHHnpIUoINUAeOB4lXN8IysOpPPfWUpITngmrF6+FbA4LP008/bSpOe/GENTU1Fs24P17hX//1X1tcE2bSp08fsyEKtugDvFH83/Rlz549W4Ql8c0/EJ7asukHzGT48OFOd7KSEW+8adMmC8GEEl/+8pf93Iwtni2+opGxQjj7/ve/LykhbhIC0haYU8eOHc0I6QPS0ddcc43ZBgJkqsD79+rVy2IyhXIwykGDBrkfSechVJ5zzjmaOXOmpGg/AoTAVatWucIRBsL7MGLECDMJ8O1vf1uS9Morr2jx4sWSovQyIcvvfvc7C9mEKq0hMIOAgABJ7cwM4jXSxJbJcdTOnTsdDyIOEt/ffvvtLWJSBLJDhw7pgQcekBSl3hBh7rrrLnsErDqeuqamxvehVpw4r3Pnzt5jAK+aCrDSVVVV9t5YfIqAevfu7fgVlsL9416LuHzVqlWSEqIVHgm28Morr7R4BsRC4syZM2e6zVwfjzlu3DinINmKKxXAaAYOHGiWgLhJrNvQ0GChjFJnBLj8/HzPCTwqouG4ceP0q1/9SlLUdwiJDQ0N1k0YY1KiNTU1bjNFPrDP48ePm0kwj1IF2tHAgQM9F2AeePhzzz1X7777riR5pSFFVLt27WrB1hASZ8+e7TJi5u4f//hHSQld4gtf+IKkiInRt5deeqnuueceSVFpM3MvLS3NY8E8aw2BGQQEBEhqZ2ZAPNijR48WG3fiAfPz8x27k5LCwhUWFurcc89tdk2s/qlTp7wmHk9JqeaOHTv005/+VFKkGaAm9+zZs4WSjkI9ZsyYFmvXUwEx8v79+x3TkWJkTX63bt0cO6IxXH311S2uRbzHop0TJ06YybCajfScFDEY+pPVbLt377a2ABOJp2nxZHjAVIA32rt3rzWD5CzIrFmzXNxEkU5c22Ae8H3W3ufk5FgNZ8zQCRoaGswk6AsYxtatW617MG9I0z7xxBPOAKBfpArYyebNmz13SC2y8GrDhg2O05lDMMt//ud/dsqZlbpktr7+9a9bDyETwt4FN9xwgxkcjJn3o0uXLn6u5NLrjh07eixTTRe3qzFgEmzfvt2TAIHt+eefl5R4OZnIUC4mMQLb6dCrVy93IKnC//iP/5CUoFyEFaxXYPIVFhY6hGBiMcmzsrKapXFSBS9bv379TI25H0LZunXrLLKxKpO02lNPPeX+SRbBpk6danoJ4rloKChUEkFpzpw5nry8lPFqSEIHDGMqoE/S09NtBBDOMPI5OTk2OrzMTNLs7GxTev6GwFpfX+/f8ZNtw/bv32/Dn7wLdFZWlucLBpwVoNnZ2S2qTVMFBmb9+vWen7SLNtfU1Pj6PMNXvvIVSc1rKnhh+f6///u/ew1M8k7dr7/+usO7r3/9682+f9ZZZ+n++++XJD344IOS1GxTYOYFIWNrCGFCQECApHZmBqTERowY0WxrMCkq4Ni6datpGF6CAowjR458aEooLS3NBT14ks9+9rOSEltCQc2okEOQ69Gjhyvb8MJY9fr6eos2bUktwiz69evntiD6ETbcfffdtvCIoDxTcXGxK+oovEKkOnz4sH8XDw8A90kWuQoLC913FKrgOY8fP95ib/5UgIe84oor7H3woAh1mzZtMh3GazE+FRUVfqZk5hWntrCqlStX+vnxuKQyueb27dt9TcIT5lrv3r091m1dtQir6tSpk5+H+/D/rKwse/HkcCszM9PjxlyEie7YscNjD0OGJd55553+G2PE/IpvSkMlImxg+fLlZoCpit+BGQQEBEhqZ2ZAGeyaNWtsVfG8xLr9+vVzfExKkdh62bJlTn3xPWLcDh062LvgjdEjpk2bZqv8pS99SVIi3Sgl0mOkuvDUpKtKS0v9O+6XCrjeunXrvCklugQrFSsrK+096Avi+379+jU7NSeOv/zlL24LGkkcPC+pNvqrR48eXjdPugtxcsKECWZt8W3SWgPFXStXrnRbEErpr/Hjx7sYDJHve9/7nqSEsAf7Q3Q9XZkwaxpIHV9wwQUWVGEyMInrrrvOugzzAZF59erVZoZtWYUqRcwjKyurRRk51+zQoYOf43SFY7SN5/vWt77lz6JhkA6lX6ZPn65/+qd/khQxENDQ0NCiTB6tqaqqyoIjLLM1BGYQEBAgqZ2ZAbH48ePHW8TExHC9evVybESaJr53IrFb8vFhvXv3thKLdSZ+6tChg+644w5JkefjbzNmzLClxxujD2zYsMGsJLkk9EzAIhcWFvrZ8dBoBnV1dVaTsfh4uaKiIvcHC45YA//HP/5RX/ziF097371791rZJoXJ/fLy8uzJSHeRAVi/fr37DO0mFaABHD582FkB2AJsoKamxtoEC44orlqyZIlXcd55552SokU4jY2N9sZkCmAf+/fvN+uDUVKQNGDAAGsFXAsGdN5551kzaIs2IkUx+dGjR70PJ3OJVHZRUZH7Hc8eB33L83zsYx+TlNAjkrd1J+v1wgsvOBOWfBjKzp07PS8/8YlPSJL+/Oc/S0poRZRCp6p3tasxYDCHDBniSUN1Gh3Vs2dPb01F3p+B37Fjhz+HESGPPnLkSNNgdhTmRYr/GyqOodm2bZtfRurDmURjxoxxqAK9TwUMwpEjR1qcJM2AFhYW2iAikJIzXrFihY1IcoVdWVmZrrzyytPet7Cw0GIRwhIiVWlpqScVwh8TLysryyIf30sF8a3N4jstS5ExGDBggKksNSLxezAeGDGerby83MaLVXesPM3KynLoQHuZF+np6TZshJD0c2lpqZ0I8ydVMEfOPfdcjwkbuTC3zjnnHK+LYDUu7ZMig0IoxRqD/Px8L0/mJ+269957bbyZg/Tn3r17LcAj4HK/0aNHO+SgorY1hDAhICBAUjszA0SSo0ePmtKTNoEKrlmzxkyAajQYxec+9zmn2DidBuv/rW99y16JYhquk5aWZvEGakZI8Oijj5rGJocnR48etfjUlhN4YAPnn3++nwmPxN/Ky8u9HoDUIixn0KBBThvCcnim2267zdeCRiNO/vKXv7QXpX9YuTlu3LgW23FDsdetW2fazCrNVID369q1q704NByxuEuXLvbMFJERAt17770WPHk2vr9//357WdgCzOK9995zqAHwnnGRjf6lT6qqqrz68HQ0/kyIzxH6igpH5uBbb73lZyUNythKEYO48cYbm/XHHXfcYbpPKpjt7+vr6x3iAgqtfve737l6lZQmIcyjjz7qayVvCPRhCMwgICBAUjszg/ghJ8TAeBdq43Nzc10Ug/XHQ6xYscIpQTwAW4PH1yagR8TLdOP/lqKY9v333/c6czwIOsbAgQNdxIPQlQrw1LW1tfbexHbEmX379tXUqVMlRR4ML/mnP/3JzIUyVbx4fLcnrk38PHDgQPfVvffeKyk6w3D9+vXWQmAgeJX4mnm8VSpAKO3atas9LnE9bSkpKbH+gQelGOauu+5qcQ4jbfrCF77gsmuETljkkiVLdPfdd0uKtAa8dGlpqQUzWCArAIcNG9biNO5UwXP26dPHonJ8nkgJfQRvfLqt9WE/PCs7Wx08eNBMim3LGOcLL7zQbYxvrgrQp+JFe7SVv3HoCyd2fRgCMwgICJDUzsyAWL66utr6AVYWb5qZmen4HK0AS7948WIr2MTEoDWrB1DQ4+vOiVPxWKi+Bw4c8HNSXpsK8GA33HCDrTksh7YtW7bM3ol0FJrFggUL7HXINJCF6N69u5VmvOhzzz0nKaFSw4r4iVZyzjnn2DNxPzb5nDJlirMObdEMiKNPnjxplgNgO7m5uW4Duges4YEHHjADop+Ih6+55hqnfGE3zJXGxkaPGZmD+DmbaBSs5CNmLi0ttVbQltOmpahQa82aNda3+AnLHTlypOcq2SOeK348H3OYfunVq5d1iJtvvllSNG6NjY2es/E0sZQoa0ZbonyZ+2RmZjqzQF+1hnY1BohpdXV1fvmhmlDJd99911V7vBDQ23379nmjBygujUeY+zAkr4REcOnQoYMnIBtL3HbbbZKaV3i1ZQNNQpnf/OY3FnRoA5V+w4cP907N5Nh5uZ5//nnnnVkKyyRuampyG6DW9GWXLl3cD6QfMSLr1683lWSZLMZk27ZtKZ+6Ewd9kp2d7ZeZfD/3PX78uGk0FJYU59SpU90GjFF8wxW+l3z61rBhw/xC8eKz2/GRI0f8khJKYuAmTpzo8UwOG1sD617WrFnja/A87OZdVFTU4oBdDPUll1zS4vDe+HqMeBpcit6VY8eO+bh25gdLofv27esQkf7AcJw6dcoOgbnfGkKYEBAQIKmdmQGWdPTo0aZTeGgoTe/evW0VEVH4zDe+8Q1vVkq65bvf/a6kxFp3xD48O7T7ySeftDjIVl08y4EDB2zF8eLx026hZBQfpQLoX/yobSw4AtvixYt9Pygi4UXfvn2dfqJ+nVV68+fPdzUjbbj11lslJWgwbcHr89zHjx83i2JNA4UqvXv3trdD6EwF0Pi+ffv6vuzfAPsYPny4wxpSijCx/fv3O3TA88L44idk4V1hR4WFhW4LbYBBTZgwwWIobSE8evzxx81YKGxLFYRU2dnZnruf+tSnJEWbzAwbNszhK2NKgVVGRoZZG8IhW53FV0LyO4TIw4cPO5xMfi+eeeYZbxZLn1IVumTJEs/d022aczoEZhAQECBJSkteCfX/J774xS82SQmLjfVOLp8dOXJkixp6LHvHjh3tMR9//HFJUTzYtWtXC0zEj8TBI0aMcP04KSJEqS5dulgkJLaiKGfHjh32vnjYpUuXthpsLly4sInnRTAkpqMMtmfPnr423opClYyMDIteyWnPwsJC6w+k8375y1+6TfwOL4SHSktLc/+QcoI5jRw50qIeuskvfvGLVts5derUJimxOw/ziHid6+3cudNenJ+M9fz5882OkouA4gVC7HBESu73v/+942/ux5h169bNWhPzhs+eddZZ7nPi6SeeeCIl8eDKK69skhJjxXzBG8OK4huuMgeZZ/HyZzw8c2Lbtm3uL5grJcQjR470JrqMO6JpVVVVs60EpYgZHDhwoIVm8s1vfvOMbQ3MICAgQFI7awbsSjNz5kx7TApgsISNjY320KSrUJrHjRvn/ezmzZsnSc3W4eP1UbmxiPEFPKQg42fbwUCw1HjqHj16OAWFB0sFeKKLL77Yz0ebeLa+fftaT6AQBmU8Xo78yCOPSIoWsMydO7fZKdFSxK4qKir87Hh/WFZNTY1VeUC6s6CgwKmw+Hb2rYF4f+XKlX5ePBMsoKyszMVGeCo8/JEjR+xBYSnoIS+++KJTYqQf0TVGjRrlsUajgA0UFBTYg7LClXEdNGiQ1X7GP1XA1Pbt2+d7wljo88bGRmslzF3Yw/jx491GNDAyRhMmTDCL4TOMwxNPPOF5wbXJFBUUFHgOwbSZ84sWLXJ/pbr9fbsaA0RCxBgpetD4FlIIaVQl8r0DBw40O59OiqrT8vPz3blQelI3R48ebXakthRR7MrKSlM5Jh2TadGiRRZvUt0gQooq7ZYuXeqJz/OyYi2+lz3PRupvxYoVThciUpHLzs7OdoqJ9pImO3HihOk2k52+vOiii5zSW79+ve8jJZbgEkIw0VMBL/ygQYNMg/kdot+CBQss8jFhofTbtm1zOxlXXuDly5e7HgIhkbHLysoyrUY0ps8HDBjgUIdVfrS3c+fODh3bcpCuFIU2EydO9NxhfhLeXXjhhW4PRof7lZeXe5wRUplTxcXFdhakKXGcc+fOtaFmbFmbsmnTJjsCDCfjkJeX53Yj9LaGECYEBARI+h9am9C9e3eHCVg2aFJjY2OLjUmxkuXl5S5EwZLiAQ8ePGh6jofHo6SlpZl2QcPwTm+//bZTNcmFSYMHD7bnwRtQ734mENYUFBSYnbDijuvk5eU5BYkXiZ8jiYUnlYpoVVhY6JQZ7YVVdevWrZm4JEVi1Zo1a8xyYAiMwahRoxx6QH1TAWzijTfeMI3GMyJovf76634+vDkiW25urlkOXv+3v/2t+yt+ArEUhT7x6jrGMy7G0Xcw0Iv80YGiAAAgAElEQVQvvlhSgiVR3MP4pwoqA3fu3GmPS4qWfiwsLGxxAjjh7NatW/38UHvGdN++fW4ra2CY13v27PHY0G+kjbt37+51PMwl3qfS0lKv+k0+a+TDEJhBQECApHZOLQYEBPy/i8AMAgICJAVjEBAQ8AGCMQgICJAUjEFAQMAHCMYgICBAUjAGAQEBHyAYg4CAAEnBGAQEBHyAYAwCAgIkBWMQEBDwAYIxCAgIkBSMQUBAwAcIxiAgIEBSMAYBAQEfIBiDgIAAScEYBAQEfIBgDAICAiQFYxAQEPABgjEICAiQFIxBQEDABwjGICAgQFI7n5vwox/9qElK7BPPOQacK8C++du3b/d5AJwEwzFedXV1PqGGveM5A+Dw4cM+nJRzDzinobKy0mcpcOYAR3KvWLHCpxtx2hEn1hQXF/vUIvau/9GPftTqQZ233HJLk5TYF59zEnhujmQvLS31mQa0BWzbtq3Z0eTxn7t371ZJSYkk6fLLL5cU7af/zjvv+Bi4Z555RlJ0zsOmTZvcr5wOxD3q6uo8Hlzrxz/+cavtnD59epMkPfDAAz6jggNNOSOgurrax49xngFnUZw8edKnJpWVlUmSTw/q1q2bz0LgTAHOWHjvvfd87gFjzHkaOTk52rJli6TozAjOkLjhhhv061//WlLiMF5Juv/++1M6ePXWW29t4n60h2em7enp6T7rg2PbGfeRI0f6tCnmEke5z5s3z+dO8KwcOzdkyJAWZ3cMGjRIUuIcCs7JSL5v165dW8yvn/70p+Hg1YCAgNbRrsyAE25ycnLsqfFWWML09HR7J7wGp9QUFxf7CGoO+sSjZWVl+QBVTqPhOPLZs2f7fpw9yEk8BQUF9v6c+IOlnz59utkJpwelAs6969Wrl0/wwSu+/PLLkhKegnbSL5zs1LNnT3t/vBztPXHihA/X5Pv0SVpamp+d03q+8Y1vSEqcRYn34eQmPltRUeFnnj59esrtvO+++yQlmAH9Azvj1KDx48e7D7kfJxxt3bpVzz//vKTI+3Nm4gUXXOCTtBg7+mL27NluAwfbchLUoUOHfKAsrJGfy5Yts7dsK2ABXbt21SuvvCIpOiuRw21LSkrsxTmzktOXMjIyfPAt82zmzJmSEkyQv82YMUNSNCeKiop8fc5hZG7s3r3bDJdzLGG1e/bs8b85gLU1tKsxAEOHDvUJwoDjoXr06OHGYiA40XbGjBk+VBUjwKR46623TJ/idFJKHC0GjeSQVajeU089ZcrJ0WBMyLffftt/48i0VMD3MzIyPIk4YBajsHHjRj8LLy7Ga+vWrfrnf/5nSRGV/93vficpMdiEOhzGCuXt1auXDzmlD3i5Gxsb3WfQVV6khoYGT5xly5al3E4o90c/+lE9/PDDvpYUHem1bt0601QOQuVk6zFjxvgwUU7jxug9/fTTpr5MdF6+tWvX2sgybzhurXfv3g5VeBE56q2pqcnj3pZj5KTooNysrCz3H0aY4/EWLFjQIhzFYNfX1+tvf/ubpChEZW4dO3bMx7Fh8HBoc+fO1WuvvSYpeg8I87Kysmx0eT5OfR43blyLcKY1hDAhICBAUjszAyx2UVGRrfyOHTskyUeX19TUmNbh8fAs+/fvF8fBQWvxEBMnTrT4wvfjHhqhEksKMxk3bpxpGxQSEaagoMD0NfkQ0DNh7ty5khIeLDm84DjuAQMG2Irj/Z988klJCQ9DOAHtpC/Gjh1rRgB9xHOeOnXK16ftsA1JLY7vhk5nZ2d7HPDUqYDwqrS01AwEuov3r62t9TU5Av7CCy+UlJgPtBPgxQ8ePOhn+upXvyopYoPbt2/3tTikN870ENVo+znnnCMpwTSZd/RPqoClNDQ0eB7zO0KC559/3uwHZsC82bp1qz71qU816weE8YMHD5rhMM707cGDB330++LFiyVF83v48OEOAWAp8cNZYUbxOXAmBGYQEBAgqZ2ZAXFzdXW1Xn/9dUmR18diHz582NYRkQ9LOmnSJHs+xJT3339fUiL+wrr+/ve/lxTFqDk5Odq6daukKO7C6+zdu9dxPHEbPxsaGsxE0CpSwVtvveVnevHFF5s9S9zzxT2DFHmK48ePOwbGm9CmxsZGe3Ti7Pvvv19SwtMmp+9gGx/72Mf0wgsvSIrGgT7p0KGD+xMvlApgJsXFxbr66qslySIu+s1zzz3n+JefixYtcnvpX1KixNWf+cxnrB0xHni4gQMH6tlnn5UUiZHoPQMHDjQrgSmiYwwcONCpy1SPKQd448zMTMf1sExE06KiIv8O8RsGeuGFF1p3gs3gxadMmWKt4Q9/+IOkhMDMfZnzfIb2dOjQwVoBOgb33bJli9k2zKg1BGYQEBAgqZ2PZF+4cGGTlIiXsdCo2Fi/Xr162VOSdsQS9uvXT4MHD/a/pchjX3rppfr3f/93SdLdd98tKYp/d+/ebU9JfL1t2zZJiUIOrCqfwaNMmjRJxcXFkiK94+mnn261SGXcuHFNUiKOhYkQS+Md5syZY8+HRhHPKtAf9AGZh/379ztGTfbi5eXleuihhyRF/Ql7OOeccxwnc1/U7Pz8fK1bt65ZO1944YVW23nvvfc28R2yF+ggZDUmTZpk78Vcg5HceeedeuSRRyQlCoKkiEH9/ve/Nxv6xCc+IUn65Cc/KSnBGmCS8+fPlxR5TSnqY2JmPjt48GDPG6798ssvp1R0dOWVVzZJCY9NfI4OxXytq6szq0WHIq3arVs36wDJz5WRkeFCJL6PFjZ//nyPJZoJ8/Q73/mO+5l2waaHDBmijIwE8SdFu3z58jO2tV3DBBp45MgRv9R0Arnz+vp6C12ILwhCnTp18veg1NC9Tp066bHHHpMUTTqq04YPH94iN0+YMGDAAIsw3IcB2bNnjweVECQVYEw+//nPO4XFhMH41dTUeJChcbysZWVlfuFJ/3384x+XlKCdpEmTkZ2drS9+8YuSIiqOkHX8+HH3AddkMlZVVTmlh5FOBaS48vLyHBasXLlSkrRw4UJJiT5krF599VVJ0o9//GNJCdH31ltvlRRVTD744IOSEi8B/XjJJZdIkm688UZJiZeaMIo+u+KKKyRJzz77rMdqypQpkqKXp6Kiwn191113pdxOKRr/kydPqlu3bpKi+YlRWLFihcMC6gX4TFpamucAYQKGevHixb4+VZegrq7OwjZzh5/33XeffvrTnzb7Hp9dt26drrzySkmRuNgaQpgQEBAgqZ2ZAV4qOzvbQhrWkVCgoaHB9B7vTdHEpEmTTEeh9giQdXV1toBcC08ft7bJv8vOzva6CH5S7LR//357TyheKkCM+8Mf/mAqjheF6jU2NnptAaEAtO7666/3v6lSo02zZ8/+0Pump6e7X1mTcN1110lKCLMIiNdcc02z7+3bt88CHP2TChAQc3Nz7fVIpf7mN7+RlCh6osqQCkjSkLRRkgVlGM2sWbPMGkg/8vk9e/bohz/8oaRoDcTnP/95SQk2QEhGtSli3OrVqx1CQKs/+tGPptRW5kF9fb3ZImInz1VdXe21JzBC7jd58mTPWdgC45Gdne3wFcBuT5w4YUYNq2WMBg8e7DkEQ+D9mDFjhlkC4mdrCMwgICBAUjszAzx89+7dLSoRwyGeVVVVWWBBIMPSl5eXWzD87ne/K6l5CgZrzPf4WVZW5hiROJ0Ybe/evU5PUgyD5e7Tp4/jQzx8KiC9U1hYaJaBiPPLX/5SUiL9iPhDCgjmFPeYgLg0VdA+fp46dcppL7QDymjr6+sd86dauipF43LBBRf42nhNxjUtLc2s5l/+5V8knb59eH+84IUXXui0KF7zJz/5iaREahQ9iGujUbzwwguOqefNmycpYitbt251qpcxShV44zVr1ric+Nprr5UUrZK97rrrzARgtbChjRs3WsNA9KSv0tLSnHZFgEUXeuCBB5yuhUWDxsZGt437UHz10EMPmTXwjrSGwAwCAgIktTMzoFhm//79jsGJ+VGhhw4d6hVbWFcKS/bs2eP14RSpEOvW19c7jYflJmZ65JFHnHpCK+D/69ats1VlYRMZjj59+tgjt2WhEqnCpqYmZz9Id37rW9+SlCh+wjPAGsgYpIrkfRB47tMhMzPThUEsMKIPevfu3UyzSRWwpvLy8hbpNrz5vn37rF/QF6cDjIAxe/PNN72Kk3Gh7zIyMvRv//ZvkiIPT1v69etn1sn6f2Lm119/3Qp7W7QRKYrXr732Wnto7gnb3Lx5swu6mC9oDZmZmfbUsCaeoaSkxCyRfiTDlZuba40nmVE1NjZaM2Hs//SnP0lKsCKKtEiPt4Z2NQaIROeff74fkFWHcaGNDuTFZVD79evn6j5o5Q9+8ANJEcWPA2Ny8803m1b+9re/lSQvQ73kkktarArjhSgvL/fkhr6lAmhdnz59PKikCsmnr1q1yhOTVBMCZqrAGDAhunfv7t/x3LS7W7dunnzQVSbQ1q1bTfNPR+E/DBi9Cy64wMIVBp9VjHfddZf79XShDvUevPAIcE1NTR5bXjZCrscee8xGgOflxfz4xz+un/3sZ5KiMAFMmTLFdJzQMFUwXy6++GIbtbgBkhIvN3l+wllSjCtWrGjRDp7lnHPO8XvAWJJ+Xb16ta8BSL0fPXrUy8IxPhj8F154wXOOa7eGECYEBARIamdmgMc/cuSIKSbpH9Iu48aNMxPAU5L+OXHihK0pRSqnK8DBO1KQsm/fPguOpIMeeOABSQlRhmsQcmD5+/fvb+/ZlqIjQpglS5Y4tQf9gw5OnTrVounp6DPsJNmbNjU1+VqwK577nXfe0f/5P/9HUkThQVykwlNAd8877zx7K8YoFdC2v/3tb64cpPDrtttuk5RgV1Q8nm6lIOHi5z73OUkR29i8ebNZw3/+539KigTPnJwci5cwEkKK0tJS03C8NAJfbm6uGSgp2FRBurixsdH9z/URLGtraz1eCHu/+tWvJCUETlan0h947rS0tGapRCkSle+++24zSMB9d+zY4cpR+pY50b179za3MTCDgIAASe3MDIhZ9+7d6/QWBSh4rSVLltiCIiZhCS+88EKvEDtdbIt1xZujOSxatMjM48tf/nKzz+bn53uVGzEgYtbevXv9O76fChBxOnfubO9GiTM7Cc2bN8/W/3SsgzbAcihWOnz4sL3uV77yFUnSj370I0kJ7/WLX/xCkswQ4kIZ+yy8+eabkqJU5qZNm9yftD0VEBdfeOGFTuPCLBBFpcQ6jA9D8toPtIYvf/nLLQrMEBCPHTvmOB1w/7y8PI8nz4f4N2fOHJdiJ++01RrQVAoKCtxHpGERtUtKSiwgUtaN9589e7a/hxdHz6mrq/Mzw4aJ/Xv16uW5wDMjzmZkZFiHQzSnHwcPHmwtjO9/85vfPGMbAzMICAiQ1M7MgFTaxz72MXsOVnVhvfLz8+0NUV+JmeK78PCZeOkxlhbw/wcffNBWFQ/7xz/+UVIiRoUloPyzaKegoMDWn3RVKsBKl5eX+9rErddff72kREzPOv1kVFVV2cJT5osHHTFihFN1sABSo3l5eWZcxLVxZkAf41VJPdXV1VljYFFPKuC+O3fu9P1Q+RmfpqamMxZs0a5Pf/rTkqJ+uvHGG62pMAZoBmgVccAia2trXbRGP8GEXn/9dbeZz6SKuD5CGTZenD0kOnfu7H/TH/GVt/Q/ugge/qmnnvK8gDUwr19++WX3H33F/PrsZz/r65PBon3z5s0zK0l1oVK7GgNEn1deeaXFii8oa69evZyegh7yvb///e9eyktnxVNpn/3sZyVFlJFcdGZmpl88Jg3CVceOHZ02JGQhdbN//36LPRimVIARKisr84QmzckA3XTTTR+a6961a5c37+DFhep+5jOfcd6ZFZtQ02effdZ9xYYw9957b4vrQ2vpkyuuuMK1B6lOHCmaeOnp6abRhGa8FCdPnnR4kryJjBRtZAqlxWhPnjzZbWZ9xumeDWPLPKqqqnL/s0oSwbSpqcljyzVTBSm8gQMHeu7hPGhDbW2tU6SkBnm+b3/727rpppskyUvtmW9DhgzxM9NG3o8RI0Z4uzMqHnFoPXv2PO2mJlKi35m7qYa4IUwICAiQ1M7MAKuck5NjihTfBkxKMAM+xyYYpGkWLVqkL33pS5IiZoDXycrKMmXCGkPtbrnlFhf74JWgY0ePHm2xlz7PtmvXLjMCmEsqgOLPnz/f6Tvq0SkwOlMF3MiRI90H3/72tyXJ7e7Ro4dFSLwIKwTnzp3rzU1IvZ4OhGuImo8//riLtkhTpgK8cf/+/d3nPDdFPTNnzvS+BNw3vt8ELO7mm2+W1LyqMrmi8nTsjLHjfv3793eR09tvv+37SAnxlhQkrCNVwB6rq6st+P7jP/6jpEhcXLVqla9P3xJ23X///d6rAbbH+MU3fyX04vmWLVvWbCv8+N9Gjx5tlkcIRVp12bJlXpPAu9UaAjMICAiQ1M7MgJjx2LFjFqyIf8CECRNsAYlJ8VYzZ860dyAViefNycmx0ELcRvHSzTffbCaB16dYY/Xq1bbGWPy4gEk6qC2aAbHaa6+95nay0eXXvvY1SWcuPc7MzDRzYJ0+5bBdu3Z16pVnYy3Hfffd58NX0F3iwCNT0k06q7i42F67LVvCk7qrrq52mhShFSb06KOP2lOj96BrtFYUk8zYTpdOZh7gZffs2dNiWzfuM2nSpGYFQm0B/VNTU2PGsnTpUkkRa4gXWNFG5vCNN97oPQfQH9AcJk+e7GIj9jhAT5g9e3azcmcp2rKtpqbGf0NrgSkMGDDA/U5hX2sIzCAgIEBSOzMDlPWamhrHlsTwlOQ2NDTYu1Aiyx56hw8ftpXHK/HZ7Oxse8jko8VKSkoc32KpYQgNDQ2OaVnsEd8hhmviGVIBqZ/4ARhoFLS3sbHxQ/coqK2t9edpJ+r3wYMH/TeKsSg+ysjIOG2xEYAdkaIl5Rbfxpv4NxWg0VRUVLRgcywWuuyyy9yfxK5PPfWUpMSiNJgTOzjFD4ghhcd28adjBiw8I8Oya9cuayrEz3jSiy66yCwT7SZVwDbz8vLMJJnDeOA1a9a0KANHCxg4cKAPg2ETWFT+RYsW+bmYL2QO+vbt63mC94c95OXleUyT9/4YPny4042plpi3qzFATOnWrZtpER1CxdZVV13lziXf/+c//1lSIseLYEjuGXFx5cqVuv322yVF9eAIKPfcc4+fgbCCyq36+nrTNYQZ/j937lxTcV68VMCgVVZWmr5yX4TMMwmIZ511ljcB/cxnPtPsmc477zwbTvqC9OE3v/nNM6465OUn7UgoUVFRYbEteTKfCYh248ePb3FeJc+/bds2P/stt9wiKaobWbJkideKEMLwjN/73vdcCwClj4cwvIisW6Hqs7q62oIh98VANjU1mUZTGZoqCGfT09MdYtLXX/jCFyQlQjjGlT7GuPXp08frG9gGjrqBq666yrUHGGrei6ysLIet0H02ohkwYIDbw/tEu0pLS/03fraGECYEBARI+h8SEDMyMuxJ8JxQugkTJtjyYXkfffRRSQk2QIENVBmLePHFF3tFIGk1ik3S09O9xoCt0bDAI0eOtKXH01HFd+DAATMCioVSAZT1oYceMkWD5UCVm5qaWlRMgrS0NFPRJ554QlJUTJKZmWn6DPNhY5gzbW5SV1dnz0Jf4Hn37dvnEC557fyZQLHNq6++agZD+EXfNzQ0mHWwUhQPf/HFFzt9/Nxzz0mKRMYXX3zRwhxpz1mzZvneeDvCRrzs5MmTfS1YAyxwyJAhZn+kAFMFRT3r16/3/GAuUvw1Y8aMFtvcIUqnp6c75GQLPp6rurra7aESkzGWImYEs6Zvjxw54veI+8H2XnvtNYfLZ5oXcQRmEBAQIKmdmQEeoVOnTva4CCBYtqlTp1qAA//1X/8lKeHxic8oPSamr66utgdBR4iv9qIQiHiemHPdunUWEGEnWOKTJ0/aYsMoUsH3v/99SYniEmI/7odAN3ny5Bar1+JANKJsmhRSenq64+szrdyMr4iTEjEsQh4MCs87dOhQMxFi7/vuu6/VdsJyxo4daw+P5+X+mZmZZh14Tf6fl5dntnjnnXdKirSZzMxMe8LTnYuIx0Uw4+euXbu84m/16tWSoni/oKDA12f1IrpLa4DBxtOAzJO4/sN4MbZoRbt27dJf/vIXSZH3xvtfdtllPjUq+RCViooK7/XAu8Ic7tmzp0VCGBXi6alTp8wgUi2wCswgICBAUjszA7zP8ePHba1IiWC9KyoqbHHxqnj/48eP27Pi1bDKo0ePdvyId4wvKCFeZlUc3mbHjh1mBBSDwEyqqqp8rbZslY7HPnDggDUDFs2QCfjhD39ob4BGcjolvy17EjY2NtrzsbiFYqCvfe1r3leAaxL7ZmVlmR0ls7IzAc3irLPO8liR6oU1xHe1Qo/gGUeOHOnMAguz0DPuu+++FicMg71793r+MG/I0vzsZz9zNgqNge3Dy8rKnA6FAaUKvHG8WIw0cTIbk6J5SQlyRUWF2RYsk2eOj3vyjkdf+tKX/KzMF1jujh073DY+DyOZNWuW+y/VE8Tb1RgwCcrLy/3iJu8X/8477zicYPswkJaW5jptfsYRT/9IUVpn6dKlrjyDotF5559/vicgVJP0VufOnU3lkislzwRyxFu2bPHA8+KQY//Upz5loZMXlqq9Hj16fKi4GAfGjsHOzc11Gpb+Jc06atQorwykL6DtM2fOdOjQls1NSHllZmZ64sVX1EmJdBiGgfUH8TUKiFycqcDmNf/6r//qic74cM3+/ftbUKWegTHPz8+3saNNfK+ystJhSVtXLca3oSN9yjx9/PHHJUm33377h45bvHIUMRk0NTW5/2gXVaJTpkxxOxg3tukrLCz0XMWhMPe6dOni+RzChICAgDbhf2Q/g2PHjjntk7yV+MGDB73hCQII1DourmDtSAe+8sortryAVNa0adOceoJyQvH27dtnq4/wFD8/AU/5f3OeQGNjo6k54iYrDFevXu12JW8Am5WVZc/Os0Cnc3Nz7ZlIO8a9IvXyMC680KlTp3x2A9dkPMrKyhwGfdgJz6dD/IwDWBxFRAhzt912m6sS+RtUff/+/e5fBGEKxzp27GhWBi3GMz700ENeV0EhD2m6Pn36uPKU9RyI0126dDHLaEsRWfzeW7ZscUoV0RQx88EHH/SeBafrR+YQz85n77zzTjNIwljWwqSnpzuUph/4bEFBgdkWQjE/ly9f7hA11RA3MIOAgABJ7cwMsPRTpkyxp8Z6YS1Hjhzp4gxSS1jU999/3/E1QguMom/fvi4egkEgEtbW1jo2hYnw/5MnTzo2pY4cL1BWVmbm0ZYNUf/6179KSngi4j28MWxn+/btLsbhpB2824QJE5wWS94O/aWXXvLJS3yfOLu2ttapUERR7jtnzhz/GzGM/u3Zs6c1G/olFbBCLz8/3wVMlByzsen5559vZsB26jCE7Oxsb/fFT9LCFRUV9t4wENJmzz33nIuGmBt8b9u2bfre974nKfLY6DXvvvuumUhbBGGp+SlbnKjN72BYW7ZssVBMERbsr7a21noRYwoTXL16tecFoi6fKSkpsTaBzgUbiq82Bczh3Nxc9x86RKttTOlTAQEB/+vRrsyA3YIqKyvtMYl38Win26A0fhIyMTgLQUgHbtmyxfESK9JQldPT031vLDXFGhdccIGvgeckJmxqarJKm1wMciaQVsrMzLS6TtyH5a+srLRHweKD9evXu1yaohXKfKdMmeK+gtHgHVetWuV2okYTl+7YscMpN665YMECSQlWhkdpyw5A6BoNDQ3uc7w4C5V27drlQhz6l+PdSkpKnDYj9YvH/shHPmLmwSI20srz58/3OMaPeJMSbId5QMaJvps1a5bjbT7fVqxfv96ZCBhsPLPFXGXDXbIEw4cPb5HCJpuTl5fn35GNoB+qq6vN1kjNkwbOzMz0HIIFoDUMGzbM70iqbK9djQGT59ChQ6Y+TEIm08mTJ1ts2EDj42cc8H3obX5+vmkvExKamJ2d7ZefNBOC3KFDh1rs+Y8w1NTUZCGO8CQVMCCXXnqp1w1Ao1kqPHToUFe1QTeZHBUVFRa6mBRMsrVr19pAMbl4SaZOner6Amgnk2znzp3uR/oQEbVTp042KKmucIu3pX///q4SxfhATQsKCjxWhD4YnM2bN7sNbOLC/Z988knTaNYAECpdf/31TqlhNDEK7733nkM6XiwEy927d3uMMZZsXdYa4hv4Ig5ieAlP4zUIzEGeb+DAgd6aDAdI3cA777xjB4QD5PszZsxo8VLz7CNGjPA9mTt85o033vA8SXXDmhAmBAQESGpnZoBlHzhwoD0XVIuUyvHjx23toIJ4xQ4dOriABfaA1Zci4Q9viHWtqKhwWgZ2gviWl5fn78EIEJzWrVvnmu+2HMkeP1OQMAGKFy8YwUNCJbnHnDlz7CF4brxQ3759LS7BhOLbhSPSJj/36NGj7cFgBDCF7OxshwwU5aQC6HFtba3+6Z/+SVLktWBbUtTnCxculBR5v+zsbDMgqDdzpGPHjmY5eHg+8/zzz3v+ILoydkOHDnVYAtuh77p06WK22JZKS6m5mE2owVgyfosWLfK8xNPD/urq6jzPCGOYy9OmTfOzInAiuh48eNBshiIvrj148GCzLeYs/dG1a1eHZcyP1hCYQUBAgCQpLVWrERAQ8L8bgRkEBARICsYgICDgAwRjEBAQICkYg4CAgA8QjEFAQICkYAwCAgI+QDAGAQEBkoIxCAgI+ADBGAQEBEgKxiAgIOADBGMQEBAgKRiDgICADxCMQUBAgKRgDAICAj5AMAYBAQGSgjEICAj4AMEYBAQESArGICAg4AMEYxAQECApGIOAgIAPEIxBQECApPY/UalJkq655hrvl88+9pwvcOTIEZ+uxCkx7Fk/YMAA7yvPkWScTrNu3TqfGdeBkkIAACAASURBVMDpR5yb0NDQ4KO6OJOBU2bWrFmjMWPGSIrODGCf+pqaGp9twP73y5cvT2utnXfeeWeTlDhGjP3wOSuAay9evFizZs2SFB1EyjkRFRUVPox127ZtkqKTcg4fPuz99tlbn3tkZmb6hCm+zwlF27Zt8/kDHBXH+Ql9+/b1kXCcpfD1r3+91XbefPPNTXyHZ0k+l+DAgQM+5o6+5Eiw4uJiH1XPiUjg2LFj/h79wslT5eXlHmNO5OL0oNLSUreTOcbZGrW1tc1OPZKkn/70p622M97W3NxctzV+UpOUOK2LNvKT8x0qKys9Pxkv5mTHjh19TeYl70P8dxwTx9zfs2eP280pXvRtVlZWs2PdJenhhx8+Y1sDMwgICJDUzswAT7h27VqfcoO15BSivn376pVXXpGUOM5big4ybWhosFXkJ55sxIgR9gh4R7x5dna2rThWFks8dOhQH2vNyT9Y+hEjRpidcLJRKuB0m8LCQj8DJ+3gDS655JIWnou+qK+v98GdHCvPaTzr16/3+Yv0IWwjPT3dLCfZ0+bm5tojwQzwHFVVVWZf8ZOQWgOnNXXv3t3PRJvwUDt27GjGtKSo77t37+7Tr2Aw/MzNzXW/wNjon40bN/qa9CsncvXr18/PwN+YKyUlJfbYfD9VMDdqa2vNUPDe06dPd5s5HxSPDaqrq/1cnCLGIbzl5eUeE8Zh6NChkqT333/f1+BwVTz9qFGj3EZO2aLPGhsbfT+evTW0qzHgJZs0aZKPpGKC8LcBAwb4oE0mAcdKVVdXO0yANvNyZWZmurN4GaHYAwcO9ABAOTEwlZWVzQ5vlaLw4plnnjHdxuikAl5STkmWoqO0OP7q8ssvd/u4Hy/ili1b9A//8A+SoqPFOMC1qqpKZWVlkqSJEye26B8OluXoL2jqypUrPXEwfhi67du3u184IDYVQOMLCgp8mCthwqZNmyQlXhheHu6LYVu9erVPQ2Y+cNBtcXGxJzMvBMeSXXHFFb4+84E+PHLkiF9IDnXFUOzZs8d9xdFjP/jBD1JqK8autLTULzoniXP9rKwsh178je/FT+TGwDP+1dXVLcIKDNioUaO0ceNGSYn3RoqOD6yrq/O84n2gfcXFxR7veMhxJoQwISAgQFI7MwMs1L59+2zJsY54j5KSkhaHqkLRS0pKfA2OhcMDNjY2mkZee+21kqTvf//7khJeGWqFJ4EZ9OrVq5noEv/MuHHjbGn5WyrgO127drVXgxrfeeedkhKMCCbDs0AV+/bt6wNMCZ94pl69erUQhhDRpkyZ4mtCDQkNxowZY3Zx6aWXSoq8z7x58+zd6M9UwDPl5ua6DfwkHMvKyjKFhRnwjEOHDnWoAQuIX5PnwyOCl156yQyI49c5+vzgwYP2shyuiycfMGCA+wyPnSron759+3q+0Na4qM3v6EeYTufOnf09mAtjM2nSJDMK2CzsMj6vYQQc4rtv3z4zR94RnmXQoEFm3akephuYQUBAgKR2ZgYIJlJk5YjTwZEjR2xN0RGIh7KyshxvEuPihXv27GmtAdbBtUeNGqXt27dLio4MnzBhgqSEh+YI7y1btjS7H8/BvVMFMf2xY8ecyiIWxAM8/PDD9t7EzXj4SZMm6frrr2/2LHjatLQ0e4O4JiIljjP/85//3OxZEKQ2btxoD8Pv6MOuXbu6XznKPRXQ94WFhVq7dq0kOVUIc2toaHDszhgg3p06dcqMAM++bNkySQnPltxnHAFfVVXl773wwgvN2tSxY0d/j/5Ex+jUqZN1Drx0qqA9nTp18rxA5IPBlJeXm/3wk7FqaGiw94aVoPnU1ta6b5g7ce+Pt6cd3L+urs7zi+dDgK2oqPA1mDutITCDgIAASe3MDIib6+vrrQvgXYjzOnbsaOtNfIfVz8/PV7du3STJMeOXv/xlSQl9gWsR35Hyeffdd21NuS9q9ODBg52RIE7jHt26dXN8B9tIBVjpsWPH6qWXXpKUYCdSFC9PmTLF7Ij7zZkzx23BG54JZE3A2LFjnQ2g72jnqFGjrEns3btXUuSFevfu3aIoKhXgncvKyqyQk3UhHs7IyHC/8hMWsHLlShcnMcawpBEjRphR0E483KlTp+xJKVCDIRw5csRZHPoQ3WbQoEH+HvMtVXDvjIwMtzFZOxgyZIjnC5kh2Ft2drafC0+PHnTixAk/D1kI5snhw4c9bldeeaU/LyXYA2PA3I9rajwf71NraFdjAIXp2LGj03k8KDS1oKDAOXIoEBNLiqjVHXfcISkyClIklDz22GOSpDfffFNSgsZCmZjsUMmysrIWqTroZXp6uo0HQlcqwOg988wzmjJliiS1qGQcMWKEXw4MVbxKEoMCzUwVn/zkJyVFYRgG8Wc/+5knLYIaVHbw4MF+vr///e8p32vnzp2SpOuuu87fJ9XFSzF58mRPcMaYF7K8vFyrVq2SFL0YpPp69+7t3yX3RceOHW0oCPFIFfJMkvTcc89JiozPiRMnPKdIZaaK+FykjfQn7crLy/OLzouICH7gwAG/uKSrmfuNjY0OObjmO++8IymRDuX5GTfmy7Jly+xIAPM1ngpnfreGECYEBARIamdmAEaOHGkRZd26dZIimlhVVWWPgKfn56hRo2wxk6uqqqurzTagaLfffrukhIeGasIyKP4577zzHAIki5pVVVX2SljcVNsnSbNnz3ZhzxtvvCEporWLFi3yfUircq8TJ06YRT3yyCOSIs83Z84cC6UIsngjriNFoiKiVffu3bVkyRJJEVugL3fs2OHvQttTAfeoqKgwq8H74ZkOHz7sECnO8CTpnnvusSfkmfj/6RhR/Ps8L971xhtvlJSgzj//+c8lJVLDUsQeO3fu7DQnYmSq4H4dOnSw+EwbKWg7efKkwzPWEeCV+/fvb3GWPiJcW716tUMIBOMrrrhCUmLewUSShd8+ffqYyfFMMJL6+voW/d1qG9v06YCAgP+1aFdmEC9VxQsSb+Fl4ikfYmo8y+bNm/WnP/1JUuQ5uE5paanjz+eff15S5BmGDx9u78/3sPSbN29u4Q3xpgUFBbbKCDSpAIv/3nvvuawYEYg2bdu2zV6E4piXX35ZUiL1hLaAN7/oooskJYQyxDJ+hx6yYMGCFh6VVGpZWZk1EX4Sb5eVlbkgid+lAoqBVq5caS0GL4nYVV1d7ZQtY4yodvfddztWpn/j7AagR/C948eP67zzzpMUCaXMoxkzZvhzaD/oA3hkKdItUgXj1qNHD2tCPDMsIyMjw/MXNgsDrqiocFtnzpwpSfrrX//q9iHATp06VVKkvaxevdr3hgUgiJ46depD1x0UFxebYSev1PwwBGYQEBAgqZ2ZAdb4nHPOsbUDKKUHDhywJcdjo0zX1dU5pgIsXnnxxRf1+OOPS4pWty1atEhSQqnGg+AdUPl37txpL0waDmteXl5u/SHuVVoD3+/Ro4djaTQANIRZs2Z5cQ/t47lzcnJ0yy23SIoW29BfGzZs0H333SdJ+sMf/tCsD04H4uUDBw74+kuXLpUUeYy6ujrrEG2JM9EccnJynMYj9ocdxe+D1/zOd74jKaGfwNiIsfG2VVVVeuKJJyRFfYfOM23aNPcrK2FXrFjh//O7V199tdn3Bw0a5GeApaYK+v/YsWNmecxF2ExZWZnTflyf75111lnWktB/SIFfffXV9uIwHPpv4MCBznxRkEVhV1ZWlrMJfA9mmJeX10K/aA3tagwQOdLT0y168fAYir59+9oYbNiwQVI0iXJyctxoAB377W9/62txbXLD48aNsziIMEMeNyMjw6kvBDmEof3797tD21KzT1v69OljGoeQxOClpaWZEtKGeO0DabEnn3xSUrSe4JOf/KQn32c/+1lJ0Qt/OtGN9Optt93mlwKaSdpr+fLlprptqafgxe3YsWOLtQ2ELqtWrXL9BEaBeVBdXe30JgaNl/pnP/uZ23PJJZdIal65SB/zsjG+c+fOdVsQa0nFLV682FQ9npJOBTx7PA3IPCW3X11dbVEYo8qLOGbMGIe0n/vc55r11d69e50Spk8J77p06eLwgBoMUo1vvfWWDRIhMXUtmZmZDq9CajEgIKBNaFdmgIVuamqyV4Iy4bXq6upMNfGUiFF33XWXvSIe7Pe//72kBBvgmtB0/r9582bTLrwUVO/tt99uUQ0J1Rs7dqwpPD9TAcJaSUmJ28X9aNMVV1zhDUwICbDkr776arNnlxKFPVKCyUDpz1RZxn1hH++++66WL18uKWJAhEcFBQUWtRDfUgEsp2PHjvaWMC7QsWNHMzU2XomzO1KuFHUh+mVmZtqr8jtSx+vXr7eXZKwRLjMzM90veGmqMidOnNjmIi4Aw6usrHRRHIwVFpCbm2uWl1z9N3ToUAuGeOqbb75ZUsL7wxpgpYx/dXW1x5J+XLNmjaRE2BNf7cvvuA59CvtqDYEZBAQESGpnZkDK7uyzz7YF5XfEdzU1NbaEWFV2eonHeVhSvp+Xl+eVfhSW4EG/+tWvWoTB4hJrTZ482ZYeTwILqKystDXGi6YC7pGZmWndg2Kaa665RlJCV2BvAzwXotPZZ5/tIpRf//rXkqKCE9rYGvCmxNQrVqxwm/HMeOrf/OY3Wrx4saRoHD796U+3eg+8clFRkVd10nbGYPjw4Y7hEfZAY2Ojx+/FF1+UFLGNwsJC6wgXX3yxpGgMpk+f7s8TK5OakyLtBJGYZ9m/f7+FYMTUVIHHPn78eIsVifFVmfyb8cI79+vXzxoBhWSM0Sc+8QnPdeZ1fLcu2B39QdFRTk6O+5ZVo7Rr5cqVfo9SFb8DMwgICJDUzsyAeOass86yGoxKi+XdvXu3f4cHQ0l/99137d34/GWXXSYpkYXAulKQgnVeuXKlY/b4vn/cHyYAW2EF36BBg+z9zpS+SwaLZaZMmWKdhLbDNDZu3OjiFSw4XvWqq66yxjF//nxJqe+ngGchdicdNWfOnGZ79UlRtmbevHl+hnhKsDXQT927d/c10V3iKz9JzyYXFH3ve98zK2N8ZsyYISnhzdCT6DOwYsUKX5P+jWsVyQubtm7dKinRv8l7JqYK5lJ889fkHYs6d+5spkPREF58z549ZnUUi9G+/Pz8ZouwpCjOLygo8Dwhq/Dtb3/bz8Xf0JbIjPXt29fPkmoatV2NAR10/Phxp57oZAa1a9euzlnzcvPiDxo0yOIen0FISk9P90SETkJ5Dx061IJiMVk3b95sQQaRCDGsurraRiNVESZ+31deecXpTQYmLuLxLLyIrNPIz893+o2XpK2gXzB+K1eu9CSOb68mJUQ8nrktKTfGYOfOnQ5rqD3AgHfo0MFUHjCeixYtMlXG8MfPOCCfTn0BKcbi4mKHAOykTcglRS8nLyvOJTMz0wJp8u7FrSG+IzLXZZ7gRNLS0twnpB15ua+66ir/m/5HKI+DOcx13nnnHYveCI5xo0q/cU3Ckv79+7fYWrDVNqb0qYCAgP/1aFdmgGc6++yzTV3iHlpKFGLg/bHA1MuXlpaajiZ7sPT0dLMLUlIUDO3cudMpvY985COSIoudm5trD0nxCFa2vLy8hTdNBfHCD2gpBTPxDTGgunEqLyUY0ZlEH5gPNJPVcGlpaabIsCr6Yvjw4fY6UEnGoLi4WFdffbWktu1nwFhccsklZlUwPsKNyy67rEUKFJaWnp7u/oU5EWJt377dTJIxw1sOGzZM//Vf/yUposwItPFNPZgPeM+ioiJ787YCYa6mpsbXZRxIeV511VXNVilKEUtsaGhoto1eMhgb+o0+u+mmm8zumJ/xsAmBmP4j3Fi+fHmLrdVbQ2AGAQEBktqZGeCldu/ebatKjIjnPXz4cItDHxCALr/8cqeUSKlgbdPS0nwt4mXi89dff91CC5YbS19eXm5PBVsgpu3Ro8f/VWqRFGVFRYW1BpgPAuj06dNtxWFCsIHDhw97fT5xIp7m+eef18KFCyVFqVO8Q5cuXdxOvCHaw9/+9jczLDwsqwn79+/vop22HBaDgLh161aLtvQv90hOJ0pRTf64ceMczzPmsJUTJ044TQeTIQ6/9NJLHQ+jVcRXldIHaA141pMnTzq9l7w2pjVQ1JOVleVxgrnS1qqqKvcfz0V8v2PHDp8QlixeHjp0yPOL1aNcc+vWrda0YG233nqrpESfkVJMnp/Z2dm+D2ytNQRmEBAQIKmdmQGWvVu3bi0We+BBDx8+7PgPa4w+0NjY6L/hXfj++++/74IeClDY+6CysrLF6i68zSuvvNKsFFqK1OfKykr/jfumArx4VlaWPQUqNnsJlJaWWk0mtmNfg8GDB+sb3/iGJLXYKLO2ttar+egXrpmWluY4Hq9AH95yyy361re+1ezzMIU333zTXrgtzIB+jrM5Yl08/KpVq3TDDTc0+x4FYIWFhU4JElvDzvr27es5gQZAau6ll16yVsBYwSzr6+tb7FVAH0ycOLHFBrypguvX1dWZbcEMuP6qVas8lsyzeMqVwi7YIXMyvg8CLJg+GjJkiK/PeMHiNmzY4PkJu4wvhGM+J5eIfxja1RjQwNLSUr/EyamYrl27+mWis5kgK1asaHYIqxSlx4qLi11Rx4BTg9ChQwev9GKysjVWUVGRQ4H4eY98lhcu1Q6VIoq4du1aC0LxTS6kRA0Cm7aQYoTqLVu2zIIc1BBhcNy4cU65AV78uro6h2L8jlqCCRMm6J577pEUbRhL31166aVeLdiW8yGYlPX19X4pEat4YagbiINQoqioyNeAepM+jOfsGQ/StI899lizcySk6OXes2ePKzqpPKSfT5486XHgBUsVzNOTJ086Hc61aPvQoUP9N+YpYeybb77peczSfOb5+PHjPfbUlWActmzZ4h3AmfOkD48cOeLxpl6DdTb19fV+llTHNIQJAQEBktqZGSDoDBo0yJYcj0d6ZuzYsf43NBSvNXPmTHsEhKBnn33W3yN9BzMgbNi/f7+tKgINxS59+vSx8JhcWFRUVGQmwWdSQVyA5Pu0CfpcUFDQrEpPigpnNmzY4LAAhoAoOW3aNH3+85+XFAmycYqOp4yf8cdnENZoJ3s7LF261BT0dJ78w8BKx8LCQreZ+3Gy08iRIx0mIKbRlyNGjLDwiJgJgzt06JCfk5AA79zU1OR2wgIQyQ4ePOjiLT4TP+cAjw3bSBU8e1FRkYXb5JTd3r17PV6IljxX/KxLxG+eoWfPnp4XjBFh9Hnnned+YI8DCq2OHTvmv3EtCozS09P9LKTYW21jSp8KCAj4X492ZQaUpdbU1LQ4PAXvWFJSYiuHSEhsVl9f30KgWrBggaREXIjHwYrjHTt27KiHH35YUiQqEqNNmjTJcT0iEcwiOzvbz0X8mQrYViwrK8vPxMozvFZ9fX2LtfWkO5966imvfcdTxktq8W7oGMT+HTp0sBdMPt24oqLCpcLcB1YWX7nJBqykNs8Eip6OHTvmtuC9WXW3Zs0a/xtxjbH74he/aMEML8ZWZV/5ylesAXHN+JZo7OBEWx599FG3m7GFOTGuJ0+e9PzhPqkC7WX48OEt5gsiXlNTk/udMSGFeeWVV5olIOz95S9/kSQtXLjQv4MZxBkpcxcRGhbXqVOnFsVGMIXMzEyzy1RLzAMzCAgIkNTOzCC+TTnxPaW76AMHDhywqo/qShxaXFxsq89CFWLpHj16tIiXiel+97vfeU9BvAxKbllZma0w144vKCEGS3VTyfhnT5w44SwJz0TmYM2aNU6nJTOEs846S/PmzTvttWtqaswMYB3EhPX19VbqibPpp3feecdeNPnsw+PHj9vbpFq6Gv9sdna2PSEeFOTk5LhQjPQlz5GZmal/+7d/kxTpJd/97nf9NwCDoXCrrKzMO1wl7/+4evVqf5e/MYbdunVrocGkivjqVeYObYUhpKen+95kA9DGSkpKfG+YL7rCF77wBc9LngtN7LHHHjMTIdMSn6ewrOSCuSNHjpiJk3ZsDe1qDOL5ezqNCjUozfjx4532oU6dlzV+BiG0CuHp3HPP9ed++9vfSkqcpMRnMT4IibxIhw4d8osAVUbg2bRpk2kXVDAV8OIPGzbMA0G6kRdo3759LVbjpYJ4mih+Vp8kPfHEE06j0Z9UY/bp08dtx0D98pe/lJSYnPQnomIqIMQ7++yzfU0MHKnNLVu2WGjkBSHP3r17d58BwaRmfBsbGz3paR9Gtra21gYw+RyMoUOHOr2G8eBF6d69u+dLW1KoUuSsNm3a5HnJS80c2b9/f4uKWtpVWFjoezLPmAtz5sxxbQQiY7xqkrHhvlwnPT3dz4CQisHt2LFjmw+ZDWFCQECApHZmBniLPXv2tBC/8M4bN240jYTmIOKtWrXK23xTzYVl/NjHPmaKjMfj+506dTIlhkZRzJOVleXVcckboAwYMMDCYVv22ed6Bw8e9GrA5FN/161bZ0GIZ8OLd+rU6YyeC+8J/YWuVlZWeoPR5A1Famtr7ZHxsKT8du7c6T7/sBN6Tgf6d9OmTX5exhFPNWjQoBb181/60pckJZhF8mpQWEBDQ4PFRTaOjYcg0PbkfQPq6uo8xrAHCqA2bNhgJkG4liqYd3V1dQ4/EPu4d3V1tedJ8glhW7du9eeYe/RfSUmJn2v27NmSIsaTnp7uceb9oR/T0tLMWJMFyxMnTrR5O/jADAICAiS1MzMgfs7JyWlRc09M36tXL3sp0jTEYTU1NdYd8I54sqefftreKXnN+u7du1ukgRBsTp065ZRX8olKW7ZscWqvLbXs1157raSEB8ZS45WJY6urq62bIJrRtvz8fP8N78OZjUeOHHEb4jG/lBDmEKAouCL1dPToUW+RjtdBmD158qTjf+LSDxMw4yD2nTVrlouqVq9eLSnyVDt27HD/cr8HH3xQknTHHXfYgybrHz//+c99dibsjD5sbGy0l4wfYEIf4DnpewrM8vLyPI7Jh/G0Bjx+z549fU9ieebwqVOnrMvAXEkpDx8+3B4eDYU52dDQ4OchFUx/pKenm8nxO1j15MmTzUK5L+zjdKs4W0NgBgEBAZLamRmAESNG2AtjxbH+Y8eO9d/weKQahw4damsfXwAiJTwRin3yarLRo0c7/iR+jK9Px1snL5rq3LmzC5+SN+U8E9Au0tLSmpVZS5FH+shHPuKUEe3E4mdnZzsrwEpG+mDdunX2SKyPxwuXlpb63mgF6B9XX321Y1WeCeX63HPPtddGjU4F8eO7UMbxYrC5nj172iNScAXzu+eee6wx0E48aVVVlfcpTF5VevDgQSv4jDkesbKy0h4X1ohHzczMtOdty5mSUuT9+/XrZ0bEXGKxVX5+vucQz4XWMHDgQLeV/qdfOnfu7O8xJ+LnYPLMzEHaVV5e7jlDf9P/TU1NZsqp6kDtagygV8XFxQ4LAEahvr7eLyMvDp9du3atO4mfiDDl5eW+RvK+9mVlZabPpPP4f5cuXWw8+Dz327x5s+loW7Y9Iw31xhtvuI4d2shLvnbtWm8ayguL6FddXe36C8ALMWnSJA8uBhFqv3PnTqdF+Qwi0saNGz05qAiEYvbo0cMGsS3CGkYoIyPD98OoYJRKS0vdh/Q59D83N9epPr6PkS4rK/PLT9jG+GRkZNg4MnYYv6amJguWzAOeqV+/fu6zthoDQqzy8nJXRtIujFvXrl3trKDmtKuwsNApT17u+BhhTKmtwcAcOnTI/UZ/kzIsKyvzvVmhiFE8deqU75PqTtAhTAgICJDUzswAS11RUWFBBqsFVd65c6ctICIhXiB+Cg5hRZwKYU2pAccj7NixwyyDzUNhH1lZWf4bXiaersHCc61UQAqspqbG308+I7JDhw6mzdBtvEO/fv1s4REA8Zj19fX2/vQh3rxXr172Nqxwoy0jR440vWUc/r/2zjQ4y/J641cIEAihYTeGQsgAshQkrLKURakLWqUK1lKKFe0yTmk7wwyWVtvaoQtdpqUzVTtFrbVqpQK1WgrIomEtkSAgEnbZQtgCsgSSkJD/hze/63lJgLz5f0g/9L6+hCXv+zzPfd/POde5zrnvw+fOnj3r6yV6rLYUCYhNmjQxc+JZ8MDZ2dn+M/fC9bt37+65rVkR2LFjRzM9KHR852VYFNSbaxw7dszMDiYBLW/ZsqWvXd+io/jj5OKP6It/5pSUlFqHl8JgO3fu7PtANI0/2AfWwHxD+wsLC712CCEIDVJTUz1fjB9jnJycnHAnJRCYQUBAgCQpCe8bEBDwv43ADAICAiQFYxAQEFCNYAwCAgIkBWMQEBBQjWAMAgICJAVjEBAQUI1gDAICAiQFYxAQEFCNYAwCAgIkBWMQEBBQjWAMAgICJAVjEBAQUI1gDAICAiQFYxAQEFCNYAwCAgIkBWMQEBBQjWAMAgICJAVjEBAQUI1gDAICAiQFYxAQEFCNYAwCAgIkNXDfhAcffLBKirWe4kx32mfTdr1Zs2a1Gk3GnxtPhyBaTXFmfXl5uc/Vp+8CnXiOHz/uvgP0SKAJbGZmpht61mzd1rp1a98X3X1mzZqVVNdz/uQnP6mSYufi0yeB56Wb0dmzZ91YlvvlnkpKSvzs/OQc/fXr17utF+fw5+TkSIr1XajZ34G25Hv27FGvXr2uuA69Epo3b+7uSvQVmDt3bp3P+eyzz1ZJsfFasWKFJPn8f8a5adOm7olBqzHGtGnTpu5/Qf8DekLs27fP/8cz0evg1KlTHtea3ZrOnTvnbk70F4hv2Mp3MJ5z5syp8zklacOGDVWStHLlSvfloO383XffLUmaNWuWBg4cKCnqVsX6PH78uBvy0hshfp1yj6tXr5YUdRgrLi72uqZhK/1DXnjhBa8P2tKxTjMyMjRy5EhJ0bhPnz79us8amEFAQICkBmYGWNQbb7zRVp8GlXS/SUpKshfF2mOBu3Tp4g4yWFcsfadOnfz9NZt4ZmZm2hPQzQamcOjQIXuqXbt2SYpautMV5rut/QAAHcZJREFUR4rawycC+t41adLE1+UZRowYIUnauXOnOyLRHQgPWlpaasZEFx283WOPPeYxoHsSDVS7dOniPoBz586VJI0dO1ZSrMfjqFGjJEWdkLinY8eO2YMl2pdPivoBZmZmmhHA2GgpX1JS4r6G3DfPXVZWZu9NT0o6LLVr185rhO+kx0fLli29bvCEXKOiosLsi/E5deqUpFi3ITwuv5MoaMC7f/9+9+ucOnWqJGnhwoWSYgyBdQLLpO/mxo0bNW/ePElRVy+a8c6fP9/drWBtjMvs2bO9Bv785z9Liub71ltvVW5urqSoFyRdmvr166cFCxZIkue9LjSoMWBSioqKTP1pWwUV6tSpk6ktE8ACPXLkiCefF5+uwenp6X6JeeHoOlxRUeEXvWZ4kpKS4jZnGB/ChI8//thUmsWaCDBQjRo18gtwzz33SIraX7Vr187PDjUcOnSopFibNxYt9JGQYOXKlQ6juLfPfe5zkmLGi8XAWHAv27dvNxVnHvj74cOH3VquPg1muQbzJUW0mPnZt2+f28ZhiFnoGRkZvh7zAgXevXu3DSDzwnV27NjhF52fGJHKykobY8aXl2/16tU2uPV5Tilqbjtx4kSPFffHy5mammonxTzwwufk5PhFB++++66kWAs6jCnGA4Pz4osvul3c7bffLilqi/fUU095DnlW5vbnP/+5w0eMwle+8pXrPmMIEwICAiQ1MDOIb2IKVdy5c6ekmLgjxcIEaCEWGCGwsLDQlJ6GlohL48aNs+eAAm7dulVSzJNgQfGU0OlNmzbZetOWfNy4cZJi7c+hYbCMRAB97tKli4W0bdu2SZI+//nPS4pRXZqj4umXLVsmKdaiG09Rs838Zz/7Wd8n1BjW07dvX3vh+KazUsxTc1+wIqh2Zmamxw7PmQj47uLiYocjUFrCvuLiYgue/D7ePC0trVbowH20atXK34mHQwjr2rWrmRJzzO+cPHnSlJmwAqY3YcIE3x/CW6JAfC0rKzM7feeddyRJ3/3udyXFvDJrl/CQe3jnnXe8hmo2jS0pKTFTJsSF6UydOtUhV35+vqRoDU+dOlVvv/22pKg5LSx68uTJHiPWYF0IzCAgIEBSAzMD0K1bN8db9913n6TIKxYVFVncwzsSZ5eWljoenDBhgqTII8RbeqwxsWm7du0cr2GBEXo2btxoz0wM/Lvf/c5/J2YfPXp0ws8H0ygrK/N10RzeeOMNSTHPiYcm5QQLKCwstPefPHmypFjsyFiQXuUZYEJHjx41g2CcYFCtWrWyNoGmwuezsrKUlZUlKdJpEsEtt9wiKeaxEftgeOgwqamp9mTcN/F0hw4ddOedd0qKPBrs8ezZs9aR/v3vf0uK9JMHHnjAXhKGx1yfO3fO38+48JxpaWn2slu2bEn4OaVIszl06JAWL14sKSbgSRFzfeWVV/TlL3/5inH4zW9+I0m6//77fa/E9TDDwYMHa+LEiZKitffTn/5UkvT222+bIffv319SxFL/85//+B2JZ02SNGbMGC1fvlxSxFLqQmAGAQEBkhqYGRBr7dixw7EiMSKeqUePHvYqFHD85S9/kRRTWnv27CkpipHwFpL097//XZJsEYlbGzVqZLWatBrK7BNPPGEmQuxNccfp06fNJLDixIfXA16uRYsWjmmx7qBVq1aOHRctWiQpUokzMzMd561cuVJSlCZFpZek4cOHS5JWrVolSRo/frwZATEnGsvx48d9PZgQyvW2bdvMrOqTWsTjZmdne1xrpvo6d+7sDAMshZTt6NGjHd8zPtxbRkaG5w8Gxb29/PLLvncYJppDkyZN/J3cEwympKTEnhSGUN9npShKilgMzKVVq1Z65ZVXJEWs9otf/KKkmObAs8EQpk+fXus6v/jFL674e05Ojv7xj39IiuabYqWWLVuagZCp4fqNGzc2g3nkkUcSesYGNQYs9vLycj8EA8RkFhcX6+abb5YUCSZQyczMTC8MqDgLhomRIoEKcfKxxx4z/YV6Hj582J9jIbJISUV98MEHDkOg7YkAwzNq1CjTS54JIXHo0KGme6QGuY8hQ4Z4wpcsWXLFfRcVFTlEghqTv160aJEFJb6LVN3mzZtNa0nVYZBvu+02Gx1e3ESAIHjXXXfZCAEobefOnX3vGAjGtHfv3g4hridy1ayqnDZtmv/MenjqqackxRwIxh3Rj3V04cIF5/8Zg0RBKnLt2rW6//77r7g2QuDAgQP13HPPSVKtmo7NmzdrypQpdT7r1cD1CH8xbkVFRRZHMRiMzfnz5+24/vnPf0qK6iKuhRAmBAQESGpgZkBqq0+fPqZ8FFcg9jRt2tR13Xg3aH96eroefPBBSVGqDc9SUFDgVM8LL7wgKbKEmZmZLgwZNmyYpKhgJzk52cIdXoP0XFZWlv8MA0kECJ65ubn2TlwfT/3hhx+aqsJqEKK2bNli4RHhkt9du3atxwAGRFhz99132+uSzoP+T5482UwJRgDWr19vkQl6mwig/evXr/fnoO0wr+XLl9tzMhawpMrKymuO6+XLl+0JCdWu9ruwhqVLl0qKVeLBMtesWSMpCgm3bNniEAKvnihgjdOmTbMQize+6667/P0wIpgHa6Fjx4724ozNunXrJMXCO+a35jPG/50/E/rl5OTozTfflCR961vfkhQJzX369DHL+8IXvpDQMwZmEBAQIKmBmQFeqrCw0FaSnVV4mT179vj/8Pqkwj744ANbVbwocejmzZv9+8RY/N+jjz7q1B5eg9g9OzvbzIAiHDxZWlqaS0bxTongtttukxSL6Uj54IkQSvfs2WMRlBJWRLGDBw9qw4YNkqJ4D+3g2LFjjo9rMoOsrCwLeIwFuHz5sr0I3gvP0aFDB8f8FOUkAkS19u3bm+nBaNAnMjMz7UnxyrDBrKws60EwMNjZSy+9ZLH40UcflXR10Q/2gNhcUFDgdQY7Qu8pKSnxmMeXUCcCxvPdd9+1kFeT8SxdutRjwr0///zzvj+0qPHjx0uS04mLFi2y/gLDQkhcv359LY0BvS03N9eaFGuB78zPz/f8JiqWBmYQEBAgqYGZAdZyy5Yt9tp4Aqzs5cuX7SmJr7GW/fv3d7xM/IQnat26dS2rTIHPxIkTXeiB2o73Tk1NtffGuuLlFi9erL59+0qKPFAiKCgokBSLn8kKENuy82zw4MGOr9ExYAGlpaW+ly996UuSpD/+8Y+SYiwJVkR2hu+5cOGCx47Ykc1PW7du9T2wWzE+vRtfnJQomJeioiKPGZ735ZdflhRLxeGZ0Czw2Onp6U6vUQbNnLVv395FStfzbN/+9rclRcyyoqLCDITCItZRenq6swIwqETBmiouLjZzxZvn5eVJijEdznWA2aH5NGrUyLoMmhabnzZu3FirJB6WWpPhSRHLfPHFFz0H7FJFe0tOTvbmuL/97W+SolL4a6FBjQF5/DvuuMNVYqThEHt69erliUUoiU93sUAQdMjjb9682RScyeeFSklJ8YJilyM/Fy9e7El6//33JUWCU05OTq2DKOqDnJwcPzM5fl7uffv2OXSBRhMCNW7c2JVkNSsne/fu7cXAwiGEaNSokcVXnglK3qVLF1cJsoDiDzvhRa2PgMhi7tKli78LoxkfAjGGLE7qRjp37uyXhu9C7OrZs6eefPLJOu+Bl3rfvn2SYi8RdSrcAwbuzJkzNhD1SaFK0Tj26dNHb731lqTIgTGPq1atspiIcfvrX/8qKZbrRxCn2pawYezYsTYoVKOylkm9x+MPf/iDv5swljoDxOjt27e7/oS1VxdCmBAQECDpv1R0dPToUVswBBBw/PhxVxVC+7H0gwcPtnhCdRUHS+zZs6dWhR20eO3atfZcFOjgkVq3bu00I2yF6+7fv9+Moj4CIt7q6NGj9njsSUe46ty5s70NdJPx6dWrl4VO6GN8WMPvw6rwNOPGjbNwx++Q0szJyfG/wUBAXl6eU5Kk6L7//e/X+Zw8y6lTpyzIMp943gEDBng8Kfz68Y9/LCkWTlHsRFUen6dy72rYu3evi2vwynjZvXv3WkCEPcLO2rZt63Gtz+5MPivFCoZgHIiujOeAAQMs0nL/7DFYs2aNq1hfffVVSZHw+4Mf/MDFSTwXdL+qqsohMeuTisLdu3d7DSEyIg7fcsstTuEmut8kMIOAgABJ/yVmUFBQ4KIMYlti3dLSUsdWFBYh+syYMcNeH2EMa9u3b1+zBvaUx5eC4jEfeOABSVGd95o1a/w57gEv0LJlS5fS1ifGxEsOGTLEjID0JUJmcnKyY05YB1pASUmJvvGNb0iK4t34k3nYn8B4ciDnkSNHHGcjzBJLHjx40MIXPxFxL1265D8zLokAb7Rr1y4LXjAM5mnnzp3eV8EzPPHEE5Kk3//+95o/f76kSHAkjfiZz3zmmgVJ3bp10w9/+ENfO/5ZMjMzzS5gOU8//bSkmFDHfJLeSxQIlQsWLPB3wErw8LNmzdKkSZMkRalSPPXSpUutmZBOpyhu+fLl/n2+m7UwbNgwMzBYDT9PnDhhsZT55gyIOXPmWFuABT3++OPXfcbADAICAiQ1MDMgvrnhhhucKcAi4h0rKyvtzX75y19KiuKutm3b2kpi/fEIa9ascZyFEjtz5kxJsTQk3hQP/81vflNS7DBKNpUQdxJbZ2RkWL8gM5EISBXeeOON9v7Exlj1fv361dpVByM5ePCgfx9Lj0qfkpJS6/QjPG7Xrl01e/ZsSVHRCpuZSktLnR4jAwMTys7ONlu4mnp9LTBno0eP9p8ZX34ePnzYXphn+PWvfy0pljHA+//2t7+t83owuOXLl7tAix2feNTNmzdbSyEDRJaosrLSrLGmVlUXXnvtNUkxXQZvTGoWdpKdne2Se66NNpaenq5Zs2ZJim2ck+S09ZIlS5xFIJMWXxQFU2atk77s1KlTrfMrYAj33nuvT+wi1V0XGtQYIMalp6ebLjMpvCQpKSkWPHg5mOiLFy/6O0i98fm+fft6sKDWLL7z5897cBEVodPNmze/YsejFFH5iooKL2pe3ETAYrx06ZLTeRgoqH1xcbG3GVM1Rv4/OTnZh1jW3GW3ZMmSWufnjxkzRlJsfKGE0HXGJz093d/FYqZuvnnz5t7pd7W89rWA0T579qxfAsYeEbV///6eT4wYBnLQoEEJHT9Wc4/C2LFj/W8Yyw8//FBSbLcg1yalyboYNWqU07jMcaJg3l599VULzjwPNRbHjh3THXfcISna6vyrX/1KkvTmm2/agBFeYahnzpxpw0IFaPxWa76f+eO6ubm5FjNZCxiFhQsXep2wHutCCBMCAgIkNTAzgNJ8/PHH9sZYS7x/hw4d7L2hRxTenDp1ytVUNYXA0tJSfwe0CI9ZVFTk60GRYRYjR470fndSMaTjLl68aI9ec6ff9QD9W758uYVOPDT3WF5ebq+G5+TepIj6szMOj924cWMLcOxXR2waP368aT7Xg10VFhaaffFd/Pzoo4/sffA6iSD+0FVCNMINrn/DDTfYq3J+A+nWZ555xlQWehwfpsDmYATxO/sIL3g+1lbbtm1djMW4EOJt3brVbAx2kigo7mnbtq0LtEhlI5C+//77HgfYyEMPPVTr2oQJzP/GjRu9xvlJSJScnGwGB9tDdE9KSjLD4d+4z0OHDtU6OKYuBGYQEBAgqYGZAaJh48aNbfmIZ/DAw4cPd7qQ1A1C17x582yNia34+4YNGyxU1fQM69ats9clPkdISk5OtmWnZpxy5PPnzzum5f4SAbH/yJEjrRng1eL7KuKF8dikoRYsWOB7oOiImDwvL8+shhJunqmystLjivfCK5aUlLgEG32Ace3evbtjzfoU43Csd5s2bTzWMCjmeu3atWYQeHi82cSJE72nnxp+mN+JEycseDKGMKEmTZpYm+A7Ga+8vDyzBMRpxqRZs2b+XH3KrvmsFCt7rlkuT9HX7NmzzWYQ+ZjvsWPHOm3K/hoE9dWrV7vo6qtf/eoVn58+fbpThKSQWQtz5851ARLlzOz7SEtL85wmeix8YAYBAQGSGpgZ4I3PnDlj70ZsTIz50ksvXXGSixSVYfbv39+lyVhcLOpNN93kWB0dgV2AZ8+e1de//nVJUZknMeeIESPMJPCceOry8vL/19HaeJEVK1b4+UhbEjd27tzZhTo19YwJEyZYv2C3It70yJEjfnZKXuNZFh6awpZnn31WUsxjcBIUBVhkSvLz8329+mgGzGHz5s1rHWJL+feGDRvstUjZooDPmzfP7O9f//rXFfc7Y8YMrwlYGTsaKciSap/+s2nTplodmuM7fMc3d6kPeNaUlBTrFJQhM3YnT568YkemdGWLN9K+fBfaSXl5uZkAWsaMGTP8fw8//LCkiPGyTu68806zPBgS93Ty5EkzbNhlXWhQY0B67tSpU06vsPhYxIMGDbKIAuVisT/++OOuOSCXj+AULzxRG8DLsmvXLi/OmsjNzTWdRPQhBGnTpo0XZKIDKkW0bOjQoRZ2mECMw9ChQ03J+cl95Ofne6FwWCr/N2rUKP8bxoRQq6CgwAIeIQDjVFVV5R4V0EdSZL179651XFki4DOZmZlOM/ICkhrt2LGjhdyazVkLCwv9ssQf1yXFKDQvLt/N2MXT3pp9Grp37+5nIBWHcU5JSbkibVwf8B3xvTt4AVmvN910k++NugEo/s9+9jPvaOSwHr4zLy/PNQiESRjOnj172iFRK0O4NHDgQBsf6lJYS+PGjfO9sHbqQggTAgICJDUwM4De9uvXz9SftAfWdsCAARahKNzAg1VVVdl7k26BPVytjh0PhEAYDzrdJCUl2cJzPQTAZs2a+b7q40kIBfr3729GACXHcp87d86ejueLDxvY6YflJyX56U9/2s8KbcRDHzhwwB4FakwxysmTJ2u1eY8vxOI69XlOxLjc3Fwf3464Bf1v166d99XDBvHcHTp0cLEQVBixsLCw0PeHSExBjxQVIjEGfOfFixddoAW7Iixp2bKlD7eBqicKmFZ8ERWsBhYQf6Q7907YVF5e7jQ6wi9h8NChQ81i6ZTM7tr09HSPG6EUh5Q88sgjFi+5Hqxh1apVZt0UPtWFwAwCAgIkNTAzQJj76KOP7NkR7WAKR48eNVtgbzhllcOGDbPA8qc//UlS5P2nTZt23ePM8XiUo8IwGjdu7OvVTAN+8skn3reAZ04EpPPy8vL8OQpA8Mp79+71v+G9se4DBgyw4EhMTLxdVlZmT4vYRlpu586djp0p5gGlpaUWzfC08cUoFFrBEBJBfOoP3YJnQsNJSkryn9FySM2tXLnSJxR97WtfkxQVYD355JP2tBRuxc8vZxWwDhjz+B2Y7BKM7/vIPcPGEgWFbK1btzYbQZRmnY4ZM+aK3aVStHbPnDljAZHOX7C44cOHW+vhGRGAd+/ebQaCcInukZeXZ1bIfMNE27Rp43lGt5gzZ851nzEwg4CAAEkNzAywcCUlJT65h6OkUbpJsUjR6UBY4k996lPWHbCSWNmnn37aHXApOiFO37Rpk60w/0ZRTnl5uYt9OBgVzeLEiRNmLol2spUiD3/hwgV7J1JAZFRuvfVWx9doFVc7vhsvB7PZuHGjy3ux9OxQ3L9/v7s24zHwaGlpaY6z0Q4oVlqwYIHTd/VJoaJS33fffY5nicU5SSonJ8epXjQRVP5NmzZ5ZykeG2/Wp0+fK8pu41FWVmaGBZNg7g8cOOCxIpUKC1i5cqWzFfXNJhD7L1u2zHoMrIaYfv/+/dfMOsUfqMu14xvdwJrjj6/n2dnRyRqiFP+ZZ57xd7DmYQjLli0zE0v0WPgGNQYsuObNm3sgSTvxkmdkZJhqQrEZyFatWvlzDBov63vvveeDKukuw9bV1q1be+EyyGwbjq9Yg+JhaNq1a+cXFgEpEWD0evbs6YNOEI+g+KmpqW7YyQvLgnj++ecteiEssRPvnnvucYcphE/+PnPmTIcVHAfH+B45csThD5SUisu+ffu6FuBaKdirge+ZP3++qTxhGGFNVVWVx5DKOzB69Gin5WqGBFcDocFrr73m+aDvAns4evToYQGRlxQRuFu3blfUedQH7F8ZNGhQrRCDe3nrrbds8Gr2h4wHKT+MihQZfV5c/v6jH/3IAiVpbj4/adIkPxvvCgJknz59HBZSuVgXQpgQEBAgqYGZAamOw4cPm05CAdnbnZWV5ZQQwhjUtVmzZvaGpP/idwHCPBBY8NAjRoyw10ck5HNt27a1d8Kj8PkWLVrYW9cnTCDM2Lx5s4UtDnAlPNq+fbutOkyE5xw1apSfjyO7vvOd70iK7dtHbOXzhCL5+fkuZMHDExKkpKTYo0E38V4HDhxwQUyie9/jP5+amuqwhDHEQx46dMjhHp493iMiANdEaWmp2R9iM+nLhx9+2PfJM8GAtm/fbgYEm0LALCkpccVqfZ5TilhQXl6eQxt2YfKsixcv9n4DqiWv9XzxqKqqcujAGMEgq6qqzC75LoTfTZs2eecj65OQrKSkxO9RfBv56yEwg4CAAEkNzAyw8Pfee6/THew2w5vu2LHDBSvE+cTPn3zyiT0tzAJPmJGRYU8C24CJnDhxwrE0XgMm0r9/fxesEOdindPS0uz98HyJAAs+YsQIF5iQKkI8O3bs2BXHYUvR/vZVq1Y5tYgmQqOU8vJy3x9eGMR7O+6Bcdq+fbtjSMqZee7Vq1e7AKY+JwAh3vXo0cPPRczPQaeTJk1yARWelHRtvLBFMdBzzz0nKabXcE/MMbpLUVGR5xqWg7Zy8uRJ7xWgNj++UxbeEjaWKDhMtGnTpo7ZYVOvv/66pBjrY40zxhS8NWnSxCwNYQ/RtEOHDv4/yopZr5cvX6512hWM8MiRI2YJ6DIwpG3btjllzf1xT9dCYAYBAQGSGpgZoO4fOHDAsR7xENa7R48e9pSo7MRk8R12UViJ5S5cuGB2UdNjrl271l4GFZnCl8OHD9uLcrAlbOW9995zKrA+G5XwDvn5+Vav0T8oH50yZYp1BNgKXquiosJaBaoyqbPdu3eb8aAxkBotKyuzhyFOJKXapk0bX4d7iG/hlZubKyliYYkALSApKcnMiTmA3b3xxhsuW67ZXqy0tNSsgRJb5rWgoMC/z3ziSY8ePVrr4FBi9NGjR1sr4nkZy6qqKjMC5ihRcJ2CggJnb2AjfH+LFi3s9Tlbg/WTlpbmXbUc4c66njdvnr1/zSK38vJyvw/cO9d/6KGH/P0wR9bwzTffbH0qUc2gQY0BkztkyBALgdTqk5Lq2rWrU4uIIiymZs2aeQGyy43z85cuXWrqD8UiHx+/+5A8Nr976dKlWoeoQKuys7MtdrFoEwF09ty5c1e0z5YiQ/P666+bUkOfec7k5GTTeyYXSp6dne3wCRrIwm7fvr2ND6IoNLpp06b+fQwqCy4rK8tGldAlETBezZo18wvBfTKH7du3d+qW+WQ/QteuXX0P/Bv0//Llyw57EExxIE2aNHGKGeOOSLhw4UIvfp6J8SkoKLABrM9p11IUJhYXF7smBrEQan7gwAE/I0aZtVVRUeE1xPrAUI8ePbrWgbKs3eTkZP+ZueXYu9OnT3uMvve970mKUqzp6el2tIke5BLChICAAEkNzAw4VEOKvBNUF2teVVVl74J3w/r36dPHFnfKlCmSonPzW7VqZa/Pd+Nl1q1bZ6/Cd0H7Ll68aNEGqxxfEQhtvl5b8JrA4qenp5vJQJ/5v5ycHN8nHpuQoLKy0iIo/4fnLSsrsxhJxSSC4r59+0wNqcxEiDx9+nQt8Sy+1h16S7VnIsAjlpSU2PvCRPD0gwYN8nzCDEl/HT16tFbrcbx5amqq96HggZmfkydPejwYV4Tetm3buqCMI9V4tj179pix1LcLc3wnLK6JV2bvw5IlSywYEpZy7z169DC7YJ65lxUrVji1yPkTrPPbb7/d4TUCMOu1TZs2V4QaUpR+Xbp0qXd5JlptGZhBQECAJCkpvmY6ICDgfxeBGQQEBEgKxiAgIKAawRgEBARICsYgICCgGsEYBAQESArGICAgoBrBGAQEBEgKxiAgIKAawRgEBARICsYgICCgGsEYBAQESArGICAgoBrBGAQEBEgKxiAgIKAawRgEBARICsYgICCgGsEYBAQESArGICAgoBrBGAQEBEgKxiAgIKAawRgEBARICsYgICCgGsEYBAQESJL+D8PW6PtkkBT3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x360 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(4,5))\n",
    "for i in range(16):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plt.imshow(gen_imgs.data[i].squeeze().cpu().detach(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.savefig('../result/GAN/1-GAN/3-fake-images.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-4. Model save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'epoch': num_epochs,\n",
    "    'model_G_state_dict': generator.state_dict(),\n",
    "    'model_D_state_dict': discriminator.state_dict(),\n",
    "    'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "    'optimizer_D_state_dict': optimizer_D.state_dict()\n",
    "}, '../result/GAN/1-GAN/model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization (Interpolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z_opposites = random_sample_z_space(2)\n",
    "fake_img = generator(z_opposites)\n",
    "\n",
    "plt.subplot(121); plt.imshow(fake_img[0].squeeze().cpu().detach(), cmap='gray')\n",
    "plt.subplot(122); plt.imshow(fake_img[1].squeeze().cpu().detach(), cmap='gray')\n",
    "\n",
    "plt.savefig('../result/GAN/1-GAN/5-side-images.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x144 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_interpolation = 10\n",
    "\n",
    "z_interpolation = Variable(Tensor(np.linspace(z_opposites[0].cpu(), z_opposites[1].cpu(), num_interpolation)))\n",
    "fake_img = generator(z_interpolation)\n",
    "\n",
    "plt.figure(figsize=(12,2))\n",
    "for i in range(num_interpolation):\n",
    "    plt.subplot(1,num_interpolation,i+1)\n",
    "    plt.imshow(fake_img[i].squeeze().cpu().detach(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.savefig('../result/GAN/1-GAN/6-interpolation.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch35",
   "language": "python",
   "name": "torch35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
